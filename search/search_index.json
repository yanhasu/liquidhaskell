{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LiquidHaskell (LH) refines Haskell's types with logical predicates that let you enforce important properties at compile time. Guarantee Functions are Total \u00b6 LH warns you that head is not total as it is missing the case for [] and checks that it is total on NonEmpty lists. (more...) The input contract propagates to uses of head which are verified by ensuring the arguments are NonEmpty . Keep Pointers Within Bounds \u00b6 LH lets you avoid off-by-one errors that can lead to crashes or buffer overflows. (more...) Dependent contracts let you specify, e.g. that dotProduct requires equal-sized vectors. Avoid Infinite Loops \u00b6 LH checks that functions terminate and so warns about the infinite recursion due to the missing case in fib . (more...) Metrics let you check that recursive functions over complex data types terminate. Enforce Correctness Properties \u00b6 Write correctness requirements, for example a list is ordered, as refinements. LH makes illegal values be unrepresentable . (more...) LH automatically points out logic bugs, and proves that functions return correct outputs for all inputs . Prove Laws by Writing Code \u00b6 Specify laws , e.g. that the append function ++ is associative, as Haskell functions. Verify laws via equational proofs that are plain Haskell functions. Induction is simply recursion, and case-splitting is just pattern-matching. Get Started \u00b6 The easiest way to try LiquidHaskell is online, in your browser . This environment is ideal for quick experiments or following one of the tutorials: The Official Tutorial (long but complete) (has interactive exercises) Andres Loeh's Tutorial (concise but incomplete) For links to more documentation, see the nav-bar at the top of this page. Get Involved \u00b6 If you are interested in contributing to LH and its ecosystem, that's great! We have more information on our GitHub repository .","title":""},{"location":"#guarantee-functions-are-total","text":"LH warns you that head is not total as it is missing the case for [] and checks that it is total on NonEmpty lists. (more...) The input contract propagates to uses of head which are verified by ensuring the arguments are NonEmpty .","title":"Guarantee Functions are Total"},{"location":"#keep-pointers-within-bounds","text":"LH lets you avoid off-by-one errors that can lead to crashes or buffer overflows. (more...) Dependent contracts let you specify, e.g. that dotProduct requires equal-sized vectors.","title":"Keep Pointers Within Bounds"},{"location":"#avoid-infinite-loops","text":"LH checks that functions terminate and so warns about the infinite recursion due to the missing case in fib . (more...) Metrics let you check that recursive functions over complex data types terminate.","title":"Avoid Infinite Loops"},{"location":"#enforce-correctness-properties","text":"Write correctness requirements, for example a list is ordered, as refinements. LH makes illegal values be unrepresentable . (more...) LH automatically points out logic bugs, and proves that functions return correct outputs for all inputs .","title":"Enforce Correctness Properties"},{"location":"#prove-laws-by-writing-code","text":"Specify laws , e.g. that the append function ++ is associative, as Haskell functions. Verify laws via equational proofs that are plain Haskell functions. Induction is simply recursion, and case-splitting is just pattern-matching.","title":"Prove Laws by Writing Code"},{"location":"#get-started","text":"The easiest way to try LiquidHaskell is online, in your browser . This environment is ideal for quick experiments or following one of the tutorials: The Official Tutorial (long but complete) (has interactive exercises) Andres Loeh's Tutorial (concise but incomplete) For links to more documentation, see the nav-bar at the top of this page.","title":"Get Started"},{"location":"#get-involved","text":"If you are interested in contributing to LH and its ecosystem, that's great! We have more information on our GitHub repository .","title":"Get Involved"},{"location":"install/","text":"How to Install \u00b6 This sections documents how to install LH and its dependencies. External Software Requirements \u00b6 In order to use LiquidHaskell, you will need a SMT solver installed on your system. Download and install at least one of: Z3 or Microsoft official binary CVC4 MathSat Note: The SMT solver binary should be on your PATH ; LiquidHaskell will execute it as a child process. Installing LiquidHaskell \u00b6 LiquidHaskell itself is installed&enabled by adding it as a dependency in your project's .cabal file. Just add liquidhaskell and liquid-base to the build-depends section of your .cabal file, as you would any other dependency. This causes stack (or cabal ) to automatically: Install LiquidHaskell Tell GHC to use LH during compilation Display liquid type errors during compilation Integrate LH with ghci , ghcid and all GHC compatible tooling for your favorite editor. Examples \u00b6 The following concrete examples show the LiquidHaskell plugin in action: Example Project 1 Example Project 2 (uses Example Project 1 as a dependency) You can use the .cabal , stack.yaml and cabal.project files in the sample packages to see how to write the equivalent files for your own codebase. Liquid Dependencies \u00b6 If you project depends on some well known library package foo (e.g. base or containers ), then it's likely that the LiquidHaksell developers have annotated it with Liquid Types. You can use these annotations by adding the liquid-foo package to your build-depends . Editor Integration \u00b6 Since LiquidHaskell is implemented as a GHC plugin, you get to automatically reuse all ghc -based support for your editor as is. The sample packages include examples for vscode , vim and emacs . Uninstallation \u00b6 Just remove the liquid packages from your build-depends again, and GHC won't use LiquidHaskell anymore. You may also want to delete the .liquid directories placed alongside your source files (they contain debug information). Other Options \u00b6 Online Demo : For small projects without a .cabal file, you can paste your code into the online demo . Legacy Executable : A stanadalone executable is also provided, although it is deprecated and will be removed in the future.","title":"<i aria-hidden=true class='mdi mdi-download'></i> Installation"},{"location":"install/#how-to-install","text":"This sections documents how to install LH and its dependencies.","title":"How to Install"},{"location":"install/#external-software-requirements","text":"In order to use LiquidHaskell, you will need a SMT solver installed on your system. Download and install at least one of: Z3 or Microsoft official binary CVC4 MathSat Note: The SMT solver binary should be on your PATH ; LiquidHaskell will execute it as a child process.","title":"External Software Requirements"},{"location":"install/#installing-liquidhaskell","text":"LiquidHaskell itself is installed&enabled by adding it as a dependency in your project's .cabal file. Just add liquidhaskell and liquid-base to the build-depends section of your .cabal file, as you would any other dependency. This causes stack (or cabal ) to automatically: Install LiquidHaskell Tell GHC to use LH during compilation Display liquid type errors during compilation Integrate LH with ghci , ghcid and all GHC compatible tooling for your favorite editor.","title":"Installing LiquidHaskell"},{"location":"install/#examples","text":"The following concrete examples show the LiquidHaskell plugin in action: Example Project 1 Example Project 2 (uses Example Project 1 as a dependency) You can use the .cabal , stack.yaml and cabal.project files in the sample packages to see how to write the equivalent files for your own codebase.","title":"Examples"},{"location":"install/#liquid-dependencies","text":"If you project depends on some well known library package foo (e.g. base or containers ), then it's likely that the LiquidHaksell developers have annotated it with Liquid Types. You can use these annotations by adding the liquid-foo package to your build-depends .","title":"Liquid Dependencies"},{"location":"install/#editor-integration","text":"Since LiquidHaskell is implemented as a GHC plugin, you get to automatically reuse all ghc -based support for your editor as is. The sample packages include examples for vscode , vim and emacs .","title":"Editor Integration"},{"location":"install/#uninstallation","text":"Just remove the liquid packages from your build-depends again, and GHC won't use LiquidHaskell anymore. You may also want to delete the .liquid directories placed alongside your source files (they contain debug information).","title":"Uninstallation"},{"location":"install/#other-options","text":"Online Demo : For small projects without a .cabal file, you can paste your code into the online demo . Legacy Executable : A stanadalone executable is also provided, although it is deprecated and will be removed in the future.","title":"Other Options"},{"location":"legacy/","text":"Installing the Legacy LiquidHaskell Executable \u00b6 We strongly recommend that you use the GHC Plugin available in version 0.8.10 onwards, as the legacy executable is deprecated and has been kept around for backwards compatibility. It will eventually be removed from future LH releases. External software requirements \u00b6 Make sure all the required external software software is installed before proceeding. Installation options \u00b6 You can install the liquid binary via package manager or source. Via Package Manager \u00b6 Simply do: cabal install liquidhaskell We are working to put liquid on stackage . You can designate a specific version of LiquidHaskell to ensure that the correct GHC version is in the environment. For example: cabal install liquidhaskell-0.8.10.1 Build from Source \u00b6 If you want the most recent version, you can build from source as follows, either using stack (recommended) or cabal . In either case: recursively clone the repo: git clone --recursive https://github.com/ucsd-progsys/liquidhaskell.git Go inside the liquidhaskell directory: cd liquidhaskell Build the package: a. with stack : stack install liquidhaskell b. or with cabal : cabal v2-build liquidhaskell Running in GHCi \u00b6 To run inside ghci e.g. when developing do: $ stack ghci liquidhaskell ghci> :m +Language.Haskell.Liquid.Liquid ghci> liquid [\"tests/pos/Abs.hs\"]","title":"Installing the Legacy LiquidHaskell Executable"},{"location":"legacy/#installing-the-legacy-liquidhaskell-executable","text":"We strongly recommend that you use the GHC Plugin available in version 0.8.10 onwards, as the legacy executable is deprecated and has been kept around for backwards compatibility. It will eventually be removed from future LH releases.","title":"Installing the Legacy LiquidHaskell Executable"},{"location":"legacy/#external-software-requirements","text":"Make sure all the required external software software is installed before proceeding.","title":"External software requirements"},{"location":"legacy/#installation-options","text":"You can install the liquid binary via package manager or source.","title":"Installation options"},{"location":"legacy/#via-package-manager","text":"Simply do: cabal install liquidhaskell We are working to put liquid on stackage . You can designate a specific version of LiquidHaskell to ensure that the correct GHC version is in the environment. For example: cabal install liquidhaskell-0.8.10.1","title":"Via Package Manager"},{"location":"legacy/#build-from-source","text":"If you want the most recent version, you can build from source as follows, either using stack (recommended) or cabal . In either case: recursively clone the repo: git clone --recursive https://github.com/ucsd-progsys/liquidhaskell.git Go inside the liquidhaskell directory: cd liquidhaskell Build the package: a. with stack : stack install liquidhaskell b. or with cabal : cabal v2-build liquidhaskell","title":"Build from Source"},{"location":"legacy/#running-in-ghci","text":"To run inside ghci e.g. when developing do: $ stack ghci liquidhaskell ghci> :m +Language.Haskell.Liquid.Liquid ghci> liquid [\"tests/pos/Abs.hs\"]","title":"Running in GHCi"},{"location":"options/","text":"Options and Pragmas \u00b6 LiquidHaskell supports several configuration options, to alter the type checking. You can pass options in different ways: As a pragma , directly added to the source file: (recommended) {-@ LIQUID \"opt1\" @-} As a plugin option : ghc-options: -fplugin-opt=LiquidHaskell:--opt1 -fplugin-opt=LiquidHaskell:--opt2 In the environment variable LIQUIDHASKELL_OPTS (e.g. in your .bashrc or Makefile ): LIQUIDHASKELL_OPTS=\"--opt1 --opt2\" From the command line , if you use the legacy executable : liquid --opt1 --opt2 ... The options are descibed below (and by the legacy executable: liquid --help ) Theorem Proving \u00b6 Options: reflection , ple , ple-local , extensionality Directives: automatic-instances To enable theorem proving, e.g. as described here use the option {-@ LIQUID \"--reflection\" @-} To additionally turn on proof by logical evaluation use the option {-@ LIQUID \"--ple\" @-} You can see many examples of proofs by logical evaluation in benchmarks/popl18/ple/pos This flag is global and will symbolically evaluate all the terms that appear in the specifications. As an alternative, the liquidinstanceslocal flag has local behavior. See {-@ LIQUID \"--ple-local\" @-} will only evaluate terms appearing in the specifications of the function theorem , in the function theorem is annotated for automatic instantiation using the following liquid annotation {-@ automatic-instances theorem @-} To allow reasoning about function extensionality use the --extensionality flag. See test T1577 . {-@ LIQUID \"--extensionality\" @-} Fast Checking \u00b6 Options: fast , nopolyinfer The option --fast or --nopolyinfer greatly recudes verification time, can also reduces precision of type checking. It, per module, deactivates inference of refinements during instantiation of polymorphic type variables. It is suggested to use on theorem proving style when reflected functions are trivially refined. Incremental Checking \u00b6 Options: diff The LiquidHaskell executable supports incremental checking where each run only checks the part of the program that has been modified since the previous run. Each run of liquid saves the file to a .bak file and the subsequent run does a diff to see what has changed w.r.t. the .bak file only generates constraints for the [CoreBind] corresponding to the changed top-level binders and their transitive dependencies. The time savings are quite significant. For example: $ time liquid --notermination -i . Data/ByteString.hs > log 2>&1 real 7m3.179s user 4m18.628s sys 0m21.549s Now if you go and tweak the definition of spanEnd on line 1192 and re-run: $ time liquid --diff --notermination -i . Data/ByteString.hs > log 2>&1 real 0m11.584s user 0m6.008s sys 0m0.696s The diff is only performed against code , i.e. if you only change specifications, qualifiers, measures, etc. liquid -d will not perform any checks. In this case, you may specify individual definitions to verify: $ liquid -b bar -b baz foo.hs This will verify bar and baz , as well as any functions they use. If you always want to run a given file with diff-checking, add the pragma: {-@ LIQUID \"--diff\" @-} Full Checking (DEFAULT) \u00b6 Options: full You can force LiquidHaskell to check the whole file (which is the DEFAULT ) using the --full option. This will override any other --diff incantation elsewhere (e.g. inside the file). If you always want to run a given file with full-checking, add the pragma: {-@ LIQUID \"--full\" @-} Specifying Different SMT Solvers \u00b6 Options: smtsolver By default, LiquidHaskell uses the SMTLIB2 interface for Z3. To run a different solver (supporting SMTLIB2) do: $ liquid --smtsolver=NAME foo.hs Currently, LiquidHaskell supports CVC4 MathSat To use these solvers, you must install the corresponding binaries from the above web-pages into your PATH . You can also build and link against the Z3 API (faster but requires more dependencies). If you do so, you can use that interface with: $ liquid --smtsolver=z3mem foo.hs Short Error Messages \u00b6 Options: short-errors By default, subtyping error messages will contain the inferred type, the expected type -- which is not a super-type, hence the error -- and a context containing relevant variables and their type to help you understand the error. If you don't want the above and instead, want only the source position of the error use --short-errors . Short (Unqualified) Module Names \u00b6 Options: short-names By default, the inferred types will have fully qualified module names. To use unqualified names, much easier to read, use --short-names . Disabling Checks on Functions \u00b6 Directives: ignore You can disable checking of a particular function (e.g. because it is unsafe, or somehow not currently outside the scope of LH) by using the ignore directive. For example, {-@ ignore foo @-} will disable the checking of the code for the top-level binder foo . See tests/pos/Ignores.hs for an example. Totality Check \u00b6 Options: no-totality LiquidHaskell proves the absence of pattern match failures. For example, the definition fromJust :: Maybe a -> a fromJust (Just a) = a is not total and it will create an error message. If we exclude Nothing from its domain, for example using the following specification {-@ fromJust :: {v:Maybe a | (isJust v)} -> a @-} fromJust will be safe. Use the no-totality flag to disable totality checking. Termination Check \u00b6 Options: no-termination By default a termination check is performed on all recursive functions, but you can disable the check with the --no-termination option. See the specifications section for how to write termination specifications. Total Haskell \u00b6 Options: total-Haskell LiquidHaskell provides a total Haskell flag that checks both totallity and termination of the program, overriding a potential no-termination flag. Lazy Variables \u00b6 A variable can be specified as LAZYVAR {-@ LAZYVAR z @-} With this annotation the definition of z will be checked at the points where it is used. For example, with the above annotation the following code is SAFE: foo = if x > 0 then z else x where z = 42 `safeDiv` x x = choose 0 By default, all the variables starting with fail are marked as LAZY, to defer failing checks at the point where these variables are used. No measure fields \u00b6 Options: no-measure-fields When a data type is refined, Liquid Haskell automatically turns the data constructor fields into measures. For example, {-@ data L a = N | C {hd :: a, tl :: L a} @-} will automatically create two measures hd and td . To deactivate this automatic measure definition, and speed up verification, you can use the --no-measure-fields flag. Prune Unsorted Predicates \u00b6 Options: prune-unsorted The --prune-unsorted flag is needed when using measures over specialized instances of ADTs. For example, consider a measure over lists of integers sum :: [Int] -> Int sum [] = 0 sum (x:xs) = 1 + sum xs This measure will translate into strengthening the types of list constructors [] :: {v:[Int] | sum v = 0 } (:) :: x:Int -> xs:[Int] -> {v:[Int] | sum v = x + sum xs} But what if our list is polymorphic [a] and later instantiate to list of ints? The workaround we have right now is to strengthen the polymorphic list with the sum information [] :: {v:[a] | sum v = 0 } (:) :: x:a -> xs:[a] -> {v:[a] | sum v = x + sum xs} But for non numeric a s, refinements like x + sum xs are ill-sorted! We use the flag --prune-unsorted to prune away unsorted expressions (like x + sum xs ) inside refinements. Case Expansion \u00b6 Options: no-case-expand By default LiquidHaskell expands all data constructors to the case statements. For example, given the definition data F = A1 | A2 | .. | A10 LiquidHaskell will expand the code case f of {A1 -> True; _ -> False} to case f of {A1 -> True; A2 -> False; ...; A10 -> False} This expansion can lead to more precise code analysis but it can get really expensive due to code explosion. The --no-case-expand flag prevents this expansion and keeps the user provided cases for the case expression. Higher order logic \u00b6 Options: higherorder The flag --higherorder allows reasoning about higher order functions. Restriction to Linear Arithmetic \u00b6 Options: linear When using z3 as the solver, LiquidHaskell allows for non-linear arithmetic: division and multiplication on integers are interpreted by z3 . To treat division and multiplication as uninterpreted functions use the --linear flag. Counter examples \u00b6 Options: counter-examples Status: experimental When given the --counter-examples flag, LiquidHaskell will attempt to produce counter-examples for the type errors it discovers. For example, see tests/neg/ListElem.hs % liquid --counter-examples tests/neg/ListElem.hs ... tests/neg/ListElem.hs:12:1-8: Error: Liquid Type Mismatch 12 | listElem _ [] = False ^^^^^^^^ Inferred type VV : {VV : Bool | VV == True} VV = True not a subtype of Required type VV : {VV : Bool | Prop VV <=> Set_mem ?b (listElts ?a)} In Context ?a : {?a : [a] | len ?a >= 0} ?a = [1] ?b : a ?b = 0 The --counter-examples flag requires that each type in the context be an instance of GHC.Generics.Generic or Test.Targetable.Targetable (provided as part of LiquidHaskell). LiquidHaskell cannot generate counter-examples for polymorphic types, but will try (naively) to instantiate type variables with Int (as seen in the example above). Typeclasses \u00b6 Options: typeclass Status: experimental The --typeclass flag enables LiquidHaskell's support of typeclasses. One limitation is that proofs cannot be written directly within the instance definition unless the --aux-inline flag is turned on as well. Generating HTML Output \u00b6 The system produces HTML files with colorized source, and mouseover inferred type annotations, which are quite handy for debugging failed verification attempts. Regular Haskell When you run: liquid foo.hs you get a file foo.hs.html with the annotations. The coloring is done using hscolour . Markdown + Literate Haskell You can also feed in literate haskell files where the comments are in Pandoc markdown . In this case, the tool will run pandoc to generate the HTML from the comments. Of course, this requires that you have pandoc installed as a binary on your system. If not, hscolour is used to render the HTML. It is also possible to generate slide shows from the above. See the slides directory for an example.","title":"<i aria-hidden=true class='mdi mdi-flag'></i> Flag Reference"},{"location":"options/#options-and-pragmas","text":"LiquidHaskell supports several configuration options, to alter the type checking. You can pass options in different ways: As a pragma , directly added to the source file: (recommended) {-@ LIQUID \"opt1\" @-} As a plugin option : ghc-options: -fplugin-opt=LiquidHaskell:--opt1 -fplugin-opt=LiquidHaskell:--opt2 In the environment variable LIQUIDHASKELL_OPTS (e.g. in your .bashrc or Makefile ): LIQUIDHASKELL_OPTS=\"--opt1 --opt2\" From the command line , if you use the legacy executable : liquid --opt1 --opt2 ... The options are descibed below (and by the legacy executable: liquid --help )","title":"Options and Pragmas"},{"location":"options/#theorem-proving","text":"Options: reflection , ple , ple-local , extensionality Directives: automatic-instances To enable theorem proving, e.g. as described here use the option {-@ LIQUID \"--reflection\" @-} To additionally turn on proof by logical evaluation use the option {-@ LIQUID \"--ple\" @-} You can see many examples of proofs by logical evaluation in benchmarks/popl18/ple/pos This flag is global and will symbolically evaluate all the terms that appear in the specifications. As an alternative, the liquidinstanceslocal flag has local behavior. See {-@ LIQUID \"--ple-local\" @-} will only evaluate terms appearing in the specifications of the function theorem , in the function theorem is annotated for automatic instantiation using the following liquid annotation {-@ automatic-instances theorem @-} To allow reasoning about function extensionality use the --extensionality flag. See test T1577 . {-@ LIQUID \"--extensionality\" @-}","title":"Theorem Proving"},{"location":"options/#fast-checking","text":"Options: fast , nopolyinfer The option --fast or --nopolyinfer greatly recudes verification time, can also reduces precision of type checking. It, per module, deactivates inference of refinements during instantiation of polymorphic type variables. It is suggested to use on theorem proving style when reflected functions are trivially refined.","title":"Fast Checking"},{"location":"options/#incremental-checking","text":"Options: diff The LiquidHaskell executable supports incremental checking where each run only checks the part of the program that has been modified since the previous run. Each run of liquid saves the file to a .bak file and the subsequent run does a diff to see what has changed w.r.t. the .bak file only generates constraints for the [CoreBind] corresponding to the changed top-level binders and their transitive dependencies. The time savings are quite significant. For example: $ time liquid --notermination -i . Data/ByteString.hs > log 2>&1 real 7m3.179s user 4m18.628s sys 0m21.549s Now if you go and tweak the definition of spanEnd on line 1192 and re-run: $ time liquid --diff --notermination -i . Data/ByteString.hs > log 2>&1 real 0m11.584s user 0m6.008s sys 0m0.696s The diff is only performed against code , i.e. if you only change specifications, qualifiers, measures, etc. liquid -d will not perform any checks. In this case, you may specify individual definitions to verify: $ liquid -b bar -b baz foo.hs This will verify bar and baz , as well as any functions they use. If you always want to run a given file with diff-checking, add the pragma: {-@ LIQUID \"--diff\" @-}","title":"Incremental Checking"},{"location":"options/#full-checking-default","text":"Options: full You can force LiquidHaskell to check the whole file (which is the DEFAULT ) using the --full option. This will override any other --diff incantation elsewhere (e.g. inside the file). If you always want to run a given file with full-checking, add the pragma: {-@ LIQUID \"--full\" @-}","title":"Full Checking (DEFAULT)"},{"location":"options/#specifying-different-smt-solvers","text":"Options: smtsolver By default, LiquidHaskell uses the SMTLIB2 interface for Z3. To run a different solver (supporting SMTLIB2) do: $ liquid --smtsolver=NAME foo.hs Currently, LiquidHaskell supports CVC4 MathSat To use these solvers, you must install the corresponding binaries from the above web-pages into your PATH . You can also build and link against the Z3 API (faster but requires more dependencies). If you do so, you can use that interface with: $ liquid --smtsolver=z3mem foo.hs","title":"Specifying Different SMT Solvers"},{"location":"options/#short-error-messages","text":"Options: short-errors By default, subtyping error messages will contain the inferred type, the expected type -- which is not a super-type, hence the error -- and a context containing relevant variables and their type to help you understand the error. If you don't want the above and instead, want only the source position of the error use --short-errors .","title":"Short Error Messages"},{"location":"options/#short-unqualified-module-names","text":"Options: short-names By default, the inferred types will have fully qualified module names. To use unqualified names, much easier to read, use --short-names .","title":"Short (Unqualified) Module Names"},{"location":"options/#disabling-checks-on-functions","text":"Directives: ignore You can disable checking of a particular function (e.g. because it is unsafe, or somehow not currently outside the scope of LH) by using the ignore directive. For example, {-@ ignore foo @-} will disable the checking of the code for the top-level binder foo . See tests/pos/Ignores.hs for an example.","title":"Disabling Checks on Functions"},{"location":"options/#totality-check","text":"Options: no-totality LiquidHaskell proves the absence of pattern match failures. For example, the definition fromJust :: Maybe a -> a fromJust (Just a) = a is not total and it will create an error message. If we exclude Nothing from its domain, for example using the following specification {-@ fromJust :: {v:Maybe a | (isJust v)} -> a @-} fromJust will be safe. Use the no-totality flag to disable totality checking.","title":"Totality Check"},{"location":"options/#termination-check","text":"Options: no-termination By default a termination check is performed on all recursive functions, but you can disable the check with the --no-termination option. See the specifications section for how to write termination specifications.","title":"Termination Check"},{"location":"options/#total-haskell","text":"Options: total-Haskell LiquidHaskell provides a total Haskell flag that checks both totallity and termination of the program, overriding a potential no-termination flag.","title":"Total Haskell"},{"location":"options/#lazy-variables","text":"A variable can be specified as LAZYVAR {-@ LAZYVAR z @-} With this annotation the definition of z will be checked at the points where it is used. For example, with the above annotation the following code is SAFE: foo = if x > 0 then z else x where z = 42 `safeDiv` x x = choose 0 By default, all the variables starting with fail are marked as LAZY, to defer failing checks at the point where these variables are used.","title":"Lazy Variables"},{"location":"options/#no-measure-fields","text":"Options: no-measure-fields When a data type is refined, Liquid Haskell automatically turns the data constructor fields into measures. For example, {-@ data L a = N | C {hd :: a, tl :: L a} @-} will automatically create two measures hd and td . To deactivate this automatic measure definition, and speed up verification, you can use the --no-measure-fields flag.","title":"No measure fields"},{"location":"options/#prune-unsorted-predicates","text":"Options: prune-unsorted The --prune-unsorted flag is needed when using measures over specialized instances of ADTs. For example, consider a measure over lists of integers sum :: [Int] -> Int sum [] = 0 sum (x:xs) = 1 + sum xs This measure will translate into strengthening the types of list constructors [] :: {v:[Int] | sum v = 0 } (:) :: x:Int -> xs:[Int] -> {v:[Int] | sum v = x + sum xs} But what if our list is polymorphic [a] and later instantiate to list of ints? The workaround we have right now is to strengthen the polymorphic list with the sum information [] :: {v:[a] | sum v = 0 } (:) :: x:a -> xs:[a] -> {v:[a] | sum v = x + sum xs} But for non numeric a s, refinements like x + sum xs are ill-sorted! We use the flag --prune-unsorted to prune away unsorted expressions (like x + sum xs ) inside refinements.","title":"Prune Unsorted Predicates"},{"location":"options/#case-expansion","text":"Options: no-case-expand By default LiquidHaskell expands all data constructors to the case statements. For example, given the definition data F = A1 | A2 | .. | A10 LiquidHaskell will expand the code case f of {A1 -> True; _ -> False} to case f of {A1 -> True; A2 -> False; ...; A10 -> False} This expansion can lead to more precise code analysis but it can get really expensive due to code explosion. The --no-case-expand flag prevents this expansion and keeps the user provided cases for the case expression.","title":"Case Expansion"},{"location":"options/#higher-order-logic","text":"Options: higherorder The flag --higherorder allows reasoning about higher order functions.","title":"Higher order logic"},{"location":"options/#restriction-to-linear-arithmetic","text":"Options: linear When using z3 as the solver, LiquidHaskell allows for non-linear arithmetic: division and multiplication on integers are interpreted by z3 . To treat division and multiplication as uninterpreted functions use the --linear flag.","title":"Restriction to Linear Arithmetic"},{"location":"options/#counter-examples","text":"Options: counter-examples Status: experimental When given the --counter-examples flag, LiquidHaskell will attempt to produce counter-examples for the type errors it discovers. For example, see tests/neg/ListElem.hs % liquid --counter-examples tests/neg/ListElem.hs ... tests/neg/ListElem.hs:12:1-8: Error: Liquid Type Mismatch 12 | listElem _ [] = False ^^^^^^^^ Inferred type VV : {VV : Bool | VV == True} VV = True not a subtype of Required type VV : {VV : Bool | Prop VV <=> Set_mem ?b (listElts ?a)} In Context ?a : {?a : [a] | len ?a >= 0} ?a = [1] ?b : a ?b = 0 The --counter-examples flag requires that each type in the context be an instance of GHC.Generics.Generic or Test.Targetable.Targetable (provided as part of LiquidHaskell). LiquidHaskell cannot generate counter-examples for polymorphic types, but will try (naively) to instantiate type variables with Int (as seen in the example above).","title":"Counter examples"},{"location":"options/#typeclasses","text":"Options: typeclass Status: experimental The --typeclass flag enables LiquidHaskell's support of typeclasses. One limitation is that proofs cannot be written directly within the instance definition unless the --aux-inline flag is turned on as well.","title":"Typeclasses"},{"location":"options/#generating-html-output","text":"The system produces HTML files with colorized source, and mouseover inferred type annotations, which are quite handy for debugging failed verification attempts. Regular Haskell When you run: liquid foo.hs you get a file foo.hs.html with the annotations. The coloring is done using hscolour . Markdown + Literate Haskell You can also feed in literate haskell files where the comments are in Pandoc markdown . In this case, the tool will run pandoc to generate the HTML from the comments. Of course, this requires that you have pandoc installed as a binary on your system. If not, hscolour is used to render the HTML. It is also possible to generate slide shows from the above. See the slides directory for an example.","title":"Generating HTML Output"},{"location":"papers/","text":"Papers etc. \u00b6 Papers \u00b6 To learn about the theory behind Liquid Types, I recommend reading first the PLDI 2008 paper and then the ESOP 2013 paper. Alternatively, one lazy weekend, you could curl up with: Pat Rondon's Ph.D Dissertation Tech Report Haskell \u00b6 Refinement Types For Haskell, ICFP 2014 LiquidHaskell in the Real World, Haskell 2014 Abstract Refinement Types, ESOP 2013 ML \u00b6 Liquid Types, PLDI 2008 Type-based Data Structure Verification, PLDI 2009 Dsolve: Safety Verification via Liquid Types, CAV 2010 HMC: Verifying Functional Programs with Abstract Interpreters, CAV 2011 C \u00b6 Low-level Liquid Types, POPL 2010 Deterministic Parallelism With Liquid Effects, PLDI 2012 Verifying C With Liquid Types, CAV 2012 Talks \u00b6 The following talks are good tutorial introductions to the techniques. Tutorial at VMCAI Tutorial at CAV People \u00b6 Liquid Types have been developed in the UCSD Programming Systems group by Alexander Bakst Ranjit Jhala Ming Kawaguchi Patrick Rondon Eric Seidel Michael Smith Anish Tondwalkar Chris Tetreault Niki Vazou Thanks \u00b6 This work is funded by NSF grants CCF-0644361, CNS-0720802, CCF-0702603, and generous gifts from Microsoft Research.","title":"<i aria-hidden=true class='mdi mdi-school'></i> Papers"},{"location":"papers/#papers-etc","text":"","title":"Papers etc."},{"location":"papers/#papers","text":"To learn about the theory behind Liquid Types, I recommend reading first the PLDI 2008 paper and then the ESOP 2013 paper. Alternatively, one lazy weekend, you could curl up with: Pat Rondon's Ph.D Dissertation Tech Report","title":"Papers"},{"location":"papers/#haskell","text":"Refinement Types For Haskell, ICFP 2014 LiquidHaskell in the Real World, Haskell 2014 Abstract Refinement Types, ESOP 2013","title":"Haskell"},{"location":"papers/#ml","text":"Liquid Types, PLDI 2008 Type-based Data Structure Verification, PLDI 2009 Dsolve: Safety Verification via Liquid Types, CAV 2010 HMC: Verifying Functional Programs with Abstract Interpreters, CAV 2011","title":"ML"},{"location":"papers/#c","text":"Low-level Liquid Types, POPL 2010 Deterministic Parallelism With Liquid Effects, PLDI 2012 Verifying C With Liquid Types, CAV 2012","title":"C"},{"location":"papers/#talks","text":"The following talks are good tutorial introductions to the techniques. Tutorial at VMCAI Tutorial at CAV","title":"Talks"},{"location":"papers/#people","text":"Liquid Types have been developed in the UCSD Programming Systems group by Alexander Bakst Ranjit Jhala Ming Kawaguchi Patrick Rondon Eric Seidel Michael Smith Anish Tondwalkar Chris Tetreault Niki Vazou","title":"People"},{"location":"papers/#thanks","text":"This work is funded by NSF grants CCF-0644361, CNS-0720802, CCF-0702603, and generous gifts from Microsoft Research.","title":"Thanks"},{"location":"specifications/","text":"Writing Specifications \u00b6 This section documents how you can actually annotate new or existing code with refinement types, leveraging the full power of LiquidHaskell. There are a lot of different ways to annotate your code, and so we've included a brief summary of each here. {-@ inline <binding-name> @-} copies a Haskell definition to the refinement logic. ( Jump to: Inlines ) All parts of the definition must already be available to the refinement logic. The definition cannot be recursive. {-@ measure <function-name>[ <refinement-type>] @-} copies a Haskell function to the refinement logic, adds an inferred refinement type to the constructor of the function's first argument, and emits an inferred global invariant related to the refinement. ( Jump to: Measures ) All parts of the definition must already be available to the refinement logic. The function must have only one argument and it must pattern match on the constructors of the type. The function may structurally recurse on the single argument. {-@ reflect <function-name> @-} creates an uninterpreted function of the same name in the refinement logic, copies the implementation to a refinement type alias, and adds a refinement to the type of the uninterpreted function that specifies the type alias as a post-condition. ( See more: Section 2.2 of this paper ) All parts of the definition must already be available to the refinement logic. The function may be recursive. {-@ type <type-alias-head> = <refinement-type> @-} introduces a type alias that looks like Haskell syntax but can contain refinements and may be parameterized over both types and values. ( Jump to: Type Aliases ) {-@ predicate .. @-} introduces something like {-@ type .. @-} . ( Deprecated, use inline instead , Jump to: Predicate Aliases ) {-@ invariant <refinement-type> @-} introduces a globally available refinement which may be used by Liquid Haskel, but is not checked. ( Unchecked , Deprecated , Jump to: Invariants ) {-@ data <data-type-head><termination-measure>[ <data-type-body] @-} introduces a refined datatype, and introduces measures for each field of a record datatype. ( Jump to: Data Refinements ) Optionally you may also add refinements to datatype fields. Optionally you may also add a termination measure to the datatype. {-@ assume <binding-signature-with-refinement-type> @-} introduces a refinement type for the named Haskell definition. ( Unchecked ) For a function, the refinements become pre and post conditions for the functions use. {-@ <binding-signature-with-refinement-type> @-} introduces a refinement type for the named Haskell definition. For a function, the refinements become pre and post conditions for the functions use. This is probably the most used Liquid Haskell annotation! The following sections detail more variety for the uses of the above annotations. Modules WITHOUT code \u00b6 The following section is slightly different depending on whether you are using the plugin (which you should!) or the legacy executable. (Plugin) Adding refinements for external modules \u00b6 See the installation section, which cointains a link to a walkthrough document that describes how to add refinements for external packages (cfr. \"Providing Specifications for Existing Packages\" ) (Legacy executable) Adding refinements for external modules \u00b6 When checking a file target.hs , you can specify an include directory by liquid -i /path/to/include/ target.hs Now, to write specifications for some external module Foo.Bar.Baz for which you do not have the code , you can create a .spec file at: /path/to/include/Foo/Bar/Baz.spec See, for example, the contents of: include/Prelude.spec include/Data/List.spec include/Data/Vector.spec Note : The above directories are part of the LH prelude, and included by default when running liquid . The .spec mechanism is only for external modules without code, see below for standalone specifications for internal or home * modules. Modules WITH code: Data \u00b6 Write the specification directly into the .hs or .lhs file, above the data definition. See, for example, tests/pos/Map.hs : {-@ data Map k a <l :: k -> k -> Prop, r :: k -> k -> Prop> = Tip | Bin (sz :: Size) (key :: k) (value :: a) (left :: Map <l, r> (k <l key>) a) (right :: Map <l, r> (k <r key>) a) @-} data Map k a = Tip | Bin Size k a (Map k a) (Map k a) You can also write invariants for data type definitions together with the types. For example, see tests/pos/record0.hs : {-@ data LL a = BXYZ { size :: {v: Int | v > 0 } , elems :: {v: [a] | (len v) = size } } @-} Finally you can specify the variance of type variables for data types. For example, see tests/pos/Variance.hs , where data type Foo has four type variables a , b , c , d , specified as invariant, bivariant, covariant and contravariant, respectively. {-@ data variance Foo invariant bivariant covariant contravariant @-} data Foo a b c d Modules WITH code: Functions \u00b6 Write the specification directly into the .hs or .lhs file, above the function definition. For example : {-@ incr :: x:{v: Int | v > 0} -> {v: Int | v > x} @-} incr :: Int -> Int incr x = x + 1 Modules WITH code: Type Classes \u00b6 Write the specification directly into the .hs or .lhs file. The constrained variable must match the one from the class definition. A class must have at least one refinement signature (even if it's a trivial one) to be lifted to the refinement logic. For example : class Semigroup a where {-@ mappend :: a -> a -> a @-} mappend :: a -> a -> a sconcat :: NonEmpty a -> a class Semigroup a => VSemigroup a where {-@ lawAssociative :: v:a -> v':a -> v'':a -> {mappend (mappend v v') v'' == mappend v (mappend v' v'')} @-} lawAssociative :: a -> a -> a -> () Without the extra signature for mappend , the above example would not work. Instances can be defined without any special annotations: data PNat = Z | S PNat instance Semigroup PNat where mappend Z n = n mappend (S m) n = S (mappend m n) sconcat (NonEmpty h t) = foldlList mappend h t instance VSemigroup PNat where lawAssociative Z _ _ = () lawAssociative (S p) m n = lawAssociative p m n The example above inlines the proofs directly into the instance definition. This requires the --aux-inline flag. Modules WITH code: Type Classes (Legacy) \u00b6 Write the specification directly into the .hs or .lhs file, above the type class definition. For example : {-@ class Sized s where size :: forall a. x:s a -> {v:Int | v = (size x)} @-} class Sized s where size :: s a -> Int Any measures used in the refined class definition will need to be generic (see Specifying Measures ). As an alternative, you can refine class instances. For example : instance Compare Int where {-@ instance Compare Int where cmax :: Odd -> Odd -> Odd @-} cmax y x = if x >= y then x else y When cmax method is used on Int , liquidHaskell will give it the refined type Odd -> Odd -> Odd . Note that currently liquidHaskell does not allow refining instances of refined classes . Modules WITH code: QuasiQuotation \u00b6 Instead of writing both a Haskell type signature and a LiquidHaskell specification for a function, the lq quasiquoter in the LiquidHaskell module can be used to generate both from just the LiquidHaskell specification. module Nats (nats) where {-@ nats :: [{v:Int | 0 <= v}] @-} nats :: [Int] nats = [1,2,3] can be written as {-# LANGUAGE QuasiQuotes #-} module Nats (nats) where import LiquidHaskell [lq| nats :: [{v:Int | 0 <= v}] |] nats = [1,2,3] and the lq quasiquoter will generate the plain nats :: [Int] when GHC compiles the module. Refined type aliases (see the next section) can also be written inside lq ; for example: {-# LANGUAGE QuasiQuoters #-} module Nats (Nat, nats) where [lq| type Nat = {v:Int | 0 <= v} |] [lq| nats :: [Nat] |] nats = [1,2,3] Here, the lq quasiquoter will generate a plain Haskell type synonym for Nat as well as the refined one. Note that this is still an experimental feature, and currently requires that one depend on LiquidHaskell as a build dependency for your project; the quasiquoter will be split out eventually into an independent, dependency-light package. Also, at this time, writing a type inside lq which refers to a refined type alias for which there is not a plain Haskell type synonym of the same name will result in a \"not in scope\" error from GHC. Standalone Specifications for Internal Modules \u00b6 Recall that the .spec mechanism is only for modules whose code is absent; if code is present then there can be multiple, possibly conflicting specifications. Nevertheless, you may want, for one reason or another, to write (assumed) specifications outside the file implementing the module. You can do this as follows. Lib.hs module Lib (foo) where foo a = a now, instead of a .spec file, just use a haskell module, e.g. LibSpec.hs module LibSpec ( module Lib ) where import Lib -- Don't forget to qualify the name! {-@ Lib.foo :: {v:a | false} -> a @-} and then here's Client.hs module Client where import Lib -- use this if you DON'T want the spec import LibSpec -- use this if you DO want the spec, in addition to OR instead of the previous import. bar = foo 1 -- if you `import LibSpec` then this call is rejected by LH Inductive Predicates \u00b6 Status: very_experimental LH recently added support for Inductive Predicates in the style of Isabelle, Coq etc. These are encoded simply as plain Haskell GADTs but suitably refined. Apologies for the minimal documentation; see the following examples for details: Palindrome Permutations Transitive Closure RegExp Derivatives Type Safety of STLC Implicit Arguments \u00b6 Status: experimental There is experimental support for implicit arguments, solved for with congruence closure. For example, consider Implicit1.hs : {-@ type IntN N = {v:Int | v = N} @-} {-@ foo :: n:Int ~> (() -> IntN n) -> IntN {n+1} @-} foo f = 1 + f () {-@ test1 :: IntN 11 @-} test1 = foo (\\_ -> 10) Here, the refinement on (\\_ -> 10) :: Int -> { v:Int | v = 10 } allows us to solve for n = 10 , the implicit argument to foo . Refinement Type Aliases \u00b6 Predicate Aliases \u00b6 Often, the propositions in the refinements can get rather long and verbose. You can write predicate aliases like so: {-@ predicate Lt X Y = X < Y @-} {-@ predicate Ge X Y = not (Lt X Y) @-} and then use the aliases inside refinements, for example {-@ incr :: x:{v:Int | (Pos v)} -> { v:Int | ((Pos v) && (Ge v x))} @-} incr :: Int -> Int incr x = x + 1 See Data.Map for a more substantial and compelling example. Syntax: The key requirements for type aliases are: Value parameters are specified in upper case: X , Y , Z etc. Failing Specifications \u00b6 The fail b declaration checks that the definition of b is unsafe. E.g., the following is SAFE. {-@ fail unsafe @-} {-@ unsafe :: () -> { 0 == 1 } @-} unsafe :: () -> () unsafe _ = () An error is created if fail definitions are safe or binders defined as fail are used by (failing or not) definitions. Type Aliases \u00b6 Similarly, it is often quite tedious to keep writing {v: Int | v > 0} Thus, LiquidHaskell supports refinement-type aliases of the form: {-@ type Gt N = {v: Int | N < v} @-} {-@ type GeNum a N = {v: a | N <= v} @-} or {-@ type SortedList a = [a]<{\\fld v -> (v >= fld)}> @-} or {-@ type OMap k a = Map <{\\root v -> v < root}, {\\root v -> v > root}> k a @-} or {-@ type MinSPair a = (a, OSplay a) <\\fld -> {v : Splay {v:a|v>fld} | 0=0}> @-} and then use the above in signatures like: {-@ incr: x: Int -> GeNum Int x @-} or {-@ incr: x: Int -> Gt x @-} and: {-@ assert insert :: (Ord a) => a -> SortedList a -> SortedList a @-} see tests/pos/ListSort.hs and: {-@ assert insert :: (Ord k) => k -> a -> OMap k a -> OMap k a @-} see tests/pos/Map.hs Syntax: The key requirements for type aliases are: Type parameters are specified in lower case: a , b , c etc. Value parameters are specified in upper case: X , Y , Z etc. Infix Operators \u00b6 You can define infix types and logical operators in logic Haskell's infix notation . For example, if (+++) is defined as a measure or reflected function, you can use it infix by declaring {-@ infixl 9 +++ @-} Note: infix operators cannot contain the dot character . . If (==>) is a Haskell infix type ( see ) infixr 1 ==> then to use it as infix in the refinements types you need to add the refinement infix notation. {-@ infixr 1 ==> @-} {-@ test :: g:(f ==> g) -> f x -> f y -> () @-} Specifying Measures \u00b6 They can be placed in a .spec file or in a .hs/.lhs file wrapped around {-@ @-} . Value measures: GHC/Base.spec measure len :: forall a. [a] -> GHC.Types.Int len ([]) = 0 len (y:ys) = 1 + len(ys) Propositional measures: tests/pos/LambdaEval.hs {-@ measure isValue :: Expr -> Bool isValue (Const i) = true isValue (Lam x e) = true isValue (Var x) = false isValue (App e1 e2) = false isValue (Plus e1 e2) = false isValue (Fst e) = false isValue (Snd e) = false isValue (Pair e1 e2) = ((? (isValue(e1))) && (? (isValue(e2)))) @-} Raw measures: tests/pos/meas8.hs {-@ measure rlen :: [a] -> Int rlen ([]) = {v | v = 0} rlen (y:ys) = {v | v = (1 + rlen(ys))} @-} Generic measures: tests/pos/Class.hs {-@ class measure size :: a -> Int @-} {-@ instance measure size :: [a] -> Int size ([]) = 0 size (x:xs) = 1 + (size xs) @-} {-@ instance measure size :: Tree a -> Int size (Leaf) = 0 size (Node x l r) = 1 + (size l) + (size r) @-} Note: Measure names do not have to be the same as field name, e.g. we could call the measure sz in the above as shown in tests/pos/Class2.hs . Haskell Functions as Measures (beta): tests/pos/HaskellMeasure.hs Inductive Haskell Functions from Data Types to some type can be lifted to logic {-@ measure llen @-} llen :: [a] -> Int llen [] = 0 llen (x:xs) = 1 + llen xs The above definition: refines list's data constructors types with the llen information, and specifies a singleton type for the haskell function llen :: xs:[a] -> {v:Int | v == llen xs} . If the user specifies another type for llen , say llen :: xs:[a] -> {v:Int | llen xs >= 0} , then the auto generated singleton type is overwritten. Inlines \u00b6 The inline lets you use a Haskell function in a type specification. {-@ inline max @-} {-@ max :: Int -> Int -> Int @-} max :: Int -> Int -> Int max x y = if x > y then x else y For example, if you write the above you can then write a function: {-@ floor :: x:Int -> {v:Int | max 0 x} @-} floor :: Int -> Int floor x | x <= 0 = 0 | otherwise = x That is, you can use the haskell max in the refinement type and it will automatically get \u201cexpanded\u201d out to the full definition. This makes it useful e.g. to reuse plain Haskell code to compose specifications, and to share definitions common to refinements and code. However, as they are expanded at compile time, inline functions cannot be recursive . The can call other (non-recursive) inline functions. If you want to talk about arbitrary (recursive) functions inside your types, then you need to use reflect described in the blog . Self-Invariants \u00b6 Sometimes, we require specifications that allow inner components of a type to refer to the outer components, typically, to measure-based properties of outer components. For example, the following invariant about Maybe values {-@ type IMaybe a = {v0 : Maybe {v : a | ((isJust v0) && v = (fromJust v0))} | 0 = 0 } @-} states that the inner a enjoys the property that the outer container is definitely a Just and furthermore, the inner value is exactly the same as the fromJust property of the outer container. As another example, suppose we have a measure : measure listElts :: [a] -> (Set a) listElts([]) = {v | (? Set_emp(v))} listElts(x:xs) = {v | v = Set_cup(Set_sng(x), listElts(xs)) } Now, all lists enjoy the property {-@ type IList a = {v0 : List {v : a | (Set_mem v (listElts v0)) } | true } @-} which simply states that each inner element is indeed, a member of the set of the elements belonging to the entire list. One often needs these circular or self invariants to connect different levels (or rather, to reify the connections between the two levels.) See this test for a simple example and hedgeUnion and Data.Map.Base for a complex one. Abstract and Bounded Refinements \u00b6 This is probably the best example of the abstract refinement syntax: Abstract Refinements Bounded Refinements Unfortunately, the best documentation for these two advanced features is the relevant papers at: ESOP 2013 ICFP 2015 The bounds correspond to Horn implications between abstract refinements, which, as in the classical setting, correspond to subtyping constraints that must be satisfied by the concrete refinements used at any call-site. Dependent Pairs \u00b6 Dependent Pairs are expressed by binding the initial tuples of the pair. For example incrPair defines an increasing pair. {-@ incrPair :: Int -> (x::Int, {v:Int | x <= v}) @-} incrPair i = (i, i+1) Internally dependent pairs are implemented using abstract refinement types. That is (x::a, {v:b | p x}) desugars to (a,b)<\\x -> {v:b | p x}> . Invariants \u00b6 LH lets you locally associate invariants with specific data types. For example, in tests/measure/pos/Using00.hs every list is treated as a Stream . To establish this local invariant one can use the using declaration {-@ using ([a]) as {v:[a] | (len v > 0)} @-} denoting that each list is not empty. Then, LiquidHaskell will prove that this invariant holds, by proving that all calls to List's constructors (ie., : and [] ) satisfy it, and will assume that each list element that is created satisfies this invariant. With this, at the above test LiquidHaskell proves that taking the head of a list is safe. But, at tests/measure/neg/Using00.hs the usage of [] falsifies this local invariant resulting in an \"Invariant Check\" error. WARNING: There is an older global invariant mechanism that attaches a refinement to a datatype globally. Do not use this mechanism -- it is unsound and about to deprecated in favor of something that is actually sound For example, the length of a list cannot be negative {-@ invariant {v:[a] | (len v >= 0)} @-} LiquidHaskell can prove that this invariant holds, by proving that all List's constructors (ie., : and [] ) satisfy it.(TODO!) Then, LiquidHaskell assumes that each list element that is created satisfies this invariant. Rewriting \u00b6 Status: experimental You use the rewriteWith annotation to indicate equalities that PLE will apply automatically. For example, suppose that you have proven associativity of ++ for lists. {-@ assoc :: xs:[a] -> ys:[a] -> zs:[a] -> { xs ++ (ys ++ zs) == (xs ++ ys) ++ zs } @-} Using the rewriteWith annotation, PLE will automatically apply the equality for associativity whenever it encounters an expression of the form xs ++ (ys ++ zs) or (xs ++ ys) ++ zs . For example, you can prove assoc2 for free. {-@ rewriteWith assoc2 [assoc] @-} {-@ assoc2 :: xs:[a] -> ys:[a] -> zs:[a] -> ws:[a] -> { xs ++ (ys ++ (zs ++ ws)) == ((xs ++ ys) ++ zs) ++ ws } @-} assoc2 :: [a] -> [a] -> [a] -> [a] -> () assoc2 xs ys zs ws = () You can also annotate a function as being a global rewrite rule by using the rewrite annotation, in which case PLE will apply it across the entire module. {-@ rewrite assoc @-} {-@ assoc :: xs:[a] -> ys:[a] -> zs:[a] -> { xs ++ (ys ++ zs) == (xs ++ ys) ++ zs } @-} Limitations \u00b6 Currently, rewriting does not work if the equality that uses the rewrite rule includes parameters that contain inner refinements ( test ). Rewriting works by pattern-matching expressions to determine if there is a variable substitution that would allow it to match against either side of a rewrite rule. If so, that substitution is applied to the opposite side and the corresponding equality is generated. If one side of the equality contains any parameters that are not bound on the other side, it will not be possible to generate a rewrite in that direction, because those variables cannot be instantiated. Likewise, if there are free variables on both sides of an equality, no rewrite can be generated at all ( test ). It's possible in theory for rewriting rules to diverge. We have a simple check to ensure that rewriting rules that will always diverge do not get instantiated. However, it's possible that applying a combination of rewrite rules could cause divergence. Formal Grammar of Refinement Predicates \u00b6 (C)onstants \u00b6 c := 0, 1, 2, ... (V)ariables \u00b6 v := x, y, z, ... (E)xpressions \u00b6 e := v -- variable | c -- constant | (e + e) -- addition | (e - e) -- subtraction | (c * e) -- multiplication by constant | (v e1 e2 ... en) -- uninterpreted function application | (if p then e else e) -- if-then-else (R)elations \u00b6 r := == -- equality | /= -- disequality | >= -- greater than or equal | <= -- less than or equal | > -- greater than | < -- less than (P)redicates \u00b6 p := (e r e) -- binary relation | (v e1 e2 ... en) -- predicate (or alias) application | (p && p) -- and | (p || p) -- or | (p => p) -- implies | (not p) -- negation | true | false Specifying Qualifiers \u00b6 There are several ways to specify qualifiers. By Separate .hquals Files \u00b6 You can write qualifier files e.g. Prelude.hquals .. If a module is called or imports Foo.Bar.Baz Then the system automatically searches for include/Foo/Bar/Baz.hquals By Including .hquals Files \u00b6 Additional qualifiers may be used by adding lines of the form: {-@ include <path/to/file.hquals> @-} to the Haskell source. See, this for example. In Haskell Source or Spec Files \u00b6 Finally, you can specifiers directly inside source (.hs or .lhs) or spec (.spec) files by writing as shown here {-@ qualif Foo(v:Int, a: Int) : (v = a + 100) @-} Note In addition to these, LiquidHaskell scrapes qualifiers from all the specifications you write i.e. all imported type signatures, measure bodies and, data constructor definitions. Termination Metrics \u00b6 In recursive functions the first algebraic or integer argument should be decreasing. The default decreasing measure for lists is length and Integers its value. Default Termination Metrics \u00b6 The user can specify the size of a data-type in the data definition {-@ data L [llen] a = Nil | Cons { x::a, xs:: L a} @-} In the above, the measure llen , which needs to be defined by the user (see below), is defined as the default metric for the type L a . LH will use this default metric to automatically prove that the following terminates: append :: L a -> L a -> L a append N ys = ys append (Cons x xs) ys = Cons x (append xs ys) as, by default the first (non-function) argument with an associated size metric is checked to be strictly terminating and non-negative at each recursive call. A default termination metric is a Haskell function that is proved terminating using structural induction. To deactivate structional induction check on the termination metric, use the --trust-sizes flag. Explicit Termination Metrics \u00b6 However, consider the function reverse : reverseAcc :: L a -> L a -> L a reverseAcc acc N = acc reverseAcc acc (Cons x xs) = reverseAcc (Cons x acc) xs Here, the first argument does not decrease, instead the second does. We can tell LH to use the second argument using the explicit termination metric reverseAcc :: L a -> xs:L a -> L a / [llen xs] which tells LH that the llen of the second argument xs is what decreases at each recursive call. Decreasing expressions can be arbitrary refinement expressions, e.g., {-@ merge :: Ord a => xs:L a -> ys:L a -> L a / [llen xs + llen ys] @-} states that at each recursive call of merge the sum of the lengths of its arguments will decrease. Lexicographic Termination Metrics \u00b6 Some functions do not decrease on a single argument, but rather a combination of arguments, e.g. the Ackermann function. {-@ ack :: m:Int -> n:Int -> Nat / [m, n] @-} ack m n | m == 0 = n + 1 | m > 0 && n == 0 = ack (m-1) 1 | m > 0 && n > 0 = ack (m-1) (ack m (n-1)) In all but one recursive call m decreases, in the final call m does not decrease but n does. We can capture this notion of m normally decreases, but if it does not, n will decrease with a lexicographic termination metric [m, n] . An alternative way to express this specification is by annotating the function's type with the appropriate numeric decreasing expressions. As an example, you can give ack a type {-@ ack :: m:Nat -> n:Nat -> Nat / [m,n] @-} stating that the numeric expressions [m, n] are lexicographically decreasing. Mutually Recursive Functions \u00b6 When dealing with mutually recursive functions you may run into a situation where the decreasing parameter must be measured across a series of invocations, e.g. even :: Int -> Bool even 0 = True even n = odd (n-1) odd :: Int -> Bool odd n = not (even n) In this case, you can introduce a ghost parameter that orders the functions {-@ isEven :: n:Nat -> Bool / [n, 0] @-} isEven :: Int -> Bool isEven 0 = True isEven n = isOdd (n-1) {-@ isOdd :: n:Nat -> Bool / [n, 1] @-} isOdd :: Int -> Bool isOdd n = not $ isEven n thus recovering a decreasing measure for the pair of functions, the pair of arguments. This can be encoded with the lexicographic termination annotation as shown above. See tests/pos/mutrec.hs for the full example. Automatic Termination Metrics \u00b6 Apart from specifying a specific decreasing measure for an Algebraic Data Type, the user can specify that the ADT follows the expected decreasing measure by {-@ autosize L @-} Then, LH will define an instance of the function autosize for L that decreases by 1 at each recursive call and use autosize at functions that recurse on L . For example, autosize L will refine the data constructors of L a with the autosize :: a -> Int information, such that Nil :: {v:L a | autosize v = 0} Cons :: x:a -> xs:L a -> {v:L a | autosize v = 1 + autosize xs} Also, an invariant that autosize is non negative will be generated invariant {v:L a| autosize v >= 0 } This information is all LiquidHaskell needs to prove termination on functions that recurse on L a (on ADTs in general.) Disabling Termination Checking \u00b6 To disable termination checking for foo that is, to assume that it is terminating (possibly for some complicated reason currently beyond the scope of LH) you can write {-@ lazy foo @-} Synthesis \u00b6 Status: experimental LH has some very preliminary support for program synthesis. How to use it \u00b6 Activate the flag for typed holes in LiquidHaskell. E.g. from command line: liquid --typedholes In a Haskell source file: {-@ LIQUID --typed-holes @-} Using the flag for typed holes, two more flags can be used: max-match-depth : Maximum number of pattern match expressions used during synthesis (default value: 4). max-app-depth : Maximum number of same function applications used during synthesis (default value: 2). Having the program specified in a Haskell source file, use GHC' s hole variables, e.g.: {-@ myMap :: (a -> b) -> xs:[a] -> {v:[b] | len v == len xs} @-} myMap :: (a -> b) -> [a] -> [b] myMap = _goal Limitations \u00b6 This is an experimental feature, so potential users could only expect to synthesize programs, like these . Current limitations include: No boolean conditionals are synthesized. Holes can only appear at top level, e.g.: {-@ f :: x: [a] -> { v: [a] | v == x } @-} f :: [a] -> [a] -- This works f = _hole -- This does not work f x = _hole Only one hole can appear in each module.","title":"<i aria-hidden=true class='mdi mdi-script'></i> Spec Reference"},{"location":"specifications/#writing-specifications","text":"This section documents how you can actually annotate new or existing code with refinement types, leveraging the full power of LiquidHaskell. There are a lot of different ways to annotate your code, and so we've included a brief summary of each here. {-@ inline <binding-name> @-} copies a Haskell definition to the refinement logic. ( Jump to: Inlines ) All parts of the definition must already be available to the refinement logic. The definition cannot be recursive. {-@ measure <function-name>[ <refinement-type>] @-} copies a Haskell function to the refinement logic, adds an inferred refinement type to the constructor of the function's first argument, and emits an inferred global invariant related to the refinement. ( Jump to: Measures ) All parts of the definition must already be available to the refinement logic. The function must have only one argument and it must pattern match on the constructors of the type. The function may structurally recurse on the single argument. {-@ reflect <function-name> @-} creates an uninterpreted function of the same name in the refinement logic, copies the implementation to a refinement type alias, and adds a refinement to the type of the uninterpreted function that specifies the type alias as a post-condition. ( See more: Section 2.2 of this paper ) All parts of the definition must already be available to the refinement logic. The function may be recursive. {-@ type <type-alias-head> = <refinement-type> @-} introduces a type alias that looks like Haskell syntax but can contain refinements and may be parameterized over both types and values. ( Jump to: Type Aliases ) {-@ predicate .. @-} introduces something like {-@ type .. @-} . ( Deprecated, use inline instead , Jump to: Predicate Aliases ) {-@ invariant <refinement-type> @-} introduces a globally available refinement which may be used by Liquid Haskel, but is not checked. ( Unchecked , Deprecated , Jump to: Invariants ) {-@ data <data-type-head><termination-measure>[ <data-type-body] @-} introduces a refined datatype, and introduces measures for each field of a record datatype. ( Jump to: Data Refinements ) Optionally you may also add refinements to datatype fields. Optionally you may also add a termination measure to the datatype. {-@ assume <binding-signature-with-refinement-type> @-} introduces a refinement type for the named Haskell definition. ( Unchecked ) For a function, the refinements become pre and post conditions for the functions use. {-@ <binding-signature-with-refinement-type> @-} introduces a refinement type for the named Haskell definition. For a function, the refinements become pre and post conditions for the functions use. This is probably the most used Liquid Haskell annotation! The following sections detail more variety for the uses of the above annotations.","title":"Writing Specifications"},{"location":"specifications/#modules-without-code","text":"The following section is slightly different depending on whether you are using the plugin (which you should!) or the legacy executable.","title":"Modules WITHOUT code"},{"location":"specifications/#plugin-adding-refinements-for-external-modules","text":"See the installation section, which cointains a link to a walkthrough document that describes how to add refinements for external packages (cfr. \"Providing Specifications for Existing Packages\" )","title":"(Plugin) Adding refinements for external modules"},{"location":"specifications/#legacy-executable-adding-refinements-for-external-modules","text":"When checking a file target.hs , you can specify an include directory by liquid -i /path/to/include/ target.hs Now, to write specifications for some external module Foo.Bar.Baz for which you do not have the code , you can create a .spec file at: /path/to/include/Foo/Bar/Baz.spec See, for example, the contents of: include/Prelude.spec include/Data/List.spec include/Data/Vector.spec Note : The above directories are part of the LH prelude, and included by default when running liquid . The .spec mechanism is only for external modules without code, see below for standalone specifications for internal or home * modules.","title":"(Legacy executable) Adding refinements for external modules"},{"location":"specifications/#modules-with-code-data","text":"Write the specification directly into the .hs or .lhs file, above the data definition. See, for example, tests/pos/Map.hs : {-@ data Map k a <l :: k -> k -> Prop, r :: k -> k -> Prop> = Tip | Bin (sz :: Size) (key :: k) (value :: a) (left :: Map <l, r> (k <l key>) a) (right :: Map <l, r> (k <r key>) a) @-} data Map k a = Tip | Bin Size k a (Map k a) (Map k a) You can also write invariants for data type definitions together with the types. For example, see tests/pos/record0.hs : {-@ data LL a = BXYZ { size :: {v: Int | v > 0 } , elems :: {v: [a] | (len v) = size } } @-} Finally you can specify the variance of type variables for data types. For example, see tests/pos/Variance.hs , where data type Foo has four type variables a , b , c , d , specified as invariant, bivariant, covariant and contravariant, respectively. {-@ data variance Foo invariant bivariant covariant contravariant @-} data Foo a b c d","title":"Modules WITH code: Data"},{"location":"specifications/#modules-with-code-functions","text":"Write the specification directly into the .hs or .lhs file, above the function definition. For example : {-@ incr :: x:{v: Int | v > 0} -> {v: Int | v > x} @-} incr :: Int -> Int incr x = x + 1","title":"Modules WITH code: Functions"},{"location":"specifications/#modules-with-code-type-classes","text":"Write the specification directly into the .hs or .lhs file. The constrained variable must match the one from the class definition. A class must have at least one refinement signature (even if it's a trivial one) to be lifted to the refinement logic. For example : class Semigroup a where {-@ mappend :: a -> a -> a @-} mappend :: a -> a -> a sconcat :: NonEmpty a -> a class Semigroup a => VSemigroup a where {-@ lawAssociative :: v:a -> v':a -> v'':a -> {mappend (mappend v v') v'' == mappend v (mappend v' v'')} @-} lawAssociative :: a -> a -> a -> () Without the extra signature for mappend , the above example would not work. Instances can be defined without any special annotations: data PNat = Z | S PNat instance Semigroup PNat where mappend Z n = n mappend (S m) n = S (mappend m n) sconcat (NonEmpty h t) = foldlList mappend h t instance VSemigroup PNat where lawAssociative Z _ _ = () lawAssociative (S p) m n = lawAssociative p m n The example above inlines the proofs directly into the instance definition. This requires the --aux-inline flag.","title":"Modules WITH code: Type Classes"},{"location":"specifications/#modules-with-code-type-classes-legacy","text":"Write the specification directly into the .hs or .lhs file, above the type class definition. For example : {-@ class Sized s where size :: forall a. x:s a -> {v:Int | v = (size x)} @-} class Sized s where size :: s a -> Int Any measures used in the refined class definition will need to be generic (see Specifying Measures ). As an alternative, you can refine class instances. For example : instance Compare Int where {-@ instance Compare Int where cmax :: Odd -> Odd -> Odd @-} cmax y x = if x >= y then x else y When cmax method is used on Int , liquidHaskell will give it the refined type Odd -> Odd -> Odd . Note that currently liquidHaskell does not allow refining instances of refined classes .","title":"Modules WITH code: Type Classes (Legacy)"},{"location":"specifications/#modules-with-code-quasiquotation","text":"Instead of writing both a Haskell type signature and a LiquidHaskell specification for a function, the lq quasiquoter in the LiquidHaskell module can be used to generate both from just the LiquidHaskell specification. module Nats (nats) where {-@ nats :: [{v:Int | 0 <= v}] @-} nats :: [Int] nats = [1,2,3] can be written as {-# LANGUAGE QuasiQuotes #-} module Nats (nats) where import LiquidHaskell [lq| nats :: [{v:Int | 0 <= v}] |] nats = [1,2,3] and the lq quasiquoter will generate the plain nats :: [Int] when GHC compiles the module. Refined type aliases (see the next section) can also be written inside lq ; for example: {-# LANGUAGE QuasiQuoters #-} module Nats (Nat, nats) where [lq| type Nat = {v:Int | 0 <= v} |] [lq| nats :: [Nat] |] nats = [1,2,3] Here, the lq quasiquoter will generate a plain Haskell type synonym for Nat as well as the refined one. Note that this is still an experimental feature, and currently requires that one depend on LiquidHaskell as a build dependency for your project; the quasiquoter will be split out eventually into an independent, dependency-light package. Also, at this time, writing a type inside lq which refers to a refined type alias for which there is not a plain Haskell type synonym of the same name will result in a \"not in scope\" error from GHC.","title":"Modules WITH code: QuasiQuotation"},{"location":"specifications/#standalone-specifications-for-internal-modules","text":"Recall that the .spec mechanism is only for modules whose code is absent; if code is present then there can be multiple, possibly conflicting specifications. Nevertheless, you may want, for one reason or another, to write (assumed) specifications outside the file implementing the module. You can do this as follows. Lib.hs module Lib (foo) where foo a = a now, instead of a .spec file, just use a haskell module, e.g. LibSpec.hs module LibSpec ( module Lib ) where import Lib -- Don't forget to qualify the name! {-@ Lib.foo :: {v:a | false} -> a @-} and then here's Client.hs module Client where import Lib -- use this if you DON'T want the spec import LibSpec -- use this if you DO want the spec, in addition to OR instead of the previous import. bar = foo 1 -- if you `import LibSpec` then this call is rejected by LH","title":"Standalone Specifications for Internal Modules"},{"location":"specifications/#inductive-predicates","text":"Status: very_experimental LH recently added support for Inductive Predicates in the style of Isabelle, Coq etc. These are encoded simply as plain Haskell GADTs but suitably refined. Apologies for the minimal documentation; see the following examples for details: Palindrome Permutations Transitive Closure RegExp Derivatives Type Safety of STLC","title":"Inductive Predicates"},{"location":"specifications/#implicit-arguments","text":"Status: experimental There is experimental support for implicit arguments, solved for with congruence closure. For example, consider Implicit1.hs : {-@ type IntN N = {v:Int | v = N} @-} {-@ foo :: n:Int ~> (() -> IntN n) -> IntN {n+1} @-} foo f = 1 + f () {-@ test1 :: IntN 11 @-} test1 = foo (\\_ -> 10) Here, the refinement on (\\_ -> 10) :: Int -> { v:Int | v = 10 } allows us to solve for n = 10 , the implicit argument to foo .","title":"Implicit Arguments"},{"location":"specifications/#refinement-type-aliases","text":"","title":"Refinement Type Aliases"},{"location":"specifications/#predicate-aliases","text":"Often, the propositions in the refinements can get rather long and verbose. You can write predicate aliases like so: {-@ predicate Lt X Y = X < Y @-} {-@ predicate Ge X Y = not (Lt X Y) @-} and then use the aliases inside refinements, for example {-@ incr :: x:{v:Int | (Pos v)} -> { v:Int | ((Pos v) && (Ge v x))} @-} incr :: Int -> Int incr x = x + 1 See Data.Map for a more substantial and compelling example. Syntax: The key requirements for type aliases are: Value parameters are specified in upper case: X , Y , Z etc.","title":"Predicate Aliases"},{"location":"specifications/#failing-specifications","text":"The fail b declaration checks that the definition of b is unsafe. E.g., the following is SAFE. {-@ fail unsafe @-} {-@ unsafe :: () -> { 0 == 1 } @-} unsafe :: () -> () unsafe _ = () An error is created if fail definitions are safe or binders defined as fail are used by (failing or not) definitions.","title":"Failing Specifications"},{"location":"specifications/#type-aliases","text":"Similarly, it is often quite tedious to keep writing {v: Int | v > 0} Thus, LiquidHaskell supports refinement-type aliases of the form: {-@ type Gt N = {v: Int | N < v} @-} {-@ type GeNum a N = {v: a | N <= v} @-} or {-@ type SortedList a = [a]<{\\fld v -> (v >= fld)}> @-} or {-@ type OMap k a = Map <{\\root v -> v < root}, {\\root v -> v > root}> k a @-} or {-@ type MinSPair a = (a, OSplay a) <\\fld -> {v : Splay {v:a|v>fld} | 0=0}> @-} and then use the above in signatures like: {-@ incr: x: Int -> GeNum Int x @-} or {-@ incr: x: Int -> Gt x @-} and: {-@ assert insert :: (Ord a) => a -> SortedList a -> SortedList a @-} see tests/pos/ListSort.hs and: {-@ assert insert :: (Ord k) => k -> a -> OMap k a -> OMap k a @-} see tests/pos/Map.hs Syntax: The key requirements for type aliases are: Type parameters are specified in lower case: a , b , c etc. Value parameters are specified in upper case: X , Y , Z etc.","title":"Type Aliases"},{"location":"specifications/#infix-operators","text":"You can define infix types and logical operators in logic Haskell's infix notation . For example, if (+++) is defined as a measure or reflected function, you can use it infix by declaring {-@ infixl 9 +++ @-} Note: infix operators cannot contain the dot character . . If (==>) is a Haskell infix type ( see ) infixr 1 ==> then to use it as infix in the refinements types you need to add the refinement infix notation. {-@ infixr 1 ==> @-} {-@ test :: g:(f ==> g) -> f x -> f y -> () @-}","title":"Infix  Operators"},{"location":"specifications/#specifying-measures","text":"They can be placed in a .spec file or in a .hs/.lhs file wrapped around {-@ @-} . Value measures: GHC/Base.spec measure len :: forall a. [a] -> GHC.Types.Int len ([]) = 0 len (y:ys) = 1 + len(ys) Propositional measures: tests/pos/LambdaEval.hs {-@ measure isValue :: Expr -> Bool isValue (Const i) = true isValue (Lam x e) = true isValue (Var x) = false isValue (App e1 e2) = false isValue (Plus e1 e2) = false isValue (Fst e) = false isValue (Snd e) = false isValue (Pair e1 e2) = ((? (isValue(e1))) && (? (isValue(e2)))) @-} Raw measures: tests/pos/meas8.hs {-@ measure rlen :: [a] -> Int rlen ([]) = {v | v = 0} rlen (y:ys) = {v | v = (1 + rlen(ys))} @-} Generic measures: tests/pos/Class.hs {-@ class measure size :: a -> Int @-} {-@ instance measure size :: [a] -> Int size ([]) = 0 size (x:xs) = 1 + (size xs) @-} {-@ instance measure size :: Tree a -> Int size (Leaf) = 0 size (Node x l r) = 1 + (size l) + (size r) @-} Note: Measure names do not have to be the same as field name, e.g. we could call the measure sz in the above as shown in tests/pos/Class2.hs . Haskell Functions as Measures (beta): tests/pos/HaskellMeasure.hs Inductive Haskell Functions from Data Types to some type can be lifted to logic {-@ measure llen @-} llen :: [a] -> Int llen [] = 0 llen (x:xs) = 1 + llen xs The above definition: refines list's data constructors types with the llen information, and specifies a singleton type for the haskell function llen :: xs:[a] -> {v:Int | v == llen xs} . If the user specifies another type for llen , say llen :: xs:[a] -> {v:Int | llen xs >= 0} , then the auto generated singleton type is overwritten.","title":"Specifying Measures"},{"location":"specifications/#inlines","text":"The inline lets you use a Haskell function in a type specification. {-@ inline max @-} {-@ max :: Int -> Int -> Int @-} max :: Int -> Int -> Int max x y = if x > y then x else y For example, if you write the above you can then write a function: {-@ floor :: x:Int -> {v:Int | max 0 x} @-} floor :: Int -> Int floor x | x <= 0 = 0 | otherwise = x That is, you can use the haskell max in the refinement type and it will automatically get \u201cexpanded\u201d out to the full definition. This makes it useful e.g. to reuse plain Haskell code to compose specifications, and to share definitions common to refinements and code. However, as they are expanded at compile time, inline functions cannot be recursive . The can call other (non-recursive) inline functions. If you want to talk about arbitrary (recursive) functions inside your types, then you need to use reflect described in the blog .","title":"Inlines"},{"location":"specifications/#self-invariants","text":"Sometimes, we require specifications that allow inner components of a type to refer to the outer components, typically, to measure-based properties of outer components. For example, the following invariant about Maybe values {-@ type IMaybe a = {v0 : Maybe {v : a | ((isJust v0) && v = (fromJust v0))} | 0 = 0 } @-} states that the inner a enjoys the property that the outer container is definitely a Just and furthermore, the inner value is exactly the same as the fromJust property of the outer container. As another example, suppose we have a measure : measure listElts :: [a] -> (Set a) listElts([]) = {v | (? Set_emp(v))} listElts(x:xs) = {v | v = Set_cup(Set_sng(x), listElts(xs)) } Now, all lists enjoy the property {-@ type IList a = {v0 : List {v : a | (Set_mem v (listElts v0)) } | true } @-} which simply states that each inner element is indeed, a member of the set of the elements belonging to the entire list. One often needs these circular or self invariants to connect different levels (or rather, to reify the connections between the two levels.) See this test for a simple example and hedgeUnion and Data.Map.Base for a complex one.","title":"Self-Invariants"},{"location":"specifications/#abstract-and-bounded-refinements","text":"This is probably the best example of the abstract refinement syntax: Abstract Refinements Bounded Refinements Unfortunately, the best documentation for these two advanced features is the relevant papers at: ESOP 2013 ICFP 2015 The bounds correspond to Horn implications between abstract refinements, which, as in the classical setting, correspond to subtyping constraints that must be satisfied by the concrete refinements used at any call-site.","title":"Abstract and Bounded Refinements"},{"location":"specifications/#dependent-pairs","text":"Dependent Pairs are expressed by binding the initial tuples of the pair. For example incrPair defines an increasing pair. {-@ incrPair :: Int -> (x::Int, {v:Int | x <= v}) @-} incrPair i = (i, i+1) Internally dependent pairs are implemented using abstract refinement types. That is (x::a, {v:b | p x}) desugars to (a,b)<\\x -> {v:b | p x}> .","title":"Dependent Pairs"},{"location":"specifications/#invariants","text":"LH lets you locally associate invariants with specific data types. For example, in tests/measure/pos/Using00.hs every list is treated as a Stream . To establish this local invariant one can use the using declaration {-@ using ([a]) as {v:[a] | (len v > 0)} @-} denoting that each list is not empty. Then, LiquidHaskell will prove that this invariant holds, by proving that all calls to List's constructors (ie., : and [] ) satisfy it, and will assume that each list element that is created satisfies this invariant. With this, at the above test LiquidHaskell proves that taking the head of a list is safe. But, at tests/measure/neg/Using00.hs the usage of [] falsifies this local invariant resulting in an \"Invariant Check\" error. WARNING: There is an older global invariant mechanism that attaches a refinement to a datatype globally. Do not use this mechanism -- it is unsound and about to deprecated in favor of something that is actually sound For example, the length of a list cannot be negative {-@ invariant {v:[a] | (len v >= 0)} @-} LiquidHaskell can prove that this invariant holds, by proving that all List's constructors (ie., : and [] ) satisfy it.(TODO!) Then, LiquidHaskell assumes that each list element that is created satisfies this invariant.","title":"Invariants"},{"location":"specifications/#rewriting","text":"Status: experimental You use the rewriteWith annotation to indicate equalities that PLE will apply automatically. For example, suppose that you have proven associativity of ++ for lists. {-@ assoc :: xs:[a] -> ys:[a] -> zs:[a] -> { xs ++ (ys ++ zs) == (xs ++ ys) ++ zs } @-} Using the rewriteWith annotation, PLE will automatically apply the equality for associativity whenever it encounters an expression of the form xs ++ (ys ++ zs) or (xs ++ ys) ++ zs . For example, you can prove assoc2 for free. {-@ rewriteWith assoc2 [assoc] @-} {-@ assoc2 :: xs:[a] -> ys:[a] -> zs:[a] -> ws:[a] -> { xs ++ (ys ++ (zs ++ ws)) == ((xs ++ ys) ++ zs) ++ ws } @-} assoc2 :: [a] -> [a] -> [a] -> [a] -> () assoc2 xs ys zs ws = () You can also annotate a function as being a global rewrite rule by using the rewrite annotation, in which case PLE will apply it across the entire module. {-@ rewrite assoc @-} {-@ assoc :: xs:[a] -> ys:[a] -> zs:[a] -> { xs ++ (ys ++ zs) == (xs ++ ys) ++ zs } @-}","title":"Rewriting"},{"location":"specifications/#limitations","text":"Currently, rewriting does not work if the equality that uses the rewrite rule includes parameters that contain inner refinements ( test ). Rewriting works by pattern-matching expressions to determine if there is a variable substitution that would allow it to match against either side of a rewrite rule. If so, that substitution is applied to the opposite side and the corresponding equality is generated. If one side of the equality contains any parameters that are not bound on the other side, it will not be possible to generate a rewrite in that direction, because those variables cannot be instantiated. Likewise, if there are free variables on both sides of an equality, no rewrite can be generated at all ( test ). It's possible in theory for rewriting rules to diverge. We have a simple check to ensure that rewriting rules that will always diverge do not get instantiated. However, it's possible that applying a combination of rewrite rules could cause divergence.","title":"Limitations"},{"location":"specifications/#formal-grammar-of-refinement-predicates","text":"","title":"Formal Grammar of Refinement Predicates"},{"location":"specifications/#constants","text":"c := 0, 1, 2, ...","title":"(C)onstants"},{"location":"specifications/#variables","text":"v := x, y, z, ...","title":"(V)ariables"},{"location":"specifications/#expressions","text":"e := v -- variable | c -- constant | (e + e) -- addition | (e - e) -- subtraction | (c * e) -- multiplication by constant | (v e1 e2 ... en) -- uninterpreted function application | (if p then e else e) -- if-then-else","title":"(E)xpressions"},{"location":"specifications/#relations","text":"r := == -- equality | /= -- disequality | >= -- greater than or equal | <= -- less than or equal | > -- greater than | < -- less than","title":"(R)elations"},{"location":"specifications/#predicates","text":"p := (e r e) -- binary relation | (v e1 e2 ... en) -- predicate (or alias) application | (p && p) -- and | (p || p) -- or | (p => p) -- implies | (not p) -- negation | true | false","title":"(P)redicates"},{"location":"specifications/#specifying-qualifiers","text":"There are several ways to specify qualifiers.","title":"Specifying Qualifiers"},{"location":"specifications/#by-separate-hquals-files","text":"You can write qualifier files e.g. Prelude.hquals .. If a module is called or imports Foo.Bar.Baz Then the system automatically searches for include/Foo/Bar/Baz.hquals","title":"By Separate .hquals Files"},{"location":"specifications/#by-including-hquals-files","text":"Additional qualifiers may be used by adding lines of the form: {-@ include <path/to/file.hquals> @-} to the Haskell source. See, this for example.","title":"By Including .hquals Files"},{"location":"specifications/#in-haskell-source-or-spec-files","text":"Finally, you can specifiers directly inside source (.hs or .lhs) or spec (.spec) files by writing as shown here {-@ qualif Foo(v:Int, a: Int) : (v = a + 100) @-} Note In addition to these, LiquidHaskell scrapes qualifiers from all the specifications you write i.e. all imported type signatures, measure bodies and, data constructor definitions.","title":"In Haskell Source or Spec Files"},{"location":"specifications/#termination-metrics","text":"In recursive functions the first algebraic or integer argument should be decreasing. The default decreasing measure for lists is length and Integers its value.","title":"Termination Metrics"},{"location":"specifications/#default-termination-metrics","text":"The user can specify the size of a data-type in the data definition {-@ data L [llen] a = Nil | Cons { x::a, xs:: L a} @-} In the above, the measure llen , which needs to be defined by the user (see below), is defined as the default metric for the type L a . LH will use this default metric to automatically prove that the following terminates: append :: L a -> L a -> L a append N ys = ys append (Cons x xs) ys = Cons x (append xs ys) as, by default the first (non-function) argument with an associated size metric is checked to be strictly terminating and non-negative at each recursive call. A default termination metric is a Haskell function that is proved terminating using structural induction. To deactivate structional induction check on the termination metric, use the --trust-sizes flag.","title":"Default Termination Metrics"},{"location":"specifications/#explicit-termination-metrics","text":"However, consider the function reverse : reverseAcc :: L a -> L a -> L a reverseAcc acc N = acc reverseAcc acc (Cons x xs) = reverseAcc (Cons x acc) xs Here, the first argument does not decrease, instead the second does. We can tell LH to use the second argument using the explicit termination metric reverseAcc :: L a -> xs:L a -> L a / [llen xs] which tells LH that the llen of the second argument xs is what decreases at each recursive call. Decreasing expressions can be arbitrary refinement expressions, e.g., {-@ merge :: Ord a => xs:L a -> ys:L a -> L a / [llen xs + llen ys] @-} states that at each recursive call of merge the sum of the lengths of its arguments will decrease.","title":"Explicit Termination Metrics"},{"location":"specifications/#lexicographic-termination-metrics","text":"Some functions do not decrease on a single argument, but rather a combination of arguments, e.g. the Ackermann function. {-@ ack :: m:Int -> n:Int -> Nat / [m, n] @-} ack m n | m == 0 = n + 1 | m > 0 && n == 0 = ack (m-1) 1 | m > 0 && n > 0 = ack (m-1) (ack m (n-1)) In all but one recursive call m decreases, in the final call m does not decrease but n does. We can capture this notion of m normally decreases, but if it does not, n will decrease with a lexicographic termination metric [m, n] . An alternative way to express this specification is by annotating the function's type with the appropriate numeric decreasing expressions. As an example, you can give ack a type {-@ ack :: m:Nat -> n:Nat -> Nat / [m,n] @-} stating that the numeric expressions [m, n] are lexicographically decreasing.","title":"Lexicographic Termination Metrics"},{"location":"specifications/#mutually-recursive-functions","text":"When dealing with mutually recursive functions you may run into a situation where the decreasing parameter must be measured across a series of invocations, e.g. even :: Int -> Bool even 0 = True even n = odd (n-1) odd :: Int -> Bool odd n = not (even n) In this case, you can introduce a ghost parameter that orders the functions {-@ isEven :: n:Nat -> Bool / [n, 0] @-} isEven :: Int -> Bool isEven 0 = True isEven n = isOdd (n-1) {-@ isOdd :: n:Nat -> Bool / [n, 1] @-} isOdd :: Int -> Bool isOdd n = not $ isEven n thus recovering a decreasing measure for the pair of functions, the pair of arguments. This can be encoded with the lexicographic termination annotation as shown above. See tests/pos/mutrec.hs for the full example.","title":"Mutually Recursive Functions"},{"location":"specifications/#automatic-termination-metrics","text":"Apart from specifying a specific decreasing measure for an Algebraic Data Type, the user can specify that the ADT follows the expected decreasing measure by {-@ autosize L @-} Then, LH will define an instance of the function autosize for L that decreases by 1 at each recursive call and use autosize at functions that recurse on L . For example, autosize L will refine the data constructors of L a with the autosize :: a -> Int information, such that Nil :: {v:L a | autosize v = 0} Cons :: x:a -> xs:L a -> {v:L a | autosize v = 1 + autosize xs} Also, an invariant that autosize is non negative will be generated invariant {v:L a| autosize v >= 0 } This information is all LiquidHaskell needs to prove termination on functions that recurse on L a (on ADTs in general.)","title":"Automatic Termination Metrics"},{"location":"specifications/#disabling-termination-checking","text":"To disable termination checking for foo that is, to assume that it is terminating (possibly for some complicated reason currently beyond the scope of LH) you can write {-@ lazy foo @-}","title":"Disabling Termination Checking"},{"location":"specifications/#synthesis","text":"Status: experimental LH has some very preliminary support for program synthesis.","title":"Synthesis"},{"location":"specifications/#how-to-use-it","text":"Activate the flag for typed holes in LiquidHaskell. E.g. from command line: liquid --typedholes In a Haskell source file: {-@ LIQUID --typed-holes @-} Using the flag for typed holes, two more flags can be used: max-match-depth : Maximum number of pattern match expressions used during synthesis (default value: 4). max-app-depth : Maximum number of same function applications used during synthesis (default value: 2). Having the program specified in a Haskell source file, use GHC' s hole variables, e.g.: {-@ myMap :: (a -> b) -> xs:[a] -> {v:[b] | len v == len xs} @-} myMap :: (a -> b) -> [a] -> [b] myMap = _goal","title":"How to use it"},{"location":"specifications/#limitations_1","text":"This is an experimental feature, so potential users could only expect to synthesize programs, like these . Current limitations include: No boolean conditionals are synthesized. Holes can only appear at top level, e.g.: {-@ f :: x: [a] -> { v: [a] | v == x } @-} f :: [a] -> [a] -- This works f = _hole -- This does not work f x = _hole Only one hole can appear in each module.","title":"Limitations"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/","text":"One of the great things about Haskell is its brainy type system that allows one to enforce a variety of invariants at compile time, thereby nipping a large swathe of run-time errors in the bud. Refinement types allow us to use modern logic solvers ( aka SAT and SMT engines) to dramatically extend the scope of invariants that can be statically verified. What is a Refinement Type? \u00b6 In a nutshell, Refinement Types = Types + Logical Predicates That is, refinement types allow us to decorate types with logical predicates (think boolean-valued Haskell expressions) which constrain the set of values described by the type, and hence allow us to specify sophisticated invariants of the underlying values. Say what? (Btw, click the title to demo LiquidHaskell on the code in this article) 42: module Intro where 43: 44: import Language . Haskell . Liquid . Prelude ( liquidAssert ) Let us jump right in with a simple example, the number 0 :: Int . As far as Haskell is concerned, the number is simply an Int (lets not worry about things like Num for the moment). So are 2 , 7 , and 904 . With refinements we can dress up these values so that they stand apart. For example, consider the binder 54: zero' :: Int 55: {VV : (GHC.Types.Int) | (0 <= VV)} zero' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 We can ascribe to the variable zero' the refinement type 61: {-@ zero' :: {v: Int | 0 <= v} @-} which is simply the basic type Int dressed up with a predicate. The binder v is called the value variable , and so the above denotes the set of Int values which are greater than 0 . Of course, we can attach other predicates to the above value, for example Note: We will use @ -marked comments to write refinement type annotations the Haskell source file, making these types, quite literally, machine-checked comments! 75: {-@ zero'' :: {v: Int | (0 <= v && v < 100) } @-} 76: zero'' :: Int 77: {VV : (GHC.Types.Int) | (VV < 100),(0 <= VV)} zero'' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 which states that the number is in the range 0 to 100 , or 83: {-@ zero''' :: {v: Int | ((v mod 2) = 0) } @-} 84: zero''' :: Int 85: {VV : (GHC.Types.Int) | ((VV mod 2) = 0)} zero''' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 where mod is the modulus operator in the refinement logic. Thus, the type above states that zero is an even number. We can also use a singleton type that precisely describes the constant 94: {-@ zero'''' :: {v: Int | v = 0 } @-} 95: zero'''' :: Int 96: {VV : (GHC.Types.Int) | (VV = 0)} zero'''' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 (Aside: we use a different names zero' , zero'' etc. for a silly technical reason -- LiquidHaskell requires that we ascribe a single refinement type to a top-level name.) Finally, we could write a single type that captures all the properties above: 106: {-@ zero :: {v: Int | ((0 <= v) && ((v mod 2) = 0) && (v < 100)) } @-} 107: zero :: Int 108: {VV : (GHC.Types.Int) | ((VV mod 2) = 0),(VV < 100),(0 <= VV)} zero = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 The key points are: A refinement type is just a type decorated with logical predicates. A value can have different refinement types that describe different properties. If we erase the green bits (i.e. the logical predicates) we get back exactly the usual Haskell types that we know and love. A vanilla Haskell type, say Int has the trivial refinement true i.e. is really {v: Int | true} . We have built a refinement type-based verifier called LiquidHaskell. Lets see how we can use refinement types to specify and verify interesting program invariants in LiquidHaskell. Writing Safety Specifications \u00b6 We can use refinement types to write various kinds of more interesting safety specifications. First, we can write a wrapper around the usual error function 133: {-@ error' :: {v: String | false } -> a @-} 134: error' :: String -> a 135: {VV : [(GHC.Types.Char)] | false} -> a error' = [(GHC.Types.Char)] -> a error The interesting thing about the type signature for error' is that the input type has the refinement false . That is, the function must only be called with String s that satisfy the predicate false . Of course, there are no such values. Thus, a program containing the above function typechecks exactly when LiquidHaskell can prove that the function error' is never called . Next, we can use refinements to encode arbitrary programmer-specified assertions by defining a function 149: {-@ lAssert :: {v: Bool | (Prop v)} -> a -> a @-} 150: lAssert :: Bool -> a -> a 151: {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> a -> a lAssert True a x = {VV : a | (VV = x)} x 152: lAssert False _ = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"lAssert failure\" In the refinement, (Prop v) denotes the Haskell Bool value v interpreted as a logical predicate. In other words, the input type for this function specifies that the function must only be called with the value True . Refining Function Types : Preconditions \u00b6 Lets use the above to write a divide function that only accepts non-zero denominators. 168: divide :: Int -> Int -> Int 169: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 170: divide n d = {VV : (GHC.Types.Int) | (VV = n)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV != 0)} d We can specify that the non-zero denominator precondition with a suitable refinement on the input component of the function's type 177: {-@ divide :: Int -> {v: Int | v != 0 } -> Int @-} How does LiquidHaskell verify the above function? The key step is that LiquidHaskell deduces that the expression \"divide by zero\" is not merely of type String , but in fact has the the refined type {v:String | false} in the context in which the call to error' occurs. LiquidHaskell arrives at this conclusion by using the fact that in the first equation for divide the denominator parameter is in fact 0 :: {v: Int | v = 0} which contradicts the precondition (i.e. input) type. In other words, LiquidHaskell deduces by contradiction, that the first equation is dead code and hence error' will not be called at run-time. If you are paranoid, you can put in an explicit assertion 199: divide' :: Int -> Int -> Int 200: {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} divide' {VV : (GHC.Types.Int) | false} n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 201: divide' n d = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} lAssert ( {VV : (GHC.Types.Int) | false} d x:{VV : (GHC.Types.Int) | false} -> y:{VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ({VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false}) -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} $ {VV : (GHC.Types.Int) | false} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | false} d and LiquidHaskell will verify the assertion (by verifying the call to lAssert ) for you. Refining Function Types : Postconditions \u00b6 Next, lets see how we can use refinements to describe the outputs of a function. Consider the following simple absolute value function 214: abz :: Int -> Int 215: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n)} n = {VV : (GHC.Types.Int) | (VV = n)} n 216: | otherwise = {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = n)} n We can use a refinement on the output type to specify that the function returns non-negative values 223: {-@ abz :: Int -> {v: Int | 0 <= v } @-} LiquidHaskell verifies that abz indeed enjoys the above type by deducing that n is trivially non-negative when 0 < n and that in the otherwise case, i.e. when not (0 < n) the value 0 - n is indeed non-negative (lets not worry about underflows for the moment.) LiquidHaskell is able to automatically make these arithmetic deductions by using an SMT solver which has decision built-in procedures for arithmetic, to reason about the logical refinements. Putting It All Together \u00b6 Lets wrap up this introduction with a simple truncate function that connects all the dots. 244: {-@ truncate :: Int -> Int -> Int @-} 245: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate (GHC.Types.Int) i (GHC.Types.Int) max 246: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 247: | otherwise = {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 248: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 249: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max truncate i n simply returns i if its absolute value is less the upper bound max , and otherwise truncates the value at the maximum. LiquidHaskell verifies that the use of divide is safe by inferring that at the call site i' > max' from the branch condition. 0 <= i' from the abz postcondition (hover mouse over i' ). 0 <= max' from the abz postcondition (hover mouse over max' ). From the above, LiquidHaskell infers that i' != 0 . That is, at the call site i' :: {v: Int | v != 0} , thereby satisfying the precondition for divide and verifying that the program has no pesky divide-by-zero errors. Again, if you really want to make sure, put in an assertion 268: {-@ truncate' :: Int -> Int -> Int @-} 269: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate' (GHC.Types.Int) i (GHC.Types.Int) max 270: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 271: | otherwise = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> (GHC.Types.Int) -> (GHC.Types.Int) lAssert ( {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ((GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) -> (GHC.Types.Int) $ {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 272: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 273: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max and lo! LiquidHaskell will verify it for you. Modular Verification \u00b6 Incidentally, note the import statement at the top. Rather than rolling our own lAssert we can import and use a pre-defined version liquidAssert defined in an external module 286: {-@ truncate'' :: Int -> Int -> Int @-} 287: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate'' (GHC.Types.Int) i (GHC.Types.Int) max 288: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 289: | otherwise = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> (GHC.Types.Int) -> (GHC.Types.Int) liquidAssert ( {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ((GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) -> (GHC.Types.Int) $ {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 290: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 291: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max In fact, LiquidHaskell comes equipped with suitable refinements for standard functions and it is easy to add refinements as we shall demonstrate in subsequent articles. Conclusion \u00b6 This concludes our quick introduction to Refinement Types and LiquidHaskell. Hopefully you have some sense of how to Specify fine-grained properties of values by decorating their types with logical predicates. Encode assertions, preconditions, and postconditions with suitable function types. Verify semantic properties of code by using automatic logic engines (SMT solvers) to track and establish the key relationships between program values.","title":"Refinement Types 101"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#what-is-a-refinement-type","text":"In a nutshell, Refinement Types = Types + Logical Predicates That is, refinement types allow us to decorate types with logical predicates (think boolean-valued Haskell expressions) which constrain the set of values described by the type, and hence allow us to specify sophisticated invariants of the underlying values. Say what? (Btw, click the title to demo LiquidHaskell on the code in this article) 42: module Intro where 43: 44: import Language . Haskell . Liquid . Prelude ( liquidAssert ) Let us jump right in with a simple example, the number 0 :: Int . As far as Haskell is concerned, the number is simply an Int (lets not worry about things like Num for the moment). So are 2 , 7 , and 904 . With refinements we can dress up these values so that they stand apart. For example, consider the binder 54: zero' :: Int 55: {VV : (GHC.Types.Int) | (0 <= VV)} zero' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 We can ascribe to the variable zero' the refinement type 61: {-@ zero' :: {v: Int | 0 <= v} @-} which is simply the basic type Int dressed up with a predicate. The binder v is called the value variable , and so the above denotes the set of Int values which are greater than 0 . Of course, we can attach other predicates to the above value, for example Note: We will use @ -marked comments to write refinement type annotations the Haskell source file, making these types, quite literally, machine-checked comments! 75: {-@ zero'' :: {v: Int | (0 <= v && v < 100) } @-} 76: zero'' :: Int 77: {VV : (GHC.Types.Int) | (VV < 100),(0 <= VV)} zero'' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 which states that the number is in the range 0 to 100 , or 83: {-@ zero''' :: {v: Int | ((v mod 2) = 0) } @-} 84: zero''' :: Int 85: {VV : (GHC.Types.Int) | ((VV mod 2) = 0)} zero''' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 where mod is the modulus operator in the refinement logic. Thus, the type above states that zero is an even number. We can also use a singleton type that precisely describes the constant 94: {-@ zero'''' :: {v: Int | v = 0 } @-} 95: zero'''' :: Int 96: {VV : (GHC.Types.Int) | (VV = 0)} zero'''' = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 (Aside: we use a different names zero' , zero'' etc. for a silly technical reason -- LiquidHaskell requires that we ascribe a single refinement type to a top-level name.) Finally, we could write a single type that captures all the properties above: 106: {-@ zero :: {v: Int | ((0 <= v) && ((v mod 2) = 0) && (v < 100)) } @-} 107: zero :: Int 108: {VV : (GHC.Types.Int) | ((VV mod 2) = 0),(VV < 100),(0 <= VV)} zero = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 The key points are: A refinement type is just a type decorated with logical predicates. A value can have different refinement types that describe different properties. If we erase the green bits (i.e. the logical predicates) we get back exactly the usual Haskell types that we know and love. A vanilla Haskell type, say Int has the trivial refinement true i.e. is really {v: Int | true} . We have built a refinement type-based verifier called LiquidHaskell. Lets see how we can use refinement types to specify and verify interesting program invariants in LiquidHaskell.","title":"What is a Refinement Type?"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#writing-safety-specifications","text":"We can use refinement types to write various kinds of more interesting safety specifications. First, we can write a wrapper around the usual error function 133: {-@ error' :: {v: String | false } -> a @-} 134: error' :: String -> a 135: {VV : [(GHC.Types.Char)] | false} -> a error' = [(GHC.Types.Char)] -> a error The interesting thing about the type signature for error' is that the input type has the refinement false . That is, the function must only be called with String s that satisfy the predicate false . Of course, there are no such values. Thus, a program containing the above function typechecks exactly when LiquidHaskell can prove that the function error' is never called . Next, we can use refinements to encode arbitrary programmer-specified assertions by defining a function 149: {-@ lAssert :: {v: Bool | (Prop v)} -> a -> a @-} 150: lAssert :: Bool -> a -> a 151: {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> a -> a lAssert True a x = {VV : a | (VV = x)} x 152: lAssert False _ = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"lAssert failure\" In the refinement, (Prop v) denotes the Haskell Bool value v interpreted as a logical predicate. In other words, the input type for this function specifies that the function must only be called with the value True .","title":"Writing Safety Specifications"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#refining-function-types-preconditions","text":"Lets use the above to write a divide function that only accepts non-zero denominators. 168: divide :: Int -> Int -> Int 169: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 170: divide n d = {VV : (GHC.Types.Int) | (VV = n)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV != 0)} d We can specify that the non-zero denominator precondition with a suitable refinement on the input component of the function's type 177: {-@ divide :: Int -> {v: Int | v != 0 } -> Int @-} How does LiquidHaskell verify the above function? The key step is that LiquidHaskell deduces that the expression \"divide by zero\" is not merely of type String , but in fact has the the refined type {v:String | false} in the context in which the call to error' occurs. LiquidHaskell arrives at this conclusion by using the fact that in the first equation for divide the denominator parameter is in fact 0 :: {v: Int | v = 0} which contradicts the precondition (i.e. input) type. In other words, LiquidHaskell deduces by contradiction, that the first equation is dead code and hence error' will not be called at run-time. If you are paranoid, you can put in an explicit assertion 199: divide' :: Int -> Int -> Int 200: {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} divide' {VV : (GHC.Types.Int) | false} n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} error' {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 201: divide' n d = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} lAssert ( {VV : (GHC.Types.Int) | false} d x:{VV : (GHC.Types.Int) | false} -> y:{VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ({VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false}) -> {VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Int) | false} $ {VV : (GHC.Types.Int) | false} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | false} d and LiquidHaskell will verify the assertion (by verifying the call to lAssert ) for you.","title":"Refining Function Types : Preconditions"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#refining-function-types-postconditions","text":"Next, lets see how we can use refinements to describe the outputs of a function. Consider the following simple absolute value function 214: abz :: Int -> Int 215: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n)} n = {VV : (GHC.Types.Int) | (VV = n)} n 216: | otherwise = {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = n)} n We can use a refinement on the output type to specify that the function returns non-negative values 223: {-@ abz :: Int -> {v: Int | 0 <= v } @-} LiquidHaskell verifies that abz indeed enjoys the above type by deducing that n is trivially non-negative when 0 < n and that in the otherwise case, i.e. when not (0 < n) the value 0 - n is indeed non-negative (lets not worry about underflows for the moment.) LiquidHaskell is able to automatically make these arithmetic deductions by using an SMT solver which has decision built-in procedures for arithmetic, to reason about the logical refinements.","title":"Refining Function Types : Postconditions"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#putting-it-all-together","text":"Lets wrap up this introduction with a simple truncate function that connects all the dots. 244: {-@ truncate :: Int -> Int -> Int @-} 245: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate (GHC.Types.Int) i (GHC.Types.Int) max 246: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 247: | otherwise = {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 248: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 249: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max truncate i n simply returns i if its absolute value is less the upper bound max , and otherwise truncates the value at the maximum. LiquidHaskell verifies that the use of divide is safe by inferring that at the call site i' > max' from the branch condition. 0 <= i' from the abz postcondition (hover mouse over i' ). 0 <= max' from the abz postcondition (hover mouse over max' ). From the above, LiquidHaskell infers that i' != 0 . That is, at the call site i' :: {v: Int | v != 0} , thereby satisfying the precondition for divide and verifying that the program has no pesky divide-by-zero errors. Again, if you really want to make sure, put in an assertion 268: {-@ truncate' :: Int -> Int -> Int @-} 269: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate' (GHC.Types.Int) i (GHC.Types.Int) max 270: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 271: | otherwise = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> (GHC.Types.Int) -> (GHC.Types.Int) lAssert ( {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ((GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) -> (GHC.Types.Int) $ {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 272: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 273: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max and lo! LiquidHaskell will verify it for you.","title":"Putting It All Together"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#modular-verification","text":"Incidentally, note the import statement at the top. Rather than rolling our own lAssert we can import and use a pre-defined version liquidAssert defined in an external module 286: {-@ truncate'' :: Int -> Int -> Int @-} 287: (GHC.Types.Int) -> (GHC.Types.Int) -> (GHC.Types.Int) truncate'' (GHC.Types.Int) i (GHC.Types.Int) max 288: | {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(VV >= zero''''),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' = {VV : (GHC.Types.Int) | (VV = i)} i 289: | otherwise = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> (GHC.Types.Int) -> (GHC.Types.Int) liquidAssert ( {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= zero''''), (0 <= VV), (VV <= i')} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ) ((GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) -> (GHC.Types.Int) $ {VV : (GHC.Types.Int) | (VV = max'),(0 <= VV)} max' x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (GHC.Types.Int) | (VV = i)} i (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = i'),(0 <= VV)} i' ) 290: where {VV : (GHC.Types.Int) | (0 <= VV)} i' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = i)} i 291: {VV : (GHC.Types.Int) | (0 <= VV)} max' = (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = max)} max In fact, LiquidHaskell comes equipped with suitable refinements for standard functions and it is easy to add refinements as we shall demonstrate in subsequent articles.","title":"Modular Verification"},{"location":"blogposts/2013-01-01-refinement-types-101.lhs/#conclusion","text":"This concludes our quick introduction to Refinement Types and LiquidHaskell. Hopefully you have some sense of how to Specify fine-grained properties of values by decorating their types with logical predicates. Encode assertions, preconditions, and postconditions with suitable function types. Verify semantic properties of code by using automatic logic engines (SMT solvers) to track and establish the key relationships between program values.","title":"Conclusion"},{"location":"blogposts/2013-01-27-refinements101-reax.lhs/","text":"Hopefully, the previous article gave you a basic idea about what refinement types look like. Several folks had interesting questions, that are worth discussing in a separate post, since they throw a lot of light on the strengths (or weaknesses, depending on your point of view!) of LiquidHaskell. 22: module Refinements101Reax where How to relate outputs and inputs \u00b6 Recall the function divide 31: {-@ divide :: Int -> {v: Int | v /= 0 } -> Int @-} 32: divide :: Int -> Int -> Int 33: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = [(GHC.Types.Char)] -> {VV : (GHC.Types.Int) | false} error {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 34: divide n d = {VV : (GHC.Types.Int) | (VV = n)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV != 0)} d and abz was the absolute value function 40: abz :: Int -> Int 41: x:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | ((VV = 0) <=> (x = 0)),(0 <= VV)} abz (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n)} n = {VV : (GHC.Types.Int) | (VV = n)} n 42: | otherwise = {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = n)} n nanothief remarked that LiquidHaskell was unable to verify the safety of the following call to divide (i.e. was unable to show that x was non-zero at the callsite). 50: {-@ f :: Int -> Int @-} 51: (GHC.Types.Int) -> (GHC.Types.Int) f (GHC.Types.Int) x | x:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | ((VV = 0) <=> (x = 0)),(0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = x)} x x:{VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 3 52: | otherwise = {VV : (GHC.Types.Int) | (VV = (3 : int))} 3 (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = x)} x Nanothief correctly argues that the code is clearly safe as \" abz x == 0 being false implies x /= 0 \" . Indeed, the code is safe , however, the reason that LiquidHaskell rejected it has nothing to do with its inability to \"track the constraints of values based on tests using new values derived from that value\" as Nanothief surmised, but instead, because LiquidHaskell supports modular verification where the only thing known about abz at a use site is whatever is specified in its type . Concretely speaking, the type 64: abz :: Int -> { v : Int | 0 <= v } is too anemic to verify f above, as it tells us nothing about the relationship between the output and input -- looking at it, we have now way of telling that when the output (of abz ) is non-zero, the input must also have been non-zero. Instead, we can write a stronger type which does capture this information, for example 73: abz :: x : Int -> { v : Int | v = ( if ( x > 0 ) then x else ( 0 - x ) ) } where 77: v = ( if p then e1 else e2 ) is an abbreviation for the formula 81: ( p => v == e1 ) && ( ( not p ) => v = e2 ) With this specification for abz , LiquidHaskell is able to reason that when abz x is non-zero, x is also non-zero. Of course, abz is trivial enough that we can very precisely capture its exact semantics in the refinement type, but thats is rarely the case. Nevertheless, even here, you could write a somewhat weaker specification, that still had enough juice to allow the verification of the divide call in f . In particular, we might write 94: {-@ abz :: x : Int -> {v: Int | ((0 <= v) && ((v = 0) <=> (x = 0))) } @-} which states the output is 0 if and only if the input is 0 . LiquidHaskell will happily verify that abz implements this specification, and will use it to verify the safety of f above. (BTW, follow the link above to demo this code yourself.) How to tell a Fib \u00b6 Chris Done asked why LiquidHaskell refused to verify the following definition of fib . 110: {-@ fib :: n : Int -> { b: Int | (n >= 0 && b >= n) } @-} 111: fib :: Int -> Int 112: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 113: fib 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 114: fib n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) Indeed, the both the specification and the implementation look pretty legit, so what gives? It turns out that there are two different reasons why. Reason 1: Assumptions vs. Guarantees What we really want to say over here is that the input n is non-negative. However, putting the refinement n >= 0 in the output constraint means that it becomes something that LiquidHaskell checks that the function fib guarantees (or ensures ). That is, the type states that we can pass fib any value n (including negative values) and yet, fib must return values b such that b >= n and n >= 0 . The latter requirement is a rather tall order when an arbitrary n is passed in as input. fib can make no such guarantees since it was given the value n as a parameter. The only way n could be non-negative was that if the caller had sent in a non-negative value. Thus, we want to put the burden of proof on the right entity here, namely the caller. To assign the burden of proof appropriately, we place the non-negative refinement on the input type 142: {-@ fib' :: n : {v: Int | v >= 0} -> {b: Int | (n >= 0 && b >= n) } @-} 143: fib' :: Int -> Int 144: n:{VV : (GHC.Types.Int) | (VV >= 0)} -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib' 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 145: fib' 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 146: fib' n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( {VV : (GHC.Types.Int) | (VV >= 0)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( {VV : (GHC.Types.Int) | (VV >= 0)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) where now at calls to fib' LiquidHaskell will check that the argument is non-negative, and furthermore, when checking fib' LiquidHaskell will assume that the parameter n is indeed non-negative. So now the constraint n >= 0 on the output is somewhat redundant, and the non-negative n guarantee holds trivially. Reason 2: The Specification is a Fib If you run the above in the demo, you will see that LiquidHaskell still doth protest loudly, and frankly, one might start getting a little frustrated at the stubbornness and petulance of the checker. However, if you stare at the implementation, you will see that it in fact, does not meet the specification, as 162: fib' 2 == fib' 1 + fib' 0 163: == 0 + 1 164: == 1 LiquidHaskell is reluctant to prove things that are false. Rather than anthropomorphize frivolously, lets see why it is unhappy. First, recall the somewhat simplified specification 171: fib' :: n : Int -> { b : Int | ( b >= n ) } As we saw in the discussion about abz , at each recursive callsite the only information LiquidHaskell uses about the returned value, is that described in the output type for that function call. Thus, LiquidHaskell reasons that the expression: 179: fib' ( n - 1 ) + fib' ( n - 2 ) has the type 183: { b : Int | exists b1 , b2 . b == b1 + b2 184: && b1 >= n - 1 185: && b2 >= n - 2 } where the b1 and b2 denote the values returned by the recursive calls --- we get the above by plugging the parameters n-1 and n-2 in for the parameter n in output type for fib' . The SMT solver simplifies the above to 193: { b : Int | b >= 2 n - 3 } Finally, to check the output guarantee is met, LiquidHaskell asks the SMT solver to prove that 197: ( b >= 2 n - 2 ) => ( b >= n ) The SMT solver will refuse, of course, since the above implication is not valid (e.g. when n is 2 ) Thus, via SMT, LiquidHaskell proclaims that the function fib' does not implement the advertised type and hence marks it unsafe . Fixing The Code \u00b6 How then, do we get Chris' specification to work out? It seems like it should hold (except for that pesky case where n=2 . Indeed, let's rig the code, so that all the base cases return 1 . 213: {-@ fibOK :: n : Int -> {b: Int | ((b >= n) && (b >= 1))} @-} 214: fibOK :: Int -> Int 215: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 216: fibOK 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 217: fibOK n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) Here' we specify that not only is the output greater than the input, it is also greater than 1 . Now in the recursive case, LiquidHaskell reasons that the value being output is 224: { b : Int | exists b1 , b2 . b == b1 + b2 225: && b1 >= n - 1 && b1 >= 1 226: && b2 >= n - 2 && b2 >= 1 } which reduces to 230: { b : Int | b = 2 n - 3 && n >= 2 } which, the SMT solver is happy to verify, is indeed a subtype 234: of ( i . e . implies the refinement of ) the specified output 235: { b : Int | b >= n && b >= 1 } Conclusion \u00b6 There are several things to take away. We need to distinguish between assumptions and guarantees when writing specifications for functions. For modularity , LiquidHaskell, like every type system, uses only the (refinement) type of each function at each use site, and not the function's body . Some seemingly intuitive specifications often aren't; in future work it would be useful to actually generate tests as counterexamples that illustrate when a specification fails .","title":"Refinements 101 (contd.)"},{"location":"blogposts/2013-01-27-refinements101-reax.lhs/#how-to-relate-outputs-and-inputs","text":"Recall the function divide 31: {-@ divide :: Int -> {v: Int | v /= 0 } -> Int @-} 32: divide :: Int -> Int -> Int 33: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = [(GHC.Types.Char)] -> {VV : (GHC.Types.Int) | false} error {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 34: divide n d = {VV : (GHC.Types.Int) | (VV = n)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV != 0)} d and abz was the absolute value function 40: abz :: Int -> Int 41: x:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | ((VV = 0) <=> (x = 0)),(0 <= VV)} abz (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n)} n = {VV : (GHC.Types.Int) | (VV = n)} n 42: | otherwise = {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = n)} n nanothief remarked that LiquidHaskell was unable to verify the safety of the following call to divide (i.e. was unable to show that x was non-zero at the callsite). 50: {-@ f :: Int -> Int @-} 51: (GHC.Types.Int) -> (GHC.Types.Int) f (GHC.Types.Int) x | x:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | ((VV = 0) <=> (x = 0)),(0 <= VV)} abz {VV : (GHC.Types.Int) | (VV = x)} x x:{VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 3 52: | otherwise = {VV : (GHC.Types.Int) | (VV = (3 : int))} 3 (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV != 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV = x)} x Nanothief correctly argues that the code is clearly safe as \" abz x == 0 being false implies x /= 0 \" . Indeed, the code is safe , however, the reason that LiquidHaskell rejected it has nothing to do with its inability to \"track the constraints of values based on tests using new values derived from that value\" as Nanothief surmised, but instead, because LiquidHaskell supports modular verification where the only thing known about abz at a use site is whatever is specified in its type . Concretely speaking, the type 64: abz :: Int -> { v : Int | 0 <= v } is too anemic to verify f above, as it tells us nothing about the relationship between the output and input -- looking at it, we have now way of telling that when the output (of abz ) is non-zero, the input must also have been non-zero. Instead, we can write a stronger type which does capture this information, for example 73: abz :: x : Int -> { v : Int | v = ( if ( x > 0 ) then x else ( 0 - x ) ) } where 77: v = ( if p then e1 else e2 ) is an abbreviation for the formula 81: ( p => v == e1 ) && ( ( not p ) => v = e2 ) With this specification for abz , LiquidHaskell is able to reason that when abz x is non-zero, x is also non-zero. Of course, abz is trivial enough that we can very precisely capture its exact semantics in the refinement type, but thats is rarely the case. Nevertheless, even here, you could write a somewhat weaker specification, that still had enough juice to allow the verification of the divide call in f . In particular, we might write 94: {-@ abz :: x : Int -> {v: Int | ((0 <= v) && ((v = 0) <=> (x = 0))) } @-} which states the output is 0 if and only if the input is 0 . LiquidHaskell will happily verify that abz implements this specification, and will use it to verify the safety of f above. (BTW, follow the link above to demo this code yourself.)","title":"How to relate outputs and inputs"},{"location":"blogposts/2013-01-27-refinements101-reax.lhs/#how-to-tell-a-fib","text":"Chris Done asked why LiquidHaskell refused to verify the following definition of fib . 110: {-@ fib :: n : Int -> { b: Int | (n >= 0 && b >= n) } @-} 111: fib :: Int -> Int 112: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 113: fib 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 114: fib n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) Indeed, the both the specification and the implementation look pretty legit, so what gives? It turns out that there are two different reasons why. Reason 1: Assumptions vs. Guarantees What we really want to say over here is that the input n is non-negative. However, putting the refinement n >= 0 in the output constraint means that it becomes something that LiquidHaskell checks that the function fib guarantees (or ensures ). That is, the type states that we can pass fib any value n (including negative values) and yet, fib must return values b such that b >= n and n >= 0 . The latter requirement is a rather tall order when an arbitrary n is passed in as input. fib can make no such guarantees since it was given the value n as a parameter. The only way n could be non-negative was that if the caller had sent in a non-negative value. Thus, we want to put the burden of proof on the right entity here, namely the caller. To assign the burden of proof appropriately, we place the non-negative refinement on the input type 142: {-@ fib' :: n : {v: Int | v >= 0} -> {b: Int | (n >= 0 && b >= n) } @-} 143: fib' :: Int -> Int 144: n:{VV : (GHC.Types.Int) | (VV >= 0)} -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib' 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 145: fib' 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 146: fib' n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( {VV : (GHC.Types.Int) | (VV >= 0)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= n),(n >= 0)} fib ( {VV : (GHC.Types.Int) | (VV >= 0)} n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) where now at calls to fib' LiquidHaskell will check that the argument is non-negative, and furthermore, when checking fib' LiquidHaskell will assume that the parameter n is indeed non-negative. So now the constraint n >= 0 on the output is somewhat redundant, and the non-negative n guarantee holds trivially. Reason 2: The Specification is a Fib If you run the above in the demo, you will see that LiquidHaskell still doth protest loudly, and frankly, one might start getting a little frustrated at the stubbornness and petulance of the checker. However, if you stare at the implementation, you will see that it in fact, does not meet the specification, as 162: fib' 2 == fib' 1 + fib' 0 163: == 0 + 1 164: == 1 LiquidHaskell is reluctant to prove things that are false. Rather than anthropomorphize frivolously, lets see why it is unhappy. First, recall the somewhat simplified specification 171: fib' :: n : Int -> { b : Int | ( b >= n ) } As we saw in the discussion about abz , at each recursive callsite the only information LiquidHaskell uses about the returned value, is that described in the output type for that function call. Thus, LiquidHaskell reasons that the expression: 179: fib' ( n - 1 ) + fib' ( n - 2 ) has the type 183: { b : Int | exists b1 , b2 . b == b1 + b2 184: && b1 >= n - 1 185: && b2 >= n - 2 } where the b1 and b2 denote the values returned by the recursive calls --- we get the above by plugging the parameters n-1 and n-2 in for the parameter n in output type for fib' . The SMT solver simplifies the above to 193: { b : Int | b >= 2 n - 3 } Finally, to check the output guarantee is met, LiquidHaskell asks the SMT solver to prove that 197: ( b >= 2 n - 2 ) => ( b >= n ) The SMT solver will refuse, of course, since the above implication is not valid (e.g. when n is 2 ) Thus, via SMT, LiquidHaskell proclaims that the function fib' does not implement the advertised type and hence marks it unsafe .","title":"How to tell a Fib"},{"location":"blogposts/2013-01-27-refinements101-reax.lhs/#fixing-the-code","text":"How then, do we get Chris' specification to work out? It seems like it should hold (except for that pesky case where n=2 . Indeed, let's rig the code, so that all the base cases return 1 . 213: {-@ fibOK :: n : Int -> {b: Int | ((b >= n) && (b >= 1))} @-} 214: fibOK :: Int -> Int 215: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK 0 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 216: fibOK 1 = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 1 217: fibOK n = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 1),(VV >= n)} fibOK ( (GHC.Types.Int) n x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (2 : int))} 2 ) Here' we specify that not only is the output greater than the input, it is also greater than 1 . Now in the recursive case, LiquidHaskell reasons that the value being output is 224: { b : Int | exists b1 , b2 . b == b1 + b2 225: && b1 >= n - 1 && b1 >= 1 226: && b2 >= n - 2 && b2 >= 1 } which reduces to 230: { b : Int | b = 2 n - 3 && n >= 2 } which, the SMT solver is happy to verify, is indeed a subtype 234: of ( i . e . implies the refinement of ) the specified output 235: { b : Int | b >= n && b >= 1 }","title":"Fixing The Code"},{"location":"blogposts/2013-01-27-refinements101-reax.lhs/#conclusion","text":"There are several things to take away. We need to distinguish between assumptions and guarantees when writing specifications for functions. For modularity , LiquidHaskell, like every type system, uses only the (refinement) type of each function at each use site, and not the function's body . Some seemingly intuitive specifications often aren't; in future work it would be useful to actually generate tests as counterexamples that illustrate when a specification fails .","title":"Conclusion"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/","text":"Hopefully, these [articles ref102 gave you a basic idea about what basic refinement types look like. Today, lets move on to some fancier properties, namely, the static verification of vector access bounds . Along the way, we'll see some examples that illustrate how LiquidHaskell reasons about recursion , higher-order functions , data types , and polymorphism . 23: module VectorBounds ( 24: safeLookup 25: , unsafeLookup , unsafeLookup' 26: , absoluteSum , absoluteSum' 27: , dotProduct 28: , sparseProduct , sparseProduct' 29: ) where 30: 31: import Prelude hiding ( length ) 32: import Data . List ( foldl' ) 33: import Data . Vector hiding ( foldl' ) Specifying Bounds for Vectors \u00b6 One classical use-case for refinement types is to verify the safety of accesses of arrays and vectors and such, by proving that the indices used in such accesses are within the vector bounds. In this article, we will illustrate this use case by writing a few short functions that manipulate vectors, in particular, those from the popular vector library. To start off, lets specify bounds safety by refining the types for the key functions exported by the module Data.Vector . Specifications for Data.Vector 50: module spec Data . Vector where 51: 52: import GHC . Base 53: 54: measure vlen :: ( Vector a ) -> Int 55: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } 56: assume ! :: x : ( Vector a ) -> { v : Int | ( ( 0 <= v ) && ( v < ( vlen x ) ) ) } -> a In particular, we define a property called vlen which denotes the size of the vector, assume that the length function returns an integer equal to the vector's size, and assume that the lookup function ! requires an index between 0 and the vector's size. There are several things worth paying close attention to in the above snippet. Measures Measures define auxiliary (or so-called ghost ) properties of data values that are useful for specification and verification, but which don't actually exist at run-time . Thus, they will only appear in specifications , i.e. inside type refinements, but never inside code. Often we will use helper functions like length in this case, which pull or materialize the ghost values from the refinement world into the actual code world. Assumes We write assume because in this scenario we are not verifying the implementation of Data.Vector , we are simply using the properties of the library to verify client code. If we wanted to verify the library itself, we would ascribe the above types to the relevant functions in the Haskell source for Data.Vector . Dependent Refinements Notice that in the function type (e.g. for length ) we have named the input parameter x so that we can refer to it in the output refinement. In this case, the type 90: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } states that the Int output is exactly equal to the size of the input Vector named x . In other words, the output refinement depends on the input value, which crucially allows us to write properties that relate different program values. Verifying a Simple Wrapper Lets try write some simple functions to sanity check the above specifications. First, consider an unsafe vector lookup function: 104: forall a. vec:(Vector a) -> {VV : (Int) | (VV < vlen([vec])),(0 <= VV)} -> a unsafeLookup (Vector a) vec {VV : (Int) | (VV >= 0),(VV < vlen([vec])),(0 <= VV)} index = {VV : (Vector a) | (VV = vec),(vlen([VV]) >= 0)} vec x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = index),(VV >= 0),(VV < vlen([vec])),(0 <= VV)} index If we run this through LiquidHaskell, it will spit back a type error for the expression x ! i because (happily!) it cannot prove that index is between 0 and the vlen vec . Of course, we can specify the bounds requirement in the input type 113: {-@ unsafeLookup :: vec : Vector a 114: -> {v: Int | (0 <= v && v < (vlen vec))} 115: -> a 116: @-} then LiquidHaskell is happy to verify the lookup. Of course, now the burden of ensuring the index is valid is pushed to clients of unsafeLookup . Instead, we might write a safe lookup function that performs the bounds check before looking up the vector: 126: forall a. {VV : (Vector {VV : a | false}) | false} -> {VV : (Int) | false} -> {VV : (Maybe {VV : a | false}) | false} safeLookup {VV : (Vector {VV : a | false}) | false} x {VV : (Int) | false} i 127: | {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (Int) | false} i x:(Bool) -> y:(Bool) -> {VV : (Bool) | ((? Prop([VV])) <=> && [(? Prop([x])); (? Prop([y]))])} && {VV : (Int) | false} i x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < x:(Vector {VV : a | false}) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector {VV : a | false}) | false} x = x:{VV : a | false} -> {VV : (Maybe {VV : a | false}) | ((? isJust([VV])) <=> true), (fromJust([VV]) = x)} Just ( {VV : (Vector {VV : a | false}) | false} x x:(Vector {VV : a | false}) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (Int) | false} i ) 128: | otherwise = {VV : (Maybe {VV : a | false}) | ((? isJust([VV])) <=> false)} Nothing Predicate Aliases The type for unsafeLookup above is rather verbose as we have to spell out the upper and lower bounds and conjoin them. Just as we enjoy abstractions when programming, we will find it handy to have abstractions in the specification mechanism. To this end, LiquidHaskell supports predicate aliases , which are best illustrated by example 140: {-@ predicate Btwn Lo I Hi = ( Lo <= I && I < Hi ) @-} 141: {-@ predicate InBounds I A = ( Btwn 0 I ( vlen A ) ) @-} Now, we can simplify the type for the unsafe lookup function to 147: {-@ unsafeLookup' :: x : Vector a -> {v: Int | (InBounds v x)} -> a @-} 148: unsafeLookup' :: Vector a -> Int -> a 149: forall a. x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a unsafeLookup' (Vector a) x {VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} i = {VV : (Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i),(VV >= 0),(VV < vlen([x])),(0 <= VV)} i Our First Recursive Function \u00b6 OK, with the tedious preliminaries out of the way, lets write some code! To start: a vanilla recursive function that adds up the absolute values of the elements of an integer vector. 162: absoluteSum :: Vector Int -> Int 163: (Vector (Int)) -> {VV : (Int) | (0 <= VV)} absoluteSum (Vector (Int)) vec = x:(Int#) -> {VV : (Int) | (VV = (x : int))} if {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | (VV >= 0),(0 <= VV),(VV <= n),(VV <= vlen([vec]))} -> y:{VV : (Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (Int) | (VV = (0 : int))} 0 {VV : (Int) | (VV = (0 : int))} 0 else x:(Int#) -> {VV : (Int) | (VV = (x : int))} 0 164: where 165: x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (Int) | (VV >= 0),(0 <= VV)} acc {VV : (Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i 166: | {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i x:{VV : (Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec])), (i <= VV)} -> y:{VV : (Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec])), (i <= VV)} -> {VV : (Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n = x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go ( {VV : (Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + n:(Int) -> {VV : (Int) | (VV >= 0),(VV >= n)} abz ( {VV : (Vector (Int)) | (VV = vec), (VV = vec), (vlen([VV]) = vlen([vec])), (vlen([VV]) >= 0)} vec x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i ) ) ( {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + {VV : (Int) | (VV = (1 : int))} 1 ) 167: | otherwise = {VV : (Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc 168: {VV : (Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Vector (Int)) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector (Int)) | (VV = vec), (VV = vec), (vlen([VV]) = vlen([vec])), (vlen([VV]) >= 0)} vec where the function abz is the absolute value function from before . 174: forall a. (Num a) -> (Ord a) -> n:a -> {VV : a | (VV >= 0),(VV >= n)} abz a n = {VV : (Integer) | (VV = 0)} if a 0 x:a -> y:a -> {VV : (Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = n)} n then {VV : a | (VV = n)} n else ( a 0 x:a -> y:a -> {VV : a | (VV = (x - y))} - {VV : a | (VV = n)} n ) Digression: Introducing Errors \u00b6 If you are following along in the demo page -- I heartily recommend that you try the following modifications, one at a time, and see what happens. What happens if: You remove the check 0 < n You replace the guard with i <= n In each case, LiquidHaskell will grumble that your program is unsafe . Do you understand why? Refinement Type Inference \u00b6 LiquidHaskell happily verifies absoluteSum -- or, to be precise, the safety of the vector accesses vec ! i . The verification works out because LiquidHaskell is able automatically infer a suitable type for go . Shuffle your mouse over the identifier above to see the inferred type. Observe that the type states that The first parameter acc (and the output) is 0 <= V . That is, the returned value is non-negative. More importantly, the type states that the second parameter i is 0 <= V and V <= n and V <= (vlen vec) . That is, the parameter i is between 0 and the vector length (inclusive). LiquidHaskell uses these and the test that i /= n to establish that i is in fact between 0 and (vlen vec) thereby verifing safety. In fact, if we want to use the function externally (i.e. in another module) we can go ahead and strengthen its type to specify that the output is non-negative. 215: {-@ absoluteSum :: Vector Int -> {v: Int | 0 <= v} @-} What happens if: You replace the output type for absoluteSum with {v: Int | 0 < v } ? Bottling Recursion With a Higher-Order loop \u00b6 Next, lets refactor the above low-level recursive function into a generic higher-order loop . 227: loop :: Int -> Int -> a -> ( Int -> a -> a ) -> a 228: forall a. lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> a -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> a -> a) -> a loop {VV : (Int) | (VV >= 0),(0 <= VV)} lo {VV : (Int) | (VV >= 0),(VV >= lo),(0 <= VV),(lo <= VV)} hi a base {VV : (Int) | (VV >= 0),(VV >= lo),(VV < hi),(0 <= VV),(lo <= VV)} -> a -> a f = {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go {VV : a | (VV = base)} base {VV : (Int) | (VV = lo),(VV >= 0),(0 <= VV)} lo 229: where 230: {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go a acc {VV : (Int) | (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i 231: | {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:{VV : (Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> y:{VV : (Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> {VV : (Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (Int) | (VV = hi), (VV = hi), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (hi <= VV), (lo <= VV), (lo <= VV)} hi = {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go ( {VV : (Int) | (VV >= 0), (VV >= lo), (VV >= lo), (VV < hi), (VV < hi), (0 <= VV), (lo <= VV), (lo <= VV)} -> a -> a f {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i {VV : a | (VV = acc)} acc ) ( {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + {VV : (Int) | (VV = (1 : int))} 1 ) 232: | otherwise = {VV : a | (VV = acc)} acc Using loop to compute absoluteSum We can now use loop to implement absoluteSum like so: 240: forall a. (Num a) -> {VV : (Vector {VV : a | false}) | false} -> {VV : a | false} absoluteSum' {VV : (Vector {VV : a | false}) | false} vec = {VV : (Integer) | (VV = 0)} if {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> {VV : a | false} -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> {VV : a | false} -> {VV : a | false}) -> {VV : a | false} loop {VV : (Int) | (VV = (0 : int))} 0 {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n a 0 {VV : (Int) | false} -> {VV : a | false} -> {VV : a | false} body else {VV : (Integer) | (VV = 0)} 0 241: where {VV : (Int) | false} -> {VV : a | false} -> {VV : a | false} body = \\ {VV : (Int) | false} i {VV : a | false} acc -> {VV : a | false} acc x:a -> y:a -> {VV : a | (VV = (x + y))} + ( {VV : (Vector {VV : a | false}) | false} vec x:(Vector {VV : a | false}) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (Int) | false} i ) 242: {VV : (Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Vector {VV : a | false}) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector {VV : a | false}) | false} vec LiquidHaskell verifies absoluteSum' without any trouble. It is very instructive to see the type that LiquidHaskell infers for loop -- it looks something like 251: {-@ loop :: lo : {v: Int | (0 <= v) } 252: -> hi : {v: Int | ((0 <= v) && (lo <= v))} 253: -> a 254: -> ( i : {v: Int | (Btwn lo v hi)} -> a -> a ) 255: -> a 256: @-} In english, the above type states that lo the loop lower bound is a non-negative integer hi the loop upper bound is a greater than lo , f the loop body is only called with integers between lo and hi . Inference is a rather convenient option -- it can be tedious to have to keep typing things like the above! Of course, if we wanted to make loop a public or exported function, we could use the inferred type to generate an explicit signature too. At the call 271: loop 0 n 0 body the parameters lo and hi are instantiated with 0 and n respectively (which, by the way is where the inference engine deduces non-negativity from) and thus LiquidHaskell concludes that body is only called with values of i that are between 0 and (vlen vec) , which shows the safety of the call vec ! i . Using loop to compute dotProduct Here's another use of loop -- this time to compute the dotProduct of two vectors. 286: dotProduct :: Vector Int -> Vector Int -> Int 287: x:(Vector (Int)) -> {VV : (Vector (Int)) | (vlen([VV]) = vlen([x]))} -> (Int) dotProduct (Vector (Int)) x {VV : (Vector (Int)) | (vlen([VV]) = vlen([x])),(vlen([VV]) >= 0)} y = lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> (Int) -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> (Int) -> (Int)) -> (Int) loop {VV : (Int) | (VV = (0 : int))} 0 ( x:(Vector (Int)) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector (Int)) | (VV = x),(vlen([VV]) >= 0)} x ) {VV : (Int) | (VV = (0 : int))} 0 ( {VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} -> (Int) -> (Int) \\ {VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i -> ( x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + ( {VV : (Vector (Int)) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) x:(Int) -> y:(Int) -> {VV : (Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (Vector (Int)) | (VV = y), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} y x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) ) ) The gimlet-eyed reader will realize that the above is quite unsafe -- what if x is a 10-dimensional vector while y has only 3-dimensions? A nasty 294: *** Exception : ./ Data / Vector / Generic . hs : 244 ( ( ! ) ) : index out of bounds ... Yech . This is precisely the sort of unwelcome surprise we want to do away with at compile-time. Refinements to the rescue! We can specify that the vectors have the same dimensions quite easily 304: {-@ dotProduct :: x : ( Vector Int ) 305: -> y : {v: ( Vector Int ) | (vlen v) = (vlen x)} 306: -> Int 307: @-} after which LiquidHaskell will gladly verify that the implementation of dotProduct is indeed safe! Refining Data Types \u00b6 Next, suppose we want to write a sparse dot product , that is, the dot product of a vector and a sparse vector represented by a list of index-value tuples. Representing Sparse Vectors We can represent the sparse vector with a refinement type alias 325: {-@ type SparseVector a N = [ ( { v : Int | ( Btwn 0 v N ) } , a ) ] @-} As with usual types, the alias SparseVector on the left is just a shorthand for the (longer) type on the right, it does not actually define a new type. Thus, the above alias is simply a refinement of Haskell's [(Int, a)] type, with a size parameter N that facilitates easy specification reuse. In this way, refinements let us express invariants of containers like lists in a straightforward manner. Aside: If you are familiar with the index-style length encoding e.g. as found in DML or Agda , then note that despite appearances, our SparseVector definition is not indexed. Instead, we deliberately choose to encode properties with logical refinement predicates, to facilitate SMT based checking and inference. Verifying Uses of Sparse Vectors Next, we can write a recursive procedure that computes the sparse product 347: {-@ sparseProduct :: ( Num a ) => x : ( Vector a ) 348: -> SparseVector a ( vlen x ) 349: -> a 350: @-} 351: forall a. (Num a) -> x:(Vector a) -> [({VV : (Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct (Vector a) x [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] y = {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a 0 {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 352: where 353: {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a sum ( ( i , v ) : y' ) = {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go ( {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Vector a) | (VV = x), (VV = x), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v ) {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y'),(len([VV]) >= 0)} y' 354: go sum [] = {VV : a | (VV = sum)} sum LiquidHaskell verifies the above by using the specification for y to conclude that for each tuple (i, v) in the list, the value of i is within the bounds of the vector x , thereby proving the safety of the access x ! i . Refinements and Polymorphism \u00b6 The sharp reader will have undoubtedly noticed that the sparse product can be more cleanly expressed as a fold . Indeed! Let us recall the type of the foldl operation 369: foldl' :: ( a -> b -> a ) -> a -> [ b ] -> a Thus, we can simply fold over the sparse vector, accumulating the sum as we go along 376: {-@ sparseProduct' :: ( Num a ) => x : ( Vector a ) 377: -> SparseVector a ( vlen x ) 378: -> a 379: @-} 380: forall a. (Num a) -> x:(Vector a) -> [({VV : (Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct' (Vector a) x [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] y = (a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a) -> a -> [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] -> a foldl' a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a body a 0 {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 381: where a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a body a sum ( i , v ) = {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i),(VV >= 0),(VV < vlen([x])),(0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v LiquidHaskell digests this too, without much difficulty. The main trick is in how the polymorphism of foldl' is instantiated. The GHC type inference engine deduces that at this site, the type variable b from the signature of foldl' is instantiated to the Haskell type (Int, a) . Correspondingly, LiquidHaskell infers that in fact b can be instantiated to the refined type ({v: Int | (Btwn 0 v (vlen x))}, a) . Walk the mouse over to i to see this inferred type. (You can also hover over foldl' above to see the rather more verbose fully instantiated type.) Thus, the inference mechanism saves us a fair bit of typing and allows us to reuse existing polymorphic functions over containers and such without ceremony. Conclusion \u00b6 Thats all for now folks! Hopefully the above gives you a reasonable idea of how one can use refinements to verify size related properties, and more generally, to specify and verify properties of recursive, and polymorphic functions operating over datatypes. Next time, we'll look at how we can teach LiquidHaskell to think about properties of recursive structures like lists and trees.","title":"Bounding Vectors"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#specifying-bounds-for-vectors","text":"One classical use-case for refinement types is to verify the safety of accesses of arrays and vectors and such, by proving that the indices used in such accesses are within the vector bounds. In this article, we will illustrate this use case by writing a few short functions that manipulate vectors, in particular, those from the popular vector library. To start off, lets specify bounds safety by refining the types for the key functions exported by the module Data.Vector . Specifications for Data.Vector 50: module spec Data . Vector where 51: 52: import GHC . Base 53: 54: measure vlen :: ( Vector a ) -> Int 55: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } 56: assume ! :: x : ( Vector a ) -> { v : Int | ( ( 0 <= v ) && ( v < ( vlen x ) ) ) } -> a In particular, we define a property called vlen which denotes the size of the vector, assume that the length function returns an integer equal to the vector's size, and assume that the lookup function ! requires an index between 0 and the vector's size. There are several things worth paying close attention to in the above snippet. Measures Measures define auxiliary (or so-called ghost ) properties of data values that are useful for specification and verification, but which don't actually exist at run-time . Thus, they will only appear in specifications , i.e. inside type refinements, but never inside code. Often we will use helper functions like length in this case, which pull or materialize the ghost values from the refinement world into the actual code world. Assumes We write assume because in this scenario we are not verifying the implementation of Data.Vector , we are simply using the properties of the library to verify client code. If we wanted to verify the library itself, we would ascribe the above types to the relevant functions in the Haskell source for Data.Vector . Dependent Refinements Notice that in the function type (e.g. for length ) we have named the input parameter x so that we can refer to it in the output refinement. In this case, the type 90: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } states that the Int output is exactly equal to the size of the input Vector named x . In other words, the output refinement depends on the input value, which crucially allows us to write properties that relate different program values. Verifying a Simple Wrapper Lets try write some simple functions to sanity check the above specifications. First, consider an unsafe vector lookup function: 104: forall a. vec:(Vector a) -> {VV : (Int) | (VV < vlen([vec])),(0 <= VV)} -> a unsafeLookup (Vector a) vec {VV : (Int) | (VV >= 0),(VV < vlen([vec])),(0 <= VV)} index = {VV : (Vector a) | (VV = vec),(vlen([VV]) >= 0)} vec x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = index),(VV >= 0),(VV < vlen([vec])),(0 <= VV)} index If we run this through LiquidHaskell, it will spit back a type error for the expression x ! i because (happily!) it cannot prove that index is between 0 and the vlen vec . Of course, we can specify the bounds requirement in the input type 113: {-@ unsafeLookup :: vec : Vector a 114: -> {v: Int | (0 <= v && v < (vlen vec))} 115: -> a 116: @-} then LiquidHaskell is happy to verify the lookup. Of course, now the burden of ensuring the index is valid is pushed to clients of unsafeLookup . Instead, we might write a safe lookup function that performs the bounds check before looking up the vector: 126: forall a. {VV : (Vector {VV : a | false}) | false} -> {VV : (Int) | false} -> {VV : (Maybe {VV : a | false}) | false} safeLookup {VV : (Vector {VV : a | false}) | false} x {VV : (Int) | false} i 127: | {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (Int) | false} i x:(Bool) -> y:(Bool) -> {VV : (Bool) | ((? Prop([VV])) <=> && [(? Prop([x])); (? Prop([y]))])} && {VV : (Int) | false} i x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < x:(Vector {VV : a | false}) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector {VV : a | false}) | false} x = x:{VV : a | false} -> {VV : (Maybe {VV : a | false}) | ((? isJust([VV])) <=> true), (fromJust([VV]) = x)} Just ( {VV : (Vector {VV : a | false}) | false} x x:(Vector {VV : a | false}) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (Int) | false} i ) 128: | otherwise = {VV : (Maybe {VV : a | false}) | ((? isJust([VV])) <=> false)} Nothing Predicate Aliases The type for unsafeLookup above is rather verbose as we have to spell out the upper and lower bounds and conjoin them. Just as we enjoy abstractions when programming, we will find it handy to have abstractions in the specification mechanism. To this end, LiquidHaskell supports predicate aliases , which are best illustrated by example 140: {-@ predicate Btwn Lo I Hi = ( Lo <= I && I < Hi ) @-} 141: {-@ predicate InBounds I A = ( Btwn 0 I ( vlen A ) ) @-} Now, we can simplify the type for the unsafe lookup function to 147: {-@ unsafeLookup' :: x : Vector a -> {v: Int | (InBounds v x)} -> a @-} 148: unsafeLookup' :: Vector a -> Int -> a 149: forall a. x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a unsafeLookup' (Vector a) x {VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} i = {VV : (Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i),(VV >= 0),(VV < vlen([x])),(0 <= VV)} i","title":"Specifying Bounds for Vectors"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#our-first-recursive-function","text":"OK, with the tedious preliminaries out of the way, lets write some code! To start: a vanilla recursive function that adds up the absolute values of the elements of an integer vector. 162: absoluteSum :: Vector Int -> Int 163: (Vector (Int)) -> {VV : (Int) | (0 <= VV)} absoluteSum (Vector (Int)) vec = x:(Int#) -> {VV : (Int) | (VV = (x : int))} if {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | (VV >= 0),(0 <= VV),(VV <= n),(VV <= vlen([vec]))} -> y:{VV : (Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (Int) | (VV = (0 : int))} 0 {VV : (Int) | (VV = (0 : int))} 0 else x:(Int#) -> {VV : (Int) | (VV = (x : int))} 0 164: where 165: x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (Int) | (VV >= 0),(0 <= VV)} acc {VV : (Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i 166: | {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i x:{VV : (Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec])), (i <= VV)} -> y:{VV : (Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec])), (i <= VV)} -> {VV : (Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n = x6:{VV : (Int) | (VV = 0),(VV < n),(VV < vlen([vec])),(0 <= VV)} -> x4:{VV : (Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go ( {VV : (Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + n:(Int) -> {VV : (Int) | (VV >= 0),(VV >= n)} abz ( {VV : (Vector (Int)) | (VV = vec), (VV = vec), (vlen([VV]) = vlen([vec])), (vlen([VV]) >= 0)} vec x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i ) ) ( {VV : (Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (VV <= vlen([vec]))} i x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + {VV : (Int) | (VV = (1 : int))} 1 ) 167: | otherwise = {VV : (Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc 168: {VV : (Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Vector (Int)) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector (Int)) | (VV = vec), (VV = vec), (vlen([VV]) = vlen([vec])), (vlen([VV]) >= 0)} vec where the function abz is the absolute value function from before . 174: forall a. (Num a) -> (Ord a) -> n:a -> {VV : a | (VV >= 0),(VV >= n)} abz a n = {VV : (Integer) | (VV = 0)} if a 0 x:a -> y:a -> {VV : (Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = n)} n then {VV : a | (VV = n)} n else ( a 0 x:a -> y:a -> {VV : a | (VV = (x - y))} - {VV : a | (VV = n)} n )","title":"Our First Recursive Function"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#digression-introducing-errors","text":"If you are following along in the demo page -- I heartily recommend that you try the following modifications, one at a time, and see what happens. What happens if: You remove the check 0 < n You replace the guard with i <= n In each case, LiquidHaskell will grumble that your program is unsafe . Do you understand why?","title":"Digression: Introducing Errors"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#refinement-type-inference","text":"LiquidHaskell happily verifies absoluteSum -- or, to be precise, the safety of the vector accesses vec ! i . The verification works out because LiquidHaskell is able automatically infer a suitable type for go . Shuffle your mouse over the identifier above to see the inferred type. Observe that the type states that The first parameter acc (and the output) is 0 <= V . That is, the returned value is non-negative. More importantly, the type states that the second parameter i is 0 <= V and V <= n and V <= (vlen vec) . That is, the parameter i is between 0 and the vector length (inclusive). LiquidHaskell uses these and the test that i /= n to establish that i is in fact between 0 and (vlen vec) thereby verifing safety. In fact, if we want to use the function externally (i.e. in another module) we can go ahead and strengthen its type to specify that the output is non-negative. 215: {-@ absoluteSum :: Vector Int -> {v: Int | 0 <= v} @-} What happens if: You replace the output type for absoluteSum with {v: Int | 0 < v } ?","title":"Refinement Type Inference"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#bottling-recursion-with-a-higher-order-loop","text":"Next, lets refactor the above low-level recursive function into a generic higher-order loop . 227: loop :: Int -> Int -> a -> ( Int -> a -> a ) -> a 228: forall a. lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> a -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> a -> a) -> a loop {VV : (Int) | (VV >= 0),(0 <= VV)} lo {VV : (Int) | (VV >= 0),(VV >= lo),(0 <= VV),(lo <= VV)} hi a base {VV : (Int) | (VV >= 0),(VV >= lo),(VV < hi),(0 <= VV),(lo <= VV)} -> a -> a f = {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go {VV : a | (VV = base)} base {VV : (Int) | (VV = lo),(VV >= 0),(0 <= VV)} lo 229: where 230: {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go a acc {VV : (Int) | (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i 231: | {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:{VV : (Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> y:{VV : (Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> {VV : (Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (Int) | (VV = hi), (VV = hi), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (hi <= VV), (lo <= VV), (lo <= VV)} hi = {VV : a | (VV = base)} -> {VV : (Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go ( {VV : (Int) | (VV >= 0), (VV >= lo), (VV >= lo), (VV < hi), (VV < hi), (0 <= VV), (lo <= VV), (lo <= VV)} -> a -> a f {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i {VV : a | (VV = acc)} acc ) ( {VV : (Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + {VV : (Int) | (VV = (1 : int))} 1 ) 232: | otherwise = {VV : a | (VV = acc)} acc Using loop to compute absoluteSum We can now use loop to implement absoluteSum like so: 240: forall a. (Num a) -> {VV : (Vector {VV : a | false}) | false} -> {VV : a | false} absoluteSum' {VV : (Vector {VV : a | false}) | false} vec = {VV : (Integer) | (VV = 0)} if {VV : (Int) | (VV = (0 : int))} 0 x:{VV : (Int) | false} -> y:{VV : (Int) | false} -> {VV : (Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> {VV : a | false} -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> {VV : a | false} -> {VV : a | false}) -> {VV : a | false} loop {VV : (Int) | (VV = (0 : int))} 0 {VV : (Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n a 0 {VV : (Int) | false} -> {VV : a | false} -> {VV : a | false} body else {VV : (Integer) | (VV = 0)} 0 241: where {VV : (Int) | false} -> {VV : a | false} -> {VV : a | false} body = \\ {VV : (Int) | false} i {VV : a | false} acc -> {VV : a | false} acc x:a -> y:a -> {VV : a | (VV = (x + y))} + ( {VV : (Vector {VV : a | false}) | false} vec x:(Vector {VV : a | false}) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (Int) | false} i ) 242: {VV : (Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Vector {VV : a | false}) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector {VV : a | false}) | false} vec LiquidHaskell verifies absoluteSum' without any trouble. It is very instructive to see the type that LiquidHaskell infers for loop -- it looks something like 251: {-@ loop :: lo : {v: Int | (0 <= v) } 252: -> hi : {v: Int | ((0 <= v) && (lo <= v))} 253: -> a 254: -> ( i : {v: Int | (Btwn lo v hi)} -> a -> a ) 255: -> a 256: @-} In english, the above type states that lo the loop lower bound is a non-negative integer hi the loop upper bound is a greater than lo , f the loop body is only called with integers between lo and hi . Inference is a rather convenient option -- it can be tedious to have to keep typing things like the above! Of course, if we wanted to make loop a public or exported function, we could use the inferred type to generate an explicit signature too. At the call 271: loop 0 n 0 body the parameters lo and hi are instantiated with 0 and n respectively (which, by the way is where the inference engine deduces non-negativity from) and thus LiquidHaskell concludes that body is only called with values of i that are between 0 and (vlen vec) , which shows the safety of the call vec ! i . Using loop to compute dotProduct Here's another use of loop -- this time to compute the dotProduct of two vectors. 286: dotProduct :: Vector Int -> Vector Int -> Int 287: x:(Vector (Int)) -> {VV : (Vector (Int)) | (vlen([VV]) = vlen([x]))} -> (Int) dotProduct (Vector (Int)) x {VV : (Vector (Int)) | (vlen([VV]) = vlen([x])),(vlen([VV]) >= 0)} y = lo:{VV : (Int) | (0 <= VV)} -> hi:{VV : (Int) | (0 <= VV),(lo <= VV)} -> (Int) -> ({VV : (Int) | (VV < hi),(lo <= VV)} -> (Int) -> (Int)) -> (Int) loop {VV : (Int) | (VV = (0 : int))} 0 ( x:(Vector (Int)) -> {VV : (Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Vector (Int)) | (VV = x),(vlen([VV]) >= 0)} x ) {VV : (Int) | (VV = (0 : int))} 0 ( {VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} -> (Int) -> (Int) \\ {VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i -> ( x:(Int) -> y:(Int) -> {VV : (Int) | (VV = (x + y))} + ( {VV : (Vector (Int)) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) x:(Int) -> y:(Int) -> {VV : (Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (Vector (Int)) | (VV = y), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} y x:(Vector (Int)) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> (Int) ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) ) ) The gimlet-eyed reader will realize that the above is quite unsafe -- what if x is a 10-dimensional vector while y has only 3-dimensions? A nasty 294: *** Exception : ./ Data / Vector / Generic . hs : 244 ( ( ! ) ) : index out of bounds ... Yech . This is precisely the sort of unwelcome surprise we want to do away with at compile-time. Refinements to the rescue! We can specify that the vectors have the same dimensions quite easily 304: {-@ dotProduct :: x : ( Vector Int ) 305: -> y : {v: ( Vector Int ) | (vlen v) = (vlen x)} 306: -> Int 307: @-} after which LiquidHaskell will gladly verify that the implementation of dotProduct is indeed safe!","title":"Bottling Recursion With a Higher-Order loop"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#refining-data-types","text":"Next, suppose we want to write a sparse dot product , that is, the dot product of a vector and a sparse vector represented by a list of index-value tuples. Representing Sparse Vectors We can represent the sparse vector with a refinement type alias 325: {-@ type SparseVector a N = [ ( { v : Int | ( Btwn 0 v N ) } , a ) ] @-} As with usual types, the alias SparseVector on the left is just a shorthand for the (longer) type on the right, it does not actually define a new type. Thus, the above alias is simply a refinement of Haskell's [(Int, a)] type, with a size parameter N that facilitates easy specification reuse. In this way, refinements let us express invariants of containers like lists in a straightforward manner. Aside: If you are familiar with the index-style length encoding e.g. as found in DML or Agda , then note that despite appearances, our SparseVector definition is not indexed. Instead, we deliberately choose to encode properties with logical refinement predicates, to facilitate SMT based checking and inference. Verifying Uses of Sparse Vectors Next, we can write a recursive procedure that computes the sparse product 347: {-@ sparseProduct :: ( Num a ) => x : ( Vector a ) 348: -> SparseVector a ( vlen x ) 349: -> a 350: @-} 351: forall a. (Num a) -> x:(Vector a) -> [({VV : (Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct (Vector a) x [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] y = {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a 0 {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 352: where 353: {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a sum ( ( i , v ) : y' ) = {VV : a | (VV = 0)} -> {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go ( {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Vector a) | (VV = x), (VV = x), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v ) {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y'),(len([VV]) >= 0)} y' 354: go sum [] = {VV : a | (VV = sum)} sum LiquidHaskell verifies the above by using the specification for y to conclude that for each tuple (i, v) in the list, the value of i is within the bounds of the vector x , thereby proving the safety of the access x ! i .","title":"Refining Data Types"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#refinements-and-polymorphism","text":"The sharp reader will have undoubtedly noticed that the sparse product can be more cleanly expressed as a fold . Indeed! Let us recall the type of the foldl operation 369: foldl' :: ( a -> b -> a ) -> a -> [ b ] -> a Thus, we can simply fold over the sparse vector, accumulating the sum as we go along 376: {-@ sparseProduct' :: ( Num a ) => x : ( Vector a ) 377: -> SparseVector a ( vlen x ) 378: -> a 379: @-} 380: forall a. (Num a) -> x:(Vector a) -> [({VV : (Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct' (Vector a) x [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] y = (a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a) -> a -> [({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a)] -> a foldl' a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a body a 0 {VV : [({VV : (Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 381: where a -> ({VV : (Int) | (VV >= 0),(VV < vlen([x])),(0 <= VV)} , a) -> a body a sum ( i , v ) = {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Vector a) -> {VV : (Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (Int) | (VV = i),(VV >= 0),(VV < vlen([x])),(0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v LiquidHaskell digests this too, without much difficulty. The main trick is in how the polymorphism of foldl' is instantiated. The GHC type inference engine deduces that at this site, the type variable b from the signature of foldl' is instantiated to the Haskell type (Int, a) . Correspondingly, LiquidHaskell infers that in fact b can be instantiated to the refined type ({v: Int | (Btwn 0 v (vlen x))}, a) . Walk the mouse over to i to see this inferred type. (You can also hover over foldl' above to see the rather more verbose fully instantiated type.) Thus, the inference mechanism saves us a fair bit of typing and allows us to reuse existing polymorphic functions over containers and such without ceremony.","title":"Refinements and Polymorphism"},{"location":"blogposts/2013-01-28-bounding-vectors.lhs/#conclusion","text":"Thats all for now folks! Hopefully the above gives you a reasonable idea of how one can use refinements to verify size related properties, and more generally, to specify and verify properties of recursive, and polymorphic functions operating over datatypes. Next time, we'll look at how we can teach LiquidHaskell to think about properties of recursive structures like lists and trees.","title":"Conclusion"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/","text":"Previously we saw some examples of how refinements could be used to encode invariants about basic Int values. Today, let's see how refinements allow us specify and verify structural invariants about recursive data types like lists. In particular, we will learn about at a new mechanism called a measure , use measures to describe the length of a list, and use the resulting refinement types to obtain compile-time assurances that canonical list manipulating operations like head , tail , foldl1 and (incomplete) pattern matches will not blow up at run-time. 26: module ListLengths where 27: 28: import Prelude hiding ( length , map , filter , head , tail , foldl1 ) 29: import Language . Haskell . Liquid . Prelude ( liquidError ) 30: import qualified Data . HashMap . Strict as M 31: import Data . Hashable Measuring the Length of a List \u00b6 To begin, we need some instrument by which to measure the length of a list. To this end, let's introduce a new mechanism called measures which define auxiliary (or so-called ghost ) properties of data values. These properties are useful for specification and verification, but don't actually exist at run-time . That is, measures will appear in specifications but never inside code. Let's reuse this mechanism, this time, providing a definition for the measure 48: measure len :: forall a . [ a ] -> GHC . Types . Int 49: len ( [] ) = 0 50: len ( y : ys ) = 1 + ( len ys ) The description of len above should be quite easy to follow. Underneath the covers, LiquidHaskell transforms the above description into refined versions of the types for the constructors (:) and [] , Something like 57: data [ a ] where 58: [] :: forall a . { v : [ a ] | ( len v ) = 0 } 59: ( : ) :: forall a . y : a -> ys : [ a ] -> { v : [ a ] | ( len v ) = 1 + ( len ys ) } To appreciate this, note that we can now check that 65: {-@ xs :: {v: [ String ] | (len v) = 1 } @-} 66: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 1)} xs = {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"dog\" y:{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} -> ys:[{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] -> {VV : [{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : [{VV : [{VV : (GHC.Types.Char) | false}] | false}] | (len([VV]) = 0), (len([VV]) >= 0)} [] 67: 68: {-@ ys :: {v: [ String ] | (len v) = 2 } @-} 69: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 2)} ys = {VV : [{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] | (len([VV]) >= 0)} [ {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"cat\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"dog\" ] 70: 71: {-@ zs :: {v: [ String ] | (len v) = 3 } @-} 72: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 3)} zs = {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"hippo\" y:[(GHC.Types.Char)] -> ys:[[(GHC.Types.Char)]] -> {VV : [[(GHC.Types.Char)]] | (len([VV]) = (1 + len([ys])))} : {VV : [[(GHC.Types.Char)]] | (VV = ys), (len([VV]) = 2), (len([VV]) >= 0)} ys Dually, when we de-construct the lists, LiquidHaskell is able to relate the type of the outer list with its constituents. For example, 79: {-@ zs' :: {v: [ String ] | (len v) = 2 } @-} 80: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 2)} zs' = case {VV : [[(GHC.Types.Char)]] | (VV = zs), (len([VV]) = 3), (len([VV]) >= 0)} zs of 81: h : t -> {VV : [[(GHC.Types.Char)]] | (VV = t),(len([VV]) >= 0)} t Here, from the use of the : in the pattern, LiquidHaskell can determine that (len zs) = 1 + (len t) ; by combining this fact with the nugget that (len zs) = 3 LiquidHaskell concludes that t , and hence, zs' contains two elements. Reasoning about Lengths \u00b6 Let's flex our new vocabulary by uttering types that describe the behavior of the usual list functions. First up: a version of the standard length function, slightly simplified for exposition. 99: {-@ length :: xs : [ a ] -> {v: Int | v = (len xs)} @-} 100: length :: [ a ] -> Int 101: xs:[a] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length [] = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 102: length ( x : xs ) = {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + xs:[a] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Note: Recall that measure values don't actually exist at run-time. However, functions like length are useful in that they allow us to effectively pull or materialize the ghost values from the refinement world into the actual code world (since the value returned by length is logically equal to the len of the input list.) Similarly, we can speak and have confirmed, the types for the usual list-manipulators like 115: {-@ map :: ( a -> b ) -> xs : [ a ] -> {v: [ b ] | (len v) = (len xs)} @-} 116: (a -> b) -> x1:[a] -> {VV : [b] | (len([VV]) = len([x1])),(len([VV]) >= 0)} map _ [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] 117: map f ( x : xs ) = ( a -> b f {VV : a | (VV = x)} x ) y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : ( (a -> b) -> x1:[a] -> {VV : [b] | (len([VV]) = len([x1])),(len([VV]) >= 0)} map a -> b f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) and 123: {-@ filter :: ( a -> Bool ) -> xs : [ a ] -> {v: [ a ] | (len v) <= (len xs)} @-} 124: (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter _ [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] 125: filter f ( x : xs ) 126: | a -> (GHC.Types.Bool) f {VV : a | (VV = x)} x = {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 127: | otherwise = (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs and, since doubtless you are wondering, 133: {-@ append :: xs : [ a ] -> ys : [ a ] -> {v: [ a ] | (len v) = (len xs) + (len ys)} @-} 134: x4:[a] -> x3:[a] -> {VV : [a] | (len([VV]) = (len([x4]) + len([x3]))), (len([VV]) = (len([x3]) + len([x4]))), (len([VV]) >= 0)} append [] [a] ys = {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys 135: append ( x : xs ) ys = {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : x4:[a] -> x3:[a] -> {VV : [a] | (len([VV]) = (len([x4]) + len([x3]))), (len([VV]) = (len([x3]) + len([x4]))), (len([VV]) >= 0)} append {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys We will return to the above at some later date. Right now, let's look at some interesting programs that LiquidHaskell can prove safe, by reasoning about the size of various lists. Example 1: Safely Catching A List by Its Tail (or Head) \u00b6 Now, let's see how we can use these new incantations to banish, forever, certain irritating kinds of errors. Recall how we always summon functions like head and tail with a degree of trepidation, unsure whether the arguments are empty, which will awaken certain beasts 150: Prelude > head [] 151: *** Exception : Prelude . head : empty list LiquidHaskell allows us to use these functions with confidence and surety! First off, let's define a predicate alias that describes non-empty lists: 159: {-@ predicate NonNull X = ( ( len X ) > 0 ) @-} Now, we can type the potentially dangerous head as: 165: {-@ head :: {v: [ a ] | (NonNull v)} -> a @-} 166: {VV : [a] | (len([VV]) > 0)} -> a head ( x : _ ) = {VV : a | (VV = x)} x 167: head [] = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"Fear not! 'twill ne'er come to pass\" As with the case of divide-by-zero , LiquidHaskell deduces that the second equation is dead code since the precondition (input) type states that the length of the input is strictly positive, which precludes the case where the parameter is [] . Similarly, we can write 178: {-@ tail :: {v: [ a ] | (NonNull v)} -> [ a ] @-} 179: {VV : [a] | (len([VV]) > 0)} -> [a] tail ( _ : xs ) = {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 180: tail [] = {VV : [(GHC.Types.Char)] | false} -> {VV : [{VV : a | false}] | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"Relaxeth! this too shall ne'er be\" Once again, LiquidHaskell will use the precondition to verify that the liquidError is never invoked. Let's use the above to write a function that eliminates stuttering, that is which converts \"ssstringssss liiiiiike thisss\" to \"strings like this\" . 190: {-@ eliminateStutter :: ( Eq a ) => [ a ] -> [ a ] @-} 191: (GHC.Classes.Eq a) -> [a] -> [a] eliminateStutter [a] xs = ({VV : [a] | (len([VV]) > 0)} -> a) -> xs:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [a] | (len([VV]) = len([xs]))} map {VV : [a] | (len([VV]) > 0)} -> a head ({VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([xs]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} -> {VV : [a] | (len([VV]) >= 0)}) -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([xs]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} -> {VV : [a] | (len([VV]) >= 0)} $ x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs The heavy lifting is done by groupEq 197: x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 198: groupEq ( x : xs ) = ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0), (len([VV]) <= len([ys]))} ys ) y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0), (len([VV]) <= len([zs]))} zs 199: where ( {VV : [a] | (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0), (len([VV]) <= len([ys]))} ys , {VV : [a] | (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0), (len([VV]) <= len([zs]))} zs ) = (a -> (GHC.Types.Bool)) -> [a] -> ([a] , [a]) span ( {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == ) {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs which gathers consecutive equal elements in the list into a single list. By using the fact that each element in the output returned by groupEq is in fact of the form x:ys , LiquidHaskell infers that groupEq returns a list of non-empty lists . (Hover over the groupEq identifier in the code above to see this.) Next, by automatically instantiating the type parameter for the map in eliminateStutter to (len v) > 0 LiquidHaskell deduces head is only called on non-empty lists, thereby verifying the safety of eliminateStutter . (Hover your mouse over map above to see the instantiated type for it!) Example 2: Risers \u00b6 The above examples of head and tail are simple, but non-empty lists pop up in many places, and it is rather convenient to have the type system track non-emptiness without having to make up special types. Let's look at a more interesting example, popularized by Neil Mitchell which is a key step in an efficient sorting procedure, which we may return to in the future when we discuss sorting algorithms. 224: risers :: ( Ord a ) => [ a ] -> [ [ a ] ] 225: (GHC.Classes.Ord a) -> zs:[a] -> {VV : [[a]] | ((len([zs]) > 0) => (len([VV]) > 0))} risers [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 226: risers [ x ] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0), (len([VV]) >= 0)} [ {VV : [{VV : a | (VV = x)}] | (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] ] 227: risers ( x : y : etc ) = {VV : [{VV : a | false}] | (len([VV]) = 0),(len([VV]) >= 0)} if {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = y)} y then ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = s), (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s ) y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : {VV : [[a]] | (VV = ss), (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss else {VV : [{VV : a | (VV = x),(VV > y)}] | (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : ( {VV : [a] | (VV = s), (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : {VV : [[a]] | (VV = ss), (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss ) 228: where 229: ( {VV : [a] | (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s , {VV : [[a]] | (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss ) = {VV : [[a]] | (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)}) safeSplit ({VV : [[a]] | ((len([etc]) > 0) => (len([VV]) > 0)), (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)})) -> {VV : [[a]] | ((len([etc]) > 0) => (len([VV]) > 0)), (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)}) $ zs:[a] -> {VV : [[a]] | ((len([zs]) > 0) => (len([VV]) > 0))} risers ( {VV : a | (VV = y)} y y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = etc),(len([VV]) >= 0)} etc ) The bit that should cause some worry is safeSplit which simply returns the head and tail of its input, if they exist, and otherwise, crashes and burns 237: {VV : [a] | (len([VV]) > 0)} -> (a , {VV : [a] | (len([VV]) >= 0)}) safeSplit ( x : xs ) = x1:a -> b -> (a , b) ( {VV : a | (VV = x)} x , {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) 238: safeSplit _ = {VV : [(GHC.Types.Char)] | false} -> {VV : ({VV : a | false} , {VV : [{VV : a | false}] | false}) | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"don't worry, be happy\" How can we verify that safeSplit will not crash ? The matter is complicated by the fact that since risers does sometimes return an empty list, we cannot blithely specify that its output type has a NonNull refinement. Once again, logic rides to our rescue! The crucial property upon which the safety of risers rests is that when the input list is non-empty, the output list returned by risers is also non-empty. It is quite easy to clue LiquidHaskell in on this, namely through a type specification: 255: {-@ risers :: ( Ord a ) 256: => zs : [ a ] 257: -> {v: [ [ a ] ] | ((NonNull zs) => (NonNull v)) } @-} Note how we relate the output's non-emptiness to the input's non-emptiness,through the (dependent) refinement type. With this specification in place, LiquidHaskell is pleased to verify risers (i.e. the call to safeSplit ). Example 3: MapReduce \u00b6 Here's a longer example that illustrates this: a toy map-reduce implementation. First, let's write a function keyMap that expands a list of inputs into a list of key-value pairs: 274: keyMap :: ( a -> [ ( k , v ) ] ) -> [ a ] -> [ ( k , v ) ] 275: (a -> {VV : [(b , c)] | (len([VV]) >= 0)}) -> [a] -> [(b , c)] keyMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f [a] xs = (a -> [(b , c)]) -> [a] -> [(b , c)] concatMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Next, let's write a function group that gathers the key-value pairs into a Map from keys to the lists of values with that same key. 282: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) group [(a , b)] kvs = ((a , b) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) foldr ( (a , b) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) \\ ( k , v ) (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) m -> a -> b -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) inserts {VV : a | (VV = k)} k {VV : a | (VV = v)} v {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m ) (Data.HashMap.Base.HashMap {VV : a | false} {VV : [{VV : b | false}] | false}) M . empty {VV : [(a , b)] | (VV = kvs),(len([VV]) >= 0)} kvs The function inserts simply adds the new value v to the list of previously known values lookupDefault [] k m for the key k . 289: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> a -> b -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) inserts a k a v (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) m = a -> {VV : [b] | (len([VV]) > 0)} -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) M . insert {VV : a | (VV = k)} k ( {VV : a | (VV = v)} v y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = vs),(len([VV]) >= 0)} vs ) {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m 290: where {VV : [a] | (len([VV]) >= 0)} vs = {VV : [a] | (len([VV]) >= 0)} -> b -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) >= 0)}) -> {VV : [a] | (len([VV]) >= 0)} M . lookupDefault {VV : [{VV : a | false}] | (len([VV]) = 0),(len([VV]) >= 0)} [] {VV : a | (VV = k)} k {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m Finally, a function that reduces the list of values for a given key in the table to a single value: 297: reduce :: ( v -> v -> v ) -> M . HashMap k [ v ] -> M . HashMap k v 298: (x2:a -> x3:a -> {VV : a | (VV > x2),(VV > x3)}) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) reduce x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op = ({VV : [a] | (len([VV]) > 0)} -> a) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) M . map ( (a -> a -> a) -> {VV : [a] | (len([VV]) > 0)} -> a foldl1 x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op ) where foldl1 is a left-fold over non-empty lists 304: {-@ foldl1 :: ( a -> a -> a ) -> {v: [ a ] | (NonNull v)} -> a @-} 305: (a -> a -> a) -> {VV : [a] | (len([VV]) > 0)} -> a foldl1 a -> a -> a f ( x : xs ) = (a -> a -> a) -> a -> [a] -> a foldl a -> a -> a f {VV : a | (VV = x)} x {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 306: foldl1 _ [] = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"will. never. happen.\" We can put the whole thing together to write a ( very ) simple Map-Reduce library 312: mapReduce :: ( Eq k , Hashable k ) 313: => ( a -> [ ( k , v ) ] ) -- ^ key-mapper 314: -> ( v -> v -> v ) -- ^ reduction operator 315: -> [ a ] -- ^ inputs 316: -> [ ( k , v ) ] -- ^ output key-values 317: 318: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> (b -> {VV : [(a , c)] | (len([VV]) >= 0)}) -> (x7:c -> x8:c -> {VV : c | (VV > x7),(VV > x8)}) -> [b] -> [(a , c)] mapReduce a -> {VV : [(b , c)] | (len([VV]) >= 0)} f x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op = (Data.HashMap.Base.HashMap a b) -> [(a , b)] M . toList 319: ((Data.HashMap.Base.HashMap a b) -> [(a , b)]) -> ([c] -> (Data.HashMap.Base.HashMap a b)) -> [c] -> [(a , b)] . (x2:a -> x3:a -> {VV : a | (VV > x2),(VV > x3)}) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) reduce x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op 320: ((Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a b)) -> ([c] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> [c] -> (Data.HashMap.Base.HashMap a b) . [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) group 321: ([(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> ([c] -> [(a , b)]) -> [c] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) . (a -> {VV : [(b , c)] | (len([VV]) >= 0)}) -> [a] -> [(b , c)] keyMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f Now, if we want to compute the frequency of Char in a given list of words, we can write: 327: {-@ charFrequency :: [ String ] -> [ ( Char , Int ) ] @-} 328: charFrequency :: [ String ] -> [ ( Char , Int ) ] 329: [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , (GHC.Types.Int))] charFrequency = ([(GHC.Types.Char)] -> {VV : [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV > 0)})] | (len([VV]) >= 0)}) -> (x8:{VV : (GHC.Types.Int) | (VV > 0)} -> x9:{VV : (GHC.Types.Int) | (VV > 0)} -> {VV : (GHC.Types.Int) | (VV > 0),(VV > x8),(VV > x9)}) -> [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV > 0)})] mapReduce x1:[(GHC.Types.Char)] -> {VV : [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([x1])), (len([VV]) >= 0)} wordChars x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} ( + ) 330: where x1:[a] -> {VV : [(a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([x1])),(len([VV]) >= 0)} wordChars = (a -> (a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})) -> xs:[a] -> {VV : [(a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([xs]))} map ( c:a -> ({VV : a | (VV = c)} , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)}) \\ a c -> x1:a -> b -> (a , b) ( {VV : a | (VV = c)} c , {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) ) You can take it out for a spin like so: 336: [((GHC.Types.Char) , (GHC.Types.Int))] f0 = [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , (GHC.Types.Int))] charFrequency [ {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"the\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"quick\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"brown\" 337: , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"fox\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"jumped\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"over\" 338: , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"the\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"lazy\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"cow\" ] Look Ma! No Types: LiquidHaskell will gobble the whole thing up, and verify that none of the undesirable liquidError calls are triggered. By the way, notice that we didn't write down any types for mapReduce and friends. The main invariant, from which safety follows is that the Map returned by the group function binds each key to a non-empty list of values. LiquidHaskell deduces this invariant by inferring suitable types for group , inserts , foldl1 and reduce , thereby relieving us of that tedium. In short, by riding on the broad and high shoulders of SMT and abstract interpretation, LiquidHaskell makes a little typing go a long way. Conclusions \u00b6 Well folks, thats all for now. I trust this article gave you a sense of How we can describe certain structural properties of data types, such as the length of a list, How we might use refinements over these properties to describe key invariants and establish, at compile-time, the safety of operations that might blow up on unexpected values at run-time, and perhaps, most importantly, How we can achieve the above, whilst just working with good old lists, without having to make up new types (which have the unfortunate effect of cluttering programs with their attendant new functions) in order to enforce special invariants.","title":"Safely Catching A List By Its Tail"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#measuring-the-length-of-a-list","text":"To begin, we need some instrument by which to measure the length of a list. To this end, let's introduce a new mechanism called measures which define auxiliary (or so-called ghost ) properties of data values. These properties are useful for specification and verification, but don't actually exist at run-time . That is, measures will appear in specifications but never inside code. Let's reuse this mechanism, this time, providing a definition for the measure 48: measure len :: forall a . [ a ] -> GHC . Types . Int 49: len ( [] ) = 0 50: len ( y : ys ) = 1 + ( len ys ) The description of len above should be quite easy to follow. Underneath the covers, LiquidHaskell transforms the above description into refined versions of the types for the constructors (:) and [] , Something like 57: data [ a ] where 58: [] :: forall a . { v : [ a ] | ( len v ) = 0 } 59: ( : ) :: forall a . y : a -> ys : [ a ] -> { v : [ a ] | ( len v ) = 1 + ( len ys ) } To appreciate this, note that we can now check that 65: {-@ xs :: {v: [ String ] | (len v) = 1 } @-} 66: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 1)} xs = {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"dog\" y:{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} -> ys:[{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] -> {VV : [{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : [{VV : [{VV : (GHC.Types.Char) | false}] | false}] | (len([VV]) = 0), (len([VV]) >= 0)} [] 67: 68: {-@ ys :: {v: [ String ] | (len v) = 2 } @-} 69: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 2)} ys = {VV : [{VV : [(GHC.Types.Char)] | (len([VV]) >= 0)}] | (len([VV]) >= 0)} [ {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"cat\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"dog\" ] 70: 71: {-@ zs :: {v: [ String ] | (len v) = 3 } @-} 72: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 3)} zs = {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"hippo\" y:[(GHC.Types.Char)] -> ys:[[(GHC.Types.Char)]] -> {VV : [[(GHC.Types.Char)]] | (len([VV]) = (1 + len([ys])))} : {VV : [[(GHC.Types.Char)]] | (VV = ys), (len([VV]) = 2), (len([VV]) >= 0)} ys Dually, when we de-construct the lists, LiquidHaskell is able to relate the type of the outer list with its constituents. For example, 79: {-@ zs' :: {v: [ String ] | (len v) = 2 } @-} 80: {VV : [[(GHC.Types.Char)]] | (len([VV]) = 2)} zs' = case {VV : [[(GHC.Types.Char)]] | (VV = zs), (len([VV]) = 3), (len([VV]) >= 0)} zs of 81: h : t -> {VV : [[(GHC.Types.Char)]] | (VV = t),(len([VV]) >= 0)} t Here, from the use of the : in the pattern, LiquidHaskell can determine that (len zs) = 1 + (len t) ; by combining this fact with the nugget that (len zs) = 3 LiquidHaskell concludes that t , and hence, zs' contains two elements.","title":"Measuring the Length of a List"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#reasoning-about-lengths","text":"Let's flex our new vocabulary by uttering types that describe the behavior of the usual list functions. First up: a version of the standard length function, slightly simplified for exposition. 99: {-@ length :: xs : [ a ] -> {v: Int | v = (len xs)} @-} 100: length :: [ a ] -> Int 101: xs:[a] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length [] = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 102: length ( x : xs ) = {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + xs:[a] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Note: Recall that measure values don't actually exist at run-time. However, functions like length are useful in that they allow us to effectively pull or materialize the ghost values from the refinement world into the actual code world (since the value returned by length is logically equal to the len of the input list.) Similarly, we can speak and have confirmed, the types for the usual list-manipulators like 115: {-@ map :: ( a -> b ) -> xs : [ a ] -> {v: [ b ] | (len v) = (len xs)} @-} 116: (a -> b) -> x1:[a] -> {VV : [b] | (len([VV]) = len([x1])),(len([VV]) >= 0)} map _ [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] 117: map f ( x : xs ) = ( a -> b f {VV : a | (VV = x)} x ) y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : ( (a -> b) -> x1:[a] -> {VV : [b] | (len([VV]) = len([x1])),(len([VV]) >= 0)} map a -> b f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) and 123: {-@ filter :: ( a -> Bool ) -> xs : [ a ] -> {v: [ a ] | (len v) <= (len xs)} @-} 124: (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter _ [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] 125: filter f ( x : xs ) 126: | a -> (GHC.Types.Bool) f {VV : a | (VV = x)} x = {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 127: | otherwise = (a -> (GHC.Types.Bool)) -> x1:[a] -> {VV : [a] | (len([VV]) >= 0),(len([VV]) <= len([x1]))} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs and, since doubtless you are wondering, 133: {-@ append :: xs : [ a ] -> ys : [ a ] -> {v: [ a ] | (len v) = (len xs) + (len ys)} @-} 134: x4:[a] -> x3:[a] -> {VV : [a] | (len([VV]) = (len([x4]) + len([x3]))), (len([VV]) = (len([x3]) + len([x4]))), (len([VV]) >= 0)} append [] [a] ys = {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys 135: append ( x : xs ) ys = {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : x4:[a] -> x3:[a] -> {VV : [a] | (len([VV]) = (len([x4]) + len([x3]))), (len([VV]) = (len([x3]) + len([x4]))), (len([VV]) >= 0)} append {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys We will return to the above at some later date. Right now, let's look at some interesting programs that LiquidHaskell can prove safe, by reasoning about the size of various lists.","title":"Reasoning about Lengths"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#example-1-safely-catching-a-list-by-its-tail-or-head","text":"Now, let's see how we can use these new incantations to banish, forever, certain irritating kinds of errors. Recall how we always summon functions like head and tail with a degree of trepidation, unsure whether the arguments are empty, which will awaken certain beasts 150: Prelude > head [] 151: *** Exception : Prelude . head : empty list LiquidHaskell allows us to use these functions with confidence and surety! First off, let's define a predicate alias that describes non-empty lists: 159: {-@ predicate NonNull X = ( ( len X ) > 0 ) @-} Now, we can type the potentially dangerous head as: 165: {-@ head :: {v: [ a ] | (NonNull v)} -> a @-} 166: {VV : [a] | (len([VV]) > 0)} -> a head ( x : _ ) = {VV : a | (VV = x)} x 167: head [] = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"Fear not! 'twill ne'er come to pass\" As with the case of divide-by-zero , LiquidHaskell deduces that the second equation is dead code since the precondition (input) type states that the length of the input is strictly positive, which precludes the case where the parameter is [] . Similarly, we can write 178: {-@ tail :: {v: [ a ] | (NonNull v)} -> [ a ] @-} 179: {VV : [a] | (len([VV]) > 0)} -> [a] tail ( _ : xs ) = {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 180: tail [] = {VV : [(GHC.Types.Char)] | false} -> {VV : [{VV : a | false}] | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"Relaxeth! this too shall ne'er be\" Once again, LiquidHaskell will use the precondition to verify that the liquidError is never invoked. Let's use the above to write a function that eliminates stuttering, that is which converts \"ssstringssss liiiiiike thisss\" to \"strings like this\" . 190: {-@ eliminateStutter :: ( Eq a ) => [ a ] -> [ a ] @-} 191: (GHC.Classes.Eq a) -> [a] -> [a] eliminateStutter [a] xs = ({VV : [a] | (len([VV]) > 0)} -> a) -> xs:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [a] | (len([VV]) = len([xs]))} map {VV : [a] | (len([VV]) > 0)} -> a head ({VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([xs]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} -> {VV : [a] | (len([VV]) >= 0)}) -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([xs]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} -> {VV : [a] | (len([VV]) >= 0)} $ x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs The heavy lifting is done by groupEq 197: x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 198: groupEq ( x : xs ) = ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0), (len([VV]) <= len([ys]))} ys ) y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : x1:{VV : [a] | (len([VV]) >= 0)} -> {VV : [{VV : [a] | (len([VV]) > 0)}] | ((len([x1]) > 0) => (len([VV]) > 0)), (len([VV]) >= 0)} groupEq {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0), (len([VV]) <= len([zs]))} zs 199: where ( {VV : [a] | (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0), (len([VV]) <= len([ys]))} ys , {VV : [a] | (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0), (len([VV]) <= len([zs]))} zs ) = (a -> (GHC.Types.Bool)) -> [a] -> ([a] , [a]) span ( {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == ) {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs which gathers consecutive equal elements in the list into a single list. By using the fact that each element in the output returned by groupEq is in fact of the form x:ys , LiquidHaskell infers that groupEq returns a list of non-empty lists . (Hover over the groupEq identifier in the code above to see this.) Next, by automatically instantiating the type parameter for the map in eliminateStutter to (len v) > 0 LiquidHaskell deduces head is only called on non-empty lists, thereby verifying the safety of eliminateStutter . (Hover your mouse over map above to see the instantiated type for it!)","title":"Example 1: Safely Catching A List by Its Tail (or Head)"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#example-2-risers","text":"The above examples of head and tail are simple, but non-empty lists pop up in many places, and it is rather convenient to have the type system track non-emptiness without having to make up special types. Let's look at a more interesting example, popularized by Neil Mitchell which is a key step in an efficient sorting procedure, which we may return to in the future when we discuss sorting algorithms. 224: risers :: ( Ord a ) => [ a ] -> [ [ a ] ] 225: (GHC.Classes.Ord a) -> zs:[a] -> {VV : [[a]] | ((len([zs]) > 0) => (len([VV]) > 0))} risers [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 226: risers [ x ] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0), (len([VV]) >= 0)} [ {VV : [{VV : a | (VV = x)}] | (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] ] 227: risers ( x : y : etc ) = {VV : [{VV : a | false}] | (len([VV]) = 0),(len([VV]) >= 0)} if {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = y)} y then ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = s), (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s ) y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : {VV : [[a]] | (VV = ss), (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss else {VV : [{VV : a | (VV = x),(VV > y)}] | (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : ( {VV : [a] | (VV = s), (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s y:[a] -> ys:[[a]] -> {VV : [[a]] | (len([VV]) = (1 + len([ys])))} : {VV : [[a]] | (VV = ss), (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss ) 228: where 229: ( {VV : [a] | (VV = s), (len([VV]) = len([s])), (len([VV]) >= 0), (len([VV]) <= len([s]))} s , {VV : [[a]] | (VV = ss), (len([VV]) = len([ss])), (len([VV]) >= 0), (len([VV]) <= len([ss]))} ss ) = {VV : [[a]] | (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)}) safeSplit ({VV : [[a]] | ((len([etc]) > 0) => (len([VV]) > 0)), (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)})) -> {VV : [[a]] | ((len([etc]) > 0) => (len([VV]) > 0)), (len([VV]) > 0)} -> ([a] , {VV : [[a]] | (len([VV]) >= 0)}) $ zs:[a] -> {VV : [[a]] | ((len([zs]) > 0) => (len([VV]) > 0))} risers ( {VV : a | (VV = y)} y y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = etc),(len([VV]) >= 0)} etc ) The bit that should cause some worry is safeSplit which simply returns the head and tail of its input, if they exist, and otherwise, crashes and burns 237: {VV : [a] | (len([VV]) > 0)} -> (a , {VV : [a] | (len([VV]) >= 0)}) safeSplit ( x : xs ) = x1:a -> b -> (a , b) ( {VV : a | (VV = x)} x , {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) 238: safeSplit _ = {VV : [(GHC.Types.Char)] | false} -> {VV : ({VV : a | false} , {VV : [{VV : a | false}] | false}) | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"don't worry, be happy\" How can we verify that safeSplit will not crash ? The matter is complicated by the fact that since risers does sometimes return an empty list, we cannot blithely specify that its output type has a NonNull refinement. Once again, logic rides to our rescue! The crucial property upon which the safety of risers rests is that when the input list is non-empty, the output list returned by risers is also non-empty. It is quite easy to clue LiquidHaskell in on this, namely through a type specification: 255: {-@ risers :: ( Ord a ) 256: => zs : [ a ] 257: -> {v: [ [ a ] ] | ((NonNull zs) => (NonNull v)) } @-} Note how we relate the output's non-emptiness to the input's non-emptiness,through the (dependent) refinement type. With this specification in place, LiquidHaskell is pleased to verify risers (i.e. the call to safeSplit ).","title":"Example 2: Risers"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#example-3-mapreduce","text":"Here's a longer example that illustrates this: a toy map-reduce implementation. First, let's write a function keyMap that expands a list of inputs into a list of key-value pairs: 274: keyMap :: ( a -> [ ( k , v ) ] ) -> [ a ] -> [ ( k , v ) ] 275: (a -> {VV : [(b , c)] | (len([VV]) >= 0)}) -> [a] -> [(b , c)] keyMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f [a] xs = (a -> [(b , c)]) -> [a] -> [(b , c)] concatMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Next, let's write a function group that gathers the key-value pairs into a Map from keys to the lists of values with that same key. 282: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) group [(a , b)] kvs = ((a , b) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) foldr ( (a , b) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) \\ ( k , v ) (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) m -> a -> b -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) inserts {VV : a | (VV = k)} k {VV : a | (VV = v)} v {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m ) (Data.HashMap.Base.HashMap {VV : a | false} {VV : [{VV : b | false}] | false}) M . empty {VV : [(a , b)] | (VV = kvs),(len([VV]) >= 0)} kvs The function inserts simply adds the new value v to the list of previously known values lookupDefault [] k m for the key k . 289: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> a -> b -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) inserts a k a v (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) m = a -> {VV : [b] | (len([VV]) > 0)} -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) M . insert {VV : a | (VV = k)} k ( {VV : a | (VV = v)} v y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = vs),(len([VV]) >= 0)} vs ) {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m 290: where {VV : [a] | (len([VV]) >= 0)} vs = {VV : [a] | (len([VV]) >= 0)} -> b -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) >= 0)}) -> {VV : [a] | (len([VV]) >= 0)} M . lookupDefault {VV : [{VV : a | false}] | (len([VV]) = 0),(len([VV]) >= 0)} [] {VV : a | (VV = k)} k {VV : (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) | (VV = m)} m Finally, a function that reduces the list of values for a given key in the table to a single value: 297: reduce :: ( v -> v -> v ) -> M . HashMap k [ v ] -> M . HashMap k v 298: (x2:a -> x3:a -> {VV : a | (VV > x2),(VV > x3)}) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) reduce x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op = ({VV : [a] | (len([VV]) > 0)} -> a) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) M . map ( (a -> a -> a) -> {VV : [a] | (len([VV]) > 0)} -> a foldl1 x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op ) where foldl1 is a left-fold over non-empty lists 304: {-@ foldl1 :: ( a -> a -> a ) -> {v: [ a ] | (NonNull v)} -> a @-} 305: (a -> a -> a) -> {VV : [a] | (len([VV]) > 0)} -> a foldl1 a -> a -> a f ( x : xs ) = (a -> a -> a) -> a -> [a] -> a foldl a -> a -> a f {VV : a | (VV = x)} x {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 306: foldl1 _ [] = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"will. never. happen.\" We can put the whole thing together to write a ( very ) simple Map-Reduce library 312: mapReduce :: ( Eq k , Hashable k ) 313: => ( a -> [ ( k , v ) ] ) -- ^ key-mapper 314: -> ( v -> v -> v ) -- ^ reduction operator 315: -> [ a ] -- ^ inputs 316: -> [ ( k , v ) ] -- ^ output key-values 317: 318: (GHC.Classes.Eq a) -> (Data.Hashable.Class.Hashable a) -> (b -> {VV : [(a , c)] | (len([VV]) >= 0)}) -> (x7:c -> x8:c -> {VV : c | (VV > x7),(VV > x8)}) -> [b] -> [(a , c)] mapReduce a -> {VV : [(b , c)] | (len([VV]) >= 0)} f x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op = (Data.HashMap.Base.HashMap a b) -> [(a , b)] M . toList 319: ((Data.HashMap.Base.HashMap a b) -> [(a , b)]) -> ([c] -> (Data.HashMap.Base.HashMap a b)) -> [c] -> [(a , b)] . (x2:a -> x3:a -> {VV : a | (VV > x2),(VV > x3)}) -> (Data.HashMap.Base.HashMap b {VV : [a] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap b a) reduce x1:a -> x2:a -> {VV : a | (VV > x1),(VV > x2)} op 320: ((Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) -> (Data.HashMap.Base.HashMap a b)) -> ([c] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> [c] -> (Data.HashMap.Base.HashMap a b) . [(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) group 321: ([(a , b)] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)})) -> ([c] -> [(a , b)]) -> [c] -> (Data.HashMap.Base.HashMap a {VV : [b] | (len([VV]) > 0)}) . (a -> {VV : [(b , c)] | (len([VV]) >= 0)}) -> [a] -> [(b , c)] keyMap a -> {VV : [(b , c)] | (len([VV]) >= 0)} f Now, if we want to compute the frequency of Char in a given list of words, we can write: 327: {-@ charFrequency :: [ String ] -> [ ( Char , Int ) ] @-} 328: charFrequency :: [ String ] -> [ ( Char , Int ) ] 329: [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , (GHC.Types.Int))] charFrequency = ([(GHC.Types.Char)] -> {VV : [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV > 0)})] | (len([VV]) >= 0)}) -> (x8:{VV : (GHC.Types.Int) | (VV > 0)} -> x9:{VV : (GHC.Types.Int) | (VV > 0)} -> {VV : (GHC.Types.Int) | (VV > 0),(VV > x8),(VV > x9)}) -> [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV > 0)})] mapReduce x1:[(GHC.Types.Char)] -> {VV : [((GHC.Types.Char) , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([x1])), (len([VV]) >= 0)} wordChars x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} ( + ) 330: where x1:[a] -> {VV : [(a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([x1])),(len([VV]) >= 0)} wordChars = (a -> (a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})) -> xs:[a] -> {VV : [(a , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)})] | (len([VV]) = len([xs]))} map ( c:a -> ({VV : a | (VV = c)} , {VV : (GHC.Types.Int) | (VV = 1), (VV = len([xs])), (VV > 0)}) \\ a c -> x1:a -> b -> (a , b) ( {VV : a | (VV = c)} c , {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) ) You can take it out for a spin like so: 336: [((GHC.Types.Char) , (GHC.Types.Int))] f0 = [[(GHC.Types.Char)]] -> [((GHC.Types.Char) , (GHC.Types.Int))] charFrequency [ {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"the\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"quick\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"brown\" 337: , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"fox\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"jumped\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"over\" 338: , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"the\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"lazy\" , {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"cow\" ] Look Ma! No Types: LiquidHaskell will gobble the whole thing up, and verify that none of the undesirable liquidError calls are triggered. By the way, notice that we didn't write down any types for mapReduce and friends. The main invariant, from which safety follows is that the Map returned by the group function binds each key to a non-empty list of values. LiquidHaskell deduces this invariant by inferring suitable types for group , inserts , foldl1 and reduce , thereby relieving us of that tedium. In short, by riding on the broad and high shoulders of SMT and abstract interpretation, LiquidHaskell makes a little typing go a long way.","title":"Example 3: MapReduce"},{"location":"blogposts/2013-01-31-safely-catching-a-list-by-its-tail.lhs/#conclusions","text":"Well folks, thats all for now. I trust this article gave you a sense of How we can describe certain structural properties of data types, such as the length of a list, How we might use refinements over these properties to describe key invariants and establish, at compile-time, the safety of operations that might blow up on unexpected values at run-time, and perhaps, most importantly, How we can achieve the above, whilst just working with good old lists, without having to make up new types (which have the unfortunate effect of cluttering programs with their attendant new functions) in order to enforce special invariants.","title":"Conclusions"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/","text":"Last time we introduced a new specification mechanism called a measure and demonstrated how to use it to encode the length of a list. We saw how measures could be used to verify that functions like head and tail were only called with non-empty lists (whose length was strictly positive). As several folks pointed out, once LiquidHaskell can reason about lengths, it can do a lot more than just analyze non-emptiness. Indeed! Over the next two posts, lets see how one might implement a Kmeans algorithm that clusters n -dimensional points groups, and how LiquidHaskell can help us write and enforce various dimensionality invariants along the way. 33: module KMeansHelper where 34: 35: import Prelude hiding ( zipWith ) 36: import Data . List ( span ) 37: import Language . Haskell . Liquid . Prelude ( liquidError ) Rather than reinvent the wheel, we will modify an existing implementation of K-Means, available on hackage . This may not be the most efficient implementation, but its a nice introduction to the algorithm, and the general invariants will hold for more sophisticated implementations. We have broken this entry into two convenient, bite-sized chunks: Part I Introduces the basic types and list operations needed by KMeans, Part II Describes how the operations are used in the KMeans implementation. The Game: Clustering Points \u00b6 The goal of K-Means clustering is the following. Given Input : A set of points represented by n-dimensional points in Euclidian space, return Output : A partitioning of the points, into K clusters, in a manner that minimizes sum of distances between each point and its cluster center. The Players: Types \u00b6 Lets make matters concrete by creating types for the different elements of the algorithm. 1. Fixed-Length Lists We will represent n-dimensional points using good old Haskell lists, refined with a predicate that describes the dimensionality (i.e. length.) To simplify matters, lets package this into a type alias that denotes lists of a given length N . 75: {-@ type List a N = { v : [ a ] | ( len v ) = N } @-} 2. Points Next, we can represent an N -dimensional point as list of Double of length N , 81: {-@ type Point N = List Double N @-} 3. Clusters A cluster is a non-empty list of points, 87: {-@ type NonEmptyList a = { v : [ a ] | ( len v ) > 0 } @-} 4. Clustering And finally, a clustering is a list of (non-empty) clusters. 93: {-@ type Clustering a = [ ( NonEmptyList a ) ] @-} Notation: When defining refinement type aliases, we use uppercase variables like N to distinguish value- parameters from the lowercase type parameters like a . Aside: By the way, if you are familiar with the index-style length encoding e.g. as found in DML or Agda , then its worth noting that despite appearances, our List and Point definitions are not indexed. We're just using the indices to define abbreviations for the refinement predicates, and we have deliberately chosen the predicates to facilitate SMT based checking and inference. Basic Operations on Points and Clusters \u00b6 Ok, with the types firmly in hand, let us go forth and develop the KMeans clustering implementation. We will use a variety of small helper functions (of the kind found in Data.List .) Lets get started by looking at them through our newly refined eyes. Grouping \u00b6 The first such function is groupBy . We can refine its type so that instead of just producing a [[a]] we know that it produces a Clustering a which is a list of non-empty lists. 124: {-@ groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) @-} 125: (a -> a -> (GHC.Types.Bool)) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} groupBy _ [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 126: groupBy eq ( x : xs ) = ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0)} ys ) y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : (a -> a -> (GHC.Types.Bool)) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} groupBy a -> a -> (GHC.Types.Bool) eq {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0)} zs 127: where ( {VV : [a] | (VV = ys),(len([VV]) = len([ys])),(len([VV]) >= 0)} ys , {VV : [a] | (VV = zs),(len([VV]) = len([zs])),(len([VV]) >= 0)} zs ) = (a -> (GHC.Types.Bool)) -> [a] -> ([a] , [a]) span ( a -> a -> (GHC.Types.Bool) eq {VV : a | (VV = x)} x ) {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Intuitively, its pretty easy to see how LiquidHaskell verifies the refined specification: Each element of the output list is of the form x:ys For any list ys the length is non-negative, i.e. (len ys) >= 0 The len of x:ys is 1 + (len ys) , that is, strictly positive. Partitioning \u00b6 Next, lets look the function 143: {-@ partition :: size : PosInt -> [ a ] -> ( Clustering a ) @-} 144: {-@ type PosInt = { v : Int | v > 0 } @-} which is given a strictly positive integer argument, a list of a values, and returns a Clustering a , that is, a list of non-empty lists. (Each inner list has a length that is less than size , but we shall elide this for simplicity.) The function is implemented in a straightforward manner, using the library functions take and drop 156: {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} partition {VV : (GHC.Types.Int) | (VV > 0)} size [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 157: partition size ys @ ( _ : _ ) = {VV : [a] | (VV = zs),(len([VV]) >= 0)} zs y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} partition {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (VV = zs'),(len([VV]) >= 0)} zs' 158: where 159: [a] zs = n:{VV : (GHC.Types.Int) | (VV >= 0)} -> xs:[a] -> {VV : [a] | (len([VV]) = ((len([xs]) < n) ? len([xs]) : n))} take {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (len([VV]) >= 0)} ys 160: [a] zs' = n:{VV : (GHC.Types.Int) | (VV >= 0)} -> xs:[a] -> {VV : [a] | (len([VV]) = ((len([xs]) < n) ? 0 : (len([xs]) - n)))} drop {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (len([VV]) >= 0)} ys To verify that a valid Clustering is produced, LiquidHaskell needs only verify that the list zs above is non-empty, by suitably connecting the properties of the inputs size and ys with the output. We have verified elsewhere that 168: take :: n : { v : Int | v >= 0 } 169: -> xs : [ a ] 170: -> { v : [ a ] | ( len v ) = ( if ( ( len xs ) < n ) then ( len xs ) else n ) } In other words, the output list's length is the smaller of the input list's length and n . Thus, since both size and the (len ys) are greater than 1 , LiquidHaskell deduces that the list returned by take size ys has a length greater than 1 , i.e., is non-empty. Zipping \u00b6 To compute the Euclidean distance between two points, we will use the zipWith function. We must make sure that it is invoked on points with the same number of dimensions, so we write 186: {-@ zipWith :: ( a -> b -> c ) 187: -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) @-} 188: (a -> b -> c) -> x4:[a] -> x2:{VV : [b] | (len([VV]) = len([x4])),(len([VV]) >= 0)} -> {VV : [c] | (len([VV]) = len([x4])), (len([VV]) = len([x2])), (len([VV]) >= 0)} zipWith a -> b -> c f ( a : as ) ( b : bs ) = a -> b -> c f {VV : a | (VV = a)} a {VV : a | (VV = b)} b y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : (a -> b -> c) -> x4:[a] -> x2:{VV : [b] | (len([VV]) = len([x4])),(len([VV]) >= 0)} -> {VV : [c] | (len([VV]) = len([x4])), (len([VV]) = len([x2])), (len([VV]) >= 0)} zipWith a -> b -> c f {VV : [a] | (VV = as),(len([VV]) >= 0)} as {VV : [a] | (VV = bs),(len([VV]) >= 0)} bs 189: zipWith _ [] [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] The type stipulates that the second input list and the output have the same length as the first input. Furthermore, it rules out the case where one list is empty and the other is not, as in that case the former's length is zero while the latter's is not. Transposing \u00b6 The last basic operation that we will require is a means to transpose a Matrix , which itself is just a list of lists: 204: {-@ type Matrix a Rows Cols = ( List ( List a Cols ) Rows ) @-} The transpose operation flips the rows and columns. I confess that I can never really understand matrices without concrete examples, and even then, barely. So, lets say we have a matrix 212: m1 :: Matrix Int 4 2 213: m1 = [ [ 1 , 2 ] 214: , [ 3 , 4 ] 215: , [ 5 , 6 ] 216: , [ 7 , 8 ] ] then the matrix m2 = transpose 2 3 m1 should be 220: m2 :: Matrix Int 2 4 221: m2 = [ [ 1 , 3 , 5 , 7 ] 222: , [ 2 , 4 , 6 , 8 ] ] We will use a Matrix a m n to represent a single cluster of m points each of which has n dimensions. We will transpose the matrix to make it easy to sum and average the points along each dimension, in order to compute the center of the cluster. As you can work out from the above, the code for transpose is quite straightforward: each output row is simply the list of head s of the input rows : 235: transpose :: Int -> Int -> [ [ a ] ] -> [ [ a ] ] 236: 237: c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [a] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [a] | (len([VV]) = r)}] | (len([v]) = c)} transpose 0 _ _ = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 238: 239: transpose c r ( ( col00 : col01s ) : row1s ) 240: = {VV : [a] | (VV = row0'),(len([VV]) >= 0)} row0' y:{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : {v : [[a]] | (v = row1s'),(len([v]) >= 0)} row1s' 241: where 242: [a] row0' = {VV : a | (VV = col00)} col00 y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (len([VV]) = len([row1s])),(len([VV]) >= 0)} [ {VV : a | (VV = col0)} col0 | ( col0 : _ ) <- {VV : [[a]] | (VV = row1s),(len([VV]) >= 0)} row1s ] 243: [{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)}] rest = {VV : [a] | (VV = col01s),(len([VV]) >= 0)} col01s y:{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)} -> ys:[{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)}] -> {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (len([VV]) = len([row1s])),(len([VV]) >= 0)} [ {VV : [a] | (VV = col1s),(len([VV]) >= 0)} col1s | ( _ : col1s ) <- {VV : [[a]] | (VV = row1s),(len([VV]) >= 0)} row1s ] 244: [[a]] row1s' = c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [a] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [a] | (len([VV]) = r)}] | (len([v]) = c)} transpose ( (GHC.Types.Int) c x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) {VV : (GHC.Types.Int) | (VV > 0)} r {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (VV = rest),(len([VV]) >= 0)} rest LiquidHaskell verifies that 250: {-@ transpose :: c : Int -> r : PosInt -> Matrix a r c -> Matrix a c r @-} Try to work it out for yourself on pencil and paper. If you like you can get a hint by seeing how LiquidHaskell figures it out. Lets work backwards . LiquidHaskell verifies the output type by inferring that 259: row0' :: ( List a r ) 260: row1s' :: List ( List a r ) ( c - 1 ) -- i.e. Matrix a (c - 1) r and so, by simply using the measure-refined type for : 264: ( : ) :: x : a -> xs : [ a ] -> { v : [ a ] | ( len v ) = 1 + ( len xs ) } LiquidHaskell deduces that 268: row0 : rows' :: List ( List a r ) c That is, 272: row0 : rows' :: Matrix a c r Excellent! Now, lets work backwards. How does it infer the types of row0' and row1s' ? The first case is easy: row0' is just the list of heads of each row, hence a List a r . Now, lets look at row1s' . Notice that row1s is the matrix of all except the first row of the input Matrix, and so 280: row1s :: Matrix a ( r - 1 ) c and so, as 284: col01s :: List a ( c - 1 ) 285: col1s :: List a ( c - 1 ) LiquidHaskell deduces that since rest is the concatenation of r-1 tails from row1s 289: rest = col01s : [ col1s | ( _ : col1s ) <- row1s ] the type of rest is 293: rest :: List ( List a ( c - 1 ) ) r which is just 297: rest :: Matrix a r ( c - 1 ) Now, LiquidHaskell deduces row1s' :: Matrix a (c-1) r by inductively plugging in the output type of the recursive call, thereby checking the function's signature. Whew! That was a fair bit of work, wasn't it! Happily, we didn't have to do any of it. Instead, using the SMT solver, LiquidHaskell ploughs through calculations like that and guarantees to us that transpose indeed flips the dimensions of the inner and outer lists. Aside: Comprehensions vs. Map Incidentally, the code above is essentially that of transpose from the Prelude with some extra local variables for exposition. You could instead use a map head and map tail and I encourage you to go ahead and see for yourself. Intermission \u00b6 Time for a break -- go see a cat video! -- or skip it, stretch your legs, and return post-haste for the next installment , in which we will use the types and functions described above, to develop the clustering algorithm.","title":"KMeans Clustering I"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#the-game-clustering-points","text":"The goal of K-Means clustering is the following. Given Input : A set of points represented by n-dimensional points in Euclidian space, return Output : A partitioning of the points, into K clusters, in a manner that minimizes sum of distances between each point and its cluster center.","title":"The Game: Clustering Points"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#the-players-types","text":"Lets make matters concrete by creating types for the different elements of the algorithm. 1. Fixed-Length Lists We will represent n-dimensional points using good old Haskell lists, refined with a predicate that describes the dimensionality (i.e. length.) To simplify matters, lets package this into a type alias that denotes lists of a given length N . 75: {-@ type List a N = { v : [ a ] | ( len v ) = N } @-} 2. Points Next, we can represent an N -dimensional point as list of Double of length N , 81: {-@ type Point N = List Double N @-} 3. Clusters A cluster is a non-empty list of points, 87: {-@ type NonEmptyList a = { v : [ a ] | ( len v ) > 0 } @-} 4. Clustering And finally, a clustering is a list of (non-empty) clusters. 93: {-@ type Clustering a = [ ( NonEmptyList a ) ] @-} Notation: When defining refinement type aliases, we use uppercase variables like N to distinguish value- parameters from the lowercase type parameters like a . Aside: By the way, if you are familiar with the index-style length encoding e.g. as found in DML or Agda , then its worth noting that despite appearances, our List and Point definitions are not indexed. We're just using the indices to define abbreviations for the refinement predicates, and we have deliberately chosen the predicates to facilitate SMT based checking and inference.","title":"The Players: Types"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#basic-operations-on-points-and-clusters","text":"Ok, with the types firmly in hand, let us go forth and develop the KMeans clustering implementation. We will use a variety of small helper functions (of the kind found in Data.List .) Lets get started by looking at them through our newly refined eyes.","title":"Basic Operations on Points and Clusters"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#grouping","text":"The first such function is groupBy . We can refine its type so that instead of just producing a [[a]] we know that it produces a Clustering a which is a list of non-empty lists. 124: {-@ groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) @-} 125: (a -> a -> (GHC.Types.Bool)) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} groupBy _ [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 126: groupBy eq ( x : xs ) = ( {VV : a | (VV = x)} x y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (len([VV]) >= 0)} ys ) y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : (a -> a -> (GHC.Types.Bool)) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} groupBy a -> a -> (GHC.Types.Bool) eq {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (len([VV]) >= 0)} zs 127: where ( {VV : [a] | (VV = ys),(len([VV]) = len([ys])),(len([VV]) >= 0)} ys , {VV : [a] | (VV = zs),(len([VV]) = len([zs])),(len([VV]) >= 0)} zs ) = (a -> (GHC.Types.Bool)) -> [a] -> ([a] , [a]) span ( a -> a -> (GHC.Types.Bool) eq {VV : a | (VV = x)} x ) {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Intuitively, its pretty easy to see how LiquidHaskell verifies the refined specification: Each element of the output list is of the form x:ys For any list ys the length is non-negative, i.e. (len ys) >= 0 The len of x:ys is 1 + (len ys) , that is, strictly positive.","title":"Grouping"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#partitioning","text":"Next, lets look the function 143: {-@ partition :: size : PosInt -> [ a ] -> ( Clustering a ) @-} 144: {-@ type PosInt = { v : Int | v > 0 } @-} which is given a strictly positive integer argument, a list of a values, and returns a Clustering a , that is, a list of non-empty lists. (Each inner list has a length that is less than size , but we shall elide this for simplicity.) The function is implemented in a straightforward manner, using the library functions take and drop 156: {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} partition {VV : (GHC.Types.Int) | (VV > 0)} size [] = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 157: partition size ys @ ( _ : _ ) = {VV : [a] | (VV = zs),(len([VV]) >= 0)} zs y:{VV : [a] | (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} partition {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (VV = zs'),(len([VV]) >= 0)} zs' 158: where 159: [a] zs = n:{VV : (GHC.Types.Int) | (VV >= 0)} -> xs:[a] -> {VV : [a] | (len([VV]) = ((len([xs]) < n) ? len([xs]) : n))} take {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (len([VV]) >= 0)} ys 160: [a] zs' = n:{VV : (GHC.Types.Int) | (VV >= 0)} -> xs:[a] -> {VV : [a] | (len([VV]) = ((len([xs]) < n) ? 0 : (len([xs]) - n)))} drop {VV : (GHC.Types.Int) | (VV = size),(VV > 0)} size {VV : [a] | (len([VV]) >= 0)} ys To verify that a valid Clustering is produced, LiquidHaskell needs only verify that the list zs above is non-empty, by suitably connecting the properties of the inputs size and ys with the output. We have verified elsewhere that 168: take :: n : { v : Int | v >= 0 } 169: -> xs : [ a ] 170: -> { v : [ a ] | ( len v ) = ( if ( ( len xs ) < n ) then ( len xs ) else n ) } In other words, the output list's length is the smaller of the input list's length and n . Thus, since both size and the (len ys) are greater than 1 , LiquidHaskell deduces that the list returned by take size ys has a length greater than 1 , i.e., is non-empty.","title":"Partitioning"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#zipping","text":"To compute the Euclidean distance between two points, we will use the zipWith function. We must make sure that it is invoked on points with the same number of dimensions, so we write 186: {-@ zipWith :: ( a -> b -> c ) 187: -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) @-} 188: (a -> b -> c) -> x4:[a] -> x2:{VV : [b] | (len([VV]) = len([x4])),(len([VV]) >= 0)} -> {VV : [c] | (len([VV]) = len([x4])), (len([VV]) = len([x2])), (len([VV]) >= 0)} zipWith a -> b -> c f ( a : as ) ( b : bs ) = a -> b -> c f {VV : a | (VV = a)} a {VV : a | (VV = b)} b y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : (a -> b -> c) -> x4:[a] -> x2:{VV : [b] | (len([VV]) = len([x4])),(len([VV]) >= 0)} -> {VV : [c] | (len([VV]) = len([x4])), (len([VV]) = len([x2])), (len([VV]) >= 0)} zipWith a -> b -> c f {VV : [a] | (VV = as),(len([VV]) >= 0)} as {VV : [a] | (VV = bs),(len([VV]) >= 0)} bs 189: zipWith _ [] [] = {VV : [{VV : a | false}] | (len([VV]) = 0)} [] The type stipulates that the second input list and the output have the same length as the first input. Furthermore, it rules out the case where one list is empty and the other is not, as in that case the former's length is zero while the latter's is not.","title":"Zipping"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#transposing","text":"The last basic operation that we will require is a means to transpose a Matrix , which itself is just a list of lists: 204: {-@ type Matrix a Rows Cols = ( List ( List a Cols ) Rows ) @-} The transpose operation flips the rows and columns. I confess that I can never really understand matrices without concrete examples, and even then, barely. So, lets say we have a matrix 212: m1 :: Matrix Int 4 2 213: m1 = [ [ 1 , 2 ] 214: , [ 3 , 4 ] 215: , [ 5 , 6 ] 216: , [ 7 , 8 ] ] then the matrix m2 = transpose 2 3 m1 should be 220: m2 :: Matrix Int 2 4 221: m2 = [ [ 1 , 3 , 5 , 7 ] 222: , [ 2 , 4 , 6 , 8 ] ] We will use a Matrix a m n to represent a single cluster of m points each of which has n dimensions. We will transpose the matrix to make it easy to sum and average the points along each dimension, in order to compute the center of the cluster. As you can work out from the above, the code for transpose is quite straightforward: each output row is simply the list of head s of the input rows : 235: transpose :: Int -> Int -> [ [ a ] ] -> [ [ a ] ] 236: 237: c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [a] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [a] | (len([VV]) = r)}] | (len([v]) = c)} transpose 0 _ _ = {VV : [{VV : [{VV : a | false}] | false}] | (len([VV]) = 0)} [] 238: 239: transpose c r ( ( col00 : col01s ) : row1s ) 240: = {VV : [a] | (VV = row0'),(len([VV]) >= 0)} row0' y:{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)} -> ys:[{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) = len([row0'])), (len([VV]) = len([rest])), (len([VV]) > 0)}] | (len([VV]) = (1 + len([ys])))} : {v : [[a]] | (v = row1s'),(len([v]) >= 0)} row1s' 241: where 242: [a] row0' = {VV : a | (VV = col00)} col00 y:a -> ys:[a] -> {VV : [a] | (len([VV]) = (1 + len([ys])))} : {VV : [a] | (len([VV]) = len([row1s])),(len([VV]) >= 0)} [ {VV : a | (VV = col0)} col0 | ( col0 : _ ) <- {VV : [[a]] | (VV = row1s),(len([VV]) >= 0)} row1s ] 243: [{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)}] rest = {VV : [a] | (VV = col01s),(len([VV]) >= 0)} col01s y:{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)} -> ys:[{VV : [a] | (len([VV]) = len([col01s])),(len([VV]) >= 0)}] -> {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (len([VV]) = (1 + len([ys])))} : {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (len([VV]) = len([row1s])),(len([VV]) >= 0)} [ {VV : [a] | (VV = col1s),(len([VV]) >= 0)} col1s | ( _ : col1s ) <- {VV : [[a]] | (VV = row1s),(len([VV]) >= 0)} row1s ] 244: [[a]] row1s' = c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [a] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [a] | (len([VV]) = r)}] | (len([v]) = c)} transpose ( (GHC.Types.Int) c x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) {VV : (GHC.Types.Int) | (VV > 0)} r {VV : [{VV : [a] | (len([VV]) = len([col01s])), (len([VV]) >= 0)}] | (VV = rest),(len([VV]) >= 0)} rest LiquidHaskell verifies that 250: {-@ transpose :: c : Int -> r : PosInt -> Matrix a r c -> Matrix a c r @-} Try to work it out for yourself on pencil and paper. If you like you can get a hint by seeing how LiquidHaskell figures it out. Lets work backwards . LiquidHaskell verifies the output type by inferring that 259: row0' :: ( List a r ) 260: row1s' :: List ( List a r ) ( c - 1 ) -- i.e. Matrix a (c - 1) r and so, by simply using the measure-refined type for : 264: ( : ) :: x : a -> xs : [ a ] -> { v : [ a ] | ( len v ) = 1 + ( len xs ) } LiquidHaskell deduces that 268: row0 : rows' :: List ( List a r ) c That is, 272: row0 : rows' :: Matrix a c r Excellent! Now, lets work backwards. How does it infer the types of row0' and row1s' ? The first case is easy: row0' is just the list of heads of each row, hence a List a r . Now, lets look at row1s' . Notice that row1s is the matrix of all except the first row of the input Matrix, and so 280: row1s :: Matrix a ( r - 1 ) c and so, as 284: col01s :: List a ( c - 1 ) 285: col1s :: List a ( c - 1 ) LiquidHaskell deduces that since rest is the concatenation of r-1 tails from row1s 289: rest = col01s : [ col1s | ( _ : col1s ) <- row1s ] the type of rest is 293: rest :: List ( List a ( c - 1 ) ) r which is just 297: rest :: Matrix a r ( c - 1 ) Now, LiquidHaskell deduces row1s' :: Matrix a (c-1) r by inductively plugging in the output type of the recursive call, thereby checking the function's signature. Whew! That was a fair bit of work, wasn't it! Happily, we didn't have to do any of it. Instead, using the SMT solver, LiquidHaskell ploughs through calculations like that and guarantees to us that transpose indeed flips the dimensions of the inner and outer lists. Aside: Comprehensions vs. Map Incidentally, the code above is essentially that of transpose from the Prelude with some extra local variables for exposition. You could instead use a map head and map tail and I encourage you to go ahead and see for yourself.","title":"Transposing"},{"location":"blogposts/2013-02-16-kmeans-clustering-I.lhs/#intermission","text":"Time for a break -- go see a cat video! -- or skip it, stretch your legs, and return post-haste for the next installment , in which we will use the types and functions described above, to develop the clustering algorithm.","title":"Intermission"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/","text":"The story so far: Previously we saw how to encode n -dimensional points using plain old Haskell lists, how to encode a matrix with r rows and c columns as a list of lists, some basic operations on points and matrices via list-manipulating functions More importantly, we saw how easy it was to encode dimensionality with refinements over the len measure, thereby allowing LiquidHaskell to precisely track the dimensions across the various operations. Next, lets use the basic types and operations to develop the actual KMeans clustering algorithm, and, along the way, see how LiquidHaskell lets us write precise module contracts which will ward against various unpleasant lumpenexceptions . 30: {-# LANGUAGE ScopedTypeVariables, TypeSynonymInstances, FlexibleInstances #-} 31: 32: module KMeans ( kmeans , kmeansGen ) where 33: 34: import KMeansHelper 35: import Prelude hiding ( zipWith ) 36: import Data . List ( sort , span , minimumBy ) 37: import Data . Function ( on ) 38: import Data . Ord ( comparing ) 39: import Language . Haskell . Liquid . Prelude ( liquidAssert , liquidError ) 40: 41: instance (GHC.Classes.Eq (KMeans.WrapType [GHC.Types.Double] a)) Eq ( WrapType [ Double ] a ) where 42: ( == ) = x:{VV : [{VV : (GHC.Types.Double) | false}] | false} -> y:{VV : [{VV : (GHC.Types.Double) | false}] | false} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} ( == ) ({VV : [{VV : (GHC.Types.Double) | false}] | false} -> {VV : [{VV : (GHC.Types.Double) | false}] | false} -> {VV : (GHC.Types.Bool) | false}) -> ({VV : (KMeans.WrapType {VV : [{VV : (GHC.Types.Double) | false}] | false} {VV : a | false}) | false} -> {VV : [{VV : (GHC.Types.Double) | false}] | false}) -> {VV : (KMeans.WrapType {VV : [{VV : (GHC.Types.Double) | false}] | false} {VV : a | false}) | false} -> {VV : (KMeans.WrapType {VV : [{VV : (GHC.Types.Double) | false}] | false} {VV : a | false}) | false} -> {VV : (GHC.Types.Bool) | false} `on` (KMeans.WrapType {VV : [{VV : (GHC.Types.Double) | false}] | false} {VV : a | false}) -> {VV : [{VV : (GHC.Types.Double) | false}] | false} getVect 43: 44: instance (GHC.Classes.Ord (KMeans.WrapType [GHC.Types.Double] a)) Ord ( WrapType [ Double ] a ) where 45: compare = (GHC.Classes.Ord [GHC.Types.Double]) comparing (KMeans.WrapType {VV : [{VV : (GHC.Types.Double) | false}] | false} {VV : a | false}) -> {VV : [{VV : (GHC.Types.Double) | false}] | false} getVect Recall that we are using a modified version of an existing KMeans implementation . While not the swiftest implementation, it serves as a nice introduction to the algorithm, and the general invariants carry over to more sophisticated implementations. A Quick Recap \u00b6 Before embarking on the journey, lets remind ourselves of our destination: the goal of K-Means clustering is Take as Input : A set of points represented by n-dimensional points in Euclidian space Return as Ouptut : A partitioning of the points, into upto K clusters, in a manner that minimizes the sum of distances between each point and its cluster center. Last time, we introduced a variety of refinement type aliases for Haskell lists Fixed Length Lists 66: type List a N = { v : [ a ] | ( len v ) = N } Non-empty Lists 70: type NonEmptyList a = { v : [ a ] | ( len v ) > 0 } N-Dimensional Points 74: type Point N = List Double N Matrices 78: type Matrix a Rows Cols = List ( List a Cols ) Rows We also saw several basic list operations 82: groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) 83: partition :: PosInt -> [ a ] -> ( Clustering a ) 84: zipWith :: ( a -> b -> c ) -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) 85: transpose :: c : Int -> r : PosInt -> Matrix a r c -> Matrix a c r whose types will prove essential in order to verify the invariants of the clustering algorithm. You might open the previous episode in a separate tab to keep those functions handy, but fear not, we will refresh our memory about them when we get around to using them below. Generalized Points \u00b6 To be more flexible, we will support arbitrary points as long as they can be projected to Euclidian space. In addition to supporting, say, an image or a cat video as a point, this will allow us to weight different dimensions to different degrees. We represent generalized points with a record 104: data WrapType b a = WrapType { (KMeans.WrapType a b) -> a getVect :: b , (KMeans.WrapType a b) -> b getVal :: a } and we can define an alias that captures the dimensionality of the point 110: {-@ type GenPoint a N = WrapType ( Point N ) a @-} That is, GenPoint a N denotes a general a value that has an N -dimensional projection into Euclidean space. Algorithm: Iterative Clustering \u00b6 Terrific, now that all the pieces are in place lets look at the KMeans algorithm. We have implemented a function kmeans' , which takes as input a dimension n , the maximum number of clusters k (which must be positive), a list of generalized points of dimension n , and returns a Clustering (i.e. a list of non-empty lists ) of the generalized points. So much verbiage -- a type is worth a thousand comments! 128: {-@ kmeans' :: n : Int 129: -> k : PosInt 130: -> points : [ ( GenPoint a n ) ] 131: -> ( Clustering ( GenPoint a n ) ) @-} There! Crisp and to the point. Sorry. Anyhoo, the function implements the above type. 138: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] kmeans' (GHC.Types.Int) n {VV : (GHC.Types.Int) | (VV > 0)} k [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] points = (GHC.Classes.Eq [[KMeans.WrapType [GHC.Types.Double] a]]) fixpoint ( n:(GHC.Types.Int) -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] refineCluster {VV : (GHC.Types.Int) | (VV = n)} n ) {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] | (VV = initialClustering), (len([VV]) >= 0)} initialClustering 139: where 140: [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] initialClustering = {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] partition {VV : (GHC.Types.Int) | (VV = clusterSize)} clusterSize {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points 141: (GHC.Types.Int) clusterSize = x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = ((x > y) ? x : y))} max {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ( (GHC.Types.Int) ( xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k ) 142: 143: fixpoint :: ( Eq a ) => ( a -> a ) -> a -> a 144: (GHC.Classes.Eq a) -> (a -> a) -> a -> a fixpoint a -> a f a x = if (GHC.Types.Bool) ( a -> a f {VV : a | (VV = x)} x ) x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == {VV : a | (VV = x)} x then {VV : a | (VV = x)} x else (GHC.Classes.Eq a) -> (a -> a) -> a -> a fixpoint a -> a f ( a -> a f {VV : a | (VV = x)} x ) That is, kmeans' creates an initialClustering by partition -ing the points into chunks with clusterSize elements. Then, it invokes fixpoint to iteratively refine the initial clustering with refineCluster until it converges to a stable clustering that cannot be improved upon. This stable clustering is returned as the output. LiquidHaskell verifies that kmeans' adheres to the given signature in two steps. 1. Initial Clustering First, LiquidHaskell determines from 159: max :: ( Ord a ) => x : a -> y : a -> { v : a | ( v >= x ) && ( v >= y ) } that clusterSize is strictly positive, and hence, from 163: partition :: size : PosInt -> [ a ] -> ( Clustering a ) which we saw last time , that initialClustering is indeed a valid Clustering of (GenPoint a n) . 2. Fixpoint Next, LiquidHaskell infers that at the call fixpoint (refineCluster n) ... , that the type parameter a of fixpoint can be instantiated with Clustering (GenPoint a n) . This is because initialClustering is a valid clustering, as we saw above, and because refineCluster takes -- and returns -- valid n -dimensional clusterings, as we shall see below. Consequently, the value returned by kmeans' is also Clustering of GenPoint a n as required. Refining A Clustering \u00b6 Thus, the real work in KMeans happens inside refineCluster , which takes a clustering and improves it, like so: 186: n:(GHC.Types.Int) -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] refineCluster (GHC.Types.Int) n [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] clusters = {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (VV = clusters'), (len([VV]) = len([centeredGroups])), (len([VV]) >= 0)} clusters' 187: where 188: -- 1. Compute cluster centers 189: {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([clusters]))} centers = ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}) -> xs:[{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([xs]))} map ( n:(GHC.Types.Int) -> {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} clusterCenter {VV : (GHC.Types.Int) | (VV = n)} n ) {VV : [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] | (VV = clusters), (len([VV]) >= 0)} clusters 190: 191: -- 2. Map points to their nearest center 192: [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] points = [[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)]] -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] concat {VV : [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] | (VV = clusters), (len([VV]) >= 0)} clusters 193: [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] centeredPoints = (GHC.Classes.Ord ([GHC.Types.Double], KMeans.WrapType [GHC.Types.Double] a)) sort {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) = len([points])), (len([VV]) >= 0)} [ ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) ( n:(GHC.Types.Int) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} nearestCenter {VV : (GHC.Types.Int) | (VV = n)} n (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) p {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (VV = centers), (len([VV]) = len([clusters])), (len([VV]) >= 0)} centers , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) p ) | p <- {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points ] 194: 195: -- 3. Group points by nearest center to get new clusters 196: [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] centeredGroups = (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (GHC.Types.Bool)) -> [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] -> [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] groupBy ( (GHC.Classes.Eq [GHC.Types.Double]) ( == ) ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> (GHC.Types.Bool)) -> (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)}) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (GHC.Types.Bool) `on` ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} fst ) {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (VV = centeredPoints), (len([VV]) >= 0)} centeredPoints 197: {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (len([VV]) = len([centeredGroups]))} clusters' = ({VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)} -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}) -> xs:[{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] -> {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (len([VV]) = len([xs]))} map ( (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> xs:[({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) = len([xs]))} map ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a) snd ) {VV : [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] | (VV = centeredGroups), (len([VV]) >= 0)} centeredGroups The behavior of refineCluster is pithily captured by its type 203: {-@ refineCluster :: n : Int 204: -> Clustering ( GenPoint a n ) 205: -> Clustering ( GenPoint a n ) @-} The refined clustering is computed in three steps. First, we compute the centers :: [(Point n)] of the current clusters . This is achieved by using clusterCenter , which maps a list of generalized n -dimensional points to a single n dimensional point (i.e. Point n ). Next, we pair each point p in the list of all points with its nearestCenter . Finally, the pairs in the list of centeredPoints are grouped by the center, i.e. the first element of the tuple. The resulting groups are projected back to the original generalized points yielding the new clustering. The type of the output follows directly from 222: groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) from last time . At the call site above, LiquidHaskell infers that a can be instantiated with ((Point n), (GenPoint a n)) thereby establishing that, after projecting away the first element, the output is a list of non-empty lists of generalized n -dimensional points. That leaves us with the two crucial bits of the algorithm: clusterCenter and nearestCenter . Computing the Center of a Cluster \u00b6 The center of an n -dimensional cluster is simply an n -dimensional point whose value in each dimension is equal to the average value of that dimension across all the points in the cluster. For example, consider a cluster of 2-dimensional points, 241: exampleCluster = [ [ 0 , 0 ] 242: , [ 1 , 10 ] 243: , [ 2 , 20 ] 244: , [ 4 , 40 ] 245: , [ 5 , 50 ] ] The center of the cluster is 249: exampleCenter = [ ( 0 + 1 + 2 + 4 + 5 ) / 5 250: , ( 0 + 10 + 20 + 40 + 50 ) / 5 ] which is just 254: exampleCenter = [ 3 , 30 ] Thus, we can compute a clusterCenter via the following procedure 260: n:(GHC.Types.Int) -> {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} clusterCenter (GHC.Types.Int) n {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} xs = ({VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double)) -> xs:[{VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} map {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) average {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = numPoints)}] | (v = xs'), (len([v]) = n), (len([v]) >= 0)} xs' 261: where 262: {VV : (GHC.Types.Int) | (VV = len([xs]))} numPoints = xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (v = xs), (len([v]) > 0), (len([v]) >= 0)} xs 263: {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = numPoints)}] | (len([v]) = n)} xs' = c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = r)}] | (len([v]) = c)} transpose {VV : (GHC.Types.Int) | (VV = n)} n {VV : (GHC.Types.Int) | (VV = numPoints),(VV = len([xs]))} numPoints ( ((KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}) -> xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([xs]))} map (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} getVect {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (v = xs), (len([v]) > 0), (len([v]) >= 0)} xs ) 264: 265: average :: [ Double ] -> Double 266: {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) average = ( (GHC.Types.Double) -> {VV : (GHC.Types.Int) | (VV > 0)} -> (GHC.Types.Double) `safeDiv` {VV : (GHC.Types.Int) | (VV = numPoints),(VV = len([xs]))} numPoints ) ((GHC.Types.Double) -> (GHC.Types.Double)) -> ({VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) . [(GHC.Types.Double)] -> (GHC.Types.Double) sum First, we transpose the matrix of points in the cluster. Suppose that xs is the exampleCluster from above (and so n is 2 and numPoints is 5 .) In this scenario, xs' is 274: xs' = [ [ 0 , 1 , 2 , 4 , 5 ] 275: , [ 0 , 10 , 20 , 40 , 50 ] ] and so map average xs' evaluates to exampleCenter from above. We have ensured that the division in the average does not lead to any nasty surprises via a safe division function whose precondition checks that the denominator is non-zero, as illustrated here . 285: {- safeDiv :: (Fractional a) => a -> {v:Int | v != 0} -> a -} 286: safeDiv :: ( Fractional a ) => a -> Int -> a 287: (GHC.Real.Fractional a) -> a -> {VV : (GHC.Types.Int) | (VV > 0)} -> a safeDiv a n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 288: safeDiv n d = {VV : a | (VV = n)} n x:a -> y:{VV : a | (VV != 0)} -> {VV : a | (VV = (x / y))} / ( (GHC.Num.Num a) fromIntegral {VV : (GHC.Types.Int) | (VV > 0)} d ) LiquidHaskell verifies that the divide-by-zero never occurs, and furthermore, that clusterCenter indeed computes an n -dimensional center by inferring that 295: {-@ clusterCenter :: n : Int -> NonEmptyList ( GenPoint a n ) -> Point n @-} LiquidHaskell deduces that the input list of points xs is non-empty from the fact that clusterCenter is only invoked on the elements of a Clustering which comprise only non-empty lists. Since xs is non-empty, i.e. (len xs) > 0 , LiquidHaskell infers that numPoints is positive (hover over length to understand why), and hence, LiquidHaskell is satisfied that the call to safeDiv will always proceed without any incident. To establish the output type Point n LiquidHaskell leans on the fact that 307: transpose :: n : Int -> m : PosInt -> Matrix a m n -> Matrix a n m to deduce that xs' is of type Matrix Double n numPoints , that is to say, a list of length n containing lists of length numPoints . Since map preserves the length, the value map average xs' is also a list of length n , i.e. Point n . Finding the Nearest Center \u00b6 The last piece of the puzzle is nearestCenter which maps each (generalized) point to the center that it is nearest. The code is pretty self-explanatory: 324: nearestCenter :: Int -> WrapType [ Double ] a -> [ [ Double ] ] -> [ Double ] 325: n:(GHC.Types.Int) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} nearestCenter (GHC.Types.Int) n (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) x = {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} minKey ({VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)}) -> ([{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)}) -> [{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} . ({VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))) -> xs:[{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] -> {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) = len([xs]))} map ( c:{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> ({VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} , (GHC.Types.Double)) \\ {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} c -> x1:a -> b -> (a , b) ( {VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} c , a:{VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} -> (GHC.Types.Double) distance {VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} c ( (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} getVect {VV : (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) | (VV = x)} x ) ) ) We map the centers to a tuple of center c and the distance between x and c , and then we select the tuple with the smallest distance 332: minKey :: ( Ord v ) => [ ( k , v ) ] -> k 333: (GHC.Classes.Ord a) -> {VV : [(b , a)] | (len([VV]) >= 0)} -> b minKey = (a , b) -> a fst ((a , b) -> a) -> ({VV : [(a , b)] | (len([VV]) >= 0)} -> (a , b)) -> {VV : [(a , b)] | (len([VV]) >= 0)} -> a . ((a , b) -> (a , b) -> (GHC.Types.Ordering)) -> [(a , b)] -> (a , b) minimumBy ( (a , b) -> (a , b) -> (GHC.Types.Ordering) \\ (a , b) x (a , b) y -> x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV = EQ) <=> (x = y)), ((VV = GT) <=> (x > y)), ((VV = LT) <=> (x < y))} compare ( (a , b) -> b snd {VV : (a , b) | (VV = x)} x ) ( (a , b) -> b snd {VV : (a , b) | (VV = y)} y ) ) The interesting bit is that the distance function uses zipWith to ensure that the dimensionality of the center and the point match up. 340: distance :: [ Double ] -> [ Double ] -> Double 341: a:{VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} -> (GHC.Types.Double) distance {VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} a {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} b = (GHC.Types.Double) -> (GHC.Types.Double) sqrt ((GHC.Types.Double) -> (GHC.Types.Double)) -> ({VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double) . [(GHC.Types.Double)] -> (GHC.Types.Double) sum ({VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double) $ ((GHC.Types.Double) -> (GHC.Types.Double) -> (GHC.Types.Double)) -> xs:[(GHC.Types.Double)] -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} zipWith ( (GHC.Types.Double) -> (GHC.Types.Double) -> (GHC.Types.Double) \\ (GHC.Types.Double) v1 (GHC.Types.Double) v2 -> {VV : (GHC.Integer.Type.Integer) | (VV = 2)} ( {VV : (GHC.Types.Double) | (VV = v1)} v1 x:(GHC.Types.Double) -> y:(GHC.Types.Double) -> {VV : (GHC.Types.Double) | (VV = (x - y))} - {VV : (GHC.Types.Double) | (VV = v2)} v2 ) (GHC.Types.Double) -> (GHC.Integer.Type.Integer) -> (GHC.Types.Double) ^ 2 ) {VV : [(GHC.Types.Double)] | (VV = a),(len([VV]) >= 0)} a {VV : [(GHC.Types.Double)] | (VV = b), (len([VV]) = len([a])), (len([VV]) >= 0)} b LiquidHaskell verifies distance by inferring that 347: {-@ nearestCenter :: n : Int -> ( GenPoint a n ) -> [ ( Point n ) ] -> ( Point n ) @-} First, LiquidHaskell deduces that each center in cs is indeed n -dimensional, which follows from the output type of clusterCenter . Since x is a (GenPoint a n) LiquidHaskell infers that both c and getVect x are of an equal length n . Consequently, the call to 355: zipWith :: ( a -> b -> c ) -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) discussed last time is determined to be safe. Finally, the value returned is just one of the input centers and so is a (Point n) . Putting It All Together: Top-Level API \u00b6 We can bundle the algorithm into two top-level API functions. First, a version that clusters generalized points. In this case, we require a function that can project an a value to an n -dimensional point. This function just wraps each a , clusters via kmeans' and then unwraps the points. 374: {-@ kmeansGen :: n : Int 375: -> ( a -> ( Point n ) ) 376: -> k : PosInt 377: -> xs : [ a ] 378: -> ( Clustering a ) 379: @-} 380: 381: n:(GHC.Types.Int) -> (a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)}) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> [{VV : [a] | (len([VV]) > 0)}] kmeansGen (GHC.Types.Int) n a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} project {VV : (GHC.Types.Int) | (VV > 0)} k = ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)} -> {VV : [a] | (len([VV]) > 0)}) -> xs:[{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = len([xs]))} map ( ((KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> a) -> xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : [a] | (len([VV]) = len([xs]))} map (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> a getVal ) 382: ([{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)}) -> ([a] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}]) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} . n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] kmeans' {VV : (GHC.Types.Int) | (VV = n)} n {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k 383: ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) >= 0)} -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}]) -> ([a] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) >= 0)}) -> [a] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] . (a -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> xs:[a] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) = len([xs]))} map ( x:a -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} {VV : a | (VV = x)}) \\ a x -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> {VV : a | (VV = x)} -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} {VV : a | (VV = x)}) WrapType ( a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} project {VV : a | (VV = x)} x ) {VV : a | (VV = x)} x ) Second, a specialized version that operates directly on n -dimensional points. The specialized version just calls the general version with a trivial id projection. 391: {-@ kmeans :: n : Int 392: -> k : PosInt 393: -> points : [ ( Point n ) ] 394: -> ( Clustering ( Point n ) ) 395: @-} 396: 397: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> [{v : [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] | (len([v]) > 0)}] kmeans (GHC.Types.Int) n = n:(GHC.Types.Int) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)}) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> [{VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) > 0)}] kmeansGen {VV : (GHC.Types.Int) | (VV = n)} n x:{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> {VV : [(GHC.Types.Double)] | (VV = x), (n = len([VV])), (len([VV]) = n)} id Conclusions \u00b6 I hope that over the last two posts you have gotten a sense of What KMeans clustering is all about, How measures and refinements can be used to describe the behavior of common list operations like map , transpose , groupBy , zipWith , and so on, How LiquidHaskell's automated inference makes it easy to write and verify invariants of non-trivial programs. The sharp reader will have noticed that the one major , non syntactic, change to the original code is the addition of the dimension parameter n throughout the code. This is critically required so that we can specify the relevant invariants (which are in terms of n .) The value is actually a ghost, and never ever used. Fortunately, Haskell's laziness means that we don't have to worry about it (or other ghost variables) imposing any run-time overhead at all. Exercise: Incidentally, if you have followed thus far I would encourage you to ponder about how you might modify the types (and implementation) to verify that KMeans indeed produces at most k clusters...","title":"KMeans Clustering II"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#a-quick-recap","text":"Before embarking on the journey, lets remind ourselves of our destination: the goal of K-Means clustering is Take as Input : A set of points represented by n-dimensional points in Euclidian space Return as Ouptut : A partitioning of the points, into upto K clusters, in a manner that minimizes the sum of distances between each point and its cluster center. Last time, we introduced a variety of refinement type aliases for Haskell lists Fixed Length Lists 66: type List a N = { v : [ a ] | ( len v ) = N } Non-empty Lists 70: type NonEmptyList a = { v : [ a ] | ( len v ) > 0 } N-Dimensional Points 74: type Point N = List Double N Matrices 78: type Matrix a Rows Cols = List ( List a Cols ) Rows We also saw several basic list operations 82: groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) 83: partition :: PosInt -> [ a ] -> ( Clustering a ) 84: zipWith :: ( a -> b -> c ) -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) 85: transpose :: c : Int -> r : PosInt -> Matrix a r c -> Matrix a c r whose types will prove essential in order to verify the invariants of the clustering algorithm. You might open the previous episode in a separate tab to keep those functions handy, but fear not, we will refresh our memory about them when we get around to using them below.","title":"A Quick Recap"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#generalized-points","text":"To be more flexible, we will support arbitrary points as long as they can be projected to Euclidian space. In addition to supporting, say, an image or a cat video as a point, this will allow us to weight different dimensions to different degrees. We represent generalized points with a record 104: data WrapType b a = WrapType { (KMeans.WrapType a b) -> a getVect :: b , (KMeans.WrapType a b) -> b getVal :: a } and we can define an alias that captures the dimensionality of the point 110: {-@ type GenPoint a N = WrapType ( Point N ) a @-} That is, GenPoint a N denotes a general a value that has an N -dimensional projection into Euclidean space.","title":"Generalized Points"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#algorithm-iterative-clustering","text":"Terrific, now that all the pieces are in place lets look at the KMeans algorithm. We have implemented a function kmeans' , which takes as input a dimension n , the maximum number of clusters k (which must be positive), a list of generalized points of dimension n , and returns a Clustering (i.e. a list of non-empty lists ) of the generalized points. So much verbiage -- a type is worth a thousand comments! 128: {-@ kmeans' :: n : Int 129: -> k : PosInt 130: -> points : [ ( GenPoint a n ) ] 131: -> ( Clustering ( GenPoint a n ) ) @-} There! Crisp and to the point. Sorry. Anyhoo, the function implements the above type. 138: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] kmeans' (GHC.Types.Int) n {VV : (GHC.Types.Int) | (VV > 0)} k [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] points = (GHC.Classes.Eq [[KMeans.WrapType [GHC.Types.Double] a]]) fixpoint ( n:(GHC.Types.Int) -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] refineCluster {VV : (GHC.Types.Int) | (VV = n)} n ) {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] | (VV = initialClustering), (len([VV]) >= 0)} initialClustering 139: where 140: [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] initialClustering = {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] partition {VV : (GHC.Types.Int) | (VV = clusterSize)} clusterSize {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points 141: (GHC.Types.Int) clusterSize = x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = ((x > y) ? x : y))} max {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ( (GHC.Types.Int) ( xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x - y))} - {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x / y))} `div` {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k ) 142: 143: fixpoint :: ( Eq a ) => ( a -> a ) -> a -> a 144: (GHC.Classes.Eq a) -> (a -> a) -> a -> a fixpoint a -> a f a x = if (GHC.Types.Bool) ( a -> a f {VV : a | (VV = x)} x ) x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x = y))} == {VV : a | (VV = x)} x then {VV : a | (VV = x)} x else (GHC.Classes.Eq a) -> (a -> a) -> a -> a fixpoint a -> a f ( a -> a f {VV : a | (VV = x)} x ) That is, kmeans' creates an initialClustering by partition -ing the points into chunks with clusterSize elements. Then, it invokes fixpoint to iteratively refine the initial clustering with refineCluster until it converges to a stable clustering that cannot be improved upon. This stable clustering is returned as the output. LiquidHaskell verifies that kmeans' adheres to the given signature in two steps. 1. Initial Clustering First, LiquidHaskell determines from 159: max :: ( Ord a ) => x : a -> y : a -> { v : a | ( v >= x ) && ( v >= y ) } that clusterSize is strictly positive, and hence, from 163: partition :: size : PosInt -> [ a ] -> ( Clustering a ) which we saw last time , that initialClustering is indeed a valid Clustering of (GenPoint a n) . 2. Fixpoint Next, LiquidHaskell infers that at the call fixpoint (refineCluster n) ... , that the type parameter a of fixpoint can be instantiated with Clustering (GenPoint a n) . This is because initialClustering is a valid clustering, as we saw above, and because refineCluster takes -- and returns -- valid n -dimensional clusterings, as we shall see below. Consequently, the value returned by kmeans' is also Clustering of GenPoint a n as required.","title":"Algorithm: Iterative Clustering"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#refining-a-clustering","text":"Thus, the real work in KMeans happens inside refineCluster , which takes a clustering and improves it, like so: 186: n:(GHC.Types.Int) -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] refineCluster (GHC.Types.Int) n [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] clusters = {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (VV = clusters'), (len([VV]) = len([centeredGroups])), (len([VV]) >= 0)} clusters' 187: where 188: -- 1. Compute cluster centers 189: {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([clusters]))} centers = ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}) -> xs:[{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([xs]))} map ( n:(GHC.Types.Int) -> {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} clusterCenter {VV : (GHC.Types.Int) | (VV = n)} n ) {VV : [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] | (VV = clusters), (len([VV]) >= 0)} clusters 190: 191: -- 2. Map points to their nearest center 192: [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] points = [[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)]] -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] concat {VV : [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] | (VV = clusters), (len([VV]) >= 0)} clusters 193: [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] centeredPoints = (GHC.Classes.Ord ([GHC.Types.Double], KMeans.WrapType [GHC.Types.Double] a)) sort {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) = len([points])), (len([VV]) >= 0)} [ ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) ( n:(GHC.Types.Int) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} nearestCenter {VV : (GHC.Types.Int) | (VV = n)} n (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) p {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (VV = centers), (len([VV]) = len([clusters])), (len([VV]) >= 0)} centers , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) p ) | p <- {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (VV = points), (len([VV]) >= 0)} points ] 194: 195: -- 3. Group points by nearest center to get new clusters 196: [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] centeredGroups = (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (GHC.Types.Bool)) -> [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] -> [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] groupBy ( (GHC.Classes.Eq [GHC.Types.Double]) ( == ) ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> (GHC.Types.Bool)) -> (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)}) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (GHC.Types.Bool) `on` ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} fst ) {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (VV = centeredPoints), (len([VV]) >= 0)} centeredPoints 197: {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (len([VV]) = len([centeredGroups]))} clusters' = ({VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)} -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}) -> xs:[{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] -> {VV : [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) > 0)}] | (len([VV]) = len([xs]))} map ( (({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> xs:[({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) = len([xs]))} map ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a) snd ) {VV : [{VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a))] | (len([VV]) > 0)}] | (VV = centeredGroups), (len([VV]) >= 0)} centeredGroups The behavior of refineCluster is pithily captured by its type 203: {-@ refineCluster :: n : Int 204: -> Clustering ( GenPoint a n ) 205: -> Clustering ( GenPoint a n ) @-} The refined clustering is computed in three steps. First, we compute the centers :: [(Point n)] of the current clusters . This is achieved by using clusterCenter , which maps a list of generalized n -dimensional points to a single n dimensional point (i.e. Point n ). Next, we pair each point p in the list of all points with its nearestCenter . Finally, the pairs in the list of centeredPoints are grouped by the center, i.e. the first element of the tuple. The resulting groups are projected back to the original generalized points yielding the new clustering. The type of the output follows directly from 222: groupBy :: ( a -> a -> Bool ) -> [ a ] -> ( Clustering a ) from last time . At the call site above, LiquidHaskell infers that a can be instantiated with ((Point n), (GenPoint a n)) thereby establishing that, after projecting away the first element, the output is a list of non-empty lists of generalized n -dimensional points. That leaves us with the two crucial bits of the algorithm: clusterCenter and nearestCenter .","title":"Refining A Clustering"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#computing-the-center-of-a-cluster","text":"The center of an n -dimensional cluster is simply an n -dimensional point whose value in each dimension is equal to the average value of that dimension across all the points in the cluster. For example, consider a cluster of 2-dimensional points, 241: exampleCluster = [ [ 0 , 0 ] 242: , [ 1 , 10 ] 243: , [ 2 , 20 ] 244: , [ 4 , 40 ] 245: , [ 5 , 50 ] ] The center of the cluster is 249: exampleCenter = [ ( 0 + 1 + 2 + 4 + 5 ) / 5 250: , ( 0 + 10 + 20 + 40 + 50 ) / 5 ] which is just 254: exampleCenter = [ 3 , 30 ] Thus, we can compute a clusterCenter via the following procedure 260: n:(GHC.Types.Int) -> {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} clusterCenter (GHC.Types.Int) n {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)} xs = ({VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double)) -> xs:[{VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} map {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) average {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = numPoints)}] | (v = xs'), (len([v]) = n), (len([v]) >= 0)} xs' 261: where 262: {VV : (GHC.Types.Int) | (VV = len([xs]))} numPoints = xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : (GHC.Types.Int) | (VV = len([xs]))} length {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (v = xs), (len([v]) > 0), (len([v]) >= 0)} xs 263: {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = numPoints)}] | (len([v]) = n)} xs' = c:(GHC.Types.Int) -> r:{VV : (GHC.Types.Int) | (VV > 0)} -> {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = c)}] | (len([v]) = r)} -> {v : [{VV : [(GHC.Types.Double)] | (len([VV]) = r)}] | (len([v]) = c)} transpose {VV : (GHC.Types.Int) | (VV = n)} n {VV : (GHC.Types.Int) | (VV = numPoints),(VV = len([xs]))} numPoints ( ((KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}) -> xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) = len([xs]))} map (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} getVect {v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (v = xs), (len([v]) > 0), (len([v]) >= 0)} xs ) 264: 265: average :: [ Double ] -> Double 266: {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) average = ( (GHC.Types.Double) -> {VV : (GHC.Types.Int) | (VV > 0)} -> (GHC.Types.Double) `safeDiv` {VV : (GHC.Types.Int) | (VV = numPoints),(VV = len([xs]))} numPoints ) ((GHC.Types.Double) -> (GHC.Types.Double)) -> ({VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (numPoints = len([VV])), (len([VV]) = numPoints), (len([VV]) = len([xs])), (len([VV]) > 0)} -> (GHC.Types.Double) . [(GHC.Types.Double)] -> (GHC.Types.Double) sum First, we transpose the matrix of points in the cluster. Suppose that xs is the exampleCluster from above (and so n is 2 and numPoints is 5 .) In this scenario, xs' is 274: xs' = [ [ 0 , 1 , 2 , 4 , 5 ] 275: , [ 0 , 10 , 20 , 40 , 50 ] ] and so map average xs' evaluates to exampleCenter from above. We have ensured that the division in the average does not lead to any nasty surprises via a safe division function whose precondition checks that the denominator is non-zero, as illustrated here . 285: {- safeDiv :: (Fractional a) => a -> {v:Int | v != 0} -> a -} 286: safeDiv :: ( Fractional a ) => a -> Int -> a 287: (GHC.Real.Fractional a) -> a -> {VV : (GHC.Types.Int) | (VV > 0)} -> a safeDiv a n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : a | false} liquidError {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"divide by zero\" 288: safeDiv n d = {VV : a | (VV = n)} n x:a -> y:{VV : a | (VV != 0)} -> {VV : a | (VV = (x / y))} / ( (GHC.Num.Num a) fromIntegral {VV : (GHC.Types.Int) | (VV > 0)} d ) LiquidHaskell verifies that the divide-by-zero never occurs, and furthermore, that clusterCenter indeed computes an n -dimensional center by inferring that 295: {-@ clusterCenter :: n : Int -> NonEmptyList ( GenPoint a n ) -> Point n @-} LiquidHaskell deduces that the input list of points xs is non-empty from the fact that clusterCenter is only invoked on the elements of a Clustering which comprise only non-empty lists. Since xs is non-empty, i.e. (len xs) > 0 , LiquidHaskell infers that numPoints is positive (hover over length to understand why), and hence, LiquidHaskell is satisfied that the call to safeDiv will always proceed without any incident. To establish the output type Point n LiquidHaskell leans on the fact that 307: transpose :: n : Int -> m : PosInt -> Matrix a m n -> Matrix a n m to deduce that xs' is of type Matrix Double n numPoints , that is to say, a list of length n containing lists of length numPoints . Since map preserves the length, the value map average xs' is also a list of length n , i.e. Point n .","title":"Computing the Center of a Cluster"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#finding-the-nearest-center","text":"The last piece of the puzzle is nearestCenter which maps each (generalized) point to the center that it is nearest. The code is pretty self-explanatory: 324: nearestCenter :: Int -> WrapType [ Double ] a -> [ [ Double ] ] -> [ Double ] 325: n:(GHC.Types.Int) -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} nearestCenter (GHC.Types.Int) n (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) x = {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} minKey ({VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)}) -> ([{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) >= 0)}) -> [{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} . ({VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> ({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))) -> xs:[{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] -> {VV : [({VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} , (GHC.Types.Double))] | (len([VV]) = len([xs]))} map ( c:{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> ({VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} , (GHC.Types.Double)) \\ {VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} c -> x1:a -> b -> (a , b) ( {VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} c , a:{VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} -> (GHC.Types.Double) distance {VV : [(GHC.Types.Double)] | (VV = c), (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} c ( (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} a) -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) = len([c])), (len([VV]) >= 0)} getVect {VV : (KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a) | (VV = x)} x ) ) ) We map the centers to a tuple of center c and the distance between x and c , and then we select the tuple with the smallest distance 332: minKey :: ( Ord v ) => [ ( k , v ) ] -> k 333: (GHC.Classes.Ord a) -> {VV : [(b , a)] | (len([VV]) >= 0)} -> b minKey = (a , b) -> a fst ((a , b) -> a) -> ({VV : [(a , b)] | (len([VV]) >= 0)} -> (a , b)) -> {VV : [(a , b)] | (len([VV]) >= 0)} -> a . ((a , b) -> (a , b) -> (GHC.Types.Ordering)) -> [(a , b)] -> (a , b) minimumBy ( (a , b) -> (a , b) -> (GHC.Types.Ordering) \\ (a , b) x (a , b) y -> x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV = EQ) <=> (x = y)), ((VV = GT) <=> (x > y)), ((VV = LT) <=> (x < y))} compare ( (a , b) -> b snd {VV : (a , b) | (VV = x)} x ) ( (a , b) -> b snd {VV : (a , b) | (VV = y)} y ) ) The interesting bit is that the distance function uses zipWith to ensure that the dimensionality of the center and the point match up. 340: distance :: [ Double ] -> [ Double ] -> Double 341: a:{VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} -> (GHC.Types.Double) distance {VV : [(GHC.Types.Double)] | (len([VV]) >= 0)} a {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) >= 0)} b = (GHC.Types.Double) -> (GHC.Types.Double) sqrt ((GHC.Types.Double) -> (GHC.Types.Double)) -> ({VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double) . [(GHC.Types.Double)] -> (GHC.Types.Double) sum ({VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double)) -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([a])), (len([VV]) = len([b])), (len([VV]) >= 0)} -> (GHC.Types.Double) $ ((GHC.Types.Double) -> (GHC.Types.Double) -> (GHC.Types.Double)) -> xs:[(GHC.Types.Double)] -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} -> {VV : [(GHC.Types.Double)] | (len([VV]) = len([xs]))} zipWith ( (GHC.Types.Double) -> (GHC.Types.Double) -> (GHC.Types.Double) \\ (GHC.Types.Double) v1 (GHC.Types.Double) v2 -> {VV : (GHC.Integer.Type.Integer) | (VV = 2)} ( {VV : (GHC.Types.Double) | (VV = v1)} v1 x:(GHC.Types.Double) -> y:(GHC.Types.Double) -> {VV : (GHC.Types.Double) | (VV = (x - y))} - {VV : (GHC.Types.Double) | (VV = v2)} v2 ) (GHC.Types.Double) -> (GHC.Integer.Type.Integer) -> (GHC.Types.Double) ^ 2 ) {VV : [(GHC.Types.Double)] | (VV = a),(len([VV]) >= 0)} a {VV : [(GHC.Types.Double)] | (VV = b), (len([VV]) = len([a])), (len([VV]) >= 0)} b LiquidHaskell verifies distance by inferring that 347: {-@ nearestCenter :: n : Int -> ( GenPoint a n ) -> [ ( Point n ) ] -> ( Point n ) @-} First, LiquidHaskell deduces that each center in cs is indeed n -dimensional, which follows from the output type of clusterCenter . Since x is a (GenPoint a n) LiquidHaskell infers that both c and getVect x are of an equal length n . Consequently, the call to 355: zipWith :: ( a -> b -> c ) -> xs : [ a ] -> ( List b ( len xs ) ) -> ( List c ( len xs ) ) discussed last time is determined to be safe. Finally, the value returned is just one of the input centers and so is a (Point n) .","title":"Finding the Nearest Center"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#putting-it-all-together-top-level-api","text":"We can bundle the algorithm into two top-level API functions. First, a version that clusters generalized points. In this case, we require a function that can project an a value to an n -dimensional point. This function just wraps each a , clusters via kmeans' and then unwraps the points. 374: {-@ kmeansGen :: n : Int 375: -> ( a -> ( Point n ) ) 376: -> k : PosInt 377: -> xs : [ a ] 378: -> ( Clustering a ) 379: @-} 380: 381: n:(GHC.Types.Int) -> (a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)}) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [a] -> [{VV : [a] | (len([VV]) > 0)}] kmeansGen (GHC.Types.Int) n a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} project {VV : (GHC.Types.Int) | (VV > 0)} k = ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)} -> {VV : [a] | (len([VV]) > 0)}) -> xs:[{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) = len([xs]))} map ( ((KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> a) -> xs:[(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] -> {VV : [a] | (len([VV]) = len([xs]))} map (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a) -> a getVal ) 382: ([{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)}) -> ([a] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}]) -> [a] -> {VV : [{VV : [a] | (len([VV]) > 0)}] | (len([VV]) >= 0)} . n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] -> [{v : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (len([VV]) = n)} a)] | (len([v]) > 0)}] kmeans' {VV : (GHC.Types.Int) | (VV = n)} n {VV : (GHC.Types.Int) | (VV = k),(VV > 0)} k 383: ({VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) >= 0)} -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}]) -> ([a] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) >= 0)}) -> [a] -> [{VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)} a)] | (len([VV]) > 0)}] . (a -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)) -> xs:[a] -> {VV : [(KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} a)] | (len([VV]) = len([xs]))} map ( x:a -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} {VV : a | (VV = x)}) \\ a x -> {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} -> {VV : a | (VV = x)} -> (KMeans.WrapType {VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n), (len([VV]) >= 0)} {VV : a | (VV = x)}) WrapType ( a -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)} project {VV : a | (VV = x)} x ) {VV : a | (VV = x)} x ) Second, a specialized version that operates directly on n -dimensional points. The specialized version just calls the general version with a trivial id projection. 391: {-@ kmeans :: n : Int 392: -> k : PosInt 393: -> points : [ ( Point n ) ] 394: -> ( Clustering ( Point n ) ) 395: @-} 396: 397: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] -> [{v : [{VV : [(GHC.Types.Double)] | (len([VV]) = n)}] | (len([v]) > 0)}] kmeans (GHC.Types.Int) n = n:(GHC.Types.Int) -> ({VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> {VV : [(GHC.Types.Double)] | (len([VV]) = n)}) -> {VV : (GHC.Types.Int) | (VV > 0)} -> [{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)}] -> [{VV : [{VV : [(GHC.Types.Double)] | (n = len([VV])), (len([VV]) = n)}] | (len([VV]) > 0)}] kmeansGen {VV : (GHC.Types.Int) | (VV = n)} n x:{VV : [(GHC.Types.Double)] | (n = len([VV])),(len([VV]) = n)} -> {VV : [(GHC.Types.Double)] | (VV = x), (n = len([VV])), (len([VV]) = n)} id","title":"Putting It All Together: Top-Level API"},{"location":"blogposts/2013-02-17-kmeans-clustering-II.lhs/#conclusions","text":"I hope that over the last two posts you have gotten a sense of What KMeans clustering is all about, How measures and refinements can be used to describe the behavior of common list operations like map , transpose , groupBy , zipWith , and so on, How LiquidHaskell's automated inference makes it easy to write and verify invariants of non-trivial programs. The sharp reader will have noticed that the one major , non syntactic, change to the original code is the addition of the dimension parameter n throughout the code. This is critically required so that we can specify the relevant invariants (which are in terms of n .) The value is actually a ghost, and never ever used. Fortunately, Haskell's laziness means that we don't have to worry about it (or other ghost variables) imposing any run-time overhead at all. Exercise: Incidentally, if you have followed thus far I would encourage you to ponder about how you might modify the types (and implementation) to verify that KMeans indeed produces at most k clusters...","title":"Conclusions"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/","text":"Today, lets look at a classic use-case for refinement types, namely, the static verification of vector access bounds . Along the way, we'll see some examples that illustrate how LiquidHaskell reasons about recursion , higher-order functions , data types , and polymorphism . 22: module VectorBounds ( 23: safeLookup 24: , unsafeLookup , unsafeLookup' 25: , absoluteSum , absoluteSum' 26: , dotProduct 27: , sparseProduct , sparseProduct' 28: ) where 29: 30: import Prelude hiding ( length ) 31: import Data . List ( foldl' ) 32: import Data . Vector hiding ( foldl' ) Specifying Bounds for Vectors \u00b6 One classical use-case for refinement types is to verify the safety of accesses of arrays and vectors and such, by proving that the indices used in such accesses are within the vector bounds. Lets see how to do this with LiquidHaskell by writing a few short functions that manipulate vectors, in particular, those from the popular vector library. First things first. Lets specify bounds safety by refining the types for the key functions exported by the module Data.Vector . Specifications for Data.Vector 50: module spec Data . Vector where 51: 52: import GHC . Base 53: 54: measure vlen :: ( Vector a ) -> Int 55: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } 56: assume ! :: x : ( Vector a ) -> { v : Int | 0 <= v && v < ( vlen x ) } -> a In particular, we define a property called vlen which denotes the size of the vector, assume that the length function returns an integer equal to the vector's size, and assume that the lookup function ! requires an index between 0 and the vector's size. There are several things worth paying close attention to in the above snippet. Measures Recall that measures define auxiliary (or so-called ghost ) properties of data values that are useful for specification and verification, but which don't actually exist at run-time . Thus, they will only appear in specifications , i.e. inside type refinements, but never inside code. Often we will use helper functions like length in this case, which pull or materialize the ghost values from the refinement world into the actual code world. Assumes We write assume because in this scenario we are not verifying the implementation of Data.Vector , we are simply using the properties of the library to verify client code. If we wanted to verify the library itself, we would ascribe the above types to the relevant functions in the Haskell source for Data.Vector . Dependent Refinements Notice that in the function type (e.g. for length ) we have named the input parameter x so that we can refer to it in the output refinement. In this case, the type 91: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } states that the Int output is exactly equal to the size of the input Vector named x . In other words, the output refinement depends on the input value, which crucially allows us to write properties that relate different program values. Verifying a Simple Wrapper Lets try write some simple functions to sanity check the above specifications. First, consider an unsafe vector lookup function: 105: vec:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([vec])),(0 <= VV)} -> a unsafeLookup (Data.Vector.Vector a) vec {VV : (GHC.Types.Int) | (VV < vlen([vec])),(0 <= VV)} index = {VV : (Data.Vector.Vector a) | (VV = vec),(vlen([VV]) >= 0)} vec x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = index),(VV < vlen([vec])),(0 <= VV)} index If we run this through LiquidHaskell, it will spit back a type error for the expression x ! i because (happily!) it cannot prove that index is between 0 and the vlen vec . Of course, we can specify the bounds requirement in the input type 114: {-@ unsafeLookup :: vec : Vector a 115: -> {v: Int | (0 <= v && v < (vlen vec))} 116: -> a 117: @-} then LiquidHaskell is happy to verify the lookup. Of course, now the burden of ensuring the index is valid is pushed to clients of unsafeLookup . Instead, we might write a safe lookup function that performs the bounds check before looking up the vector: 127: {-@ safeLookup :: Vector a -> Int -> Maybe a @-} 128: (Data.Vector.Vector a) -> (GHC.Types.Int) -> (Data.Maybe.Maybe a) safeLookup (Data.Vector.Vector a) x (GHC.Types.Int) i 129: | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = i)} i x:(GHC.Types.Bool) -> y:(GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> && [(? Prop([x])); (? Prop([y]))])} && {VV : (GHC.Types.Int) | (VV = i)} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x = x:a -> {VV : (Data.Maybe.Maybe a) | ((? isJust([VV])) <=> true), (fromJust([VV]) = x)} Just ( {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i)} i ) 130: | otherwise = {VV : (Data.Maybe.Maybe {VV : a | false}) | ((? isJust([VV])) <=> false)} Nothing Predicate Aliases The type for unsafeLookup above is rather verbose as we have to spell out the upper and lower bounds and conjoin them. Just as we enjoy abstractions when programming, we will find it handy to have abstractions in the specification mechanism. To this end, LiquidHaskell supports predicate aliases , which are best illustrated by example 142: {-@ predicate Btwn Lo I Hi = ( Lo <= I && I < Hi ) @-} 143: {-@ predicate InBounds I A = ( Btwn 0 I ( vlen A ) ) @-} Now, we can simplify the type for the unsafe lookup function to 149: {-@ unsafeLookup' :: x : Vector a -> {v: Int | (InBounds v x)} -> a @-} 150: unsafeLookup' :: Vector a -> Int -> a 151: x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a unsafeLookup' (Data.Vector.Vector a) x {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} i = {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i),(VV < vlen([x])),(0 <= VV)} i Our First Recursive Function \u00b6 OK, with the tedious preliminaries out of the way, lets write some code! To start: a vanilla recursive function that adds up the absolute values of the elements of an integer vector. 164: absoluteSum :: Vector Int -> Int 165: (Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (0 <= VV)} absoluteSum (Data.Vector.Vector (GHC.Types.Int)) vec = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} if {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:{VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 else x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 166: where 167: x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} acc {VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i 168: | {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (i <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (i <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n = x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go ( {VV : (GHC.Types.Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0),(VV >= n)} abz ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = vec), (vlen([VV]) >= 0)} vec x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i ) ) ( {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) 169: | otherwise = {VV : (GHC.Types.Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc 170: {VV : (GHC.Types.Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = vec), (vlen([VV]) >= 0)} vec where the function abz is the absolute value function from before . 176: (GHC.Num.Num a) -> (GHC.Classes.Ord a) -> n:a -> {VV : a | (VV >= 0),(VV >= n)} abz a n = {VV : (GHC.Integer.Type.Integer) | (VV = 0)} if a 0 x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = n)} n then {VV : a | (VV = n)} n else ( a 0 x:a -> y:a -> {VV : a | (VV = (x - y))} - {VV : a | (VV = n)} n ) Digression: Introducing Errors \u00b6 If you are following along in the demo page -- I heartily recommend that you try the following modifications, one at a time, and see what happens. What happens if: You remove the check 0 < n (see absoluteSumNT in the demo code) You replace the guard with i <= n In the former case, LiquidHaskell will verify safety, but in the latter case, it will grumble that your program is unsafe . Do you understand why? (Thanks to smog_alado for pointing this out :)) Refinement Type Inference \u00b6 LiquidHaskell happily verifies absoluteSum -- or, to be precise, the safety of the vector accesses vec ! i . The verification works out because LiquidHaskell is able to automatically infer a suitable type for go . Shuffle your mouse over the identifier above to see the inferred type. Observe that the type states that the first parameter acc (and the output) is 0 <= V . That is, the returned value is non-negative. More importantly, the type states that the second parameter i is 0 <= V and V <= n and V <= (vlen vec) . That is, the parameter i is between 0 and the vector length (inclusive). LiquidHaskell uses these and the test that i /= n to establish that i is in fact between 0 and (vlen vec) thereby verifing safety. In fact, if we want to use the function externally (i.e. in another module) we can go ahead and strengthen its type to specify that the output is non-negative. 221: {-@ absoluteSum :: Vector Int -> {v: Int | 0 <= v} @-} What happens if: You replace the output type for absoluteSum with {v: Int | 0 < v } ? Bottling Recursion With a Higher-Order loop \u00b6 Next, lets refactor the above low-level recursive function into a generic higher-order loop . 233: loop :: Int -> Int -> a -> ( Int -> a -> a ) -> a 234: lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> a -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> a -> a) -> a loop {VV : (GHC.Types.Int) | (0 <= VV)} lo {VV : (GHC.Types.Int) | (lo <= VV)} hi a base {VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> a -> a f = {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go {VV : a | (VV = base)} base {VV : (GHC.Types.Int) | (VV = lo),(0 <= VV)} lo 235: where 236: {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go a acc {VV : (GHC.Types.Int) | (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i 237: | {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = hi), (VV = hi), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (hi <= VV), (lo <= VV), (lo <= VV)} hi = {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go ( {VV : (GHC.Types.Int) | (VV >= 0), (VV >= lo), (VV >= lo), (VV < hi), (VV < hi), (0 <= VV), (lo <= VV), (lo <= VV)} -> a -> a f {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i {VV : a | (VV = acc)} acc ) ( {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) 238: | otherwise = {VV : a | (VV = acc)} acc Using loop to compute absoluteSum We can now use loop to implement absoluteSum like so: 246: (GHC.Num.Num a) -> {VV : (Data.Vector.Vector {VV : a | false}) | false} -> {VV : a | false} absoluteSum' {VV : (Data.Vector.Vector {VV : a | false}) | false} vec = {VV : (GHC.Integer.Type.Integer) | (VV = 0)} if {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:{VV : (GHC.Types.Int) | false} -> y:{VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> {VV : a | false} -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> {VV : a | false} -> {VV : a | false}) -> {VV : a | false} loop {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n a 0 {VV : (GHC.Types.Int) | false} -> {VV : a | false} -> {VV : a | false} body else {VV : (GHC.Integer.Type.Integer) | (VV = 0)} 0 247: where {VV : (GHC.Types.Int) | false} -> {VV : a | false} -> {VV : a | false} body = \\ {VV : (GHC.Types.Int) | false} i {VV : a | false} acc -> {VV : a | false} acc x:a -> y:a -> {VV : a | (VV = (x + y))} + ( {VV : (Data.Vector.Vector {VV : a | false}) | false} vec x:(Data.Vector.Vector {VV : a | false}) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (GHC.Types.Int) | false} i ) 248: {VV : (GHC.Types.Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Data.Vector.Vector {VV : a | false}) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector {VV : a | false}) | false} vec LiquidHaskell verifies absoluteSum' without any trouble. It is very instructive to see the type that LiquidHaskell infers for loop -- it looks something like 257: {-@ loop :: lo : {v: Int | (0 <= v) } 258: -> hi : {v: Int | (lo <= v) } 259: -> a 260: -> ( i : {v: Int | (Btwn lo v hi)} -> a -> a ) 261: -> a 262: @-} In english, the above type states that lo the loop lower bound is a non-negative integer hi the loop upper bound is a greater than lo , f the loop body is only called with integers between lo and hi . Inference is a rather convenient option -- it can be tedious to have to keep typing things like the above! Of course, if we wanted to make loop a public or exported function, we could use the inferred type to generate an explicit signature too. At the call 277: loop 0 n 0 body the parameters lo and hi are instantiated with 0 and n respectively (which, by the way is where the inference engine deduces non-negativity from) and thus LiquidHaskell concludes that body is only called with values of i that are between 0 and (vlen vec) , which shows the safety of the call vec ! i . Using loop to compute dotProduct Here's another use of loop -- this time to compute the dotProduct of two vectors. 292: dotProduct :: Vector Int -> Vector Int -> Int 293: x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (Data.Vector.Vector (GHC.Types.Int)) | (vlen([VV]) = vlen([x]))} -> (GHC.Types.Int) dotProduct (Data.Vector.Vector (GHC.Types.Int)) x {VV : (Data.Vector.Vector (GHC.Types.Int)) | (vlen([VV]) = vlen([x]))} y = lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> (GHC.Types.Int) -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> (GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) loop {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ( x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = x), (vlen([VV]) >= 0)} x ) {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ( {VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} -> (GHC.Types.Int) -> (GHC.Types.Int) \\ {VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i -> ( x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = x), (vlen([VV]) >= 0)} x x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = y), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} y x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) ) ) The gimlet-eyed reader will realize that the above is quite unsafe -- what if x is a 10-dimensional vector while y has only 3-dimensions? A nasty 300: *** Exception : ./ Data / Vector / Generic . hs : 244 ( ( ! ) ) : index out of bounds ... Yech . This is precisely the sort of unwelcome surprise we want to do away with at compile-time. Refinements to the rescue! We can specify that the vectors have the same dimensions quite easily 310: {-@ dotProduct :: x : ( Vector Int ) 311: -> y : {v: ( Vector Int ) | (vlen v) = (vlen x)} 312: -> Int 313: @-} after which LiquidHaskell will gladly verify that the implementation of dotProduct is indeed safe! Refining Data Types \u00b6 Next, suppose we want to write a sparse dot product , that is, the dot product of a vector and a sparse vector represented by a list of index-value tuples. Representing Sparse Vectors We can represent the sparse vector with a refinement type alias 331: {-@ type SparseVector a N = [ ( { v : Int | ( Btwn 0 v N ) } , a ) ] @-} As with usual types, the alias SparseVector on the left is just a shorthand for the (longer) type on the right, it does not actually define a new type. Thus, the above alias is simply a refinement of Haskell's [(Int, a)] type, with a size parameter N that facilitates easy specification reuse. In this way, refinements let us express invariants of containers like lists in a straightforward manner. Aside: If you are familiar with the index-style length encoding e.g. as found in DML or Agda , then note that despite appearances, our SparseVector definition is not indexed. Instead, we deliberately choose to encode properties with logical refinement predicates, to facilitate SMT based checking and inference. Verifying Uses of Sparse Vectors Next, we can write a recursive procedure that computes the sparse product 353: {-@ sparseProduct :: ( Num a ) => x : ( Vector a ) 354: -> SparseVector a ( vlen x ) 355: -> a 356: @-} 357: (GHC.Num.Num a) -> x:(Data.Vector.Vector a) -> [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct (Data.Vector.Vector a) x [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] y = {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a 0 {VV : [({VV : (GHC.Types.Int) | (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 358: where 359: {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a sum ( ( i , v ) : y' ) = {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go ( {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Data.Vector.Vector a) | (VV = x), (VV = x), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v ) {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y'),(len([VV]) >= 0)} y' 360: go sum [] = {VV : a | (VV = sum)} sum LiquidHaskell verifies the above by using the specification for y to conclude that for each tuple (i, v) in the list, the value of i is within the bounds of the vector x , thereby proving the safety of the access x ! i . Refinements and Polymorphism \u00b6 The sharp reader will have undoubtedly noticed that the sparse product can be more cleanly expressed as a fold . Indeed! Let us recall the type of the foldl operation 375: foldl' :: ( a -> b -> a ) -> a -> [ b ] -> a Thus, we can simply fold over the sparse vector, accumulating the sum as we go along 382: {-@ sparseProduct' :: ( Num a ) => x : ( Vector a ) 383: -> SparseVector a ( vlen x ) 384: -> a 385: @-} 386: (GHC.Num.Num a) -> x:(Data.Vector.Vector a) -> [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct' (Data.Vector.Vector a) x [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] y = (a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a) -> a -> [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] -> a foldl' a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a body a 0 {VV : [({VV : (GHC.Types.Int) | (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 387: where 388: a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a body a sum ( i , v ) = {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v LiquidHaskell digests this too, without much difficulty. The main trick is in how the polymorphism of foldl' is instantiated. The GHC type inference engine deduces that at this site, the type variable b from the signature of foldl' is instantiated to the Haskell type (Int, a) . Correspondingly, LiquidHaskell infers that in fact b can be instantiated to the refined type ({v: Int | (Btwn 0 v (vlen x))}, a) . Walk the mouse over to i to see this inferred type. (You can also hover over foldl' above to see the rather more verbose fully instantiated type.) Thus, the inference mechanism saves us a fair bit of typing and allows us to reuse existing polymorphic functions over containers and such without ceremony. Conclusion \u00b6 That's all for now folks! Hopefully the above gives you a reasonable idea of how one can use refinements to verify size related properties, and more generally, to specify and verify properties of recursive, and polymorphic functions operating over datatypes. Next time, we'll look at how we can teach LiquidHaskell to think about properties of recursive structures like lists and trees.","title":"Bounding Vectors"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#specifying-bounds-for-vectors","text":"One classical use-case for refinement types is to verify the safety of accesses of arrays and vectors and such, by proving that the indices used in such accesses are within the vector bounds. Lets see how to do this with LiquidHaskell by writing a few short functions that manipulate vectors, in particular, those from the popular vector library. First things first. Lets specify bounds safety by refining the types for the key functions exported by the module Data.Vector . Specifications for Data.Vector 50: module spec Data . Vector where 51: 52: import GHC . Base 53: 54: measure vlen :: ( Vector a ) -> Int 55: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } 56: assume ! :: x : ( Vector a ) -> { v : Int | 0 <= v && v < ( vlen x ) } -> a In particular, we define a property called vlen which denotes the size of the vector, assume that the length function returns an integer equal to the vector's size, and assume that the lookup function ! requires an index between 0 and the vector's size. There are several things worth paying close attention to in the above snippet. Measures Recall that measures define auxiliary (or so-called ghost ) properties of data values that are useful for specification and verification, but which don't actually exist at run-time . Thus, they will only appear in specifications , i.e. inside type refinements, but never inside code. Often we will use helper functions like length in this case, which pull or materialize the ghost values from the refinement world into the actual code world. Assumes We write assume because in this scenario we are not verifying the implementation of Data.Vector , we are simply using the properties of the library to verify client code. If we wanted to verify the library itself, we would ascribe the above types to the relevant functions in the Haskell source for Data.Vector . Dependent Refinements Notice that in the function type (e.g. for length ) we have named the input parameter x so that we can refer to it in the output refinement. In this case, the type 91: assume length :: x : ( Vector a ) -> { v : Int | v = ( vlen x ) } states that the Int output is exactly equal to the size of the input Vector named x . In other words, the output refinement depends on the input value, which crucially allows us to write properties that relate different program values. Verifying a Simple Wrapper Lets try write some simple functions to sanity check the above specifications. First, consider an unsafe vector lookup function: 105: vec:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([vec])),(0 <= VV)} -> a unsafeLookup (Data.Vector.Vector a) vec {VV : (GHC.Types.Int) | (VV < vlen([vec])),(0 <= VV)} index = {VV : (Data.Vector.Vector a) | (VV = vec),(vlen([VV]) >= 0)} vec x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = index),(VV < vlen([vec])),(0 <= VV)} index If we run this through LiquidHaskell, it will spit back a type error for the expression x ! i because (happily!) it cannot prove that index is between 0 and the vlen vec . Of course, we can specify the bounds requirement in the input type 114: {-@ unsafeLookup :: vec : Vector a 115: -> {v: Int | (0 <= v && v < (vlen vec))} 116: -> a 117: @-} then LiquidHaskell is happy to verify the lookup. Of course, now the burden of ensuring the index is valid is pushed to clients of unsafeLookup . Instead, we might write a safe lookup function that performs the bounds check before looking up the vector: 127: {-@ safeLookup :: Vector a -> Int -> Maybe a @-} 128: (Data.Vector.Vector a) -> (GHC.Types.Int) -> (Data.Maybe.Maybe a) safeLookup (Data.Vector.Vector a) x (GHC.Types.Int) i 129: | {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : (GHC.Types.Int) | (VV = i)} i x:(GHC.Types.Bool) -> y:(GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> && [(? Prop([x])); (? Prop([y]))])} && {VV : (GHC.Types.Int) | (VV = i)} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x = x:a -> {VV : (Data.Maybe.Maybe a) | ((? isJust([VV])) <=> true), (fromJust([VV]) = x)} Just ( {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i)} i ) 130: | otherwise = {VV : (Data.Maybe.Maybe {VV : a | false}) | ((? isJust([VV])) <=> false)} Nothing Predicate Aliases The type for unsafeLookup above is rather verbose as we have to spell out the upper and lower bounds and conjoin them. Just as we enjoy abstractions when programming, we will find it handy to have abstractions in the specification mechanism. To this end, LiquidHaskell supports predicate aliases , which are best illustrated by example 142: {-@ predicate Btwn Lo I Hi = ( Lo <= I && I < Hi ) @-} 143: {-@ predicate InBounds I A = ( Btwn 0 I ( vlen A ) ) @-} Now, we can simplify the type for the unsafe lookup function to 149: {-@ unsafeLookup' :: x : Vector a -> {v: Int | (InBounds v x)} -> a @-} 150: unsafeLookup' :: Vector a -> Int -> a 151: x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a unsafeLookup' (Data.Vector.Vector a) x {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} i = {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i),(VV < vlen([x])),(0 <= VV)} i","title":"Specifying Bounds for Vectors"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#our-first-recursive-function","text":"OK, with the tedious preliminaries out of the way, lets write some code! To start: a vanilla recursive function that adds up the absolute values of the elements of an integer vector. 164: absoluteSum :: Vector Int -> Int 165: (Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (0 <= VV)} absoluteSum (Data.Vector.Vector (GHC.Types.Int)) vec = x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} if {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:{VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 else x:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV = (x : int))} 0 166: where 167: x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go {VV : (GHC.Types.Int) | (VV >= 0),(0 <= VV)} acc {VV : (GHC.Types.Int) | (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i 168: | {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (i <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (0 <= VV), (VV <= n), (VV <= vlen([vec])), (i <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n = x6:{VV : (GHC.Types.Int) | (VV = 0), (VV < n), (VV < vlen([vec])), (0 <= VV)} -> x4:{VV : (GHC.Types.Int) | (VV = 0), (VV = x6), (VV < n), (VV < vlen([vec])), (0 <= VV), (x6 <= VV)} -> {VV : (GHC.Types.Int) | (VV >= 0), (VV >= x6), (VV >= x4), (0 <= VV), (x6 <= VV), (x4 <= VV)} go ( {VV : (GHC.Types.Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0),(VV >= n)} abz ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = vec), (vlen([VV]) >= 0)} vec x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i ) ) ( {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (0 <= VV), (VV <= n), (VV <= vlen([vec]))} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) 169: | otherwise = {VV : (GHC.Types.Int) | (VV = acc),(VV >= 0),(0 <= VV)} acc 170: {VV : (GHC.Types.Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = vec), (vlen([VV]) >= 0)} vec where the function abz is the absolute value function from before . 176: (GHC.Num.Num a) -> (GHC.Classes.Ord a) -> n:a -> {VV : a | (VV >= 0),(VV >= n)} abz a n = {VV : (GHC.Integer.Type.Integer) | (VV = 0)} if a 0 x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = n)} n then {VV : a | (VV = n)} n else ( a 0 x:a -> y:a -> {VV : a | (VV = (x - y))} - {VV : a | (VV = n)} n )","title":"Our First Recursive Function"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#digression-introducing-errors","text":"If you are following along in the demo page -- I heartily recommend that you try the following modifications, one at a time, and see what happens. What happens if: You remove the check 0 < n (see absoluteSumNT in the demo code) You replace the guard with i <= n In the former case, LiquidHaskell will verify safety, but in the latter case, it will grumble that your program is unsafe . Do you understand why? (Thanks to smog_alado for pointing this out :))","title":"Digression: Introducing Errors"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#refinement-type-inference","text":"LiquidHaskell happily verifies absoluteSum -- or, to be precise, the safety of the vector accesses vec ! i . The verification works out because LiquidHaskell is able to automatically infer a suitable type for go . Shuffle your mouse over the identifier above to see the inferred type. Observe that the type states that the first parameter acc (and the output) is 0 <= V . That is, the returned value is non-negative. More importantly, the type states that the second parameter i is 0 <= V and V <= n and V <= (vlen vec) . That is, the parameter i is between 0 and the vector length (inclusive). LiquidHaskell uses these and the test that i /= n to establish that i is in fact between 0 and (vlen vec) thereby verifing safety. In fact, if we want to use the function externally (i.e. in another module) we can go ahead and strengthen its type to specify that the output is non-negative. 221: {-@ absoluteSum :: Vector Int -> {v: Int | 0 <= v} @-} What happens if: You replace the output type for absoluteSum with {v: Int | 0 < v } ?","title":"Refinement Type Inference"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#bottling-recursion-with-a-higher-order-loop","text":"Next, lets refactor the above low-level recursive function into a generic higher-order loop . 233: loop :: Int -> Int -> a -> ( Int -> a -> a ) -> a 234: lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> a -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> a -> a) -> a loop {VV : (GHC.Types.Int) | (0 <= VV)} lo {VV : (GHC.Types.Int) | (lo <= VV)} hi a base {VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> a -> a f = {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go {VV : a | (VV = base)} base {VV : (GHC.Types.Int) | (VV = lo),(0 <= VV)} lo 235: where 236: {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go a acc {VV : (GHC.Types.Int) | (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i 237: | {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> y:{VV : (GHC.Types.Int) | (VV >= 0), (VV >= i), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (i <= VV), (lo <= VV), (lo <= VV)} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x != y))} /= {VV : (GHC.Types.Int) | (VV = hi), (VV = hi), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (hi <= VV), (lo <= VV), (lo <= VV)} hi = {VV : a | (VV = base)} -> {VV : (GHC.Types.Int) | (VV = lo), (VV >= 0), (0 <= VV), (VV <= hi), (lo <= VV)} -> a go ( {VV : (GHC.Types.Int) | (VV >= 0), (VV >= lo), (VV >= lo), (VV < hi), (VV < hi), (0 <= VV), (lo <= VV), (lo <= VV)} -> a -> a f {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i {VV : a | (VV = acc)} acc ) ( {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV >= lo), (VV >= lo), (0 <= VV), (VV <= hi), (VV <= hi), (lo <= VV), (lo <= VV)} i x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + {VV : (GHC.Types.Int) | (VV = (1 : int))} 1 ) 238: | otherwise = {VV : a | (VV = acc)} acc Using loop to compute absoluteSum We can now use loop to implement absoluteSum like so: 246: (GHC.Num.Num a) -> {VV : (Data.Vector.Vector {VV : a | false}) | false} -> {VV : a | false} absoluteSum' {VV : (Data.Vector.Vector {VV : a | false}) | false} vec = {VV : (GHC.Integer.Type.Integer) | (VV = 0)} if {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 x:{VV : (GHC.Types.Int) | false} -> y:{VV : (GHC.Types.Int) | false} -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x < y))} < {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n then lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> {VV : a | false} -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> {VV : a | false} -> {VV : a | false}) -> {VV : a | false} loop {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 {VV : (GHC.Types.Int) | (VV = n),(VV = vlen([vec])),(VV >= 0)} n a 0 {VV : (GHC.Types.Int) | false} -> {VV : a | false} -> {VV : a | false} body else {VV : (GHC.Integer.Type.Integer) | (VV = 0)} 0 247: where {VV : (GHC.Types.Int) | false} -> {VV : a | false} -> {VV : a | false} body = \\ {VV : (GHC.Types.Int) | false} i {VV : a | false} acc -> {VV : a | false} acc x:a -> y:a -> {VV : a | (VV = (x + y))} + ( {VV : (Data.Vector.Vector {VV : a | false}) | false} vec x:(Data.Vector.Vector {VV : a | false}) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> {VV : a | false} ! {VV : (GHC.Types.Int) | false} i ) 248: {VV : (GHC.Types.Int) | (VV = vlen([vec])),(VV >= 0)} n = x:(Data.Vector.Vector {VV : a | false}) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector {VV : a | false}) | false} vec LiquidHaskell verifies absoluteSum' without any trouble. It is very instructive to see the type that LiquidHaskell infers for loop -- it looks something like 257: {-@ loop :: lo : {v: Int | (0 <= v) } 258: -> hi : {v: Int | (lo <= v) } 259: -> a 260: -> ( i : {v: Int | (Btwn lo v hi)} -> a -> a ) 261: -> a 262: @-} In english, the above type states that lo the loop lower bound is a non-negative integer hi the loop upper bound is a greater than lo , f the loop body is only called with integers between lo and hi . Inference is a rather convenient option -- it can be tedious to have to keep typing things like the above! Of course, if we wanted to make loop a public or exported function, we could use the inferred type to generate an explicit signature too. At the call 277: loop 0 n 0 body the parameters lo and hi are instantiated with 0 and n respectively (which, by the way is where the inference engine deduces non-negativity from) and thus LiquidHaskell concludes that body is only called with values of i that are between 0 and (vlen vec) , which shows the safety of the call vec ! i . Using loop to compute dotProduct Here's another use of loop -- this time to compute the dotProduct of two vectors. 292: dotProduct :: Vector Int -> Vector Int -> Int 293: x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (Data.Vector.Vector (GHC.Types.Int)) | (vlen([VV]) = vlen([x]))} -> (GHC.Types.Int) dotProduct (Data.Vector.Vector (GHC.Types.Int)) x {VV : (Data.Vector.Vector (GHC.Types.Int)) | (vlen([VV]) = vlen([x]))} y = lo:{VV : (GHC.Types.Int) | (0 <= VV)} -> hi:{VV : (GHC.Types.Int) | (lo <= VV)} -> (GHC.Types.Int) -> ({VV : (GHC.Types.Int) | (VV < hi),(lo <= VV)} -> (GHC.Types.Int) -> (GHC.Types.Int)) -> (GHC.Types.Int) loop {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ( x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV = vlen([x])),(VV >= 0)} length {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = x), (vlen([VV]) >= 0)} x ) {VV : (GHC.Types.Int) | (VV = (0 : int))} 0 ( {VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} -> (GHC.Types.Int) -> (GHC.Types.Int) \\ {VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i -> ( x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV = (x + y))} + ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = x), (vlen([VV]) >= 0)} x x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) x:(GHC.Types.Int) -> y:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV = y), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} y x:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([y])), (0 <= VV)} i ) ) ) The gimlet-eyed reader will realize that the above is quite unsafe -- what if x is a 10-dimensional vector while y has only 3-dimensions? A nasty 300: *** Exception : ./ Data / Vector / Generic . hs : 244 ( ( ! ) ) : index out of bounds ... Yech . This is precisely the sort of unwelcome surprise we want to do away with at compile-time. Refinements to the rescue! We can specify that the vectors have the same dimensions quite easily 310: {-@ dotProduct :: x : ( Vector Int ) 311: -> y : {v: ( Vector Int ) | (vlen v) = (vlen x)} 312: -> Int 313: @-} after which LiquidHaskell will gladly verify that the implementation of dotProduct is indeed safe!","title":"Bottling Recursion With a Higher-Order loop"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#refining-data-types","text":"Next, suppose we want to write a sparse dot product , that is, the dot product of a vector and a sparse vector represented by a list of index-value tuples. Representing Sparse Vectors We can represent the sparse vector with a refinement type alias 331: {-@ type SparseVector a N = [ ( { v : Int | ( Btwn 0 v N ) } , a ) ] @-} As with usual types, the alias SparseVector on the left is just a shorthand for the (longer) type on the right, it does not actually define a new type. Thus, the above alias is simply a refinement of Haskell's [(Int, a)] type, with a size parameter N that facilitates easy specification reuse. In this way, refinements let us express invariants of containers like lists in a straightforward manner. Aside: If you are familiar with the index-style length encoding e.g. as found in DML or Agda , then note that despite appearances, our SparseVector definition is not indexed. Instead, we deliberately choose to encode properties with logical refinement predicates, to facilitate SMT based checking and inference. Verifying Uses of Sparse Vectors Next, we can write a recursive procedure that computes the sparse product 353: {-@ sparseProduct :: ( Num a ) => x : ( Vector a ) 354: -> SparseVector a ( vlen x ) 355: -> a 356: @-} 357: (GHC.Num.Num a) -> x:(Data.Vector.Vector a) -> [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct (Data.Vector.Vector a) x [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] y = {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a 0 {VV : [({VV : (GHC.Types.Int) | (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 358: where 359: {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go a sum ( ( i , v ) : y' ) = {VV : a | (VV = 0)} -> {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y), (len([VV]) = len([y])), (len([VV]) >= 0)} -> a go ( {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Data.Vector.Vector a) | (VV = x), (VV = x), (vlen([VV]) = vlen([x])), (vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v ) {VV : [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y'),(len([VV]) >= 0)} y' 360: go sum [] = {VV : a | (VV = sum)} sum LiquidHaskell verifies the above by using the specification for y to conclude that for each tuple (i, v) in the list, the value of i is within the bounds of the vector x , thereby proving the safety of the access x ! i .","title":"Refining Data Types"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#refinements-and-polymorphism","text":"The sharp reader will have undoubtedly noticed that the sparse product can be more cleanly expressed as a fold . Indeed! Let us recall the type of the foldl operation 375: foldl' :: ( a -> b -> a ) -> a -> [ b ] -> a Thus, we can simply fold over the sparse vector, accumulating the sum as we go along 382: {-@ sparseProduct' :: ( Num a ) => x : ( Vector a ) 383: -> SparseVector a ( vlen x ) 384: -> a 385: @-} 386: (GHC.Num.Num a) -> x:(Data.Vector.Vector a) -> [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] -> a sparseProduct' (Data.Vector.Vector a) x [({VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} , a)] y = (a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a) -> a -> [({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a)] -> a foldl' a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a body a 0 {VV : [({VV : (GHC.Types.Int) | (VV < vlen([x])), (0 <= VV)} , a)] | (VV = y),(len([VV]) >= 0)} y 387: where 388: a -> ({VV : (GHC.Types.Int) | (VV >= 0), (VV < vlen([x])), (0 <= VV)} , a) -> a body a sum ( i , v ) = {VV : a | (VV = sum)} sum x:a -> y:a -> {VV : a | (VV = (x + y))} + a ( {VV : (Data.Vector.Vector a) | (VV = x),(vlen([VV]) >= 0)} x x:(Data.Vector.Vector a) -> {VV : (GHC.Types.Int) | (VV < vlen([x])),(0 <= VV)} -> a ! {VV : (GHC.Types.Int) | (VV = i), (VV >= 0), (VV < vlen([x])), (0 <= VV)} i ) x:a -> y:a -> {VV : a | (&& [(x >= 0); (y >= 0)] => (VV >= 0))} * {VV : a | (VV = v)} v LiquidHaskell digests this too, without much difficulty. The main trick is in how the polymorphism of foldl' is instantiated. The GHC type inference engine deduces that at this site, the type variable b from the signature of foldl' is instantiated to the Haskell type (Int, a) . Correspondingly, LiquidHaskell infers that in fact b can be instantiated to the refined type ({v: Int | (Btwn 0 v (vlen x))}, a) . Walk the mouse over to i to see this inferred type. (You can also hover over foldl' above to see the rather more verbose fully instantiated type.) Thus, the inference mechanism saves us a fair bit of typing and allows us to reuse existing polymorphic functions over containers and such without ceremony.","title":"Refinements and Polymorphism"},{"location":"blogposts/2013-03-04-bounding-vectors.lhs/#conclusion","text":"That's all for now folks! Hopefully the above gives you a reasonable idea of how one can use refinements to verify size related properties, and more generally, to specify and verify properties of recursive, and polymorphic functions operating over datatypes. Next time, we'll look at how we can teach LiquidHaskell to think about properties of recursive structures like lists and trees.","title":"Conclusion"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/","text":"In the posts so far, we've seen how LiquidHaskell allows you to use SMT solvers to specify and verify numeric invariants -- denominators that are non-zero, integer indices that are within the range of an array, vectors that have the right number of dimensions and so on. However, SMT solvers are not limited to numbers, and in fact, support rather expressive logics. In the next couple of posts, let's see how LiquidHaskell uses SMT to talk about sets of values , for example, the contents of a list, and to specify and verify properties about those sets. 27: module TalkingAboutSets where 28: 29: import Data . Set hiding ( filter , split ) 30: import Prelude hiding ( reverse , filter ) 31: Talking about Sets (In Logic) \u00b6 First, we need a way to talk about sets in the refinement logic. We could roll our own special Haskell type, but why not just use the Set a type from Data.Set . The import Data.Set , also instructs LiquidHaskell to import in the various specifications defined for the Data.Set module that we have predefined in Data/Set.spec Let's look at the specifications. 46: module spec Data . Set where 47: 48: embed Set as Set_Set The embed directive tells LiquidHaskell to model the Haskell type constructor Set with the SMT type constructor Set_Set . First, we define the logical operators (i.e. measure s) 55: measure Set_sng :: a -> ( Set a ) -- ^ singleton 56: measure Set_cup :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ union 57: measure Set_cap :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ intersection 58: measure Set_dif :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ difference Next, we define predicates on Set s 62: measure Set_emp :: ( Set a ) -> Prop -- ^ emptiness 63: measure Set_mem :: a -> ( Set a ) -> Prop -- ^ membership 64: measure Set_sub :: ( Set a ) -> ( Set a ) -> Prop -- ^ inclusion Interpreted Operations \u00b6 The above operators are interpreted by the SMT solver. That is, just like the SMT solver \"knows that\" 74: 2 + 2 == 4 the SMT solver also \"knows that\" 78: ( Set_sng 1 ) == ( Set_cap ( Set_sng 1 ) ( Set_cup ( Set_sng 2 ) ( Set_sng 1 ) ) ) This is because, the above formulas belong to a decidable Theory of Sets which can be reduced to McCarthy's more general Theory of Arrays . See this recent paper if you want to learn more about how modern SMT solvers \"know\" the above equality holds... Talking about Sets (In Code) \u00b6 Of course, the above operators exist purely in the realm of the refinement logic, beyond the grasp of the programmer. To bring them down (or up, or left or right) within reach of Haskell code, we can simply assume that the various public functions in Data.Set do the Right Thing i.e. produce values that reflect the logical set operations: First, the functions that create Set values 97: empty :: { v : ( Set a ) | ( Set_emp v ) } 98: singleton :: x : a -> { v : ( Set a ) | v = ( Set_sng x ) } Next, the functions that operate on elements and Set values 102: insert :: Ord a => x : a 103: -> xs : ( Set a ) 104: -> { v : ( Set a ) | v = ( Set_cup xs ( Set_sng x ) ) } 105: 106: delete :: Ord a => x : a 107: -> xs : ( Set a ) 108: -> { v : ( Set a ) | v = ( Set_dif xs ( Set_sng x ) ) } Then, the binary Set operators 112: union :: Ord a => xs : ( Set a ) 113: -> ys : ( Set a ) 114: -> { v : ( Set a ) | v = ( Set_cup xs ys ) } 115: 116: intersection :: Ord a => xs : ( Set a ) 117: -> ys : ( Set a ) 118: -> { v : ( Set a ) | v = ( Set_cap xs ys ) } 119: 120: difference :: Ord a => xs : ( Set a ) 121: -> ys : ( Set a ) 122: -> { v : ( Set a ) | v = ( Set_dif xs ys ) } And finally, the predicates on Set values: 126: isSubsetOf :: Ord a => xs : ( Set a ) 127: -> ys : ( Set a ) 128: -> { v : Bool | ( Prop v ) <=> ( Set_sub xs ys ) } 129: 130: member :: Ord a => x : a 131: -> xs : ( Set a ) 132: -> { v : Bool | ( Prop v ) <=> ( Set_mem x xs ) } Note: Of course we shouldn't and needn't really assume , but should and will guarantee that the functions from Data.Set implement the above types. But thats a story for another day... Proving Theorems With LiquidHaskell \u00b6 OK, let's take our refined operators from Data.Set out for a spin! One pleasant consequence of being able to precisely type the operators from Data.Set is that we have a pleasant interface for using the SMT solver to prove theorems about sets, while remaining firmly rooted in Haskell. First, let's write a simple function that asserts that its input is True 151: {-@ boolAssert :: {v: Bool | (Prop v)} -> {v: Bool | (Prop v)} @-} 152: {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert True = {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV = True)} True 153: boolAssert False = [(GHC.Types.Char)] -> {VV : (GHC.Types.Bool) | false} error {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"boolAssert: False? Never!\" Now, we can use boolAssert to write some simple properties. (Yes, these do indeed look like QuickCheck properties -- but here, instead of generating tests and executing the code, the type system is proving to us that the properties will always evaluate to True ) Let's check that intersection is commutative ... 164: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cap_comm (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y 165: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 166: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ (GHC.Types.Bool) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) GHC.Classes.Eq (Data.Set.Base.Set a) == ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = x)} x ) that union is associative ... 172: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cup_assoc (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y (Data.Set.Base.Set a) z 173: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 174: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ (GHC.Types.Bool) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) ) GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z and that union distributes over intersection . 180: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cap_dist (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y (Data.Set.Base.Set a) z 181: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 182: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) ) 183: GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) Of course, while we're at it, let's make sure LiquidHaskell doesn't prove anything that isn't true ... 190: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cup_dif_bad (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y 191: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 192: ((GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> (GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ {VV : (Data.Set.Base.Set a) | (VV = x)} x GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_dif([xs; ys]))} `difference` {VV : (Data.Set.Base.Set a) | (VV = y)} y Hmm. You do know why the above doesn't hold, right? It would be nice to get a counterexample wouldn't it? Well, for the moment, there is QuickCheck! Thus, the refined types offer a nice interface for interacting with the SMT solver in order to prove theorems in LiquidHaskell. (BTW, The SBV project describes another approach for using SMT solvers from Haskell, without the indirection of refinement types.) While the above is a nice warm up exercise to understanding how LiquidHaskell reasons about sets, our overall goal is not to prove theorems about set operators, but instead to specify and verify properties of programs. The Set of Values in a List \u00b6 Let's see how we might reason about sets of values in regular Haskell programs. We'll begin with Lists, the jack-of-all-data-types. Now, instead of just talking about the number of elements in a list, we can write a measure that describes the set of elements in a list: A measure for the elements of a list, from Data/Set.spec 221: 222: measure listElts :: [ a ] -> ( Set a ) 223: listElts ( [] ) = { v | ( ? Set_emp ( v ) ) } 224: listElts ( x : xs ) = { v | v = ( Set_cup ( Set_sng x ) ( listElts xs ) ) } That is, (listElts xs) describes the set of elements contained in a list xs . Next, to make the specifications concise, let's define a few predicate aliases: 232: {-@ predicate EqElts X Y = 233: ( ( listElts X ) = ( listElts Y ) ) @-} 234: 235: {-@ predicate SubElts X Y = 236: ( Set_sub ( listElts X ) ( listElts Y ) ) @-} 237: 238: {-@ predicate UnionElts X Y Z = 239: ( ( listElts X ) = ( Set_cup ( listElts Y ) ( listElts Z ) ) ) @-} A Trivial Identity \u00b6 OK, now let's write some code to check that the listElts measure is sensible! 248: {-@ listId :: xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 249: forall a. x1:[a] -> {VV : [a] | (len([VV]) = len([x1])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} listId [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 250: listId ( x : xs ) = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. x1:[a] -> {VV : [a] | (len([VV]) = len([x1])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} listId {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs That is, LiquidHaskell checks that the set of elements of the output list is the same as those in the input. A Less Trivial Identity \u00b6 Next, let's write a function to reverse a list. Of course, we'd like to verify that reverse doesn't leave any elements behind; that is that the output has the same set of values as the input list. This is somewhat more interesting because of the tail recursive helper go . Do you understand the type that is inferred for it? (Put your mouse over go to see the inferred type.) 267: {-@ reverse :: xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 268: forall a. xs:[a] -> {VV : [a] | (listElts([VV]) = listElts([xs]))} reverse = x1:{VV : [{VV : a | false}]<\\_ VV -> false> | (len([VV]) = 0)} -> x2:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x2])])), (listElts([VV]) = Set_cup([listElts([x2]); listElts([x1])])), (len([VV]) >= 0)} go {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] 269: where 270: acc:{VV : [a] | (len([VV]) >= 0)} -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([acc]); listElts([x1])])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([acc])])), (len([VV]) >= 0)} go {VV : [a] | (len([VV]) >= 0)} acc [] = {VV : [a] | (VV = acc),(len([VV]) >= 0)} acc 271: go acc ( y : ys ) = acc:{VV : [a] | (len([VV]) >= 0)} -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([acc]); listElts([x1])])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([acc])])), (len([VV]) >= 0)} go ( {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = acc),(len([VV]) >= 0)} acc ) {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys Appending Lists \u00b6 Next, here's good old append , but now with a specification that states that the output indeed includes the elements from both the input lists. 281: {-@ append :: xs : [ a ] -> ys : [ a ] -> {v: [ a ] | (UnionElts v xs ys)} @-} 282: forall a. x1:[a] -> ys:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([ys])])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([x1])])), (len([VV]) >= 0)} append [] [a] ys = {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys 283: append ( x : xs ) ys = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. x1:[a] -> ys:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([ys])])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([x1])])), (len([VV]) >= 0)} append {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys Filtering Lists \u00b6 Let's round off the list trilogy, with filter . Here, we can verify that it returns a subset of the values of the input list. 293: {-@ filter :: ( a -> Bool ) -> xs : [ a ] -> {v: [ a ] | (SubElts v xs)} @-} 294: 295: forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 296: filter f ( x : xs ) 297: | a -> (GHC.Types.Bool) f {VV : a | (VV = x)} x = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 298: | otherwise = forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs Merge Sort \u00b6 Let's conclude this entry with one larger example: mergeSort . We'd like to verify that, well, the list that is returned contains the same set of elements as the input list. And so we will! But first, let's remind ourselves of how mergeSort works: split the input list into two halves, sort each half, recursively, merge the sorted halves to obtain the sorted list. Split \u00b6 We can split a list into two, roughly equal parts like so: 323: forall a. x1:[a] -> ({VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} , {VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)})<\\x1 VV -> (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)> split [] = forall a b <p2 :: a -> b -> Bool>. x1:a -> b<p2 x1> -> (a , b)<p2> ( {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] , {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] ) 324: split ( x : xs ) = forall a b <p2 :: a -> b -> Bool>. x1:a -> b<p2 x1> -> (a , b)<p2> ( {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = zs), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs , {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = ys), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([zs]); listElts([VV])])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys ) 325: where 326: ( {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([zs]); listElts([VV])])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys , {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) = forall a. x1:[a] -> ({VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} , {VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)})<\\x1 VV -> (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)> split {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs LiquidHaskell verifies that the relevant property of split is 332: {-@ split :: xs : [ a ] -> ( [ a ] , [ a ] ) <{\\ys zs -> (UnionElts xs ys zs)}> @-} The funny syntax with angle brackets simply says that the output of split is a pair (ys, zs) whose union is the list of elements of the input xs . (Yes, this is indeed a dependent pair; we will revisit these later to understand whats going on with the odd syntax.) Merge \u00b6 Next, we can merge two (sorted) lists like so: 346: forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge [a] xs [] = {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 347: merge [] ys = {VV : [a] | (len([VV]) >= 0)} ys 348: merge ( x : xs ) ( y : ys ) 349: | {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = y)} y = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ( {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys ) 350: | otherwise = {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge ( {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys As you might expect, the elements of the returned list are the union of the elements of the input, or as LiquidHaskell might say, 357: {-@ merge :: ( Ord a ) => x : [ a ] -> y : [ a ] -> {v: [ a ] | (UnionElts v x y)} @-} Sort \u00b6 Finally, we put all the pieces together by 366: {-@ mergeSort :: ( Ord a ) => xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 367: forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 368: mergeSort [ x ] = {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] 369: mergeSort xs = x:[a] -> y:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x]); listElts([y])]))} merge ( forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys ) ( forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) 370: where 371: ( {VV : [a] | (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys , {VV : [a] | (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) = xs:[a] -> ([a] , [a])<\\ys VV -> (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])]))> split {VV : [a] | (len([VV]) >= 0)} xs The type given to mergeSort guarantees that the set of elements in the output list is indeed the same as in the input list. Of course, it says nothing about whether the list is actually sorted . Well, Rome wasn't built in a day...","title":"Talking About Sets"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#talking-about-sets-in-logic","text":"First, we need a way to talk about sets in the refinement logic. We could roll our own special Haskell type, but why not just use the Set a type from Data.Set . The import Data.Set , also instructs LiquidHaskell to import in the various specifications defined for the Data.Set module that we have predefined in Data/Set.spec Let's look at the specifications. 46: module spec Data . Set where 47: 48: embed Set as Set_Set The embed directive tells LiquidHaskell to model the Haskell type constructor Set with the SMT type constructor Set_Set . First, we define the logical operators (i.e. measure s) 55: measure Set_sng :: a -> ( Set a ) -- ^ singleton 56: measure Set_cup :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ union 57: measure Set_cap :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ intersection 58: measure Set_dif :: ( Set a ) -> ( Set a ) -> ( Set a ) -- ^ difference Next, we define predicates on Set s 62: measure Set_emp :: ( Set a ) -> Prop -- ^ emptiness 63: measure Set_mem :: a -> ( Set a ) -> Prop -- ^ membership 64: measure Set_sub :: ( Set a ) -> ( Set a ) -> Prop -- ^ inclusion","title":"Talking about Sets (In Logic)"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#interpreted-operations","text":"The above operators are interpreted by the SMT solver. That is, just like the SMT solver \"knows that\" 74: 2 + 2 == 4 the SMT solver also \"knows that\" 78: ( Set_sng 1 ) == ( Set_cap ( Set_sng 1 ) ( Set_cup ( Set_sng 2 ) ( Set_sng 1 ) ) ) This is because, the above formulas belong to a decidable Theory of Sets which can be reduced to McCarthy's more general Theory of Arrays . See this recent paper if you want to learn more about how modern SMT solvers \"know\" the above equality holds...","title":"Interpreted Operations"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#talking-about-sets-in-code","text":"Of course, the above operators exist purely in the realm of the refinement logic, beyond the grasp of the programmer. To bring them down (or up, or left or right) within reach of Haskell code, we can simply assume that the various public functions in Data.Set do the Right Thing i.e. produce values that reflect the logical set operations: First, the functions that create Set values 97: empty :: { v : ( Set a ) | ( Set_emp v ) } 98: singleton :: x : a -> { v : ( Set a ) | v = ( Set_sng x ) } Next, the functions that operate on elements and Set values 102: insert :: Ord a => x : a 103: -> xs : ( Set a ) 104: -> { v : ( Set a ) | v = ( Set_cup xs ( Set_sng x ) ) } 105: 106: delete :: Ord a => x : a 107: -> xs : ( Set a ) 108: -> { v : ( Set a ) | v = ( Set_dif xs ( Set_sng x ) ) } Then, the binary Set operators 112: union :: Ord a => xs : ( Set a ) 113: -> ys : ( Set a ) 114: -> { v : ( Set a ) | v = ( Set_cup xs ys ) } 115: 116: intersection :: Ord a => xs : ( Set a ) 117: -> ys : ( Set a ) 118: -> { v : ( Set a ) | v = ( Set_cap xs ys ) } 119: 120: difference :: Ord a => xs : ( Set a ) 121: -> ys : ( Set a ) 122: -> { v : ( Set a ) | v = ( Set_dif xs ys ) } And finally, the predicates on Set values: 126: isSubsetOf :: Ord a => xs : ( Set a ) 127: -> ys : ( Set a ) 128: -> { v : Bool | ( Prop v ) <=> ( Set_sub xs ys ) } 129: 130: member :: Ord a => x : a 131: -> xs : ( Set a ) 132: -> { v : Bool | ( Prop v ) <=> ( Set_mem x xs ) } Note: Of course we shouldn't and needn't really assume , but should and will guarantee that the functions from Data.Set implement the above types. But thats a story for another day...","title":"Talking about Sets (In Code)"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#proving-theorems-with-liquidhaskell","text":"OK, let's take our refined operators from Data.Set out for a spin! One pleasant consequence of being able to precisely type the operators from Data.Set is that we have a pleasant interface for using the SMT solver to prove theorems about sets, while remaining firmly rooted in Haskell. First, let's write a simple function that asserts that its input is True 151: {-@ boolAssert :: {v: Bool | (Prop v)} -> {v: Bool | (Prop v)} @-} 152: {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert True = {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV = True)} True 153: boolAssert False = [(GHC.Types.Char)] -> {VV : (GHC.Types.Bool) | false} error {VV : [(GHC.Types.Char)] | (len([VV]) >= 0)} \"boolAssert: False? Never!\" Now, we can use boolAssert to write some simple properties. (Yes, these do indeed look like QuickCheck properties -- but here, instead of generating tests and executing the code, the type system is proving to us that the properties will always evaluate to True ) Let's check that intersection is commutative ... 164: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cap_comm (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y 165: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 166: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ (GHC.Types.Bool) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) GHC.Classes.Eq (Data.Set.Base.Set a) == ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = x)} x ) that union is associative ... 172: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cup_assoc (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y (Data.Set.Base.Set a) z 173: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 174: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ (GHC.Types.Bool) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) ) GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z and that union distributes over intersection . 180: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cap_dist (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y (Data.Set.Base.Set a) z 181: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 182: ({VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` ( {VV : (Data.Set.Base.Set a) | (VV = y)} y xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) ) 183: GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cap([xs; ys]))} `intersection` {VV : (Data.Set.Base.Set a) | (VV = z)} z ) Of course, while we're at it, let's make sure LiquidHaskell doesn't prove anything that isn't true ... 190: forall a. (GHC.Classes.Ord a) => (Data.Set.Base.Set a) -> (Data.Set.Base.Set a) -> (GHC.Types.Bool) prop_cup_dif_bad (Data.Set.Base.Set a) x (Data.Set.Base.Set a) y 191: = {VV : (GHC.Types.Bool) | (? Prop([VV]))} -> {VV : (GHC.Types.Bool) | (? Prop([VV]))} boolAssert 192: ((GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)}) -> (GHC.Types.Bool) -> {VV : (GHC.Types.Bool) | (? Prop([VV])),(VV != False)} $ {VV : (Data.Set.Base.Set a) | (VV = x)} x GHC.Classes.Eq (Data.Set.Base.Set a) == (Data.Set.Base.Set a) ( {VV : (Data.Set.Base.Set a) | (VV = x)} x xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_cup([xs; ys]))} `union` {VV : (Data.Set.Base.Set a) | (VV = y)} y ) xs:(Data.Set.Base.Set a) -> ys:(Data.Set.Base.Set a) -> {VV : (Data.Set.Base.Set a) | (VV = Set_dif([xs; ys]))} `difference` {VV : (Data.Set.Base.Set a) | (VV = y)} y Hmm. You do know why the above doesn't hold, right? It would be nice to get a counterexample wouldn't it? Well, for the moment, there is QuickCheck! Thus, the refined types offer a nice interface for interacting with the SMT solver in order to prove theorems in LiquidHaskell. (BTW, The SBV project describes another approach for using SMT solvers from Haskell, without the indirection of refinement types.) While the above is a nice warm up exercise to understanding how LiquidHaskell reasons about sets, our overall goal is not to prove theorems about set operators, but instead to specify and verify properties of programs.","title":"Proving Theorems With LiquidHaskell"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#the-set-of-values-in-a-list","text":"Let's see how we might reason about sets of values in regular Haskell programs. We'll begin with Lists, the jack-of-all-data-types. Now, instead of just talking about the number of elements in a list, we can write a measure that describes the set of elements in a list: A measure for the elements of a list, from Data/Set.spec 221: 222: measure listElts :: [ a ] -> ( Set a ) 223: listElts ( [] ) = { v | ( ? Set_emp ( v ) ) } 224: listElts ( x : xs ) = { v | v = ( Set_cup ( Set_sng x ) ( listElts xs ) ) } That is, (listElts xs) describes the set of elements contained in a list xs . Next, to make the specifications concise, let's define a few predicate aliases: 232: {-@ predicate EqElts X Y = 233: ( ( listElts X ) = ( listElts Y ) ) @-} 234: 235: {-@ predicate SubElts X Y = 236: ( Set_sub ( listElts X ) ( listElts Y ) ) @-} 237: 238: {-@ predicate UnionElts X Y Z = 239: ( ( listElts X ) = ( Set_cup ( listElts Y ) ( listElts Z ) ) ) @-}","title":"The Set of Values in a List"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#a-trivial-identity","text":"OK, now let's write some code to check that the listElts measure is sensible! 248: {-@ listId :: xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 249: forall a. x1:[a] -> {VV : [a] | (len([VV]) = len([x1])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} listId [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 250: listId ( x : xs ) = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. x1:[a] -> {VV : [a] | (len([VV]) = len([x1])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} listId {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs That is, LiquidHaskell checks that the set of elements of the output list is the same as those in the input.","title":"A Trivial Identity"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#a-less-trivial-identity","text":"Next, let's write a function to reverse a list. Of course, we'd like to verify that reverse doesn't leave any elements behind; that is that the output has the same set of values as the input list. This is somewhat more interesting because of the tail recursive helper go . Do you understand the type that is inferred for it? (Put your mouse over go to see the inferred type.) 267: {-@ reverse :: xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 268: forall a. xs:[a] -> {VV : [a] | (listElts([VV]) = listElts([xs]))} reverse = x1:{VV : [{VV : a | false}]<\\_ VV -> false> | (len([VV]) = 0)} -> x2:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x2])])), (listElts([VV]) = Set_cup([listElts([x2]); listElts([x1])])), (len([VV]) >= 0)} go {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] 269: where 270: acc:{VV : [a] | (len([VV]) >= 0)} -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([acc]); listElts([x1])])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([acc])])), (len([VV]) >= 0)} go {VV : [a] | (len([VV]) >= 0)} acc [] = {VV : [a] | (VV = acc),(len([VV]) >= 0)} acc 271: go acc ( y : ys ) = acc:{VV : [a] | (len([VV]) >= 0)} -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([acc]); listElts([x1])])), (listElts([VV]) = Set_cup([listElts([x1]); listElts([acc])])), (len([VV]) >= 0)} go ( {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = acc),(len([VV]) >= 0)} acc ) {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys","title":"A Less Trivial Identity"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#appending-lists","text":"Next, here's good old append , but now with a specification that states that the output indeed includes the elements from both the input lists. 281: {-@ append :: xs : [ a ] -> ys : [ a ] -> {v: [ a ] | (UnionElts v xs ys)} @-} 282: forall a. x1:[a] -> ys:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([ys])])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([x1])])), (len([VV]) >= 0)} append [] [a] ys = {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys 283: append ( x : xs ) ys = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. x1:[a] -> ys:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([ys])])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([x1])])), (len([VV]) >= 0)} append {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys","title":"Appending Lists"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#filtering-lists","text":"Let's round off the list trilogy, with filter . Here, we can verify that it returns a subset of the values of the input list. 293: {-@ filter :: ( a -> Bool ) -> xs : [ a ] -> {v: [ a ] | (SubElts v xs)} @-} 294: 295: forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 296: filter f ( x : xs ) 297: | a -> (GHC.Types.Bool) f {VV : a | (VV = x)} x = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 298: | otherwise = forall a. (a -> (GHC.Types.Bool)) -> x2:[a] -> {VV : [a] | (? Set_sub([listElts([VV]); listElts([x2])])), (listElts([x2]) = Set_cup([listElts([x2]); listElts([VV])])), (len([VV]) >= 0)} filter a -> (GHC.Types.Bool) f {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs","title":"Filtering Lists"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#merge-sort","text":"Let's conclude this entry with one larger example: mergeSort . We'd like to verify that, well, the list that is returned contains the same set of elements as the input list. And so we will! But first, let's remind ourselves of how mergeSort works: split the input list into two halves, sort each half, recursively, merge the sorted halves to obtain the sorted list.","title":"Merge Sort"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#split","text":"We can split a list into two, roughly equal parts like so: 323: forall a. x1:[a] -> ({VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} , {VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)})<\\x1 VV -> (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)> split [] = forall a b <p2 :: a -> b -> Bool>. x1:a -> b<p2 x1> -> (a , b)<p2> ( {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] , {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [] ) 324: split ( x : xs ) = forall a b <p2 :: a -> b -> Bool>. x1:a -> b<p2 x1> -> (a , b)<p2> ( {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = zs), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs , {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = ys), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([zs]); listElts([VV])])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys ) 325: where 326: ( {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([zs]); listElts([VV])])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys , {VV : [a] | (? Set_sub([listElts([VV]); listElts([xs])])), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([xs]) = Set_cup([listElts([xs]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) = forall a. x1:[a] -> ({VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)} , {VV : [a] | (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)})<\\x1 VV -> (? Set_sub([listElts([VV]); listElts([x1])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])])), (len([VV]) >= 0)> split {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs LiquidHaskell verifies that the relevant property of split is 332: {-@ split :: xs : [ a ] -> ( [ a ] , [ a ] ) <{\\ys zs -> (UnionElts xs ys zs)}> @-} The funny syntax with angle brackets simply says that the output of split is a pair (ys, zs) whose union is the list of elements of the input xs . (Yes, this is indeed a dependent pair; we will revisit these later to understand whats going on with the odd syntax.)","title":"Split"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#merge","text":"Next, we can merge two (sorted) lists like so: 346: forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge [a] xs [] = {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs 347: merge [] ys = {VV : [a] | (len([VV]) >= 0)} ys 348: merge ( x : xs ) ( y : ys ) 349: | {VV : a | (VV = x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | ((? Prop([VV])) <=> (x <= y))} <= {VV : a | (VV = y)} y = {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ( {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys ) 350: | otherwise = {VV : a | (VV = y)} y forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : forall a. (GHC.Classes.Ord a) => xs:[a] -> x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([xs])])), (listElts([VV]) = Set_cup([listElts([xs]); listElts([x1])])), (len([VV]) >= 0)} merge ( {VV : a | (VV = x)} x forall <p :: a -> a -> Bool>. y:a -> ys:[a<p y>]<p> -> {VV : [a]<p> | (len([VV]) = (1 + len([ys]))), (listElts([VV]) = Set_cup([Set_sng([y]); listElts([ys])]))} : {VV : [a] | (VV = xs),(len([VV]) >= 0)} xs ) {VV : [a] | (VV = ys),(len([VV]) >= 0)} ys As you might expect, the elements of the returned list are the union of the elements of the input, or as LiquidHaskell might say, 357: {-@ merge :: ( Ord a ) => x : [ a ] -> y : [ a ] -> {v: [ a ] | (UnionElts v x y)} @-}","title":"Merge"},{"location":"blogposts/2013-03-26-talking-about-sets.lhs/#sort","text":"Finally, we put all the pieces together by 366: {-@ mergeSort :: ( Ord a ) => xs : [ a ] -> {v: [ a ] | (EqElts v xs)} @-} 367: forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort [] = forall <p :: a -> a -> Bool>. {VV : [{VV : a | false}]<p> | (? Set_emp([listElts([VV])])), (len([VV]) = 0)} [] 368: mergeSort [ x ] = {VV : [{VV : a | false}]<\\_ VV -> false> | (? Set_emp([listElts([VV])])), (len([VV]) = 0), (len([VV]) >= 0)} [ {VV : a | (VV = x)} x ] 369: mergeSort xs = x:[a] -> y:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x]); listElts([y])]))} merge ( forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort {VV : [a] | (VV = ys), (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys ) ( forall a. (GHC.Classes.Ord a) => x1:[a] -> {VV : [a] | (listElts([VV]) = Set_cup([listElts([x1]); listElts([x1])])), (listElts([VV]) = listElts([x1])), (listElts([x1]) = Set_cup([listElts([x1]); listElts([VV])]))} mergeSort {VV : [a] | (VV = zs), (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) 370: where 371: ( {VV : [a] | (VV = ys), (len([VV]) = len([ys])), (listElts([VV]) = Set_cup([listElts([ys]); listElts([ys])])), (listElts([VV]) = listElts([ys])), (listElts([ys]) = Set_cup([listElts([ys]); listElts([VV])])), (len([VV]) >= 0)} ys , {VV : [a] | (VV = zs), (len([VV]) = len([zs])), (listElts([VV]) = Set_cup([listElts([zs]); listElts([zs])])), (listElts([VV]) = listElts([zs])), (listElts([zs]) = Set_cup([listElts([zs]); listElts([VV])])), (len([VV]) >= 0)} zs ) = xs:[a] -> ([a] , [a])<\\ys VV -> (listElts([xs]) = Set_cup([listElts([ys]); listElts([VV])]))> split {VV : [a] | (len([VV]) >= 0)} xs The type given to mergeSort guarantees that the set of elements in the output list is indeed the same as in the input list. Of course, it says nothing about whether the list is actually sorted . Well, Rome wasn't built in a day...","title":"Sort"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/","text":"The story so far: Previously we saw how we can use LiquidHaskell to talk about set of values and specifically the set of values in a list. Often, we want to enforce the invariant that a particular data structure contains no duplicates . For example, we may have a structure that holds a collection of file handles, or other resources, where the presence of duplicates could lead to unpleasant leaks. In this post, we will see how to use LiquidHaskell to talk about the set of duplicate values in data structures, and hence, let us specify and verify uniqueness, that is, the absence of duplicates. To begin, lets extend our vocabulary to talk about the set of duplicate values in lists. By constraining this set to be empty, we can specify a list without duplicates, or an unique list . Once we express uniqueness on lists, it is straightforward to describe uniqueness on other data structures that contain lists. As an example, we will illustrate the properties of a unique zipper . 37: module UniqueZipper where 38: 39: import Prelude hiding ( reverse , ( ++ ) , filter ) 40: import Data . Set hiding ( filter ) A Quick Recap \u00b6 In the previous post we used a measure for the elements of a list, from Data/Set.spec 48: measure listElts :: [ a ] -> ( Set a ) 49: listElts ( [] ) = { v | ( ? ( Set_emp v ) ) } 50: listElts ( x : xs ) = { v | v = ( Set_cup ( Set_sng x ) ( listElts xs ) ) } With this measure we defined predicate aliases that describe relations between lists: 57: {-@ predicate EqElts X Y = 58: ( ( listElts X ) = ( listElts Y ) ) @-} 59: 60: {-@ predicate DisjointElts X Y = 61: ( Set_emp ( Set_cap ( listElts X ) ( listElts Y ) ) ) @-} 62: 63: {-@ predicate SubElts X Y = 64: ( Set_sub ( listElts X ) ( listElts Y ) ) @-} 65: 66: {-@ predicate UnionElts X Y Z = 67: ( ( listElts X ) = ( Set_cup ( listElts Y ) ( listElts Z ) ) ) @-} 68: 69: {-@ predicate ListElt N X = 70: ( Set_mem N ( listElts X ) ) @-} These predicates were our vocabulary on specifying properties of list functions. Remember, that reverse returns an output list that has the same elements, i.e., EqElts , with the input list. We can extend these predicates and express list uniqueness. So reversing a unique list should again return an output list that has the same elements as the input list, and also it is unique. Describing Unique Lists \u00b6 To describe unique lists, we follow two steps: we describe the set of duplicate values of a list; and we demand this set to be empty. Towards the first step, we define a measure dups that returns the duplicate values of its input list. This measure is recursively defined: The duplicates of an empty list is the empty set. We compute the duplicates of a non-empty list, namely x:xs , as follows: If x is an element of xs , then x is a duplicate. Hence, dups is x plus the (recursively computed) duplicates in xs . Otherwise, we can ignore x and recursively compute the duplicates of xs . The above intuition can be formalized as a measure: 105: {-@ 106: measure dups :: [ a ] -> ( Set a ) 107: dups ( [] ) = { v | ( ? ( Set_emp v ) ) } 108: dups ( x : xs ) = { v | v = ( if ( Set_mem x ( listElts xs ) ) 109: then ( Set_cup ( Set_sng x ) ( dups xs ) ) 110: else ( dups xs ) ) } 111: @-} With dups in hand, it is direct to describe unique lists: A list is unique, if the set of duplicates, as computed by dups is empty. We create a type alias for unique lists and name it UList . 121: {-@ predicate ListUnique X = ( Set_emp ( dups X ) ) @-} 122: 123: {-@ type UList a = { v : [ a ] | ( ListUnique v ) } @-} Functions on Unique Lists \u00b6 In the previous post, we proved interesting properties about the list trilogy, i.e., append , reverse , and filter . Now, we will prove that apart from these properties, all these functions preserve list uniqueness. Append \u00b6 To begin with, we proved that the output of append indeed includes the elements from both the input lists. Now, we can also prove that if both input lists are unique and their elements are disjoint , then the output list is also unique. 145: infixr 5 ++ 146: {-@ ( ++ ) :: xs : ( UList a ) 147: -> ys : {v: UList a | (DisjointElts v xs)} 148: -> {v: UList a | (UnionElts v xs ys)} 149: @-} 150: ( ++ ) :: [ a ] -> [ a ] -> [ a ] 151: [] forall a. xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : [a] | ((Set_emp (dups VV)))} ys = {VV : [a] | ((Set_emp (dups VV))) && (VV == ys) && ((len VV) >= 0)} ys 152: ( x : xs ) ++ ys = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : ( {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : [a] | ((Set_emp (dups VV))) && (VV == ys) && ((len VV) >= 0)} ys ) Reverse \u00b6 Next, we can prove that if a unique list is reversed, the output list has the same elements as the input, and also it is unique. 163: {-@ reverse :: xs : ( UList a ) -> {v: UList a | (EqElts v xs)} @-} 164: reverse :: [ a ] -> [ a ] 165: forall a. xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse = x1:{VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((len VV) == 0)} -> x2:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts x1)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts x1) (listElts x2))) && ((listElts VV) == (Set_cup (listElts x2) (listElts x1))) && ((len VV) >= 0)} go {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 166: where 167: a:{VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} -> x1:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts a)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts a) (listElts x1))) && ((listElts VV) == (Set_cup (listElts x1) (listElts a))) && ((len VV) >= 0)} go {VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} a [] = {VV : [a] | ((Set_emp (dups VV))) && (VV == a) && ((len VV) >= 0)} a 168: go a ( x : xs ) = a:{VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} -> x1:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts a)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts a) (listElts x1))) && ((listElts VV) == (Set_cup (listElts x1) (listElts a))) && ((len VV) >= 0)} go ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | ((Set_emp (dups VV))) && (VV == a) && ((len VV) >= 0)} a ) {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs Filter \u00b6 Finally, filtering a unique list returns a list with a subset of values of the input list, that once again is unique! 178: {-@ filter :: ( a -> Bool ) 179: -> xs : ( UList a ) 180: -> {v: UList a | (SubElts v xs)} 181: @-} 182: forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0)} [] 183: filter p ( x : xs ) 184: | a -> (GHC.Types.Bool) p {VV : a | (VV == x)} x = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 185: | otherwise = forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs Unique Zipper \u00b6 That was easy enough! Now, lets look at a slightly more interesting structure fashioned from lists. A zipper is an aggregate data stucture that is used to arbitrary traverse the structure and update its contents. We define a zipper as a data type that contains an element (called focus ) that we are currently using, a list of elements (called up ) before the current one, and a list of elements (called down ) after the current one. 202: data Zipper a = Zipper { forall a. (UniqueZipper.Zipper a) -> a focus :: a -- focused element in this set 203: , forall a. (UniqueZipper.Zipper a) -> [a] up :: [ a ] -- elements to the left 204: , forall a. (UniqueZipper.Zipper a) -> [a] down :: [ a ] } -- elements to the right One well-known application of zippers is in the XMonad tiling window manager. The set of windows being managed is stored in a zipper similar to the above. The focus happily coincides with the window currently in focus, and the up and down to the list of windows that come before and after it. One crucial invariant maintained by XMonad is that the zipper structure is unique -- i.e. each window appears at most once inside the zipper. Lets see how we can state and check that all the values in a zipper are unique. To start with, we would like to refine the Zipper data declaration to express that both the lists in the structure are unique and do not include focus in their values. LiquidHaskell allow us to refine data type declarations, using the liquid comments. So, apart from above definition definition for the Zipper , we add a refined one, stating that the data structure always enjoys the desired properties. 229: {-@ data Zipper a = Zipper { focus :: a 230: , up :: UListDif a focus 231: , down :: UListDif a focus } 232: @-} 233: 234: {-@ type UListDif a N = { v : ( UList a ) | ( not ( ListElt N v ) ) } @-} It is worth noting that the above is kind of dependent record in that the types of the up and down fields depend on the value of the focus field. With this annotation any time we use a Zipper in the code LiquidHaskell knows that the up and down components are unique lists that do not include focus . Moreover, when a new Zipper is constructed LiquidHaskell proves that this property holds, otherwise a liquid type error is reported. Hold on a minute! The awake reader will have noticed that values inside the Zipper as specified so far, are not unique , as nothing prevents a value from appearing in both the up and the down components. So, we have to specify that the contents of those two fields are disjoint . One way to achieve this is by defining two measures getUp and getDown that return the relevant parts of the Zipper 260: {-@ measure getUp :: forall a . ( Zipper a ) -> [ a ] 261: getUp ( Zipper focus up down ) = up 262: @-} 263: 264: {-@ measure getDown :: forall a . ( Zipper a ) -> [ a ] 265: getDown ( Zipper focus up down ) = down 266: @-} With these definitions, we create a type alias UZipper that states that the two list components are disjoint, and hence, that we have a unique zipper with no duplicates. 274: {-@ 275: type UZipper a = { v : Zipper a | ( DisjointElts ( getUp v ) ( getDown v ) ) } 276: @-} Functions on Unique Zippers \u00b6 Now that we have defined a unique zipper, it is straightforward for LiquidHaskell to prove that operations on zippers preserve uniqueness. Differentiation \u00b6 We can prove that a zipper that built from elements from a unique list is indeed unique. 293: {-@ differentiate :: UList a -> Maybe ( UZipper a ) @-} 294: forall a. {VV : [a] | ((Set_emp (dups VV)))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) differentiate [] = forall a. {VV : (Data.Maybe.Maybe a) | (((isJust VV)) <=> false)} Nothing 295: differentiate ( x : xs ) = x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == x)} x {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs Integration \u00b6 And vice versa, all elements of a unique zipper yield a unique list. 304: {-@ integrate :: UZipper a -> UList a @-} 305: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : [a] | ((Set_emp (dups VV)))} integrate ( Zipper x l r ) = xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse {VV : [a] | (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == l) && ((len VV) >= 0)} l xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == r) && ((len VV) >= 0)} r Recall the types for ++ and reverse that we proved earlier -- hover your mouse over the identifiers to refresh your memory. Those types are essential for establishing the type of integrate . By the definition of UZipper we know that l is a unique list and that x is not an element of l . Thus via the type of reverse we know that reverse l is also unique and disjoint from x and r . Finally, using the previously established type for ++ LiquidHaskell can prove that since x : r is a unique list with elements disjoint from reverse l the concatenation of the two lists is also a unique list. With the exact same reasoning, we use the above list operations to create more zipper operations. Reverse \u00b6 We can reverse a unique zipper 332: {-@ reverseZipper :: UZipper a -> UZipper a @-} 333: reverseZipper :: Zipper a -> Zipper a 334: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper ( Zipper t ls rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == t)} t {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls Shifting Focus \u00b6 More the focus up or down 343: {-@ focusUp :: UZipper a -> UZipper a @-} 344: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusUp ( Zipper t [] rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == x) && (VV == x)} x {VV : [a] | (not (((Set_mem x (listElts VV))))) && (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == xs) && (VV == xs) && ((len VV) == (len xs)) && ((listElts VV) == (Set_cup (listElts xs) (listElts xs))) && ((listElts VV) == (listElts xs)) && ((len VV) >= 0)} xs {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 345: where 346: ( {VV : a | (VV == x)} x : {VV : [a] | (not (((Set_mem x (listElts VV))))) && (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == xs) && ((len VV) == (len xs)) && ((listElts VV) == (Set_cup (listElts xs) (listElts xs))) && ((listElts VV) == (listElts xs)) && ((len VV) >= 0)} xs ) = xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse ( {VV : a | (VV == t)} t forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) 347: 348: focusUp ( Zipper t ( l : ls ) rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == l)} l {VV : [a] | (VV == ls) && ((len VV) >= 0)} ls ( {VV : a | (VV == t)} t forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) 349: 350: {-@ focusDown :: UZipper a -> UZipper a @-} 351: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusDown = {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper forall <q :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool, p :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool>. (x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<p x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> (y:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<q y> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> exists [z:{VV : (UniqueZipper.Zipper a)<q x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}].{VV : (UniqueZipper.Zipper a)<p z> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} . {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusUp forall <q :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool, p :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool>. (x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<p x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> (y:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<q y> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> exists [z:{VV : (UniqueZipper.Zipper a)<q x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}].{VV : (UniqueZipper.Zipper a)<p z> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} . {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper Filter \u00b6 Finally, using the filter operation on lists allows LiquidHaskell to prove that filtering a zipper also preserves uniqueness. 361: {-@ filterZipper :: ( a -> Bool ) -> UZipper a -> Maybe ( UZipper a ) @-} 362: forall a. (a -> (GHC.Types.Bool)) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) filterZipper a -> (GHC.Types.Bool) p ( Zipper f ls rs ) 363: = case (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p ( {VV : a | (VV == f)} f forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) of 364: f' : rs' -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == f')} f' ( (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls ) {VV : [a] | (VV == rs') && ((len VV) >= 0)} rs' 365: [] -> case (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls of 366: f' : ls' -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == f')} f' {VV : [a] | (VV == ls') && ((len VV) >= 0)} ls' {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 367: [] -> forall a. {VV : (Data.Maybe.Maybe a) | (((isJust VV)) <=> false)} Nothing Conclusion \u00b6 That's all for now! This post illustrated How we can use set theory to express properties the values of the list, such as list uniqueness. How we can use LuquidHaskell to prove that these properties are preserved through list operations. How we can embed this properties in complicated data structures that use lists, such as a zipper. 390: -- TODO: Dummy function to provide qualifier hint. 391: {-@ q :: x : a -> {v: [ a ] |(not (Set_mem x (listElts v)))} @-} 392: q :: a -> [ a ] 393: forall a. x:a -> {VV : [a] | (not (((Set_mem x (listElts VV)))))} q _ = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0)} []","title":"Unique Zippers"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#a-quick-recap","text":"In the previous post we used a measure for the elements of a list, from Data/Set.spec 48: measure listElts :: [ a ] -> ( Set a ) 49: listElts ( [] ) = { v | ( ? ( Set_emp v ) ) } 50: listElts ( x : xs ) = { v | v = ( Set_cup ( Set_sng x ) ( listElts xs ) ) } With this measure we defined predicate aliases that describe relations between lists: 57: {-@ predicate EqElts X Y = 58: ( ( listElts X ) = ( listElts Y ) ) @-} 59: 60: {-@ predicate DisjointElts X Y = 61: ( Set_emp ( Set_cap ( listElts X ) ( listElts Y ) ) ) @-} 62: 63: {-@ predicate SubElts X Y = 64: ( Set_sub ( listElts X ) ( listElts Y ) ) @-} 65: 66: {-@ predicate UnionElts X Y Z = 67: ( ( listElts X ) = ( Set_cup ( listElts Y ) ( listElts Z ) ) ) @-} 68: 69: {-@ predicate ListElt N X = 70: ( Set_mem N ( listElts X ) ) @-} These predicates were our vocabulary on specifying properties of list functions. Remember, that reverse returns an output list that has the same elements, i.e., EqElts , with the input list. We can extend these predicates and express list uniqueness. So reversing a unique list should again return an output list that has the same elements as the input list, and also it is unique.","title":"A Quick Recap"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#describing-unique-lists","text":"To describe unique lists, we follow two steps: we describe the set of duplicate values of a list; and we demand this set to be empty. Towards the first step, we define a measure dups that returns the duplicate values of its input list. This measure is recursively defined: The duplicates of an empty list is the empty set. We compute the duplicates of a non-empty list, namely x:xs , as follows: If x is an element of xs , then x is a duplicate. Hence, dups is x plus the (recursively computed) duplicates in xs . Otherwise, we can ignore x and recursively compute the duplicates of xs . The above intuition can be formalized as a measure: 105: {-@ 106: measure dups :: [ a ] -> ( Set a ) 107: dups ( [] ) = { v | ( ? ( Set_emp v ) ) } 108: dups ( x : xs ) = { v | v = ( if ( Set_mem x ( listElts xs ) ) 109: then ( Set_cup ( Set_sng x ) ( dups xs ) ) 110: else ( dups xs ) ) } 111: @-} With dups in hand, it is direct to describe unique lists: A list is unique, if the set of duplicates, as computed by dups is empty. We create a type alias for unique lists and name it UList . 121: {-@ predicate ListUnique X = ( Set_emp ( dups X ) ) @-} 122: 123: {-@ type UList a = { v : [ a ] | ( ListUnique v ) } @-}","title":"Describing Unique Lists"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#functions-on-unique-lists","text":"In the previous post, we proved interesting properties about the list trilogy, i.e., append , reverse , and filter . Now, we will prove that apart from these properties, all these functions preserve list uniqueness.","title":"Functions on Unique Lists"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#append","text":"To begin with, we proved that the output of append indeed includes the elements from both the input lists. Now, we can also prove that if both input lists are unique and their elements are disjoint , then the output list is also unique. 145: infixr 5 ++ 146: {-@ ( ++ ) :: xs : ( UList a ) 147: -> ys : {v: UList a | (DisjointElts v xs)} 148: -> {v: UList a | (UnionElts v xs ys)} 149: @-} 150: ( ++ ) :: [ a ] -> [ a ] -> [ a ] 151: [] forall a. xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : [a] | ((Set_emp (dups VV)))} ys = {VV : [a] | ((Set_emp (dups VV))) && (VV == ys) && ((len VV) >= 0)} ys 152: ( x : xs ) ++ ys = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : ( {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : [a] | ((Set_emp (dups VV))) && (VV == ys) && ((len VV) >= 0)} ys )","title":"Append"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#reverse","text":"Next, we can prove that if a unique list is reversed, the output list has the same elements as the input, and also it is unique. 163: {-@ reverse :: xs : ( UList a ) -> {v: UList a | (EqElts v xs)} @-} 164: reverse :: [ a ] -> [ a ] 165: forall a. xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse = x1:{VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((len VV) == 0)} -> x2:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts x1)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts x1) (listElts x2))) && ((listElts VV) == (Set_cup (listElts x2) (listElts x1))) && ((len VV) >= 0)} go {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 166: where 167: a:{VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} -> x1:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts a)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts a) (listElts x1))) && ((listElts VV) == (Set_cup (listElts x1) (listElts a))) && ((len VV) >= 0)} go {VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} a [] = {VV : [a] | ((Set_emp (dups VV))) && (VV == a) && ((len VV) >= 0)} a 168: go a ( x : xs ) = a:{VV : [a] | ((Set_emp (dups VV))) && ((len VV) >= 0)} -> x1:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts a)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts a) (listElts x1))) && ((listElts VV) == (Set_cup (listElts x1) (listElts a))) && ((len VV) >= 0)} go ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | ((Set_emp (dups VV))) && (VV == a) && ((len VV) >= 0)} a ) {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs","title":"Reverse"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#filter","text":"Finally, filtering a unique list returns a list with a subset of values of the input list, that once again is unique! 178: {-@ filter :: ( a -> Bool ) 179: -> xs : ( UList a ) 180: -> {v: UList a | (SubElts v xs)} 181: @-} 182: forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0)} [] 183: filter p ( x : xs ) 184: | a -> (GHC.Types.Bool) p {VV : a | (VV == x)} x = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 185: | otherwise = forall a. (a -> (GHC.Types.Bool)) -> x2:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts x2))) && ((len VV) >= 0)} filter a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs","title":"Filter"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#unique-zipper","text":"That was easy enough! Now, lets look at a slightly more interesting structure fashioned from lists. A zipper is an aggregate data stucture that is used to arbitrary traverse the structure and update its contents. We define a zipper as a data type that contains an element (called focus ) that we are currently using, a list of elements (called up ) before the current one, and a list of elements (called down ) after the current one. 202: data Zipper a = Zipper { forall a. (UniqueZipper.Zipper a) -> a focus :: a -- focused element in this set 203: , forall a. (UniqueZipper.Zipper a) -> [a] up :: [ a ] -- elements to the left 204: , forall a. (UniqueZipper.Zipper a) -> [a] down :: [ a ] } -- elements to the right One well-known application of zippers is in the XMonad tiling window manager. The set of windows being managed is stored in a zipper similar to the above. The focus happily coincides with the window currently in focus, and the up and down to the list of windows that come before and after it. One crucial invariant maintained by XMonad is that the zipper structure is unique -- i.e. each window appears at most once inside the zipper. Lets see how we can state and check that all the values in a zipper are unique. To start with, we would like to refine the Zipper data declaration to express that both the lists in the structure are unique and do not include focus in their values. LiquidHaskell allow us to refine data type declarations, using the liquid comments. So, apart from above definition definition for the Zipper , we add a refined one, stating that the data structure always enjoys the desired properties. 229: {-@ data Zipper a = Zipper { focus :: a 230: , up :: UListDif a focus 231: , down :: UListDif a focus } 232: @-} 233: 234: {-@ type UListDif a N = { v : ( UList a ) | ( not ( ListElt N v ) ) } @-} It is worth noting that the above is kind of dependent record in that the types of the up and down fields depend on the value of the focus field. With this annotation any time we use a Zipper in the code LiquidHaskell knows that the up and down components are unique lists that do not include focus . Moreover, when a new Zipper is constructed LiquidHaskell proves that this property holds, otherwise a liquid type error is reported. Hold on a minute! The awake reader will have noticed that values inside the Zipper as specified so far, are not unique , as nothing prevents a value from appearing in both the up and the down components. So, we have to specify that the contents of those two fields are disjoint . One way to achieve this is by defining two measures getUp and getDown that return the relevant parts of the Zipper 260: {-@ measure getUp :: forall a . ( Zipper a ) -> [ a ] 261: getUp ( Zipper focus up down ) = up 262: @-} 263: 264: {-@ measure getDown :: forall a . ( Zipper a ) -> [ a ] 265: getDown ( Zipper focus up down ) = down 266: @-} With these definitions, we create a type alias UZipper that states that the two list components are disjoint, and hence, that we have a unique zipper with no duplicates. 274: {-@ 275: type UZipper a = { v : Zipper a | ( DisjointElts ( getUp v ) ( getDown v ) ) } 276: @-}","title":"Unique Zipper"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#functions-on-unique-zippers","text":"Now that we have defined a unique zipper, it is straightforward for LiquidHaskell to prove that operations on zippers preserve uniqueness.","title":"Functions on Unique Zippers"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#differentiation","text":"We can prove that a zipper that built from elements from a unique list is indeed unique. 293: {-@ differentiate :: UList a -> Maybe ( UZipper a ) @-} 294: forall a. {VV : [a] | ((Set_emp (dups VV)))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) differentiate [] = forall a. {VV : (Data.Maybe.Maybe a) | (((isJust VV)) <=> false)} Nothing 295: differentiate ( x : xs ) = x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == x)} x {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs","title":"Differentiation"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#integration","text":"And vice versa, all elements of a unique zipper yield a unique list. 304: {-@ integrate :: UZipper a -> UList a @-} 305: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : [a] | ((Set_emp (dups VV)))} integrate ( Zipper x l r ) = xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse {VV : [a] | (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == l) && ((len VV) >= 0)} l xs:{VV : [a] | ((Set_emp (dups VV)))} -> ys:{VV : [a] | ((Set_emp (Set_cap (listElts VV) (listElts xs)))) && ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (Set_cup (listElts xs) (listElts ys)))} ++ {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == r) && ((len VV) >= 0)} r Recall the types for ++ and reverse that we proved earlier -- hover your mouse over the identifiers to refresh your memory. Those types are essential for establishing the type of integrate . By the definition of UZipper we know that l is a unique list and that x is not an element of l . Thus via the type of reverse we know that reverse l is also unique and disjoint from x and r . Finally, using the previously established type for ++ LiquidHaskell can prove that since x : r is a unique list with elements disjoint from reverse l the concatenation of the two lists is also a unique list. With the exact same reasoning, we use the above list operations to create more zipper operations.","title":"Integration"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#reverse_1","text":"We can reverse a unique zipper 332: {-@ reverseZipper :: UZipper a -> UZipper a @-} 333: reverseZipper :: Zipper a -> Zipper a 334: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper ( Zipper t ls rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == t)} t {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls","title":"Reverse"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#shifting-focus","text":"More the focus up or down 343: {-@ focusUp :: UZipper a -> UZipper a @-} 344: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusUp ( Zipper t [] rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == x) && (VV == x)} x {VV : [a] | (not (((Set_mem x (listElts VV))))) && (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == xs) && (VV == xs) && ((len VV) == (len xs)) && ((listElts VV) == (Set_cup (listElts xs) (listElts xs))) && ((listElts VV) == (listElts xs)) && ((len VV) >= 0)} xs {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 345: where 346: ( {VV : a | (VV == x)} x : {VV : [a] | (not (((Set_mem x (listElts VV))))) && (not (((Set_mem x (listElts VV))))) && ((Set_emp (dups VV))) && (VV == xs) && ((len VV) == (len xs)) && ((listElts VV) == (Set_cup (listElts xs) (listElts xs))) && ((listElts VV) == (listElts xs)) && ((len VV) >= 0)} xs ) = xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((listElts VV) == (listElts xs))} reverse ( {VV : a | (VV == t)} t forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) 347: 348: focusUp ( Zipper t ( l : ls ) rs ) = focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == l)} l {VV : [a] | (VV == ls) && ((len VV) >= 0)} ls ( {VV : a | (VV == t)} t forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem t (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) 349: 350: {-@ focusDown :: UZipper a -> UZipper a @-} 351: forall a. {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusDown = {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper forall <q :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool, p :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool>. (x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<p x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> (y:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<q y> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> exists [z:{VV : (UniqueZipper.Zipper a)<q x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}].{VV : (UniqueZipper.Zipper a)<p z> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} . {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} focusUp forall <q :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool, p :: (UniqueZipper.Zipper a)-> (UniqueZipper.Zipper a)-> Bool>. (x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<p x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> (y:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a)<q y> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> exists [z:{VV : (UniqueZipper.Zipper a)<q x> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}].{VV : (UniqueZipper.Zipper a)<p z> | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} . {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} reverseZipper","title":"Shifting Focus"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#filter_1","text":"Finally, using the filter operation on lists allows LiquidHaskell to prove that filtering a zipper also preserves uniqueness. 361: {-@ filterZipper :: ( a -> Bool ) -> UZipper a -> Maybe ( UZipper a ) @-} 362: forall a. (a -> (GHC.Types.Bool)) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) filterZipper a -> (GHC.Types.Bool) p ( Zipper f ls rs ) 363: = case (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p ( {VV : a | (VV == f)} f forall <p :: a-> a-> Bool>. y:a -> ys:[{VV : a<p y> | true}]<p> -> {VV : [a]<p> | ((dups VV) == (if ((Set_mem y (listElts ys))) then (Set_cup (Set_sng y) (dups ys)) else (dups ys))) && ((len VV) == (1 + (len ys))) && ((listElts VV) == (Set_cup (Set_sng y) (listElts ys)))} : {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == rs) && ((len VV) >= 0)} rs ) of 364: f' : rs' -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == f')} f' ( (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls ) {VV : [a] | (VV == rs') && ((len VV) >= 0)} rs' 365: [] -> case (a -> (GHC.Types.Bool)) -> xs:{VV : [a] | ((Set_emp (dups VV)))} -> {VV : [a] | ((Set_emp (dups VV))) && ((Set_sub (listElts VV) (listElts xs)))} filter a -> (GHC.Types.Bool) p {VV : [a] | (not (((Set_mem f (listElts VV))))) && ((Set_emp (dups VV))) && (VV == ls) && ((len VV) >= 0)} ls of 366: f' : ls' -> x:{VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> {VV : (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) | (((isJust VV)) <=> true) && ((fromJust VV) == x)} Just ({VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))})) -> {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))} -> (Data.Maybe.Maybe {VV : (UniqueZipper.Zipper a) | ((Set_emp (Set_cap (listElts (getUp VV)) (listElts (getDown VV)))))}) $ focus:a -> up:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> down:{VV : [a] | (not (((Set_mem focus (listElts VV))))) && ((Set_emp (dups VV)))} -> {VV : (UniqueZipper.Zipper a) | ((getDown VV) == down) && ((getUp VV) == up)} Zipper {VV : a | (VV == f')} f' {VV : [a] | (VV == ls') && ((len VV) >= 0)} ls' {VV : [{VV : a | false}]<\\_ VV -> false> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0) && ((len VV) >= 0)} [] 367: [] -> forall a. {VV : (Data.Maybe.Maybe a) | (((isJust VV)) <=> false)} Nothing","title":"Filter"},{"location":"blogposts/2013-05-24-unique-zipper.lhs/#conclusion","text":"That's all for now! This post illustrated How we can use set theory to express properties the values of the list, such as list uniqueness. How we can use LuquidHaskell to prove that these properties are preserved through list operations. How we can embed this properties in complicated data structures that use lists, such as a zipper. 390: -- TODO: Dummy function to provide qualifier hint. 391: {-@ q :: x : a -> {v: [ a ] |(not (Set_mem x (listElts v)))} @-} 392: q :: a -> [ a ] 393: forall a. x:a -> {VV : [a] | (not (((Set_mem x (listElts VV)))))} q _ = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | ((Set_emp (dups VV))) && ((Set_emp (listElts VV))) && ((len VV) == 0)} []","title":"Conclusion"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/","text":"We've seen all sorts of interesting invariants that can be expressed with refinement predicates. For example, whether a divisor is non-zero , the dimension of lists, ensuring the safety of vector indices and reasoning about the set of values in containers and verifying their uniqueness . In each of these cases, we were working with specific refinement predicates that described whatever property was of interest. Today, (drumroll please), I want to unveil a brand new feature of LiquidHaskell, which allows us to abstract over specific properties or invariants, which significantly increases the expressiveness of the system, whilst still allowing our friend the SMT solver to carry out verification and inference automatically. 30: 31: module MickeyMouse where 32: 33: import Language . Haskell . Liquid . Prelude ( isEven ) Pin The Specification On the Function \u00b6 Lets look at some tiny mickey-mouse examples to see why we may want to abstract over refinements in the first place. Consider the following monomorphic max function on Int values: 45: maxInt :: Int -> Int -> Int 46: forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | ((papp1 p VV))} x {VV : (GHC.Types.Int) | ((papp1 p VV))} y = if {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x x:{VV : (GHC.Types.Int) | ((papp1 p VV))} -> y:{VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == y)} y then {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == y)} y else {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x We could give maxInt many, quite different and incomparable refinement types like 50: maxInt :: { v : Int | v >= 0 } -> { v : Int | v >= 0 } -> { v : Int | v >= 0 } or 54: maxInt :: { v : Int | v < 10 } -> { v : Int | v < 10 } -> { v : Int | v < 10 } or even 58: maxInt :: { v : Int | ( Even v ) } -> { v : Int | ( Even v ) } -> { v : Int | ( Even v ) } All of the above are valid. But which one is the right type? At this point, you might be exasperated for one of two reasons. First, the type enthusiasts among you may cry out -- \"What? Does this funny refinement type system not have principal types ?\" No. Or, to be precise, of course not! Principal typing is a lovely feature that is one of the many reasons why Hindley-Milner is such a delightful sweet spot. Unfortunately, the moment one wants fancier specifications one must tearfully kiss principal typing good bye. Oh well. Second, you may very well say, \"Yes yes, does it even matter? Just pick one and get on with it already!\" Unfortunately, it matters quite a bit. Suppose we had a refined type describing valid RGB values: 87: {-@ type RGB = { v : Int | ( ( 0 <= v ) && ( v < 256 ) ) } @-} Now, if I wrote a function that selected the larger, that is to say, the more intense, of two RGB values, I would certainly like to check that it produced an RGB value! 95: {-@ intenser :: RGB -> RGB -> RGB @-} 96: {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} -> {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} -> {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} intenser {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} c1 {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} c2 = forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | (VV == c1) && (VV < 256) && (0 <= VV)} c1 {VV : (GHC.Types.Int) | (VV == c2) && (VV < 256) && (0 <= VV)} c2 Well, guess what. The first type (with v >= 0 ) one would tell us that the output was non-negative, losing the upper bound. The second type (with v < 10 ) would cause LiquidHaskell to bellyache about maxInt being called with improper arguments -- muttering darkly that an RGB value is not necesarily less than 10 . As for the third type ... well, you get the idea. So alas, the choice of type does matter. If we were clairvoyant, we would give maxInt a type like 108: maxInt :: RGB -> RGB -> RGB but of course, that has its own issues. (\"What? I have to write a separate function for picking the larger of two 4 digit numbers?!\") Defining Parametric Invariants \u00b6 Lets take a step back from the types, and turn to a spot of handwaving. What's really going on with maxInt ? Well, the function returns one of its two arguments x and y . This means that if both arguments satisfy some property then the output must satisfy that property, regardless of what that property was! To teach LiquidHaskell to understand this notion of \"regardless of property\" we introduce the idea of abstracting over refinements or, if you prefer, parameterizing a type over its refinements. In particular, we type maxInt as 133: {-@ maxInt :: forall < p :: Int -> Prop >. Int < p > -> Int < p > -> Int < p > @-} Here, the definition says explicitly: for any property p that is a property of Int , the function takes two inputs each of which satisfy p and returns an output that satisfies p . That is to say, Int<p> is just an abbreviation for {v:Int | (p v)} Digression: Whither Decidability? At first glance, it may appear that these abstract p have taken us into the realm of higher-order logics, where we must leave decidable checking and our faithful SMT companion at that door, and instead roll up our sleeves for interactive proofs (not that there's anything wrong with that!) Fortunately, that's not the case. We simply encode abstract refinements p as uninterpreted function symbols in the refinement logic. Uninterpreted functions are special symbols p which satisfy only the congruence axiom . 150: forall X , Y . if ( X = Y ) then p ( X ) = p ( Y ) Happily, reasoning with such uninterpreted functions is quite decidable (thanks to Ackermann, yes, that Ackermann) and actually rather efficient. Thus, via SMT, LiquidHaskell happily verifies that maxInt indeed behaves as advertised: the input types ensure that both (p x) and (p y) hold and hence that the returned value in either branch of maxInt satisfies the refinement {v:Int | p(v)} , thereby ensuring the output type. By the same reasoning, we can define the maximumInt operator on lists: 163: {-@ maximumInt :: forall < p :: Int -> Prop >. x : [ Int < p > ] -> Int < p > @-} 164: forall <p :: (GHC.Types.Int)-> Bool>. [{VV : (GHC.Types.Int)<p> | true}] -> {VV : (GHC.Types.Int)<p> | true} maximumInt ( x : xs ) = ({VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Int) | ((papp1 p VV))}) -> {VV : (GHC.Types.Int) | ((papp1 p VV))} -> [{VV : (GHC.Types.Int) | ((papp1 p VV))}] -> {VV : (GHC.Types.Int) | ((papp1 p VV))} foldr forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x {VV : [{VV : (GHC.Types.Int) | ((papp1 p VV))}] | (VV == xs) && ((len VV) >= 0)} xs Using Parametric Invariants \u00b6 Its only useful to parametrize over invariants if there is some easy way to instantiate the parameters. Concretely, consider the function: 176: {-@ maxEvens1 :: xs : [ Int ] -> {v: Int | (Even v)} @-} 177: [(GHC.Types.Int)] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maxEvens1 [(GHC.Types.Int)] xs = forall <p :: (GHC.Types.Int)-> Bool>. [{VV : (GHC.Types.Int)<p> | true}] -> {VV : (GHC.Types.Int)<p> | true} maximumInt {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs'') && ((len VV) == (1 + (len xs'))) && ((len VV) >= 0)} xs'' 178: where 179: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) >= 0)} xs' = [ (GHC.Types.Int) x | x <- {VV : [(GHC.Types.Int)] | (VV == xs) && ((len VV) >= 0)} xs , x:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> ((x mod 2) == 0))} isEven (GHC.Types.Int) x ] 180: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) == (1 + (len xs')))} xs'' = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 forall <p :: (GHC.Types.Int)-> (GHC.Types.Int)-> Bool>. y:{VV : (GHC.Types.Int) | ((VV mod 2) == 0)} -> ys:[{VV : (GHC.Types.Int)<p y> | ((VV mod 2) == 0)}]<p> -> {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<p> | ((len VV) == (1 + (len ys)))} : {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs') && ((len VV) >= 0)} xs' where the function isEven is from the Language.Haskell.Liquid.Prelude library: 184: {- isEven :: x:Int -> {v:Bool | (Prop(v) <=> (Even x))} -} 185: isEven :: Int -> Bool 186: isEven x = x `mod` 2 == 0 where the predicate Even is defined as 192: {-@ predicate Even X = ( ( X mod 2 ) = 0 ) @-} To verify that maxEvens1 returns an even number, LiquidHaskell infers that the list (0:xs') has type [{v:Int | (Even v)}] , that is, is a list of even numbers. automatically instantiates the refinement parameter of maximumInt with the concrete refinement {\\v -> (Even v)} and so concludes that the value returned by maxEvens1 is indeed Even . Parametric Invariants and Type Classes \u00b6 Ok, lets be honest, the above is clearly quite contrived. After all, wouldn't you write a polymorphic max function? And having done so, we'd just get all the above goodness from old fashioned parametricity. That is to say, if we just wrote: 213: max :: forall a . a -> a -> a 214: max x y = if x > y then x else y 215: 216: maximum :: forall a . [ a ] -> a 217: maximum ( x : xs ) = foldr max x xs then we could happily instantiate the a with {v:Int | v > 0} or {v:Int | (Even v)} or whatever was needed at the call-site of max . Sigh. Perhaps we are still pining for Hindley-Milner. Well, if this was an ML perhaps we could but in Haskell, the types would be 225: ( > ) :: ( Ord a ) => a -> a -> Bool 226: max :: ( Ord a ) => a -> a -> a 227: maximum :: ( Ord a ) => [ a ] -> a Our first temptation may be to furtively look over our shoulders, and convinced no one was watching, just pretend that funny (Ord a) business was not there, and quietly just treat maximum as [a] -> a and summon parametricity. That would be most unwise. We may get away with it with the harmless Ord but what of, say, Num . Clearly a function 238: numCrunch :: ( Num a ) => [ a ] -> a is not going to necessarily return one of its inputs as an output. Thus, it is laughable to believe that numCrunch would, if given a list of of even (or positive, negative, prime, RGB, ...) integers, return a even (or positive, negative, prime, RGB, ...) integer, since the function might add or subtract or multiply or do other unspeakable things to the numbers in order to produce the output value. And yet, typeclasses are everywhere. How could we possibly verify that 253: {-@ maxEvens2 :: xs : [ Int ] -> {v: Int | (Even v) } @-} 254: [(GHC.Types.Int)] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maxEvens2 [(GHC.Types.Int)] xs = [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maximumPoly {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs'') && ((len VV) == (1 + (len xs'))) && ((len VV) >= 0)} xs'' 255: where 256: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) >= 0)} xs' = [ (GHC.Types.Int) x | x <- {VV : [(GHC.Types.Int)] | (VV == xs) && ((len VV) >= 0)} xs , x:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> ((x mod 2) == 0))} isEven (GHC.Types.Int) x ] 257: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) == (1 + (len xs')))} xs'' = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 forall <p :: (GHC.Types.Int)-> (GHC.Types.Int)-> Bool>. y:{VV : (GHC.Types.Int) | ((VV mod 2) == 0)} -> ys:[{VV : (GHC.Types.Int)<p y> | ((VV mod 2) == 0)}]<p> -> {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<p> | ((len VV) == (1 + (len ys)))} : {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs') && ((len VV) >= 0)} xs' where the helpers were in the usual Ord style? 263: maximumPoly :: ( Ord a ) => [ a ] -> a 264: forall a <p :: a-> Bool>. (GHC.Classes.Ord a) => [{VV : a<p> | true}] -> {VV : a<p> | true} maximumPoly ( x : xs ) = ({VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))}) -> {VV : a | ((papp1 p VV))} -> [{VV : a | ((papp1 p VV))}] -> {VV : a | ((papp1 p VV))} foldr {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} maxPoly {VV : a | ((papp1 p VV)) && (VV == x)} x {VV : [{VV : a | ((papp1 p VV))}] | (VV == xs) && ((len VV) >= 0)} xs 265: 266: maxPoly :: ( Ord a ) => a -> a -> a 267: forall a <p :: a-> Bool>. (GHC.Classes.Ord a) => {VV : a<p> | true} -> {VV : a<p> | true} -> {VV : a<p> | true} maxPoly {VV : a | ((papp1 p VV))} x {VV : a | ((papp1 p VV))} y = if {VV : a | ((papp1 p VV)) && (VV == x)} x x:{VV : a | ((papp1 p VV))} -> y:{VV : a | ((papp1 p VV))} -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | ((papp1 p VV)) && (VV == y)} y then {VV : a | ((papp1 p VV)) && (VV == y)} y else {VV : a | ((papp1 p VV)) && (VV == x)} x The answer: abstract refinements. First, via the same analysis as the monomorphic Int case, LiquidHaskell establishes that 276: {-@ maxPoly :: forall < p :: a -> Prop >. 277: ( Ord a ) => x : a < p > -> y : a < p > -> a < p > @-} and hence, that 283: {-@ maximumPoly :: forall < p :: a -> Prop >. 284: ( Ord a ) => x : [ a < p > ] -> a < p > @-} Second, at the call-site for maximumPoly in maxEvens2 LiquidHaskell instantiates the type variable a with Int , and the abstract refinement parameter p with {\\v -> (Even v)} after which, the verification proceeds as described earlier (for the Int case). And So \u00b6 If you've courageously slogged through to this point then you've learnt that Sometimes, choosing the right type can be quite difficult! But fortunately, with abstract refinements we needn't choose, but can write types that are parameterized over the actual concrete invariants or refinements, which Can be instantiated at the call-sites i.e. users of the functions. We started with some really frivolous examples, but buckle your seatbelt and hold on tight, because we're going to see some rather nifty things that this new technique makes possible, including induction, reasoning about memoizing functions, and ordering and sorting data. Stay tuned.","title":"Abstracting Over Refinements"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/#pin-the-specification-on-the-function","text":"Lets look at some tiny mickey-mouse examples to see why we may want to abstract over refinements in the first place. Consider the following monomorphic max function on Int values: 45: maxInt :: Int -> Int -> Int 46: forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | ((papp1 p VV))} x {VV : (GHC.Types.Int) | ((papp1 p VV))} y = if {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x x:{VV : (GHC.Types.Int) | ((papp1 p VV))} -> y:{VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == y)} y then {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == y)} y else {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x We could give maxInt many, quite different and incomparable refinement types like 50: maxInt :: { v : Int | v >= 0 } -> { v : Int | v >= 0 } -> { v : Int | v >= 0 } or 54: maxInt :: { v : Int | v < 10 } -> { v : Int | v < 10 } -> { v : Int | v < 10 } or even 58: maxInt :: { v : Int | ( Even v ) } -> { v : Int | ( Even v ) } -> { v : Int | ( Even v ) } All of the above are valid. But which one is the right type? At this point, you might be exasperated for one of two reasons. First, the type enthusiasts among you may cry out -- \"What? Does this funny refinement type system not have principal types ?\" No. Or, to be precise, of course not! Principal typing is a lovely feature that is one of the many reasons why Hindley-Milner is such a delightful sweet spot. Unfortunately, the moment one wants fancier specifications one must tearfully kiss principal typing good bye. Oh well. Second, you may very well say, \"Yes yes, does it even matter? Just pick one and get on with it already!\" Unfortunately, it matters quite a bit. Suppose we had a refined type describing valid RGB values: 87: {-@ type RGB = { v : Int | ( ( 0 <= v ) && ( v < 256 ) ) } @-} Now, if I wrote a function that selected the larger, that is to say, the more intense, of two RGB values, I would certainly like to check that it produced an RGB value! 95: {-@ intenser :: RGB -> RGB -> RGB @-} 96: {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} -> {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} -> {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} intenser {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} c1 {VV : (GHC.Types.Int) | (VV < 256) && (0 <= VV)} c2 = forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | (VV == c1) && (VV < 256) && (0 <= VV)} c1 {VV : (GHC.Types.Int) | (VV == c2) && (VV < 256) && (0 <= VV)} c2 Well, guess what. The first type (with v >= 0 ) one would tell us that the output was non-negative, losing the upper bound. The second type (with v < 10 ) would cause LiquidHaskell to bellyache about maxInt being called with improper arguments -- muttering darkly that an RGB value is not necesarily less than 10 . As for the third type ... well, you get the idea. So alas, the choice of type does matter. If we were clairvoyant, we would give maxInt a type like 108: maxInt :: RGB -> RGB -> RGB but of course, that has its own issues. (\"What? I have to write a separate function for picking the larger of two 4 digit numbers?!\")","title":"Pin The Specification On the Function"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/#defining-parametric-invariants","text":"Lets take a step back from the types, and turn to a spot of handwaving. What's really going on with maxInt ? Well, the function returns one of its two arguments x and y . This means that if both arguments satisfy some property then the output must satisfy that property, regardless of what that property was! To teach LiquidHaskell to understand this notion of \"regardless of property\" we introduce the idea of abstracting over refinements or, if you prefer, parameterizing a type over its refinements. In particular, we type maxInt as 133: {-@ maxInt :: forall < p :: Int -> Prop >. Int < p > -> Int < p > -> Int < p > @-} Here, the definition says explicitly: for any property p that is a property of Int , the function takes two inputs each of which satisfy p and returns an output that satisfies p . That is to say, Int<p> is just an abbreviation for {v:Int | (p v)} Digression: Whither Decidability? At first glance, it may appear that these abstract p have taken us into the realm of higher-order logics, where we must leave decidable checking and our faithful SMT companion at that door, and instead roll up our sleeves for interactive proofs (not that there's anything wrong with that!) Fortunately, that's not the case. We simply encode abstract refinements p as uninterpreted function symbols in the refinement logic. Uninterpreted functions are special symbols p which satisfy only the congruence axiom . 150: forall X , Y . if ( X = Y ) then p ( X ) = p ( Y ) Happily, reasoning with such uninterpreted functions is quite decidable (thanks to Ackermann, yes, that Ackermann) and actually rather efficient. Thus, via SMT, LiquidHaskell happily verifies that maxInt indeed behaves as advertised: the input types ensure that both (p x) and (p y) hold and hence that the returned value in either branch of maxInt satisfies the refinement {v:Int | p(v)} , thereby ensuring the output type. By the same reasoning, we can define the maximumInt operator on lists: 163: {-@ maximumInt :: forall < p :: Int -> Prop >. x : [ Int < p > ] -> Int < p > @-} 164: forall <p :: (GHC.Types.Int)-> Bool>. [{VV : (GHC.Types.Int)<p> | true}] -> {VV : (GHC.Types.Int)<p> | true} maximumInt ( x : xs ) = ({VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Int) | ((papp1 p VV))} -> {VV : (GHC.Types.Int) | ((papp1 p VV))}) -> {VV : (GHC.Types.Int) | ((papp1 p VV))} -> [{VV : (GHC.Types.Int) | ((papp1 p VV))}] -> {VV : (GHC.Types.Int) | ((papp1 p VV))} foldr forall <p :: (GHC.Types.Int)-> Bool>. {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} -> {VV : (GHC.Types.Int)<p> | true} maxInt {VV : (GHC.Types.Int) | ((papp1 p VV)) && (VV == x)} x {VV : [{VV : (GHC.Types.Int) | ((papp1 p VV))}] | (VV == xs) && ((len VV) >= 0)} xs","title":"Defining Parametric Invariants"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/#using-parametric-invariants","text":"Its only useful to parametrize over invariants if there is some easy way to instantiate the parameters. Concretely, consider the function: 176: {-@ maxEvens1 :: xs : [ Int ] -> {v: Int | (Even v)} @-} 177: [(GHC.Types.Int)] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maxEvens1 [(GHC.Types.Int)] xs = forall <p :: (GHC.Types.Int)-> Bool>. [{VV : (GHC.Types.Int)<p> | true}] -> {VV : (GHC.Types.Int)<p> | true} maximumInt {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs'') && ((len VV) == (1 + (len xs'))) && ((len VV) >= 0)} xs'' 178: where 179: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) >= 0)} xs' = [ (GHC.Types.Int) x | x <- {VV : [(GHC.Types.Int)] | (VV == xs) && ((len VV) >= 0)} xs , x:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> ((x mod 2) == 0))} isEven (GHC.Types.Int) x ] 180: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) == (1 + (len xs')))} xs'' = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 forall <p :: (GHC.Types.Int)-> (GHC.Types.Int)-> Bool>. y:{VV : (GHC.Types.Int) | ((VV mod 2) == 0)} -> ys:[{VV : (GHC.Types.Int)<p y> | ((VV mod 2) == 0)}]<p> -> {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<p> | ((len VV) == (1 + (len ys)))} : {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs') && ((len VV) >= 0)} xs' where the function isEven is from the Language.Haskell.Liquid.Prelude library: 184: {- isEven :: x:Int -> {v:Bool | (Prop(v) <=> (Even x))} -} 185: isEven :: Int -> Bool 186: isEven x = x `mod` 2 == 0 where the predicate Even is defined as 192: {-@ predicate Even X = ( ( X mod 2 ) = 0 ) @-} To verify that maxEvens1 returns an even number, LiquidHaskell infers that the list (0:xs') has type [{v:Int | (Even v)}] , that is, is a list of even numbers. automatically instantiates the refinement parameter of maximumInt with the concrete refinement {\\v -> (Even v)} and so concludes that the value returned by maxEvens1 is indeed Even .","title":"Using Parametric Invariants"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/#parametric-invariants-and-type-classes","text":"Ok, lets be honest, the above is clearly quite contrived. After all, wouldn't you write a polymorphic max function? And having done so, we'd just get all the above goodness from old fashioned parametricity. That is to say, if we just wrote: 213: max :: forall a . a -> a -> a 214: max x y = if x > y then x else y 215: 216: maximum :: forall a . [ a ] -> a 217: maximum ( x : xs ) = foldr max x xs then we could happily instantiate the a with {v:Int | v > 0} or {v:Int | (Even v)} or whatever was needed at the call-site of max . Sigh. Perhaps we are still pining for Hindley-Milner. Well, if this was an ML perhaps we could but in Haskell, the types would be 225: ( > ) :: ( Ord a ) => a -> a -> Bool 226: max :: ( Ord a ) => a -> a -> a 227: maximum :: ( Ord a ) => [ a ] -> a Our first temptation may be to furtively look over our shoulders, and convinced no one was watching, just pretend that funny (Ord a) business was not there, and quietly just treat maximum as [a] -> a and summon parametricity. That would be most unwise. We may get away with it with the harmless Ord but what of, say, Num . Clearly a function 238: numCrunch :: ( Num a ) => [ a ] -> a is not going to necessarily return one of its inputs as an output. Thus, it is laughable to believe that numCrunch would, if given a list of of even (or positive, negative, prime, RGB, ...) integers, return a even (or positive, negative, prime, RGB, ...) integer, since the function might add or subtract or multiply or do other unspeakable things to the numbers in order to produce the output value. And yet, typeclasses are everywhere. How could we possibly verify that 253: {-@ maxEvens2 :: xs : [ Int ] -> {v: Int | (Even v) } @-} 254: [(GHC.Types.Int)] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maxEvens2 [(GHC.Types.Int)] xs = [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}] -> {VV : (GHC.Types.Int) | ((VV mod 2) == 0)} maximumPoly {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs'') && ((len VV) == (1 + (len xs'))) && ((len VV) >= 0)} xs'' 255: where 256: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) >= 0)} xs' = [ (GHC.Types.Int) x | x <- {VV : [(GHC.Types.Int)] | (VV == xs) && ((len VV) >= 0)} xs , x:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> ((x mod 2) == 0))} isEven (GHC.Types.Int) x ] 257: {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | ((len VV) == (1 + (len xs')))} xs'' = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 forall <p :: (GHC.Types.Int)-> (GHC.Types.Int)-> Bool>. y:{VV : (GHC.Types.Int) | ((VV mod 2) == 0)} -> ys:[{VV : (GHC.Types.Int)<p y> | ((VV mod 2) == 0)}]<p> -> {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<p> | ((len VV) == (1 + (len ys)))} : {VV : [{VV : (GHC.Types.Int) | ((VV mod 2) == 0)}]<\\_ VV -> ((VV mod 2) == 0)> | (VV == xs') && ((len VV) >= 0)} xs' where the helpers were in the usual Ord style? 263: maximumPoly :: ( Ord a ) => [ a ] -> a 264: forall a <p :: a-> Bool>. (GHC.Classes.Ord a) => [{VV : a<p> | true}] -> {VV : a<p> | true} maximumPoly ( x : xs ) = ({VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))}) -> {VV : a | ((papp1 p VV))} -> [{VV : a | ((papp1 p VV))}] -> {VV : a | ((papp1 p VV))} foldr {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} -> {VV : a | ((papp1 p VV))} maxPoly {VV : a | ((papp1 p VV)) && (VV == x)} x {VV : [{VV : a | ((papp1 p VV))}] | (VV == xs) && ((len VV) >= 0)} xs 265: 266: maxPoly :: ( Ord a ) => a -> a -> a 267: forall a <p :: a-> Bool>. (GHC.Classes.Ord a) => {VV : a<p> | true} -> {VV : a<p> | true} -> {VV : a<p> | true} maxPoly {VV : a | ((papp1 p VV))} x {VV : a | ((papp1 p VV))} y = if {VV : a | ((papp1 p VV)) && (VV == x)} x x:{VV : a | ((papp1 p VV))} -> y:{VV : a | ((papp1 p VV))} -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | ((papp1 p VV)) && (VV == y)} y then {VV : a | ((papp1 p VV)) && (VV == y)} y else {VV : a | ((papp1 p VV)) && (VV == x)} x The answer: abstract refinements. First, via the same analysis as the monomorphic Int case, LiquidHaskell establishes that 276: {-@ maxPoly :: forall < p :: a -> Prop >. 277: ( Ord a ) => x : a < p > -> y : a < p > -> a < p > @-} and hence, that 283: {-@ maximumPoly :: forall < p :: a -> Prop >. 284: ( Ord a ) => x : [ a < p > ] -> a < p > @-} Second, at the call-site for maximumPoly in maxEvens2 LiquidHaskell instantiates the type variable a with Int , and the abstract refinement parameter p with {\\v -> (Even v)} after which, the verification proceeds as described earlier (for the Int case).","title":"Parametric Invariants and Type Classes"},{"location":"blogposts/2013-06-03-abstracting-over-refinements.lhs/#and-so","text":"If you've courageously slogged through to this point then you've learnt that Sometimes, choosing the right type can be quite difficult! But fortunately, with abstract refinements we needn't choose, but can write types that are parameterized over the actual concrete invariants or refinements, which Can be instantiated at the call-sites i.e. users of the functions. We started with some really frivolous examples, but buckle your seatbelt and hold on tight, because we're going to see some rather nifty things that this new technique makes possible, including induction, reasoning about memoizing functions, and ordering and sorting data. Stay tuned.","title":"And So"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/","text":"Hello again! Since we last met, much has happened that we're rather excited about, and which we promise to get to in the fullness of time. Today, however, lets continue with our exploration of abstract refinements. We'll see that this rather innocent looking mechanism packs quite a punch, by showing how it can encode various ordering properties of recursive data structures. 26: module PuttingThingsInOrder where 27: 28: import Prelude hiding ( break ) 29: 30: -- Haskell Type Definitions 31: plusOnes :: [ ( Int , Int ) ] 32: insertSort , mergeSort , quickSort :: ( Ord a ) => [ a ] -> [ a ] Abstract Refinements \u00b6 Recall that abstract refinements are a mechanism that let us write and check types of the form 36: maxInt :: forall < p :: Int -> Prop >. Int < p > -> Int < p > -> Int < p > which states that the output of maxInt preserves whatever invariants held for its two inputs as long as both those inputs also satisfied those invariants. First, lets see how we can (and why we may want to) abstractly refine data types. Polymorphic Association Lists \u00b6 Suppose, we require a type for association lists. Lets define one that is polymorphic over keys k and values v 55: data AssocP k v = KVP [ ( k , v ) ] Now, in a program, you might have multiple association lists, whose keys satisfy different properties. For example, we might have a table for mapping digits to the corresponding English string 64: digitsP :: AssocP Int String 65: (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (0 <= VV) && (VV <= 9)} [(GHC.Types.Char)]) digitsP = [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})] -> (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)} {VV : [(GHC.Types.Char)] | ((len VV) >= 0)}) KVP [ ({VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"one\" ) 66: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (2 : int))} 2 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"two\" ) 67: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (3 : int))} 3 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"three\" ) ] We could have a separate table for sparsely storing the contents of an array of size 1000 . 74: sparseVecP :: AssocP Int Double 75: (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (0 <= VV) && (VV <= 1000)} (GHC.Types.Double)) sparseVecP = [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double))] -> (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)} (GHC.Types.Double)) KVP [ ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (12 : int))} 12 , (GHC.Types.Double) 34.1 ) 76: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (92 : int))} 92 , (GHC.Types.Double) 902.83 ) 77: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (451 : int))} 451 , (GHC.Types.Double) 2.95 ) 78: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (877 : int))} 877 , (GHC.Types.Double) 3.1 ) ] The keys used in the two tables have rather different properties, which we may want to track at compile time. In digitsP the keys are between 0 and 9 In sparseVecP the keys are between 0 and 999 . Well, since we had the foresight to parameterize the key type in AssocP , we can express the above properties by appropriately instantiating the type of k with refined versions 94: {-@ digitsP :: AssocP {v: Int | (Btwn 0 v 9)} String @-} and 100: {-@ sparseVecP :: AssocP {v: Int | (Btwn 0 v 1000)} Double @-} where Btwn is just an alias 106: {-@ predicate Btwn Lo V Hi = ( Lo <= V && V <= Hi ) @-} Monomorphic Association Lists \u00b6 Now, suppose that for one reason or another, we want to specialize our association list so that the keys are of type Int . 117: data Assoc v = KV [ ( Int , v ) ] (We'd probably also want to exploit the Int -ness in the implementation but thats a tale for another day.) Now, we have our two tables 126: digits :: Assoc String 127: (PuttingThingsInOrder.Assoc [(GHC.Types.Char)]) digits = forall <p :: (GHC.Types.Int)-> Bool>. [({VV : (GHC.Types.Int)<p> | true}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})] -> (PuttingThingsInOrder.Assoc <p> {VV : [(GHC.Types.Char)] | ((len VV) >= 0)}) KV [ ({VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"one\" ) 128: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (2 : int))} 2 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"two\" ) 129: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (3 : int))} 3 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"three\" ) ] 130: 131: sparseVec :: Assoc Double 132: (PuttingThingsInOrder.Assoc (GHC.Types.Double)) sparseVec = forall <p :: (GHC.Types.Int)-> Bool>. [({VV : (GHC.Types.Int)<p> | true}, (GHC.Types.Double))] -> (PuttingThingsInOrder.Assoc <p> (GHC.Types.Double)) KV [ ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (12 : int))} 12 , (GHC.Types.Double) 34.1 ) 133: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (92 : int))} 92 , (GHC.Types.Double) 902.83 ) 134: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (451 : int))} 451 , (GHC.Types.Double) 2.95 ) 135: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (877 : int))} 877 , (GHC.Types.Double) 3.1 ) ] but since we didn't make the key type generic, it seems we have no way to distinguish between the invariants of the two sets of keys. Bummer! Abstractly Refined Data \u00b6 We could define two separate types of association lists that capture different invariants, but frankly, thats rather unfortunate, as we'd then have to duplicate the code the manipulates the structures. Of course, we'd like to have (type) systems help keep an eye on different invariants, but we'd really rather not have to duplicate code to achieve that end. Thats the sort of thing that drives a person to JavaScript ;-). Fortunately, all is not lost. If you were paying attention last time then you'd realize that this is the perfect job for an abstract refinement, this time applied to a data definition: 163: {-@ data Assoc v < p :: Int -> Prop > 164: = KV ( z :: [ ( Int < p > , v ) ] ) @-} The definition refines the type for Assoc to introduce an abstract refinement p which is, informally speaking, a property of Int . The definition states that each Int in the association list in fact satisfies p as, Int<p> is an abbreviation for {v:Int| (p v)} . Now, we can have our Int keys and refine them too! For example, we can write: 177: {-@ digits :: Assoc ( String ) <{\\v -> (Btwn 0 v 9)}> @-} to track the invariant for the digits map, and write 183: {-@ sparseVec :: Assoc Double <{\\v -> (Btwn 0 v 1000)}> @-} Thus, we can recover (some of) the benefits of abstracting over the type of the key by instead parameterizing the type directly over the possible invariants. We will have much more to say on association lists (or more generally, finite maps) and abstract refinements, but lets move on for the moment. Dependent Tuples \u00b6 It is no accident that we have reused Haskell's function type syntax to define abstract refinements ( p :: Int -> Prop ); interesting things start to happen if we use multiple parameters. Consider the function break from the Prelude. 203: break :: ( a -> Bool ) -> [ a ] -> ( [ a ] , [ a ] ) 204: forall a. (a -> (GHC.Types.Bool)) -> x:[a] -> ([a], [a])<\\y VV -> ((len x) == ((len y) + (len VV)))> break _ [a] xs @ [] = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [a] | (((null VV)) <=> true) && (VV == xs) && (VV == (GHC.Types.[])) && ((len VV) == 0) && ((len VV) >= 0)} xs , {VV : [a] | (((null VV)) <=> true) && (VV == xs) && (VV == (GHC.Types.[])) && ((len VV) == 0) && ((len VV) >= 0)} xs ) 205: break p xs @ ( x : xs' ) 206: | a -> (GHC.Types.Bool) p {VV : a | (VV == x)} x = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] , {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs ) 207: | otherwise = let ( {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len xs') == ((len zs) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} ys , {VV : [a] | (VV == zs) && ((len VV) == (len zs)) && ((len xs') == ((len ys) + (len VV))) && ((len xs') == ((len ys) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} zs ) = (a -> (GHC.Types.Bool)) -> x:[a] -> ([a], [a])<\\y VV -> ((len x) == ((len y) + (len VV)))> break a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs') && ((len VV) >= 0)} xs' 208: in forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len xs') == ((len zs) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} ys , {VV : [a] | (VV == zs) && (VV == zs) && ((len VV) == (len zs)) && ((len xs') == ((len ys) + (len VV))) && ((len xs') == ((len ys) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} zs ) From the comments in Data.List , break p xs : \"returns a tuple where the first element is longest prefix (possibly empty) xs of elements that do not satisfy p and second element is the remainder of the list.\" We could formalize the notion of the second-element-being-the-remainder using sizes. That is, we'd like to specify that the length of the second element equals the length of xs minus the length of the first element. That is, we need a way to allow the refinement of the second element to depend on the value in the first refinement. Again, we could define a special kind of tuple-of-lists-type that has the above property baked in , but thats just not how we roll. Instead, lets use abstract refinements to give us dependent tuples 225: data ( a , b ) < p :: a -> b -> Prop > = ( x : a , b < p x > ) Here, the abstract refinement takes two parameters, an a and a b . In the body of the tuple, the first element is named x and we specify that the second element satisfies the refinement p x , i.e. a partial application of p with the first element. In other words, the second element is a value of type {v:b | (p x v)} . As before, we can instantiate the p in different ways. For example the whimsical 240: {-@ plusOnes :: [ ( Int , Int ) <{\\x1 x2 -> x2 = x1 + 1}> ] @-} 241: [((GHC.Types.Int), (GHC.Types.Int))<\\x1 VV -> (VV == (x1 + 1))>] plusOnes = {VV : [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)})<\\x3 VV -> (VV == (x3 + 1)) && (VV > 0) && (VV > x3) && (0 <= VV) && (VV <= 1000)>]<\\x1 VV -> (VV /= x1)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ ({VV : (GHC.Types.Int) | (VV == 0) && (0 <= VV) && (VV <= 9)}, {VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)})<\\x2 VV -> (VV == 1) && (VV == (x2 + 1)) && (VV > 0) && (VV > x2)> ( {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 , {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)})<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 9)> ( {VV : (GHC.Types.Int) | (VV == (5 : int))} 5 , {VV : (GHC.Types.Int) | (VV == (6 : int))} 6 ) , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)})<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 1000)> ( {VV : (GHC.Types.Int) | (VV == (999 : int))} 999 , {VV : (GHC.Types.Int) | (VV == (1000 : int))} 1000 ) ] and returning to the remainder property for break 247: {-@ break :: ( a -> Bool ) -> x : [ a ] 248: -> ( [ a ] , [ a ] ) <{\\y z -> (Break x y z)}> @-} using the predicate alias 254: {-@ predicate Break X Y Z = ( len X ) = ( len Y ) + ( len Z ) @-} Abstractly Refined Lists \u00b6 Right, we've been going on for a bit. Time to put things in order . To recap: we've already seen one way to abstractly refine lists: to recover a generic means of refining a monomorphic list (e.g. the list of Int keys.) However, in that case we were talking about individual keys. Next, we build upon the dependent-tuples technique we just saw to use abstract refinements to relate different elements inside containers. In particular, we can use them to specify that every pair of elements inside the list is related according to some abstract relation p . By instantiating p appropriately, we will be able to recover various forms of (dis) order. Consider the refined definition of good old Haskell lists: 277: data [ a ] < p :: a -> a -> Prop > where 278: | [] :: [ a ] < p > 279: | ( : ) :: h : a -> [ a < p h > ] < p > -> [ a ] < p > Whoa! Thats a bit of a mouthful. Lets break it down. The type is parameterized with a refinement p :: a -> a -> Prop Think of p as a binary relation over the a values comprising the list. The empty list [] is a []<p> . Clearly, the empty list has no elements whatsoever and so every pair is trivially, or rather, vacuously related by p . The cons constructor (:) takes a head h of type a and a tail of a<p h> values, each of which is related to h and which (recursively) are pairwise related [...]<p> and returns a list where all elements are pairwise related [a]<p> . Pairwise Related \u00b6 Note that we're being a bit sloppy when we say pairwise related. What we really mean is that if a list 303: [ x1 , ... , xn ] :: [ a ] < p > then for each 1 <= i < j <= n we have (p xi xj) . To see why, consider the list 309: [ x1 , x2 , x3 , ... ] :: [ a ] < p > This list unfolds into a head and tail 313: x1 :: a 314: [ x2 , x3 , ... ] :: [ a < p x1 > ] < p > The above tail unfolds into 318: x2 :: a < p x1 > 319: [ x3 , ... ] :: [ a < p x1 && p x2 > ] < p > And finally into 323: x3 :: a < p x1 && p x2 > 324: [ ... ] :: [ a < p x1 && p x2 && p x3 > ] < p > That is, each element xj satisfies the refinement (p xi xj) for each i < j . Using Abstractly Refined Lists \u00b6 Urgh. Math is hard! Lets see how we can program with these funnily refined lists. For starters, we can define a few helpful type aliases. 340: {-@ type IncrList a = [ a ] < { \\ xi xj -> xi <= xj } > @-} 341: {-@ type DecrList a = [ a ] < { \\ xi xj -> xi >= xj } > @-} 342: {-@ type UniqList a = [ a ] < { \\ xi xj -> xi /= xj } > @-} As you might expect, an IncrList is a list of values in increasing order: 348: {-@ whatGosUp :: IncrList Integer @-} 349: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi <= VV)> whatGosUp = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 9)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 1 , 2 , 3 ] Similarly, a DecrList contains its values in decreasing order: 355: {-@ mustGoDown :: DecrList Integer @-} 356: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi >= VV)> mustGoDown = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x3 VV -> (VV == 1) && (x3 /= VV) && (VV > 0) && (x3 >= VV) && (VV < x3)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 3 , 2 , 1 ] My personal favorite though, is a UniqList which has no duplicates : 362: {-@ noDuplicates :: UniqList Integer @-} 363: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi /= VV)> noDuplicates = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x3 VV -> (x3 /= VV) && (VV > 0) && (x3 >= VV) && (VV < x3) && (0 <= VV) && (VV <= 9)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 1 , 3 , 2 ] Sorting Lists \u00b6 Its all very well to specify lists with various kinds of invariants. The question is, how easy is it to establish these invariants? Lets find out, by turning inevitably to that staple of all forms of formal verification: your usual textbook sorting procedures. Insertion Sort First up: insertion sort. Well, no surprises here: 380: {-@ insertSort :: ( Ord a ) => xs : [ a ] -> ( IncrList a ) @-} 381: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 382: insertSort ( x : xs ) = a -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> insert {VV : a | (VV == x)} x ( [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs ) The hard work is done by insert which places an element into the correct position of a sorted list 389: forall a. (GHC.Classes.Ord a) => a -> x1:[a]<\\x2 VV -> (VV >= x2)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} insert a y [] = {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : a | (VV == y)} y ] 390: insert y ( x : xs ) 391: | {VV : a | (VV == y)} y x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | (VV == x)} x = {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= y)} -> xs:[{VV : a<p x> | (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x) && (VV >= y)} -> xs:[{VV : a<p x> | (VV >= x) && (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= x) && (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV >= x)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs 392: | otherwise = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => a -> x1:[a]<\\x2 VV -> (VV >= x2)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} insert {VV : a | (VV == y)} y {VV : [{VV : a | (VV >= x)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs LiquidHaskell infers that if you give insert an element and a sorted list, it returns a sorted list. 399: {-@ insert :: ( Ord a ) => a -> IncrList a -> IncrList a @-} If you prefer the more Haskelly way of writing insertion sort, i.e. with a foldr , that works too. Can you figure out why? 406: {-@ insertSort' :: ( Ord a ) => [ a ] -> IncrList a @-} 407: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort' [a] xs = (a -> [a]<\\x4 VV -> (VV >= x4)> -> [a]<\\x4 VV -> (VV >= x4)>) -> [a]<\\x4 VV -> (VV >= x4)> -> [a] -> [a]<\\x4 VV -> (VV >= x4)> foldr a -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> insert {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs Merge Sort Well, you know the song goes. First, we write a function that splits the input into two parts: 416: split :: [ a ] -> ( [ a ] , [ a ] ) 417: forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split ( x : y : zs ) = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == xs) && (VV == xs) && ((len VV) == (len xs)) && ((len zs) == ((len ys) + (len VV))) && ((len VV) >= 0) && ((len VV) >= (len ys)) && ((len VV) <= (len zs))} xs , {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len zs) == ((len xs) + (len VV))) && ((len zs) == ((len xs) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len xs)) && ((len VV) <= (len xs)) && ((len VV) <= (len zs))} ys ) 418: where 419: ( {VV : [a] | (VV == xs) && ((len VV) == (len xs)) && ((len zs) == ((len ys) + (len VV))) && ((len VV) >= 0) && ((len VV) >= (len ys)) && ((len VV) <= (len zs))} xs , {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len zs) == ((len xs) + (len VV))) && ((len zs) == ((len xs) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len xs)) && ((len VV) <= (len xs)) && ((len VV) <= (len zs))} ys ) = forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split {VV : [a] | (VV == zs) && ((len VV) >= 0)} zs 420: split xs = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [a] | ((len VV) >= 0)} xs , {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] ) Then we need a function that merges two (sorted) lists 426: forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge [a]<\\x1 VV -> (x1 <= VV)> xs [] = {VV : [a]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs 427: merge [] ys = {VV : [a]<\\x1 VV -> (x1 <= VV)> | ((len VV) >= 0)} ys 428: merge ( x : xs ) ( y : ys ) 429: | {VV : a | (VV == x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | (VV == y)} y = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge {VV : [{VV : a | (x <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs ( {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x) && (VV >= y)} -> xs:[{VV : a<p x> | (VV >= x) && (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= x) && (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (y <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys ) 430: | otherwise = {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= y)} -> xs:[{VV : a<p x> | (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV > y) && (VV >= x)} -> xs:[{VV : a<p x> | (VV > y) && (VV >= x)}]<p> -> {VV : [{VV : a | (VV > y) && (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (x <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs ) {VV : [{VV : a | (y <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys LiquidHaskell deduces that if both inputs are ordered, then so is the output. 437: {-@ merge :: ( Ord a ) => IncrList a 438: -> IncrList a 439: -> IncrList a 440: @-} Finally, using the above functions we write mergeSort : 446: {-@ mergeSort :: ( Ord a ) => [ a ] -> IncrList a @-} 447: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 448: mergeSort [ x ] = {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : a | (VV == x)} x ] 449: mergeSort xs = [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> merge ( [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len VV) > 0) && ((len VV) >= 0) && ((len VV) >= (len zs))} ys ) ( [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort {VV : [a] | (VV == zs) && (VV == zs) && ((len VV) == (len zs)) && ((len VV) >= 0) && ((len VV) <= (len ys)) && ((len VV) <= (len ys))} zs ) 450: where 451: ( {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len VV) > 0) && ((len VV) >= (len zs))} ys , {VV : [a] | (VV == zs) && ((len VV) == (len zs)) && ((len VV) >= 0) && ((len VV) <= (len ys)) && ((len VV) <= (len ys))} zs ) = forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split {VV : [a] | ((len VV) >= 0)} xs Lets see how LiquidHaskell proves the output type. The first two cases are trivial: for an empty or singleton list, we can vacuously instantiate the abstract refinement with any concrete refinement. For the last case, we can inductively assume mergeSort ys and mergeSort zs are sorted lists, after which the type inferred for merge kicks in, allowing LiquidHaskell to conclude that the output is also sorted. Quick Sort The previous two were remarkable because they were, well, quite unremarkable . Pretty much the standard textbook implementations work as is . Unlike the classical developments using indexed types we don't have to define any auxiliary types for increasing lists, or lists whose value is in a particular range, or any specialized cons operators and so on. With quick sort we need to do a tiny bit of work. We would like to define quickSort as 481: {-@ quickSort' :: ( Ord a ) => [ a ] -> IncrList a @-} 482: quickSort' [] = [] 483: quickSort' ( x : xs ) = lts ++ ( x : gts ) 484: where 485: lts = quickSort' [ y | y <- xs , y < x ] 486: gts = quickSort' [ z | z <- xs , z >= x ] But, if you try it out, you'll see that LiquidHaskell does not approve . What could possibly be the trouble? The problem lies with append . What type do we give ++ ? We might try something like 495: ( ++ ) :: IncrList a -> IncrList a -> IncrList a but of course, this is bogus, as 499: [ 1 , 2 , 4 ] ++ [ 3 , 5 , 6 ] is decidedly not an IncrList ! Instead, at this particular use of ++ , there is an extra nugget of information: there is a pivot element x such that every element in the first argument is less than x and every element in the second argument is greater than x . There is no way we can give the usual append ++ a type that reflects the above as there is no pivot x to refer to. Thus, with a heavy heart, we must write a specialized pivot-append that uses this fact: 516: forall a. piv:a -> x1:[{VV : a | (VV < piv)}]<\\x3 VV -> (VV >= x3)> -> ys:[{VV : a | (piv <= VV)}]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && (VV /= ys) && ((len VV) > 0) && ((len VV) > (len x1)) && ((len VV) > (len ys))} pivApp a piv [] [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> ys = {VV : a | (VV == piv)} piv forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= piv)} -> xs:[{VV : a<p x> | (VV >= piv)}]<p> -> {VV : [{VV : a | (VV >= piv)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys 517: pivApp piv ( x : xs ) ys = {VV : a | (VV == x) && (VV < piv)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. piv:a -> x1:[{VV : a | (VV < piv)}]<\\x3 VV -> (VV >= x3)> -> ys:[{VV : a | (piv <= VV)}]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && (VV /= ys) && ((len VV) > 0) && ((len VV) > (len x1)) && ((len VV) > (len ys))} pivApp {VV : a | (VV == piv)} piv {VV : [{VV : a | (VV >= x) && (VV < piv)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs {VV : [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys Now, LiquidHaskell infers that 523: {-@ pivApp :: piv : a 524: -> IncrList {v: a | v < piv} 525: -> IncrList {v: a | v >= piv} 526: -> IncrList a 527: @-} And we can use pivApp to define `quickSort' simply as: 533: {-@ quickSort :: ( Ord a ) => [ a ] -> IncrList a @-} 534: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> quickSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 535: quickSort ( x : xs ) = piv:a -> [{VV : a | (VV < piv)}]<\\xi VV -> (xi <= VV)> -> [{VV : a | (VV >= piv)}]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> pivApp {VV : a | (VV == x)} x {VV : [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> | (VV == lts) && ((len VV) >= 0)} lts {VV : [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> | (VV == gts) && ((len VV) >= 0)} gts 536: where 537: [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> lts = [{VV : a | (VV < x)}] -> [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> quickSort {VV : [{VV : a | (VV < x)}]<\\_ VV -> (VV < x)> | ((len VV) >= 0) && ((len VV) <= (len xs))} [ a y | y <- {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs , a y x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x < y))} < {VV : a | (VV == x)} x ] 538: [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> gts = [{VV : a | (VV >= x)}] -> [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> quickSort {VV : [{VV : a | (VV >= x)}]<\\_ VV -> (VV >= x)> | ((len VV) >= 0) && ((len VV) <= (len xs))} [ a z | z <- {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs , a z x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x >= y))} >= {VV : a | (VV == x)} x ] Really Sorting Lists \u00b6 The convenient thing about our encoding is that the underlying datatype is plain Haskell lists. This yields two very concrete benefits. First, as mentioned before, we can manipulate sorted lists with the same functions we'd use for regular lists. Second, by decoupling (or rather, parameterizing) the relation or property or invariant from the actual data structure we can plug in different invariants, sometimes in the same program. To see why this is useful, lets look at a real-world sorting algorithm: the one used inside GHC's Data.List module . 560: sort :: ( Ord a ) => [ a ] -> [ a ] 561: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> sort = {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll forall <q :: [a]-> [[a]]-> Bool, p :: [[a]]-> [a]-> Bool>. (x:{VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} -> {VV : [a]<\\x4 VV -> (VV >= x4)><p x> | ((len VV) >= 0)}) -> (y:[a] -> {VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)><q y> | ((len VV) > 0)}) -> x:[a] -> exists [z:{VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)><q x> | ((len VV) > 0)}].{VV : [a]<\\x4 VV -> (VV >= x4)><p z> | ((len VV) >= 0)} . [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences 562: where 563: [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences ( a : b : xs ) 564: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x == y))} == {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending {VV : a | (VV == b)} b {VV : [{VV : a | (VV == a) && (VV > b)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} a ] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 565: | otherwise = a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending {VV : a | (VV == b)} b ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : ) {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 566: sequences [ x ] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [{VV : a | (VV == a)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} x ] ] 567: sequences [] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] ] 568: 569: a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending a a {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | ((len VV) > 0)} as ( b : bs ) 570: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x == y))} == {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending {VV : a | (VV == b)} b ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV > b) && (VV >= a)} -> xs:[{VV : a<p x> | (VV > b) && (VV >= a)}]<p> -> {VV : [{VV : a | (VV > b) && (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | (VV == as) && ((len VV) > 0) && ((len VV) >= 0)} as ) {VV : [a] | (VV == bs) && ((len VV) >= 0)} bs 571: descending a as bs = ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | (VV == as) && ((len VV) > 0) && ((len VV) >= 0)} as ) forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (VV >= x3)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences {VV : [a] | ((len VV) >= 0)} bs 572: 573: a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending a a x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as ( b : bs ) 574: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x /= y))} /= {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending {VV : a | (VV == b)} b ( ys:{VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x2 VV -> (VV >= a) && (VV >= b) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= ys) && ((len VV) > 0) && ((len VV) > (len ys))} \\ {VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x1 VV -> (VV >= a) && (VV >= b) && (VV >= x1)> | ((len VV) > 0)} ys -> x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x1 VV -> (VV >= a) && (VV >= b) && (VV >= x1)> | (VV == ys) && ((len VV) > 0) && ((len VV) >= 0)} ys ) ) {VV : [a] | (VV == bs) && ((len VV) >= 0)} bs 575: ascending a as bs = x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as {VV : [{VV : a | (VV == a)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} a ] forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (VV >= x3)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences {VV : [a] | ((len VV) >= 0)} bs 576: 577: {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll [ x ] = {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == x) && ((len VV) >= 0)} x 578: mergeAll xs = {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll ( x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} xs ) 579: 580: x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs ( a : b : xs ) = [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> merge {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == a) && ((len VV) >= 0)} a {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == b) && ((len VV) >= 0)} b forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (x3 <= VV)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (x3 <= VV)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (x3 <= VV)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (VV == xs) && ((len VV) >= 0)} xs 581: mergePairs [ x ] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == a) && ((len VV) >= 0)} x ] 582: mergePairs [] = forall <p :: [a]-> [a]-> Bool>. {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] The interesting thing about the procedure is that it generates some intermediate lists that are increasing and others that are decreasing, and then somehow miraculously whips this whirlygig into a single increasing list. Yet, to check this rather tricky algorithm with LiquidHaskell we need merely write: 595: {-@ sort :: ( Ord a ) => [ a ] -> IncrList a @-}","title":"Putting Things In Order"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#abstract-refinements","text":"Recall that abstract refinements are a mechanism that let us write and check types of the form 36: maxInt :: forall < p :: Int -> Prop >. Int < p > -> Int < p > -> Int < p > which states that the output of maxInt preserves whatever invariants held for its two inputs as long as both those inputs also satisfied those invariants. First, lets see how we can (and why we may want to) abstractly refine data types.","title":"Abstract Refinements"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#polymorphic-association-lists","text":"Suppose, we require a type for association lists. Lets define one that is polymorphic over keys k and values v 55: data AssocP k v = KVP [ ( k , v ) ] Now, in a program, you might have multiple association lists, whose keys satisfy different properties. For example, we might have a table for mapping digits to the corresponding English string 64: digitsP :: AssocP Int String 65: (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (0 <= VV) && (VV <= 9)} [(GHC.Types.Char)]) digitsP = [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})] -> (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)} {VV : [(GHC.Types.Char)] | ((len VV) >= 0)}) KVP [ ({VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"one\" ) 66: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (2 : int))} 2 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"two\" ) 67: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (3 : int))} 3 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"three\" ) ] We could have a separate table for sparsely storing the contents of an array of size 1000 . 74: sparseVecP :: AssocP Int Double 75: (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (0 <= VV) && (VV <= 1000)} (GHC.Types.Double)) sparseVecP = [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double))] -> (PuttingThingsInOrder.AssocP {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)} (GHC.Types.Double)) KVP [ ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (12 : int))} 12 , (GHC.Types.Double) 34.1 ) 76: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (92 : int))} 92 , (GHC.Types.Double) 902.83 ) 77: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (451 : int))} 451 , (GHC.Types.Double) 2.95 ) 78: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (877 : int))} 877 , (GHC.Types.Double) 3.1 ) ] The keys used in the two tables have rather different properties, which we may want to track at compile time. In digitsP the keys are between 0 and 9 In sparseVecP the keys are between 0 and 999 . Well, since we had the foresight to parameterize the key type in AssocP , we can express the above properties by appropriately instantiating the type of k with refined versions 94: {-@ digitsP :: AssocP {v: Int | (Btwn 0 v 9)} String @-} and 100: {-@ sparseVecP :: AssocP {v: Int | (Btwn 0 v 1000)} Double @-} where Btwn is just an alias 106: {-@ predicate Btwn Lo V Hi = ( Lo <= V && V <= Hi ) @-}","title":"Polymorphic Association Lists"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#monomorphic-association-lists","text":"Now, suppose that for one reason or another, we want to specialize our association list so that the keys are of type Int . 117: data Assoc v = KV [ ( Int , v ) ] (We'd probably also want to exploit the Int -ness in the implementation but thats a tale for another day.) Now, we have our two tables 126: digits :: Assoc String 127: (PuttingThingsInOrder.Assoc [(GHC.Types.Char)]) digits = forall <p :: (GHC.Types.Int)-> Bool>. [({VV : (GHC.Types.Int)<p> | true}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})] -> (PuttingThingsInOrder.Assoc <p> {VV : [(GHC.Types.Char)] | ((len VV) >= 0)}) KV [ ({VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"one\" ) 128: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (2 : int))} 2 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"two\" ) 129: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : [(GHC.Types.Char)] | ((len VV) >= 0)})<\\_ VV -> ((len VV) >= 0)> ( {VV : (GHC.Types.Int) | (VV == (3 : int))} 3 , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"three\" ) ] 130: 131: sparseVec :: Assoc Double 132: (PuttingThingsInOrder.Assoc (GHC.Types.Double)) sparseVec = forall <p :: (GHC.Types.Int)-> Bool>. [({VV : (GHC.Types.Int)<p> | true}, (GHC.Types.Double))] -> (PuttingThingsInOrder.Assoc <p> (GHC.Types.Double)) KV [ ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (12 : int))} 12 , (GHC.Types.Double) 34.1 ) 133: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (92 : int))} 92 , (GHC.Types.Double) 902.83 ) 134: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (451 : int))} 451 , (GHC.Types.Double) 2.95 ) 135: , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, (GHC.Types.Double)) ( {VV : (GHC.Types.Int) | (VV == (877 : int))} 877 , (GHC.Types.Double) 3.1 ) ] but since we didn't make the key type generic, it seems we have no way to distinguish between the invariants of the two sets of keys. Bummer!","title":"Monomorphic Association Lists"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#abstractly-refined-data","text":"We could define two separate types of association lists that capture different invariants, but frankly, thats rather unfortunate, as we'd then have to duplicate the code the manipulates the structures. Of course, we'd like to have (type) systems help keep an eye on different invariants, but we'd really rather not have to duplicate code to achieve that end. Thats the sort of thing that drives a person to JavaScript ;-). Fortunately, all is not lost. If you were paying attention last time then you'd realize that this is the perfect job for an abstract refinement, this time applied to a data definition: 163: {-@ data Assoc v < p :: Int -> Prop > 164: = KV ( z :: [ ( Int < p > , v ) ] ) @-} The definition refines the type for Assoc to introduce an abstract refinement p which is, informally speaking, a property of Int . The definition states that each Int in the association list in fact satisfies p as, Int<p> is an abbreviation for {v:Int| (p v)} . Now, we can have our Int keys and refine them too! For example, we can write: 177: {-@ digits :: Assoc ( String ) <{\\v -> (Btwn 0 v 9)}> @-} to track the invariant for the digits map, and write 183: {-@ sparseVec :: Assoc Double <{\\v -> (Btwn 0 v 1000)}> @-} Thus, we can recover (some of) the benefits of abstracting over the type of the key by instead parameterizing the type directly over the possible invariants. We will have much more to say on association lists (or more generally, finite maps) and abstract refinements, but lets move on for the moment.","title":"Abstractly Refined Data"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#dependent-tuples","text":"It is no accident that we have reused Haskell's function type syntax to define abstract refinements ( p :: Int -> Prop ); interesting things start to happen if we use multiple parameters. Consider the function break from the Prelude. 203: break :: ( a -> Bool ) -> [ a ] -> ( [ a ] , [ a ] ) 204: forall a. (a -> (GHC.Types.Bool)) -> x:[a] -> ([a], [a])<\\y VV -> ((len x) == ((len y) + (len VV)))> break _ [a] xs @ [] = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [a] | (((null VV)) <=> true) && (VV == xs) && (VV == (GHC.Types.[])) && ((len VV) == 0) && ((len VV) >= 0)} xs , {VV : [a] | (((null VV)) <=> true) && (VV == xs) && (VV == (GHC.Types.[])) && ((len VV) == 0) && ((len VV) >= 0)} xs ) 205: break p xs @ ( x : xs' ) 206: | a -> (GHC.Types.Bool) p {VV : a | (VV == x)} x = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] , {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs ) 207: | otherwise = let ( {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len xs') == ((len zs) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} ys , {VV : [a] | (VV == zs) && ((len VV) == (len zs)) && ((len xs') == ((len ys) + (len VV))) && ((len xs') == ((len ys) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} zs ) = (a -> (GHC.Types.Bool)) -> x:[a] -> ([a], [a])<\\y VV -> ((len x) == ((len y) + (len VV)))> break a -> (GHC.Types.Bool) p {VV : [a] | (VV == xs') && ((len VV) >= 0)} xs' 208: in forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len xs') == ((len zs) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} ys , {VV : [a] | (VV == zs) && (VV == zs) && ((len VV) == (len zs)) && ((len xs') == ((len ys) + (len VV))) && ((len xs') == ((len ys) + (len VV))) && (VV /= xs) && ((len VV) >= 0) && ((len VV) < (len xs)) && ((len VV) <= (len xs'))} zs ) From the comments in Data.List , break p xs : \"returns a tuple where the first element is longest prefix (possibly empty) xs of elements that do not satisfy p and second element is the remainder of the list.\" We could formalize the notion of the second-element-being-the-remainder using sizes. That is, we'd like to specify that the length of the second element equals the length of xs minus the length of the first element. That is, we need a way to allow the refinement of the second element to depend on the value in the first refinement. Again, we could define a special kind of tuple-of-lists-type that has the above property baked in , but thats just not how we roll. Instead, lets use abstract refinements to give us dependent tuples 225: data ( a , b ) < p :: a -> b -> Prop > = ( x : a , b < p x > ) Here, the abstract refinement takes two parameters, an a and a b . In the body of the tuple, the first element is named x and we specify that the second element satisfies the refinement p x , i.e. a partial application of p with the first element. In other words, the second element is a value of type {v:b | (p x v)} . As before, we can instantiate the p in different ways. For example the whimsical 240: {-@ plusOnes :: [ ( Int , Int ) <{\\x1 x2 -> x2 = x1 + 1}> ] @-} 241: [((GHC.Types.Int), (GHC.Types.Int))<\\x1 VV -> (VV == (x1 + 1))>] plusOnes = {VV : [({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)})<\\x3 VV -> (VV == (x3 + 1)) && (VV > 0) && (VV > x3) && (0 <= VV) && (VV <= 1000)>]<\\x1 VV -> (VV /= x1)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ ({VV : (GHC.Types.Int) | (VV == 0) && (0 <= VV) && (VV <= 9)}, {VV : (GHC.Types.Int) | (VV == 1) && (VV > 0)})<\\x2 VV -> (VV == 1) && (VV == (x2 + 1)) && (VV > 0) && (VV > x2)> ( {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 , {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 9)})<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 9)> ( {VV : (GHC.Types.Int) | (VV == (5 : int))} 5 , {VV : (GHC.Types.Int) | (VV == (6 : int))} 6 ) , ({VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)}, {VV : (GHC.Types.Int) | (VV > 0) && (0 <= VV) && (VV <= 1000)})<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 1000)> ( {VV : (GHC.Types.Int) | (VV == (999 : int))} 999 , {VV : (GHC.Types.Int) | (VV == (1000 : int))} 1000 ) ] and returning to the remainder property for break 247: {-@ break :: ( a -> Bool ) -> x : [ a ] 248: -> ( [ a ] , [ a ] ) <{\\y z -> (Break x y z)}> @-} using the predicate alias 254: {-@ predicate Break X Y Z = ( len X ) = ( len Y ) + ( len Z ) @-}","title":"Dependent Tuples"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#abstractly-refined-lists","text":"Right, we've been going on for a bit. Time to put things in order . To recap: we've already seen one way to abstractly refine lists: to recover a generic means of refining a monomorphic list (e.g. the list of Int keys.) However, in that case we were talking about individual keys. Next, we build upon the dependent-tuples technique we just saw to use abstract refinements to relate different elements inside containers. In particular, we can use them to specify that every pair of elements inside the list is related according to some abstract relation p . By instantiating p appropriately, we will be able to recover various forms of (dis) order. Consider the refined definition of good old Haskell lists: 277: data [ a ] < p :: a -> a -> Prop > where 278: | [] :: [ a ] < p > 279: | ( : ) :: h : a -> [ a < p h > ] < p > -> [ a ] < p > Whoa! Thats a bit of a mouthful. Lets break it down. The type is parameterized with a refinement p :: a -> a -> Prop Think of p as a binary relation over the a values comprising the list. The empty list [] is a []<p> . Clearly, the empty list has no elements whatsoever and so every pair is trivially, or rather, vacuously related by p . The cons constructor (:) takes a head h of type a and a tail of a<p h> values, each of which is related to h and which (recursively) are pairwise related [...]<p> and returns a list where all elements are pairwise related [a]<p> .","title":"Abstractly Refined Lists"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#pairwise-related","text":"Note that we're being a bit sloppy when we say pairwise related. What we really mean is that if a list 303: [ x1 , ... , xn ] :: [ a ] < p > then for each 1 <= i < j <= n we have (p xi xj) . To see why, consider the list 309: [ x1 , x2 , x3 , ... ] :: [ a ] < p > This list unfolds into a head and tail 313: x1 :: a 314: [ x2 , x3 , ... ] :: [ a < p x1 > ] < p > The above tail unfolds into 318: x2 :: a < p x1 > 319: [ x3 , ... ] :: [ a < p x1 && p x2 > ] < p > And finally into 323: x3 :: a < p x1 && p x2 > 324: [ ... ] :: [ a < p x1 && p x2 && p x3 > ] < p > That is, each element xj satisfies the refinement (p xi xj) for each i < j .","title":"Pairwise Related"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#using-abstractly-refined-lists","text":"Urgh. Math is hard! Lets see how we can program with these funnily refined lists. For starters, we can define a few helpful type aliases. 340: {-@ type IncrList a = [ a ] < { \\ xi xj -> xi <= xj } > @-} 341: {-@ type DecrList a = [ a ] < { \\ xi xj -> xi >= xj } > @-} 342: {-@ type UniqList a = [ a ] < { \\ xi xj -> xi /= xj } > @-} As you might expect, an IncrList is a list of values in increasing order: 348: {-@ whatGosUp :: IncrList Integer @-} 349: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi <= VV)> whatGosUp = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x2 VV -> (VV == (x2 + 1)) && (VV > 0) && (VV > x2) && (0 <= VV) && (VV <= 9)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 1 , 2 , 3 ] Similarly, a DecrList contains its values in decreasing order: 355: {-@ mustGoDown :: DecrList Integer @-} 356: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi >= VV)> mustGoDown = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x3 VV -> (VV == 1) && (x3 /= VV) && (VV > 0) && (x3 >= VV) && (VV < x3)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 3 , 2 , 1 ] My personal favorite though, is a UniqList which has no duplicates : 362: {-@ noDuplicates :: UniqList Integer @-} 363: [(GHC.Integer.Type.Integer)]<\\xi VV -> (xi /= VV)> noDuplicates = {VV : [{VV : (GHC.Integer.Type.Integer) | (VV > 0) && (0 <= VV) && (VV <= 9)}]<\\x3 VV -> (x3 /= VV) && (VV > 0) && (x3 >= VV) && (VV < x3) && (0 <= VV) && (VV <= 9)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ 1 , 3 , 2 ]","title":"Using Abstractly Refined Lists"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#sorting-lists","text":"Its all very well to specify lists with various kinds of invariants. The question is, how easy is it to establish these invariants? Lets find out, by turning inevitably to that staple of all forms of formal verification: your usual textbook sorting procedures. Insertion Sort First up: insertion sort. Well, no surprises here: 380: {-@ insertSort :: ( Ord a ) => xs : [ a ] -> ( IncrList a ) @-} 381: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 382: insertSort ( x : xs ) = a -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> insert {VV : a | (VV == x)} x ( [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs ) The hard work is done by insert which places an element into the correct position of a sorted list 389: forall a. (GHC.Classes.Ord a) => a -> x1:[a]<\\x2 VV -> (VV >= x2)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} insert a y [] = {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : a | (VV == y)} y ] 390: insert y ( x : xs ) 391: | {VV : a | (VV == y)} y x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | (VV == x)} x = {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= y)} -> xs:[{VV : a<p x> | (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x) && (VV >= y)} -> xs:[{VV : a<p x> | (VV >= x) && (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= x) && (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV >= x)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs 392: | otherwise = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => a -> x1:[a]<\\x2 VV -> (VV >= x2)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} insert {VV : a | (VV == y)} y {VV : [{VV : a | (VV >= x)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs LiquidHaskell infers that if you give insert an element and a sorted list, it returns a sorted list. 399: {-@ insert :: ( Ord a ) => a -> IncrList a -> IncrList a @-} If you prefer the more Haskelly way of writing insertion sort, i.e. with a foldr , that works too. Can you figure out why? 406: {-@ insertSort' :: ( Ord a ) => [ a ] -> IncrList a @-} 407: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> insertSort' [a] xs = (a -> [a]<\\x4 VV -> (VV >= x4)> -> [a]<\\x4 VV -> (VV >= x4)>) -> [a]<\\x4 VV -> (VV >= x4)> -> [a] -> [a]<\\x4 VV -> (VV >= x4)> foldr a -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> insert {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs Merge Sort Well, you know the song goes. First, we write a function that splits the input into two parts: 416: split :: [ a ] -> ( [ a ] , [ a ] ) 417: forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split ( x : y : zs ) = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == xs) && (VV == xs) && ((len VV) == (len xs)) && ((len zs) == ((len ys) + (len VV))) && ((len VV) >= 0) && ((len VV) >= (len ys)) && ((len VV) <= (len zs))} xs , {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:a -> xs:[{VV : a<p x> | true}]<p> -> {VV : [a]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len zs) == ((len xs) + (len VV))) && ((len zs) == ((len xs) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len xs)) && ((len VV) <= (len xs)) && ((len VV) <= (len zs))} ys ) 418: where 419: ( {VV : [a] | (VV == xs) && ((len VV) == (len xs)) && ((len zs) == ((len ys) + (len VV))) && ((len VV) >= 0) && ((len VV) >= (len ys)) && ((len VV) <= (len zs))} xs , {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len zs) == ((len xs) + (len VV))) && ((len zs) == ((len xs) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len xs)) && ((len VV) <= (len xs)) && ((len VV) <= (len zs))} ys ) = forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split {VV : [a] | (VV == zs) && ((len VV) >= 0)} zs 420: split xs = forall a b <p2 :: a-> b-> Bool>. a:a -> b:{VV : b<p2 a> | true} -> {VV : (a, b)<p2> | ((fst VV) == a) && ((snd VV) == b)} ( {VV : [a] | ((len VV) >= 0)} xs , {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] ) Then we need a function that merges two (sorted) lists 426: forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge [a]<\\x1 VV -> (x1 <= VV)> xs [] = {VV : [a]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs 427: merge [] ys = {VV : [a]<\\x1 VV -> (x1 <= VV)> | ((len VV) >= 0)} ys 428: merge ( x : xs ) ( y : ys ) 429: | {VV : a | (VV == x)} x x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x <= y))} <= {VV : a | (VV == y)} y = {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge {VV : [{VV : a | (x <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs ( {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x) && (VV >= y)} -> xs:[{VV : a<p x> | (VV >= x) && (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= x) && (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (y <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys ) 430: | otherwise = {VV : a | (VV == y)} y forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= y)} -> xs:[{VV : a<p x> | (VV >= y)}]<p> -> {VV : [{VV : a | (VV >= y)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. (GHC.Classes.Ord a) => xs:[a]<\\x3 VV -> (x3 <= VV)> -> x1:[a]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0) && ((len VV) >= (len x1)) && ((len VV) >= (len xs))} merge ( {VV : a | (VV == x)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV > y) && (VV >= x)} -> xs:[{VV : a<p x> | (VV > y) && (VV >= x)}]<p> -> {VV : [{VV : a | (VV > y) && (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (x <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == xs) && ((len VV) >= 0)} xs ) {VV : [{VV : a | (y <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys LiquidHaskell deduces that if both inputs are ordered, then so is the output. 437: {-@ merge :: ( Ord a ) => IncrList a 438: -> IncrList a 439: -> IncrList a 440: @-} Finally, using the above functions we write mergeSort : 446: {-@ mergeSort :: ( Ord a ) => [ a ] -> IncrList a @-} 447: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 448: mergeSort [ x ] = {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : a | (VV == x)} x ] 449: mergeSort xs = [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> merge ( [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort {VV : [a] | (VV == ys) && (VV == ys) && ((len VV) == (len ys)) && ((len VV) > 0) && ((len VV) >= 0) && ((len VV) >= (len zs))} ys ) ( [a] -> [a]<\\xi VV -> (xi <= VV)> mergeSort {VV : [a] | (VV == zs) && (VV == zs) && ((len VV) == (len zs)) && ((len VV) >= 0) && ((len VV) <= (len ys)) && ((len VV) <= (len ys))} zs ) 450: where 451: ( {VV : [a] | (VV == ys) && ((len VV) == (len ys)) && ((len VV) > 0) && ((len VV) >= (len zs))} ys , {VV : [a] | (VV == zs) && ((len VV) == (len zs)) && ((len VV) >= 0) && ((len VV) <= (len ys)) && ((len VV) <= (len ys))} zs ) = forall a. x1:{VV : [a] | ((len VV) >= 0)} -> ({VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))}, {VV : [a] | ((len VV) >= 0) && ((len VV) <= (len x1))})<\\x2 VV -> ((len x1) == ((len x2) + (len VV))) && ((len VV) >= 0) && ((len VV) <= (len x1)) && ((len VV) <= (len x2))> split {VV : [a] | ((len VV) >= 0)} xs Lets see how LiquidHaskell proves the output type. The first two cases are trivial: for an empty or singleton list, we can vacuously instantiate the abstract refinement with any concrete refinement. For the last case, we can inductively assume mergeSort ys and mergeSort zs are sorted lists, after which the type inferred for merge kicks in, allowing LiquidHaskell to conclude that the output is also sorted. Quick Sort The previous two were remarkable because they were, well, quite unremarkable . Pretty much the standard textbook implementations work as is . Unlike the classical developments using indexed types we don't have to define any auxiliary types for increasing lists, or lists whose value is in a particular range, or any specialized cons operators and so on. With quick sort we need to do a tiny bit of work. We would like to define quickSort as 481: {-@ quickSort' :: ( Ord a ) => [ a ] -> IncrList a @-} 482: quickSort' [] = [] 483: quickSort' ( x : xs ) = lts ++ ( x : gts ) 484: where 485: lts = quickSort' [ y | y <- xs , y < x ] 486: gts = quickSort' [ z | z <- xs , z >= x ] But, if you try it out, you'll see that LiquidHaskell does not approve . What could possibly be the trouble? The problem lies with append . What type do we give ++ ? We might try something like 495: ( ++ ) :: IncrList a -> IncrList a -> IncrList a but of course, this is bogus, as 499: [ 1 , 2 , 4 ] ++ [ 3 , 5 , 6 ] is decidedly not an IncrList ! Instead, at this particular use of ++ , there is an extra nugget of information: there is a pivot element x such that every element in the first argument is less than x and every element in the second argument is greater than x . There is no way we can give the usual append ++ a type that reflects the above as there is no pivot x to refer to. Thus, with a heavy heart, we must write a specialized pivot-append that uses this fact: 516: forall a. piv:a -> x1:[{VV : a | (VV < piv)}]<\\x3 VV -> (VV >= x3)> -> ys:[{VV : a | (piv <= VV)}]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && (VV /= ys) && ((len VV) > 0) && ((len VV) > (len x1)) && ((len VV) > (len ys))} pivApp a piv [] [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> ys = {VV : a | (VV == piv)} piv forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= piv)} -> xs:[{VV : a<p x> | (VV >= piv)}]<p> -> {VV : [{VV : a | (VV >= piv)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys 517: pivApp piv ( x : xs ) ys = {VV : a | (VV == x) && (VV < piv)} x forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= x)} -> xs:[{VV : a<p x> | (VV >= x)}]<p> -> {VV : [{VV : a | (VV >= x)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : forall a. piv:a -> x1:[{VV : a | (VV < piv)}]<\\x3 VV -> (VV >= x3)> -> ys:[{VV : a | (piv <= VV)}]<\\x2 VV -> (x2 <= VV)> -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && (VV /= ys) && ((len VV) > 0) && ((len VV) > (len x1)) && ((len VV) > (len ys))} pivApp {VV : a | (VV == piv)} piv {VV : [{VV : a | (VV >= x) && (VV < piv)}]<\\x1 VV -> (VV >= x1)> | (VV == xs) && ((len VV) >= 0)} xs {VV : [{VV : a | (piv <= VV)}]<\\x1 VV -> (x1 <= VV)> | (VV == ys) && ((len VV) >= 0)} ys Now, LiquidHaskell infers that 523: {-@ pivApp :: piv : a 524: -> IncrList {v: a | v < piv} 525: -> IncrList {v: a | v >= piv} 526: -> IncrList a 527: @-} And we can use pivApp to define `quickSort' simply as: 533: {-@ quickSort :: ( Ord a ) => [ a ] -> IncrList a @-} 534: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> quickSort [] = forall <p :: a-> a-> Bool>. {VV : [{VV : a | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] 535: quickSort ( x : xs ) = piv:a -> [{VV : a | (VV < piv)}]<\\xi VV -> (xi <= VV)> -> [{VV : a | (VV >= piv)}]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> pivApp {VV : a | (VV == x)} x {VV : [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> | (VV == lts) && ((len VV) >= 0)} lts {VV : [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> | (VV == gts) && ((len VV) >= 0)} gts 536: where 537: [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> lts = [{VV : a | (VV < x)}] -> [{VV : a | (VV < x)}]<\\xi VV -> (xi <= VV)> quickSort {VV : [{VV : a | (VV < x)}]<\\_ VV -> (VV < x)> | ((len VV) >= 0) && ((len VV) <= (len xs))} [ a y | y <- {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs , a y x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x < y))} < {VV : a | (VV == x)} x ] 538: [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> gts = [{VV : a | (VV >= x)}] -> [{VV : a | (VV >= x)}]<\\xi VV -> (xi <= VV)> quickSort {VV : [{VV : a | (VV >= x)}]<\\_ VV -> (VV >= x)> | ((len VV) >= 0) && ((len VV) <= (len xs))} [ a z | z <- {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs , a z x:a -> y:a -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x >= y))} >= {VV : a | (VV == x)} x ]","title":"Sorting Lists"},{"location":"blogposts/2013-07-29-putting-things-in-order.lhs/#really-sorting-lists","text":"The convenient thing about our encoding is that the underlying datatype is plain Haskell lists. This yields two very concrete benefits. First, as mentioned before, we can manipulate sorted lists with the same functions we'd use for regular lists. Second, by decoupling (or rather, parameterizing) the relation or property or invariant from the actual data structure we can plug in different invariants, sometimes in the same program. To see why this is useful, lets look at a real-world sorting algorithm: the one used inside GHC's Data.List module . 560: sort :: ( Ord a ) => [ a ] -> [ a ] 561: forall a. (GHC.Classes.Ord a) => [a] -> [a]<\\xi VV -> (xi <= VV)> sort = {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll forall <q :: [a]-> [[a]]-> Bool, p :: [[a]]-> [a]-> Bool>. (x:{VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} -> {VV : [a]<\\x4 VV -> (VV >= x4)><p x> | ((len VV) >= 0)}) -> (y:[a] -> {VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)><q y> | ((len VV) > 0)}) -> x:[a] -> exists [z:{VV : [{VV : [a]<\\x5 VV -> (VV >= x5)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)><q x> | ((len VV) > 0)}].{VV : [a]<\\x4 VV -> (VV >= x4)><p z> | ((len VV) >= 0)} . [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences 562: where 563: [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences ( a : b : xs ) 564: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x == y))} == {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending {VV : a | (VV == b)} b {VV : [{VV : a | (VV == a) && (VV > b)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} a ] {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 565: | otherwise = a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending {VV : a | (VV == b)} b ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : ) {VV : [a] | (VV == xs) && ((len VV) >= 0)} xs 566: sequences [ x ] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [{VV : a | (VV == a)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} x ] ] 567: sequences [] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [{VV : a | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [] ] 568: 569: a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending a a {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | ((len VV) > 0)} as ( b : bs ) 570: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x == y))} == {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> {VV : [{VV : a | (VV > a)}]<\\x2 VV -> (VV > a) && (VV > x2)> | ((len VV) > 0)} -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} descending {VV : a | (VV == b)} b ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV > b) && (VV >= a)} -> xs:[{VV : a<p x> | (VV > b) && (VV >= a)}]<p> -> {VV : [{VV : a | (VV > b) && (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | (VV == as) && ((len VV) > 0) && ((len VV) >= 0)} as ) {VV : [a] | (VV == bs) && ((len VV) >= 0)} bs 571: descending a as bs = ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV > a)}]<\\x1 VV -> (VV > a) && (VV > x1)> | (VV == as) && ((len VV) > 0) && ((len VV) >= 0)} as ) forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (VV >= x3)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences {VV : [a] | ((len VV) >= 0)} bs 572: 573: a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending a a x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as ( b : bs ) 574: | {VV : a | (VV == a)} a x:a -> y:a -> {VV : (GHC.Types.Ordering) | ((VV == GHC.Types.EQ) <=> (x == y)) && ((VV == GHC.Types.GT) <=> (x > y)) && ((VV == GHC.Types.LT) <=> (x < y))} `compare` {VV : a | (VV == b)} b x:(GHC.Types.Ordering) -> y:(GHC.Types.Ordering) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x /= y))} /= {VV : (GHC.Types.Ordering) | (VV == GHC.Types.GT) && ((cmp VV) == GHC.Types.GT)} GT = a:a -> (x1:{VV : [{VV : a | (VV >= a)}]<\\x3 VV -> (VV >= a) && (VV >= x3)> | ((len VV) > 0)} -> {VV : [a]<\\x2 VV -> (VV >= x2)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))}) -> {VV : [a] | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} ascending {VV : a | (VV == b)} b ( ys:{VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x2 VV -> (VV >= a) && (VV >= b) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= ys) && ((len VV) > 0) && ((len VV) > (len ys))} \\ {VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x1 VV -> (VV >= a) && (VV >= b) && (VV >= x1)> | ((len VV) > 0)} ys -> x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as ( {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x:{VV : a | (VV >= a)} -> xs:[{VV : a<p x> | (VV >= a)}]<p> -> {VV : [{VV : a | (VV >= a)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : {VV : [{VV : a | (VV >= a) && (VV >= b)}]<\\x1 VV -> (VV >= a) && (VV >= b) && (VV >= x1)> | (VV == ys) && ((len VV) > 0) && ((len VV) >= 0)} ys ) ) {VV : [a] | (VV == bs) && ((len VV) >= 0)} bs 575: ascending a as bs = x1:{VV : [{VV : a | (VV >= a)}]<\\x2 VV -> (VV >= a) && (VV >= x2)> | ((len VV) > 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV /= x1) && ((len VV) > 0) && ((len VV) > (len x1))} as {VV : [{VV : a | (VV == a)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : a | (VV == a)} a ] forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (VV >= x3)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (VV >= x3)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : [a] -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) > 0)} sequences {VV : [a] | ((len VV) >= 0)} bs 576: 577: {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll [ x ] = {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == x) && ((len VV) >= 0)} x 578: mergeAll xs = {VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)} mergeAll ( x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} xs ) 579: 580: x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs ( a : b : xs ) = [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> -> [a]<\\xi VV -> (xi <= VV)> merge {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == a) && ((len VV) >= 0)} a {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == b) && ((len VV) >= 0)} b forall <p :: [a]-> [a]-> Bool>. x:{VV : [a]<\\x3 VV -> (x3 <= VV)> | ((len VV) >= 0)} -> xs:[{VV : [a]<\\x3 VV -> (x3 <= VV)><p x> | ((len VV) >= 0)}]<p> -> {VV : [{VV : [a]<\\x3 VV -> (x3 <= VV)> | ((len VV) >= 0)}]<p> | (((null VV)) <=> false) && ((len VV) == (1 + (len xs)))} : x1:{VV : [{VV : [a]<\\x2 VV -> (VV >= x2)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0)} -> {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | ((len VV) >= 0) && ((len VV) <= (len x1))} mergePairs {VV : [{VV : [a]<\\x1 VV -> (VV >= x1)> | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (VV == xs) && ((len VV) >= 0)} xs 581: mergePairs [ x ] = {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} [ {VV : [a]<\\x1 VV -> (VV >= x1)> | (VV == a) && ((len VV) >= 0)} x ] 582: mergePairs [] = forall <p :: [a]-> [a]-> Bool>. {VV : [{VV : [{VV : a | false}]<\\_ VV -> false> | false}]<p> | (((null VV)) <=> true) && ((len VV) == 0)} [] The interesting thing about the procedure is that it generates some intermediate lists that are increasing and others that are decreasing, and then somehow miraculously whips this whirlygig into a single increasing list. Yet, to check this rather tricky algorithm with LiquidHaskell we need merely write: 595: {-@ sort :: ( Ord a ) => [ a ] -> IncrList a @-}","title":"Really Sorting Lists"},{"location":"blogposts/2013-10-10-csv-tables.lhs/","text":"Most demonstrations for verification techniques involve programs with complicated invariants and properties. However, these methods can often be rather useful for describing simple but important aspects of APIs or programs with more humble goals. I saw a rather nice example of using Scala's Shapeless library for preventing off-by-one errors in CSV processing code. Here's the same, short, example rephrased with LiquidHaskell. 23: module CSV where 24: 25: -- | Using LiquidHaskell for CSV lists 26: -- c.f. http://www.reddit.com/r/scala/comments/1nhzi2/using_shapelesss_sized_type_to_eliminate_real/ The Type \u00b6 Suppose you wanted to represent tables as a list of comma-separated values. For example, here's a table listing the articles and prices at the coffee shop I'm sitting in right now: Item Price Espresso 2.25 Macchiato 2.75 Cappucino 3.35 Americano 2.25 You might represent this with a simple Haskell data type: 64: 65: data CSV = Csv { (CSV.CSV) -> [[(GHC.Types.Char)]] headers :: [ String ] 66: , (CSV.CSV) -> [[[(GHC.Types.Char)]]] rows :: [ [ String ] ] 67: } and now, the above table is just: 73: (CSV.CSV) zumbarMenu = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Item\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Price\" ] 74: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Espresso\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.25\" ] 75: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Macchiato\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.75\" ] 76: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Cappucino\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"3.35\" ] 77: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Americano\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.25\" ] 78: ] The Errors \u00b6 Our CSV type supports tables with an arbitrary number of headers and rows but of course, we'd like to ensure that each row has data for each header, that is, we don't end up with tables like this one 89: -- Eeks, we missed the header name! 90: 91: (CSV.CSV) csvBad1 = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Date\" {- ??? -} ] 92: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Mon\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" ] 93: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Tue\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" ] 94: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Wed\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"3\" ] 95: ] 96: or this one, 102: -- Blergh! we missed a column. 103: 104: (CSV.CSV) csvBad2 = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Age\" ] 105: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Alice\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"32\" ] 106: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Bob\" {- ??? -} ] 107: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Cris\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"29\" ] 108: ] Alas, both the above are valid inhabitants of the Haskell CSV type, and so, sneak past GHC. The Invariant \u00b6 Thus, we want to refine the CSV type to specify that the number of elements in each row is exactly the same as the number of headers. To do so, we merely write a refined data type definition: 123: {-@ data CSV = Csv { headers :: [ String ] 124: , rows :: [ { v : [ String ] | ( len v ) = ( len headers ) } ] 125: } 126: @-} Here len is a measure denoting the length of a list . Thus, (len headers) is the number of headers in the table, and the refinement on the rows field states that each row is a list of String s, with exactly the same number of elements as the number of headers . We can now have our arbitrary-arity tables, but LiquidHaskell will make sure that we don't miss entries here or there. 138: -- All is well! 139: 140: (CSV.CSV) csvGood = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Id\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Days\" ] 141: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Jan\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 142: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Feb\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"28\" ] 143: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"3\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Mar\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 144: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"4\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Apr\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"30\" ] 145: ] Bonus Points \u00b6 How would you modify the specification to prevent table with degenerate entries like this one? 155: (CSV.CSV) deg = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Id\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Days\" ] 156: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Jan\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 157: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Feb\" , {VV : [{VV : (GHC.Types.Char) | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} \"\" ] 158: ]","title":"CSV Tables"},{"location":"blogposts/2013-10-10-csv-tables.lhs/#the-type","text":"Suppose you wanted to represent tables as a list of comma-separated values. For example, here's a table listing the articles and prices at the coffee shop I'm sitting in right now: Item Price Espresso 2.25 Macchiato 2.75 Cappucino 3.35 Americano 2.25 You might represent this with a simple Haskell data type: 64: 65: data CSV = Csv { (CSV.CSV) -> [[(GHC.Types.Char)]] headers :: [ String ] 66: , (CSV.CSV) -> [[[(GHC.Types.Char)]]] rows :: [ [ String ] ] 67: } and now, the above table is just: 73: (CSV.CSV) zumbarMenu = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Item\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Price\" ] 74: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Espresso\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.25\" ] 75: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Macchiato\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.75\" ] 76: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Cappucino\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"3.35\" ] 77: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Americano\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"2.25\" ] 78: ]","title":"The Type"},{"location":"blogposts/2013-10-10-csv-tables.lhs/#the-errors","text":"Our CSV type supports tables with an arbitrary number of headers and rows but of course, we'd like to ensure that each row has data for each header, that is, we don't end up with tables like this one 89: -- Eeks, we missed the header name! 90: 91: (CSV.CSV) csvBad1 = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Date\" {- ??? -} ] 92: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Mon\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" ] 93: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Tue\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" ] 94: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) > 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Wed\" , {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"3\" ] 95: ] 96: or this one, 102: -- Blergh! we missed a column. 103: 104: (CSV.CSV) csvBad2 = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Age\" ] 105: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Alice\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"32\" ] 106: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Bob\" {- ??? -} ] 107: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Cris\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"29\" ] 108: ] Alas, both the above are valid inhabitants of the Haskell CSV type, and so, sneak past GHC.","title":"The Errors"},{"location":"blogposts/2013-10-10-csv-tables.lhs/#the-invariant","text":"Thus, we want to refine the CSV type to specify that the number of elements in each row is exactly the same as the number of headers. To do so, we merely write a refined data type definition: 123: {-@ data CSV = Csv { headers :: [ String ] 124: , rows :: [ { v : [ String ] | ( len v ) = ( len headers ) } ] 125: } 126: @-} Here len is a measure denoting the length of a list . Thus, (len headers) is the number of headers in the table, and the refinement on the rows field states that each row is a list of String s, with exactly the same number of elements as the number of headers . We can now have our arbitrary-arity tables, but LiquidHaskell will make sure that we don't miss entries here or there. 138: -- All is well! 139: 140: (CSV.CSV) csvGood = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Id\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Days\" ] 141: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Jan\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 142: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Feb\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"28\" ] 143: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"3\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Mar\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 144: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"4\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Apr\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"30\" ] 145: ]","title":"The Invariant"},{"location":"blogposts/2013-10-10-csv-tables.lhs/#bonus-points","text":"How would you modify the specification to prevent table with degenerate entries like this one? 155: (CSV.CSV) deg = x1:[[(GHC.Types.Char)]] -> [{VV : [[(GHC.Types.Char)]] | ((len VV) == (len x1))}] -> (CSV.CSV) Csv {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Id\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Name\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Days\" ] 156: [ {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"1\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Jan\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"31\" ] 157: , {VV : [{VV : [(GHC.Types.Char)] | ((len VV) >= 0)}]<\\_ VV -> ((len VV) >= 0)> | (((null VV)) <=> false) && ((len VV) >= 0)} [ {VV : [(GHC.Types.Char)]<\\_ VV -> false> | (((null VV)) <=> false) && ((len VV) >= 0)} \"2\" , {VV : [(GHC.Types.Char)] | ((len VV) >= 0)} \"Feb\" , {VV : [{VV : (GHC.Types.Char) | false}]<\\_ VV -> false> | (((null VV)) <=> true) && ((len VV) == 0) && ((len VV) >= 0)} \"\" ] 158: ]","title":"Bonus Points"},{"location":"blogposts/2013-11-23-telling_lies.lhs/","text":"One crucial goal of a type system is to provide the guarantee, memorably phrased by Milner as well-typed programs don't go wrong . The whole point of LiquidHaskell (and related systems) is to provide the above guarantee for expanded notions of \"going wrong\". All this time, we've claimed (and believed) that LiquidHaskell provided such a guarantee. We were wrong. LiquidHaskell tells lies. 27: {-@ LIQUID \"--no-termination\" @-} 28: 29: module TellingLies where 30: 31: import Language . Haskell . Liquid . Prelude ( liquidError ) 32: 33: divide :: Int -> Int -> Int 34: foo :: Int -> Int 35: explode :: Int To catch LiquidHaskell red-handed, we require a notion of going wrong , a program that clearly goes wrong, and the smoking gun, a lie from LiquidHaskell that the program is safe. The Going Wrong \u00b6 Lets keep things simple with an old fashioned div -ision operator. A division by zero would be, clearly going wrong . To alert LiquidHaskell to this possibility, we encode \"not going wrong\" with the precondition that the denominator be non-zero. 54: {-@ divide :: n : Int -> d : {v: Int | v /= 0} -> Int @-} 55: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV /= 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} liquidError {VV : [(GHC.Types.Char)] | ((len VV) >= 0) && ((sumLens VV) >= 0)} \"no you didn't!\" 56: divide n d = {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (((x1 >= 0) && (x2 >= 0)) => (VV >= 0)) && (((x1 >= 0) && (x2 >= 1)) => (VV <= x1)) && (VV == (x1 / x2))} `div` {VV : (GHC.Types.Int) | (VV /= 0)} d The Program \u00b6 Now, consider the function foo . 65: {-@ foo :: n : Int -> {v: Nat | v < n} @-} 66: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x1 > x2))} > {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 = {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 67: | otherwise = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo {VV : (GHC.Types.Int) | (VV == n)} n Now, foo should only be called with strictly positive values. In which case, the function returns a Nat that is strictly smaller than the input. The function diverges when called with 0 or negative inputs. Note that the signature of foo is slightly different, but nevertheless, legitimate, as when the function returns an output, the output is indeed a Nat that is strictly less than the input parameter n . Hence, LiquidHaskell happily checks that foo does indeed satisfy its given type. So far, nothing has gone wrong either in the program, or with LiquidHaskell, but consider this innocent little function: 86: (GHC.Types.Int) explode = let {VV : (GHC.Types.Int) | (VV == (0 : int))} z = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 87: in ( x:{VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < z)} -> {VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == x) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > x) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < x) && (VV < z)} \\ {VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < z)} x -> ( {VV : (GHC.Types.Int) | (VV == (2013 : int))} 2013 (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV /= 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV == z) && (VV == (0 : int))} z ) ) ( n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo {VV : (GHC.Types.Int) | (VV == z) && (VV == (0 : int))} z ) Thanks to lazy evaluation , the call to foo is ignored, so evaluating explode leads to a crash! Ugh! The Lie \u00b6 However, LiquidHaskell produces a polyannish prognosis and cheerfully declares the program safe . Huh? Well, LiquidHaskell deduces that z == 0 from the binding, x : Nat from the output type for foo x < z from the output type for foo Of course, no such x exists! Or, rather, the SMT solver reasons 108: z == 0 && x >= 0 && x < z => z /= 0 as the hypotheses are inconsistent. In other words, LiquidHaskell deduces that the call to divide happens in an impossible environment, i.e. is dead code, and hence, the program is safe. In our defence, the above, sunny prognosis is not totally misguided . Indeed, if Haskell was like ML and had strict evaluation then indeed the program would be safe in that we would not go wrong i.e. would not crash with a divide-by-zero. But of course, thats a pretty lame excuse, since Haskell doesn't have strict semantics. So looks like LiquidHaskell (and hence, we) have been caught red-handed. Well then, is there a way to prevent LiquidHaskell from telling lies? That is, can we get Milner's well-typed programs don't go wrong guarantee under lazy evaluation? Thankfully, there is.","title":"LiquidHaskell Caught Telling Lies!"},{"location":"blogposts/2013-11-23-telling_lies.lhs/#the-going-wrong","text":"Lets keep things simple with an old fashioned div -ision operator. A division by zero would be, clearly going wrong . To alert LiquidHaskell to this possibility, we encode \"not going wrong\" with the precondition that the denominator be non-zero. 54: {-@ divide :: n : Int -> d : {v: Int | v /= 0} -> Int @-} 55: (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV /= 0)} -> (GHC.Types.Int) divide (GHC.Types.Int) n 0 = {VV : [(GHC.Types.Char)] | false} -> {VV : (GHC.Types.Int) | false} liquidError {VV : [(GHC.Types.Char)] | ((len VV) >= 0) && ((sumLens VV) >= 0)} \"no you didn't!\" 56: divide n d = {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (((x1 >= 0) && (x2 >= 0)) => (VV >= 0)) && (((x1 >= 0) && (x2 >= 1)) => (VV <= x1)) && (VV == (x1 / x2))} `div` {VV : (GHC.Types.Int) | (VV /= 0)} d","title":"The Going Wrong"},{"location":"blogposts/2013-11-23-telling_lies.lhs/#the-program","text":"Now, consider the function foo . 65: {-@ foo :: n : Int -> {v: Nat | v < n} @-} 66: n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo (GHC.Types.Int) n | {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x1 > x2))} > {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 = {VV : (GHC.Types.Int) | (VV == n)} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 67: | otherwise = n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo {VV : (GHC.Types.Int) | (VV == n)} n Now, foo should only be called with strictly positive values. In which case, the function returns a Nat that is strictly smaller than the input. The function diverges when called with 0 or negative inputs. Note that the signature of foo is slightly different, but nevertheless, legitimate, as when the function returns an output, the output is indeed a Nat that is strictly less than the input parameter n . Hence, LiquidHaskell happily checks that foo does indeed satisfy its given type. So far, nothing has gone wrong either in the program, or with LiquidHaskell, but consider this innocent little function: 86: (GHC.Types.Int) explode = let {VV : (GHC.Types.Int) | (VV == (0 : int))} z = {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 87: in ( x:{VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < z)} -> {VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == x) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > x) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < x) && (VV < z)} \\ {VV : (GHC.Types.Int) | (VV == 0) && (VV == 1) && (VV == TellingLies.explode) && (VV == z) && (VV > 0) && (VV > TellingLies.explode) && (VV > z) && (VV < 0) && (VV < TellingLies.explode) && (VV < z)} x -> ( {VV : (GHC.Types.Int) | (VV == (2013 : int))} 2013 (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV /= 0)} -> (GHC.Types.Int) `divide` {VV : (GHC.Types.Int) | (VV == z) && (VV == (0 : int))} z ) ) ( n:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < n)} foo {VV : (GHC.Types.Int) | (VV == z) && (VV == (0 : int))} z ) Thanks to lazy evaluation , the call to foo is ignored, so evaluating explode leads to a crash! Ugh!","title":"The Program"},{"location":"blogposts/2013-11-23-telling_lies.lhs/#the-lie","text":"However, LiquidHaskell produces a polyannish prognosis and cheerfully declares the program safe . Huh? Well, LiquidHaskell deduces that z == 0 from the binding, x : Nat from the output type for foo x < z from the output type for foo Of course, no such x exists! Or, rather, the SMT solver reasons 108: z == 0 && x >= 0 && x < z => z /= 0 as the hypotheses are inconsistent. In other words, LiquidHaskell deduces that the call to divide happens in an impossible environment, i.e. is dead code, and hence, the program is safe. In our defence, the above, sunny prognosis is not totally misguided . Indeed, if Haskell was like ML and had strict evaluation then indeed the program would be safe in that we would not go wrong i.e. would not crash with a divide-by-zero. But of course, thats a pretty lame excuse, since Haskell doesn't have strict semantics. So looks like LiquidHaskell (and hence, we) have been caught red-handed. Well then, is there a way to prevent LiquidHaskell from telling lies? That is, can we get Milner's well-typed programs don't go wrong guarantee under lazy evaluation? Thankfully, there is.","title":"The Lie"},{"location":"blogposts/2013-12-02-getting-to-the-bottom.lhs/","text":"Previously , we caught LiquidHaskell telling a lie. Today, lets try to get to the bottom of this mendacity, in order to understand how we can ensure that it always tells the truth. 20: module GettingToTheBottom where The Truth Lies At the Bottom \u00b6 To figure out how we might prevent falsehoods, lets try to understand whats really going on. We need to go back to the beginning. Recall that the refinement type: 30: { v : Int | 0 <= v } is supposed to denote the set of Int values that are greater than 0 . Consider a function: 36: fib :: { n : Int | 0 <= n } -> { v : Int | 0 <= v } 37: fib n = e Intuitively, the type signature states that when checking the body e we can assume that 0 <= n . This is indeed the case with strict evaluation, as we are guaranteed that n will be evaluated before e . Thus, either: n diverges and so we don't care about e as we won't evaluate it, or, n is a non-negative value. Thus, either way, e is only evaluated in a context where 0 <= n . But this is not the case with lazy evaluation, as we may well start evaluating e without evaluating n . Indeed, we may finish evaluating e without evaluating n . Of course, if n is evaluated, it will yield a non-negative value, but if it is not (or does not) evaluate to a value, we cannot assume that the rest of the computation is dead (as with eager evaluation). That is, with lazy evaluation, the refinement type {n:Int | 0 <= n} actually means: 60: ( n = _ | _ ) || ( 0 <= n ) Keeping LiquidHaskell Honest \u00b6 One approach to forcing LiquidHaskell to telling the truth is to force it to always split cases and reason about _|_ . Lets revisit explode 70: explode = let z = 0 71: in ( \\ x -> 2013 `divide` z ) ( foo z ) The case splitting prevents the cheerful but bogus prognosis that explode above was safe, because the SMT solver cannot prove that at the call to divide 75: z == 0 && ( x = _ | _ || ( x >= 0 && x < z ) ) => z /= 0 But alas, this cure is worse than the disease. It would end up lobotomizing LiquidHaskell making it unable to prove even trivial things like: _ 82: {-@ trivial :: x : Int -> y : Int -> {pf: () | x < y} -> Int @-} 83: trivial x y pf = liquidAssert ( x < y ) 10 as the corresponding SMT query 87: ( pf = _ | _ || x < y ) => ( x < y ) is, thanks to the pesky _|_ , not valid. Terminating The Bottom \u00b6 Thus, to make LiquidHaskell tell the truth while also not just pessimistically rejecting perfectly good programs, we need a way to get rid of the _|_ . That is, we require a means of teaching LiquidHaskell to determine when a value is definitely not bottom. In other words, we need to teach LiquidHaskell how to prove that a computation definitely terminates.","title":"Getting To the Bottom"},{"location":"blogposts/2013-12-02-getting-to-the-bottom.lhs/#the-truth-lies-at-the-bottom","text":"To figure out how we might prevent falsehoods, lets try to understand whats really going on. We need to go back to the beginning. Recall that the refinement type: 30: { v : Int | 0 <= v } is supposed to denote the set of Int values that are greater than 0 . Consider a function: 36: fib :: { n : Int | 0 <= n } -> { v : Int | 0 <= v } 37: fib n = e Intuitively, the type signature states that when checking the body e we can assume that 0 <= n . This is indeed the case with strict evaluation, as we are guaranteed that n will be evaluated before e . Thus, either: n diverges and so we don't care about e as we won't evaluate it, or, n is a non-negative value. Thus, either way, e is only evaluated in a context where 0 <= n . But this is not the case with lazy evaluation, as we may well start evaluating e without evaluating n . Indeed, we may finish evaluating e without evaluating n . Of course, if n is evaluated, it will yield a non-negative value, but if it is not (or does not) evaluate to a value, we cannot assume that the rest of the computation is dead (as with eager evaluation). That is, with lazy evaluation, the refinement type {n:Int | 0 <= n} actually means: 60: ( n = _ | _ ) || ( 0 <= n )","title":"The Truth Lies At the Bottom"},{"location":"blogposts/2013-12-02-getting-to-the-bottom.lhs/#keeping-liquidhaskell-honest","text":"One approach to forcing LiquidHaskell to telling the truth is to force it to always split cases and reason about _|_ . Lets revisit explode 70: explode = let z = 0 71: in ( \\ x -> 2013 `divide` z ) ( foo z ) The case splitting prevents the cheerful but bogus prognosis that explode above was safe, because the SMT solver cannot prove that at the call to divide 75: z == 0 && ( x = _ | _ || ( x >= 0 && x < z ) ) => z /= 0 But alas, this cure is worse than the disease. It would end up lobotomizing LiquidHaskell making it unable to prove even trivial things like: _ 82: {-@ trivial :: x : Int -> y : Int -> {pf: () | x < y} -> Int @-} 83: trivial x y pf = liquidAssert ( x < y ) 10 as the corresponding SMT query 87: ( pf = _ | _ || x < y ) => ( x < y ) is, thanks to the pesky _|_ , not valid.","title":"Keeping LiquidHaskell Honest"},{"location":"blogposts/2013-12-02-getting-to-the-bottom.lhs/#terminating-the-bottom","text":"Thus, to make LiquidHaskell tell the truth while also not just pessimistically rejecting perfectly good programs, we need a way to get rid of the _|_ . That is, we require a means of teaching LiquidHaskell to determine when a value is definitely not bottom. In other words, we need to teach LiquidHaskell how to prove that a computation definitely terminates.","title":"Terminating The Bottom"},{"location":"blogposts/2013-12-09-checking-termination.lhs/","text":"As explained in the last two posts, we need a termination checker to ensure that LiquidHaskell is not tricked by divergent, lazy computations into telling lies. Happily, it turns out that with very little retrofitting, and a bit of jiu jitsu, we can use refinements themselves to prove termination! How do you prove this fellow will stop falling? 38: module Termination where 39: 40: import Prelude hiding ( sum ) 41: import Data . Vector hiding ( sum ) Lets first see how LiquidHaskell proves termination on simple recursive functions, and then later, we'll see how to look at fancier cases. Looping Over Vectors \u00b6 Lets write a bunch of little functions that operate on 1-dimensional vectors 54: type Val = Int 55: type Vec = Vector Val Next, lets write a simple recursive function that loops over to add up the first n elements of a vector: 62: sum :: Vec -> Int -> Val 63: x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum (Data.Vector.Vector (GHC.Types.Int)) a 0 = x1:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV == (x1 : int))} 0 64: sum a n = ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) ) x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) Proving Termination By Hand(waving) \u00b6 Does sum terminate? First off, it is apparent that if we call sum with a negative n then it will not terminate. Thus, we should only call sum with non-negative integers. Fine, lets assume n is non-negative. Why then does it terminate? Intuitively, If n is 0 then it trivially returns with the value 0 . If n is non-zero, then we recurse but with a strictly smaller n ... ... but ultimately hit 0 at which point it terminates. Thus we can, somewhat more formally, prove termination by induction on n . Base Case n == 0 The function clearly terminates for the base case input of 0 . Inductive Hypothesis Lets assume that sum terminates on all 0 <= k < n . Inductive Step Prove that sum n only recursively invokes sum with values that satisfy the inductive hypothesis and hence, which terminate. This reasoning suffices to convince ourselves that sum i terminates for every natural number i . That is, we have shown that sum terminates because a well-founded metric (i.e., the natural number i ) is decreasing at each recursive call. Proving Termination By Types \u00b6 We can teach LiquidHaskell to prove termination by applying the same reasoning as above, by rephrasing it in terms of refinement types. First, we specify that the input is restricted to the set of Nat ural numbers 109: {-@ sum :: a : Vec -> {v: Nat | v < (vlen a)} -> Val @-} where recall that Nat is just the refinement type {v:Int | v >= 0} . Second, we typecheck the body of sum under an environment that restricts sum to only be called on inputs less than n , i.e. using an environment: a :: Vec n :: Nat sum :: Vec -> n':{v:Nat | v < n} -> Val This ensures that any (recursive) call in the body only calls sum with inputs smaller than the current parameter n . Since its body typechecks in this environment, i.e. sum is called with n-1 which is smaller than n and, in this case, a Nat , LiquidHaskell proves that sum terminates for all n . For those keeping track at home, this is the technique of sized types , , expressed using refinements. Sized types themselves are an instance of the classical method of proving termination via well founded metrics that goes back, at least, to Turing . Choosing the Correct Argument \u00b6 The example above is quite straightforward, and you might well wonder if this method works well for ``real-world\" programs. With a few generalizations and extensions, and by judiciously using the wealth of information captured in refinement types, the answer is an emphatic, yes! Lets see one extension today. We saw that liquidHaskell can happily check that some Natural number is decreasing at each iteration, but it uses a na\u00efve heuristic to choose which one -- for now, assume that it always chooses the first Int parameter. As you might imagine, this is quite simpleminded. Consider, a tail-recursive implementation of sum : 153: {-@ sum' :: a : Vec -> Val -> {v: Nat | v < (vlen a)} -> Val @-} 154: sum' :: Vec -> Val -> Int -> Val 155: x1:(Data.Vector.Vector (GHC.Types.Int)) -> (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum' (Data.Vector.Vector (GHC.Types.Int)) a (GHC.Types.Int) acc 0 = {VV : (GHC.Types.Int) | (VV == acc)} acc x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 156: sum' a acc n = x1:(Data.Vector.Vector (GHC.Types.Int)) -> (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum' {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a ( {VV : (GHC.Types.Int) | (VV == acc)} acc x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n ) ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) Clearly, the proof fails as liquidHaskell wants to prove that the acc umulator is a Nat ural number that decreases at each iteration, neither of which may be true. The remedy is easy. We can point liquidHaskell to the correct argument n using a Decrease annotation: 164: {-@ Decrease sum' 3 @-} which directs liquidHaskell to verify that the third argument (i.e., n ) is decreasing. With this hint, liquidHaskell will happily verify that sum' is indeed a terminating function. Thats all for now, next time we'll see how the basic technique can be extended to a variety of real-world settings.","title":"Checking Termination"},{"location":"blogposts/2013-12-09-checking-termination.lhs/#looping-over-vectors","text":"Lets write a bunch of little functions that operate on 1-dimensional vectors 54: type Val = Int 55: type Vec = Vector Val Next, lets write a simple recursive function that loops over to add up the first n elements of a vector: 62: sum :: Vec -> Int -> Val 63: x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum (Data.Vector.Vector (GHC.Types.Int)) a 0 = x1:(GHC.Prim.Int#) -> {VV : (GHC.Types.Int) | (VV == (x1 : int))} 0 64: sum a n = ( {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) ) x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 )","title":"Looping Over Vectors"},{"location":"blogposts/2013-12-09-checking-termination.lhs/#proving-termination-by-handwaving","text":"Does sum terminate? First off, it is apparent that if we call sum with a negative n then it will not terminate. Thus, we should only call sum with non-negative integers. Fine, lets assume n is non-negative. Why then does it terminate? Intuitively, If n is 0 then it trivially returns with the value 0 . If n is non-zero, then we recurse but with a strictly smaller n ... ... but ultimately hit 0 at which point it terminates. Thus we can, somewhat more formally, prove termination by induction on n . Base Case n == 0 The function clearly terminates for the base case input of 0 . Inductive Hypothesis Lets assume that sum terminates on all 0 <= k < n . Inductive Step Prove that sum n only recursively invokes sum with values that satisfy the inductive hypothesis and hence, which terminate. This reasoning suffices to convince ourselves that sum i terminates for every natural number i . That is, we have shown that sum terminates because a well-founded metric (i.e., the natural number i ) is decreasing at each recursive call.","title":"Proving Termination By Hand(waving)"},{"location":"blogposts/2013-12-09-checking-termination.lhs/#proving-termination-by-types","text":"We can teach LiquidHaskell to prove termination by applying the same reasoning as above, by rephrasing it in terms of refinement types. First, we specify that the input is restricted to the set of Nat ural numbers 109: {-@ sum :: a : Vec -> {v: Nat | v < (vlen a)} -> Val @-} where recall that Nat is just the refinement type {v:Int | v >= 0} . Second, we typecheck the body of sum under an environment that restricts sum to only be called on inputs less than n , i.e. using an environment: a :: Vec n :: Nat sum :: Vec -> n':{v:Nat | v < n} -> Val This ensures that any (recursive) call in the body only calls sum with inputs smaller than the current parameter n . Since its body typechecks in this environment, i.e. sum is called with n-1 which is smaller than n and, in this case, a Nat , LiquidHaskell proves that sum terminates for all n . For those keeping track at home, this is the technique of sized types , , expressed using refinements. Sized types themselves are an instance of the classical method of proving termination via well founded metrics that goes back, at least, to Turing .","title":"Proving Termination By Types"},{"location":"blogposts/2013-12-09-checking-termination.lhs/#choosing-the-correct-argument","text":"The example above is quite straightforward, and you might well wonder if this method works well for ``real-world\" programs. With a few generalizations and extensions, and by judiciously using the wealth of information captured in refinement types, the answer is an emphatic, yes! Lets see one extension today. We saw that liquidHaskell can happily check that some Natural number is decreasing at each iteration, but it uses a na\u00efve heuristic to choose which one -- for now, assume that it always chooses the first Int parameter. As you might imagine, this is quite simpleminded. Consider, a tail-recursive implementation of sum : 153: {-@ sum' :: a : Vec -> Val -> {v: Nat | v < (vlen a)} -> Val @-} 154: sum' :: Vec -> Val -> Int -> Val 155: x1:(Data.Vector.Vector (GHC.Types.Int)) -> (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum' (Data.Vector.Vector (GHC.Types.Int)) a (GHC.Types.Int) acc 0 = {VV : (GHC.Types.Int) | (VV == acc)} acc x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV == (0 : int))} 0 156: sum' a acc n = x1:(Data.Vector.Vector (GHC.Types.Int)) -> (GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen x1))} -> (GHC.Types.Int) sum' {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a ( {VV : (GHC.Types.Int) | (VV == acc)} acc x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 + x2))} + {VV : (Data.Vector.Vector (GHC.Types.Int)) | (VV == a) && ((vlen VV) >= 0)} a x1:(Data.Vector.Vector (GHC.Types.Int)) -> {VV : (GHC.Types.Int) | (VV < (vlen x1)) && (0 <= VV)} -> (GHC.Types.Int) ! {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n ) ( {VV : (GHC.Types.Int) | (VV >= 0) && (VV < (vlen a))} n x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == (1 : int))} 1 ) Clearly, the proof fails as liquidHaskell wants to prove that the acc umulator is a Nat ural number that decreases at each iteration, neither of which may be true. The remedy is easy. We can point liquidHaskell to the correct argument n using a Decrease annotation: 164: {-@ Decrease sum' 3 @-} which directs liquidHaskell to verify that the third argument (i.e., n ) is decreasing. With this hint, liquidHaskell will happily verify that sum' is indeed a terminating function. Thats all for now, next time we'll see how the basic technique can be extended to a variety of real-world settings.","title":"Choosing the Correct Argument"},{"location":"blogposts/2013-12-14-gcd.lhs/","text":"We've seen how, in the presence of lazy evaluation , refinements require termination . Next , we saw how LiquidHaskell can be used to prove termination. Today, lets see how termination requires refinements . That is, a crucial feature of LiquidHaskell's termination prover is that it is not syntactically driven, i.e. is not limited to say, structural recursion. Instead, it uses the wealth of information captured by refinements that are at our disposal, in order to prove termination. This turns out to be crucial in practice. As a quick toy example -- motivated by a question by Elias -- lets see how, unlike purely syntax-directed (structural) approaches, LiquidHaskell proves that recursive functions, such as Euclid's GCD algorithm, terminates. With LiquidHaskell, Euclid wouldn't have had to wave his hands. 51: module GCD where 52: 53: import Prelude hiding ( gcd , mod ) 54: 55: mod :: Int -> Int -> Int 56: gcd :: Int -> Int -> Int The Euclidean algorithm is one of the oldest numerical algorithms still in common use and calculates the the greatest common divisor (GCD) of two natural numbers a and b . Assume that a > b and consider the following implementation of gcd 66: {-@ gcd :: a : Nat -> b : {v: Nat | v < a} -> Int @-} 67: x1:{VV : (GHC.Types.Int) | (VV >= 0)} -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < x1)} -> (GHC.Types.Int) gcd {VV : (GHC.Types.Int) | (VV >= 0)} a 0 = {VV : (GHC.Types.Int) | (VV == a) && (VV >= 0)} a 68: gcd a b = x1:{VV : (GHC.Types.Int) | (VV >= 0)} -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < x1)} -> (GHC.Types.Int) gcd {VV : (GHC.Types.Int) | (VV >= 0) && (VV < a)} b ( {VV : (GHC.Types.Int) | (VV == a) && (VV >= 0)} a {VV : (GHC.Types.Int) | (VV >= 0)} -> x2:{VV : (GHC.Types.Int) | (VV >= 0) && (0 < VV)} -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < x2)} `mod` {VV : (GHC.Types.Int) | (VV >= 0) && (VV < a)} b ) From our previous post, to prove that gcd is terminating, it suffices to prove that the first argument decreases as each recursive call. By gcd 's type signature, a < b holds at each iteration, thus liquidHaskell will happily discharge the terminating condition. The only condition left to prove is that gcd 's second argument, ie., a mod b is less that b . This property follows from the behavior of the mod operator. So, to prove gcd terminating, liquidHaskell needs a refined signature for mod that captures this behavior, i.e., that for any a and b the value mod a b is less than b . Fortunately, we can stipulate this via a refined type: 88: {-@ mod :: a : Nat -> b : {v: Nat | 0 < v} -> {v: Nat | v < b} @-} 89: {VV : (GHC.Types.Int) | (VV >= 0)} -> x2:{VV : (GHC.Types.Int) | (VV >= 0) && (0 < VV)} -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < x2)} mod {VV : (GHC.Types.Int) | (VV >= 0)} a {VV : (GHC.Types.Int) | (VV >= 0) && (0 < VV)} b 90: | {VV : (GHC.Types.Int) | (VV == a) && (VV >= 0)} a x1:{VV : (GHC.Types.Int) | (VV >= 0)} -> x2:{VV : (GHC.Types.Int) | (VV >= 0)} -> {VV : (GHC.Types.Bool) | (((Prop VV)) <=> (x1 < x2))} < {VV : (GHC.Types.Int) | (VV == b) && (VV >= 0) && (0 < VV)} b = {VV : (GHC.Types.Int) | (VV == a) && (VV >= 0)} a 91: | otherwise = {VV : (GHC.Types.Int) | (VV >= 0)} -> x2:{VV : (GHC.Types.Int) | (VV >= 0) && (0 < VV)} -> {VV : (GHC.Types.Int) | (VV >= 0) && (VV < x2)} mod ( {VV : (GHC.Types.Int) | (VV == a) && (VV >= 0)} a x1:(GHC.Types.Int) -> x2:(GHC.Types.Int) -> {VV : (GHC.Types.Int) | (VV == (x1 - x2))} - {VV : (GHC.Types.Int) | (VV == b) && (VV >= 0) && (0 < VV)} b ) {VV : (GHC.Types.Int) | (VV == b) && (VV >= 0) && (0 < VV)} b Euclid's original version of gcd is different 95: gcd' :: Int -> Int -> Int 96: gcd' a b | a == b = a 97: | a > b = gcd' ( a - b ) b 98: | a < b = gcd' a ( b - a ) Though this version is simpler, turns out that LiquidHaskell needs a more sophisticated mechanism, called lexicographic ordering , to prove it terminates. Stay tuned!","title":"Termination Requires Refinements"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/","text":"Yesterday someone asked on Reddit how one might define GHC's OrdList in a way that statically enforces its three key invariants. The accepted solution required rewriting OrdList as a GADT indexed by a proof of emptiness (which is essentially created by a run-time check), and used the new Closed Type Families extension in GHC 7.8 to define a type-level join of the Emptiness index. Today, let's see a somewhat more direct way of tackling this problem in LiquidHaskell, in which we need not change a single line of code (well.. maybe one), and need not perform any dynamic checks. 27: module OrdList ( 28: OrdList , 29: nilOL , isNilOL , unitOL , appOL , consOL , snocOL , concatOL , 30: mapOL , fromOL , toOL , foldrOL , foldlOL , foldr' , concatOL' 31: ) where 32: 33: infixl 5 `appOL` 34: infixl 5 `snocOL` 35: infixr 5 `consOL` 36: -- UGH parsing issues... 37: {-@ 38: data OrdList [ olen ] a = None 39: | One ( x :: a ) 40: | Many ( xs :: ListNE a ) 41: | Cons ( x :: a ) ( xs :: OrdList a ) 42: | Snoc ( xs :: OrdList a ) ( x :: a ) 43: | Two ( x :: OrdListNE a ) ( y :: OrdListNE a ) 44: @-} The OrdList Type \u00b6 The OrdList type is defined as follows: 54: data OrdList a 55: = None 56: | One a 57: | Many [ a ] -- Invariant: non-empty 58: | Cons a ( OrdList a ) 59: | Snoc ( OrdList a ) a 60: | Two ( OrdList a ) -- Invariant: non-empty 61: ( OrdList a ) -- Invariant: non-empty As indicated by the comments the key invariants are that: Many should take a non-empty list, Two takes two non-empty OrdList s. What is a Non-Empty OrdList? \u00b6 To proceed, we must tell LiquidHaskell what non-empty means. We do this with a measure that describes the number of elements in a structure. When this number is strictly positive, the structure is non-empty. We've previously seen how to measure the size of a list. 77: measure len :: [ a ] -> Int 78: len ( [] ) = 0 79: len ( x : xs ) = 1 + ( len xs ) We can use the same technique to measure the size of an OrdList . 85: {-@ measure olen :: OrdList a -> Int 86: olen ( None ) = 0 87: olen ( One x ) = 1 88: olen ( Many xs ) = ( len xs ) 89: olen ( Cons x xs ) = 1 + ( olen xs ) 90: olen ( Snoc xs x ) = 1 + ( olen xs ) 91: olen ( Two x y ) = ( olen x ) + ( olen y ) 92: @-} 93: 94: {-@ invariant {v: OrdList a | (olen v) >= 0} @-} Now, we can use the measures to define aliases for non-empty lists and OrdList s. 100: {-@ type ListNE a = { v : [ a ] | ( len v ) > 0 } @-} 101: {-@ type OrdListNE a = { v : OrdList a | ( olen v ) > 0 } @-} Capturing the Invariants In a Refined Type \u00b6 Let's return to the original type, and refine it with the above non-empty variants to specify the invariants as part of the data declaration 110: {-@ data OrdList [ olen ] a 111: = None 112: | One ( x :: a ) 113: | Many ( xs :: ListNE a ) 114: | Cons ( x :: a ) ( xs :: OrdList a ) 115: | Snoc ( xs :: OrdList a ) ( x :: a ) 116: | Two ( x :: OrdListNE a ) ( y :: OrdListNE a ) 117: @-} Notice immediately that LiquidHaskell can use the refined definition to warn us about malformed OrdList values. 124: (OrdList.OrdList {VV : (GHC.Integer.Type.Integer) | (VV > 0)}) ok = x1:{x6 : [{x9 : (GHC.Integer.Type.Integer) | (x9 > 0)}] | ((len x6) > 0)} -> {x2 : (OrdList.OrdList {x9 : (GHC.Integer.Type.Integer) | (x9 > 0)}) | ((olen x2) == (len x1))} Many {x5 : [{x11 : (GHC.Integer.Type.Integer) | (x11 > 0)}]<\\x9 VV -> (x8 > 0) && (x8 > x9)> | (((null x5)) <=> false) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} [ 1 , 2 , 3 ] 125: forall a. {VV : (OrdList.OrdList {VV : a | false}) | ((olen VV) == 0)} bad = x1:{x4 : [{VV : a | false}] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList {VV : a | false}) | ((olen x2) == (len x1))} Many {x8 : [{VV : a | false}]<\\_ VV -> false> | (((null x8)) <=> true) && ((len x8) == 0) && ((olens x8) == 0) && ((sumLens x8) == 0) && ((len x8) >= 0) && ((olens x8) >= 0) && ((sumLens x8) >= 0)} [] 126: {VV : (OrdList.OrdList {VV : (GHC.Integer.Type.Integer) | (VV > 0)}) | ((olen VV) == (olen OrdList.ok))} badder = x1:{x10 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x10) > 0)} -> x2:{x6 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x6) > 0)} -> {x2 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x2) == ((olen x1) + (olen x2)))} Two {x3 : (OrdList.OrdList {x4 : (GHC.Integer.Type.Integer) | false}) | ((olen x3) == 0) && ((olen x3) >= 0)} None {x3 : (OrdList.OrdList {x5 : (GHC.Integer.Type.Integer) | (x5 > 0)}) | (x3 == OrdList.ok) && ((olen x3) >= 0)} ok All of the above are accepted by GHC, but only the first one is actually a valid OrdList . Happily, LiquidHaskell will reject the latter two, as they violate the invariants. Basic Functions \u00b6 Now let's look at some of the functions! First, we'll define a handy alias for OrdList s of a given size: 142: {-@ type OrdListN a N = { v : OrdList a | ( olen v ) = N } @-} Now, the nilOL constructor returns an empty OrdList : 148: {-@ nilOL :: OrdListN a {0} @-} 149: forall a. {v : (OrdList.OrdList a) | ((olen v) == 0)} nilOL = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None the unitOL constructor returns an OrdList with one element: 155: {-@ unitOL :: a -> OrdListN a {1} @-} 156: forall a. a -> {v : (OrdList.OrdList a) | ((olen v) == 1)} unitOL a as = {VV : a | (VV == as)} -> {x2 : (OrdList.OrdList {VV : a | (VV == as)}) | ((olen x2) == 1)} One {VV : a | (VV == as)} as and snocOL and consOL return outputs with precisely one more element: 162: {-@ snocOL :: xs : OrdList a -> a -> OrdListN a {1 + (olen xs)} @-} 163: forall a. xs:(OrdList.OrdList a) -> a -> {v : (OrdList.OrdList a) | ((olen v) == (1 + (olen xs)))} snocOL (OrdList.OrdList a) as a b = x1:(OrdList.OrdList a) -> a -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x1)))} Snoc {x3 : (OrdList.OrdList a) | (x3 == as) && ((olen x3) >= 0)} as {VV : a | (VV == b)} b 164: 165: {-@ consOL :: a -> xs : OrdList a -> OrdListN a {1 + (olen xs)} @-} 166: forall a. a -> xs:(OrdList.OrdList a) -> {v : (OrdList.OrdList a) | ((olen v) == (1 + (olen xs)))} consOL a a (OrdList.OrdList a) bs = a -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x2)))} Cons {VV : a | (VV == a)} a {x3 : (OrdList.OrdList a) | (x3 == bs) && ((olen x3) >= 0)} bs Note: The OrdListN a {e} syntax just lets us use LiquidHaskell expressions e as a parameter to the type alias OrdListN . 175: {-@ isNilOL :: xs : OrdList a -> {v: Bool | ((Prop v) <=> ((olen xs) = 0))} @-} 176: forall a. xs:(OrdList.OrdList a) -> {v : (GHC.Types.Bool) | (((Prop v)) <=> ((olen xs) == 0))} isNilOL None = {x3 : (GHC.Types.Bool) | ((Prop x3)) && (x3 == GHC.Types.True)} True 177: isNilOL _ = {x3 : (GHC.Types.Bool) | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False Appending OrdList s \u00b6 The above functions really aren't terribly interesting, however, since their types fall right out of the definition of olen . So how about something that takes a little thinking? 190: {-@ appOL :: xs : OrdList a -> ys : OrdList a 191: -> OrdListN a {(olen xs) + (olen ys)} 192: @-} 193: None forall a. xs:(OrdList.OrdList a) -> ys:(OrdList.OrdList a) -> {v : (OrdList.OrdList a) | ((olen v) == ((olen xs) + (olen ys)))} `appOL` (OrdList.OrdList a) b = {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b 194: a `appOL` None = {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a 195: One a `appOL` b = {VV : a | (VV == a) && (VV > a) && (VV < a)} -> x2:(OrdList.OrdList {VV : a | (VV == a) && (VV > a) && (VV < a)}) -> {x2 : (OrdList.OrdList {VV : a | (VV == a) && (VV > a) && (VV < a)}) | ((olen x2) == (1 + (olen x2)))} Cons {VV : a | (VV == a)} a {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b 196: a `appOL` One b = x1:(OrdList.OrdList {VV : a | (VV == b) && (VV > b) && (VV < b)}) -> {VV : a | (VV == b) && (VV > b) && (VV < b)} -> {x2 : (OrdList.OrdList {VV : a | (VV == b) && (VV > b) && (VV < b)}) | ((olen x2) == (1 + (olen x1)))} Snoc {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a {VV : a | (VV == b)} b 197: a `appOL` b = x1:{x6 : (OrdList.OrdList a) | ((olen x6) > 0)} -> x2:{x4 : (OrdList.OrdList a) | ((olen x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} Two {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b appOL takes two OrdList s and returns a list whose length is the sum of the two input lists. The most important thing to notice here is that we haven't had to insert any extra checks in appOL , unlike the GADT solution. LiquidHaskell uses the definition of olen to infer that in the last case of appOL , a and b must be non-empty , so they are valid arguments to Two . We can prove other things about OrdList s as well, like the fact that converting an OrdList to a Haskell list preserves length 211: {-@ toOL :: xs : [ a ] -> OrdListN a {(len xs)} @-} 212: forall a. xs:[a] -> {v : (OrdList.OrdList a) | ((olen v) == (len xs))} toOL [] = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 213: toOL xs = x1:{x4 : [a] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == (len x1))} Many {x4 : [a] | ((len x4) >= 0) && ((olens x4) >= 0) && ((sumLens x4) >= 0)} xs as does mapping over an OrdList 219: {-@ mapOL :: ( a -> b ) -> xs : OrdList a -> OrdListN b {(olen xs)} @-} 220: forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL _ None = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 221: mapOL f ( One x ) = a -> {x2 : (OrdList.OrdList a) | ((olen x2) == 1)} One ( a -> b f {VV : a | (VV == x)} x ) 222: mapOL f ( Cons x xs ) = a -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x2)))} Cons ( a -> b f {VV : a | (VV == x)} x ) ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) 223: mapOL f ( Snoc xs x ) = x1:(OrdList.OrdList a) -> a -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x1)))} Snoc ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) ( a -> b f {VV : a | (VV == x)} x ) 224: mapOL f ( Two x y ) = x1:{x6 : (OrdList.OrdList a) | ((olen x6) > 0)} -> x2:{x4 : (OrdList.OrdList a) | ((olen x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} Two ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x4 : (OrdList.OrdList a) | (x4 == x) && ((olen x4) > 0) && ((olen x4) >= 0)} x ) ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x4 : (OrdList.OrdList a) | (x4 == y) && ((olen x4) > 0) && ((olen x4) >= 0)} y ) 225: mapOL f ( Many xs ) = x1:{x4 : [a] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == (len x1))} Many ( (a -> b) -> x3:[a] -> {x2 : [b] | ((len x2) == (len x3))} map a -> b f {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs ) as does converting a Haskell list to an OrdList . 231: {-@ type ListN a N = { v : [ a ] | ( len v ) = N } @-} 232: 233: {-@ fromOL :: xs : OrdList a -> ListN a {(olen xs)} @-} 234: forall a. xs:(OrdList.OrdList a) -> {v : [a] | ((len v) == (olen xs))} fromOL (OrdList.OrdList a) a = x1:(OrdList.OrdList a) -> x2:{x4 : [a] | ((len x4) == 0)} -> {x2 : [a] | ((len x2) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == a) && ((olen x3) >= 0)} a {x8 : [{VV : a | false}]<\\_ VV -> false> | (((null x8)) <=> true) && ((len x8) == 0) && ((olens x8) == 0) && ((sumLens x8) == 0) && ((len x8) >= 0) && ((olens x8) >= 0) && ((sumLens x8) >= 0)} [] 235: where 236: {-@ go :: xs : _ -> ys : _ 237: -> {v: _ | (len v) = (olen xs) + (len ys)} 238: @-} 239: x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go None {VV : [a] | ((len VV) >= 0)} acc = {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 240: go ( One a ) acc = {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 241: go ( Cons a b ) acc = {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 242: go ( Snoc a b ) acc = x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == a) && ((olen x3) >= 0)} a ( {VV : a | (VV == b)} b forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc ) 243: go ( Two a b ) acc = x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x4 : (OrdList.OrdList a) | (x4 == a) && ((olen x4) > 0) && ((olen x4) >= 0)} a ( x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x4 : (OrdList.OrdList a) | (x4 == b) && ((olen x4) > 0) && ((olen x4) >= 0)} b {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc ) 244: go ( Many xs ) acc = {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs x1:[a] -> x2:[a] -> {x2 : [a] | ((len x2) == ((len x1) + (len x2)))} ++ {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc though for this last one we actually need to provide an explicit qualifier, which we haven't really seen so far. Can anyone guess why? 252: {-@ qualif Go ( v : List a , xs : OrdList a , ys : List a ) : 253: ( len v ) = ( olen xs ) + ( len ys ) 254: @-} The answer is that the return type of `go` must refer to the length of the `OrdList` that it's folding over *as well as* the length of the accumulator `acc`! We haven't written a refinement like that in any of our type signatures in this module, so LiquidHaskell doesn't know to guess that type. There's nothing super interesting to say about the foldOL s but I'll include them here for completeness' sake. 268: foldrOL :: ( a -> b -> b ) -> b -> OrdList a -> b 269: forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL _ a z None = {VV : a | (VV == z)} z 270: foldrOL k z ( One x ) = a -> b -> b k {VV : a | (VV == x)} x {VV : a | (VV == z)} z 271: foldrOL k z ( Cons x xs ) = a -> b -> b k {VV : a | (VV == x)} x ( forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k {VV : a | (VV == z)} z {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) 272: foldrOL k z ( Snoc xs x ) = forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k ( a -> b -> b k {VV : a | (VV == x)} x {VV : a | (VV == z)} z ) {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs 273: foldrOL k z ( Two b1 b2 ) = forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k ( forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k {VV : a | (VV == z)} z {x4 : (OrdList.OrdList a) | (x4 == b2) && ((olen x4) > 0) && ((olen x4) >= 0)} b2 ) {x4 : (OrdList.OrdList a) | (x4 == b1) && ((olen x4) > 0) && ((olen x4) >= 0)} b1 274: foldrOL k z ( Many xs ) = (a -> b -> b) -> b -> [a] -> b foldr a -> b -> b k {VV : a | (VV == z)} z {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs 275: 276: foldlOL :: ( b -> a -> b ) -> b -> OrdList a -> b 277: forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL _ a z None = {VV : a | (VV == z)} z 278: foldlOL k z ( One x ) = a -> b -> a k {VV : a | (VV == z)} z {VV : a | (VV == x)} x 279: foldlOL k z ( Cons x xs ) = forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k ( a -> b -> a k {VV : a | (VV == z)} z {VV : a | (VV == x)} x ) {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs 280: foldlOL k z ( Snoc xs x ) = a -> b -> a k ( forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k {VV : a | (VV == z)} z {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) {VV : a | (VV == x)} x 281: foldlOL k z ( Two b1 b2 ) = forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k ( forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k {VV : a | (VV == z)} z {x4 : (OrdList.OrdList a) | (x4 == b1) && ((olen x4) > 0) && ((olen x4) >= 0)} b1 ) {x4 : (OrdList.OrdList a) | (x4 == b2) && ((olen x4) > 0) && ((olen x4) >= 0)} b2 282: foldlOL k z ( Many xs ) = (a -> b -> a) -> a -> [b] -> a foldl a -> b -> a k {VV : a | (VV == z)} z {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs Concatenatation: Nested Measures \u00b6 Now, the astute readers will have probably noticed that I'm missing one function, concatOL , which glues a list of OrdList s into a single long OrdList . With LiquidHaskell we can give concatOL a super precise type, which states that the size of the output list equals the sum-of-the-sizes of the input OrdLists . 298: {-@ concatOL :: xs : [ OrdList a ] -> OrdListN a {(olens xs)} @-} 299: forall a. x1:[(OrdList.OrdList a)] -> {VV : (OrdList.OrdList a) | ((olen VV) == (olens x1))} concatOL [] = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 300: concatOL ( ol : ols ) = {x3 : (OrdList.OrdList a) | (x3 == ol) && ((olen x3) >= 0)} ol x1:(OrdList.OrdList a) -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} `appOL` forall a. x1:[(OrdList.OrdList a)] -> {VV : (OrdList.OrdList a) | ((olen VV) == (olens x1))} concatOL {x5 : [(OrdList.OrdList a)] | (x5 == ols) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} ols The notion of sum-of-the-sizes of the input lists is specifed by the measure 306: {-@ measure olens :: [ OrdList a ] -> Int 307: olens ( [] ) = 0 308: olens ( ol : ols ) = ( olen ol ) + ( olens ols ) 309: @-} 310: 311: {-@ invariant {v: [ OrdList a ] | (olens v) >= 0} @-} LiquidHaskell is happy to verify the above signature, again without requiring any explict proofs. Conclusion \u00b6 The above illustrates the flexibility provided by LiquidHaskell measures . Instead of having to bake particular invariants into a datatype using indices or phantom types (as in the GADT approach), we are able to split our properties out into independent views of the datatype, yielding an approach that is more modular as we didn't have to go back and change the definition of [] to talk about OrdList s, we didn't have to provide explict non-emptiness witnesses, we obtained extra information about the behavior of API functions like concatOL . We can actually even verify the original definition of `concatOL` with a clever use of *abstract refinements*, but we have to slightly change the signature of `foldr`. 338: {- UGH CAN'T PARSE `GHC.Types.:`... foldr' :: forall <p :: [a] -> b -> Prop>. (xs:[a] -> x:a -> b<p xs> -> b<p (GHC.Types.: x xs)>) -> b<p GHC.Types.[]> -> ys:[a] -> b<p ys> @-} 345: forall a b. ({VV : [a] | ((len VV) >= 0)} -> a -> b -> b) -> b -> [a] -> b foldr' {VV : [a] | ((len VV) >= 0)} -> a -> b -> b f a z [] = {VV : a | (VV == z)} z 346: foldr' f z ( x : xs ) = {x2 : [a] | ((len x2) >= 0)} -> a -> b -> b f {x5 : [a] | (x5 == xs) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} xs {VV : a | (VV == x)} x ( forall a b. ({VV : [a] | ((len VV) >= 0)} -> a -> b -> b) -> b -> [a] -> b foldr' {x2 : [a] | ((len x2) >= 0)} -> a -> b -> b f {VV : a | (VV == z)} z {x5 : [a] | (x5 == xs) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} xs ) We've added a *ghost parameter* to the folding function, letting us refer to the tail of the list at each folding step. This lets us encode inductive reasoning in the type of `foldr`, specifically that 1. given a base case `z` that satisfies `p []` 2. and a function that, given a value that satisfies `p xs`, returns a value satisfying `p (x:xs)` 3. the value returned by `foldr f z ys` must satisfy `p ys`! LiquidHaskell can use this signature, instantiating `p` with `\\xs -> {v:OrdList a | (olen v) = (olens xs)}` to prove the original definition of `concatOL`! 363: {- concatOL' :: xs:[OrdList a] -> OrdListN a {(olens xs)} @-} 364: forall a. [(OrdList.OrdList a)] -> (OrdList.OrdList a) concatOL' [(OrdList.OrdList a)] aas = ([(OrdList.OrdList a)] -> (OrdList.OrdList a) -> (OrdList.OrdList a) -> (OrdList.OrdList a)) -> (OrdList.OrdList a) -> [(OrdList.OrdList a)] -> (OrdList.OrdList a) foldr' ( (x5:(OrdList.OrdList a) -> x6:(OrdList.OrdList a) -> {x15 : (OrdList.OrdList a) | ((olen x15) == ((olen x5) + (olen x6))) && ((olen x15) == ((olen x6) + (olen x5)))}) -> [(OrdList.OrdList a)] -> x5:(OrdList.OrdList a) -> x6:(OrdList.OrdList a) -> {x15 : (OrdList.OrdList a) | ((olen x15) == ((olen x5) + (olen x6))) && ((olen x15) == ((olen x6) + (olen x5)))} const x1:(OrdList.OrdList a) -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} appOL ) {x3 : (OrdList.OrdList {VV : a | false}) | ((olen x3) == 0) && ((olen x3) >= 0)} None {x5 : [(OrdList.OrdList a)] | (x5 == aas) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} aas We haven't added the modified version of `foldr` to the LiquidHaskell Prelude yet because it adds the ghost variable to the Haskell type-signature.","title":"The Advantage of Measures"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#the-ordlist-type","text":"The OrdList type is defined as follows: 54: data OrdList a 55: = None 56: | One a 57: | Many [ a ] -- Invariant: non-empty 58: | Cons a ( OrdList a ) 59: | Snoc ( OrdList a ) a 60: | Two ( OrdList a ) -- Invariant: non-empty 61: ( OrdList a ) -- Invariant: non-empty As indicated by the comments the key invariants are that: Many should take a non-empty list, Two takes two non-empty OrdList s.","title":"The OrdList Type"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#what-is-a-non-empty-ordlist","text":"To proceed, we must tell LiquidHaskell what non-empty means. We do this with a measure that describes the number of elements in a structure. When this number is strictly positive, the structure is non-empty. We've previously seen how to measure the size of a list. 77: measure len :: [ a ] -> Int 78: len ( [] ) = 0 79: len ( x : xs ) = 1 + ( len xs ) We can use the same technique to measure the size of an OrdList . 85: {-@ measure olen :: OrdList a -> Int 86: olen ( None ) = 0 87: olen ( One x ) = 1 88: olen ( Many xs ) = ( len xs ) 89: olen ( Cons x xs ) = 1 + ( olen xs ) 90: olen ( Snoc xs x ) = 1 + ( olen xs ) 91: olen ( Two x y ) = ( olen x ) + ( olen y ) 92: @-} 93: 94: {-@ invariant {v: OrdList a | (olen v) >= 0} @-} Now, we can use the measures to define aliases for non-empty lists and OrdList s. 100: {-@ type ListNE a = { v : [ a ] | ( len v ) > 0 } @-} 101: {-@ type OrdListNE a = { v : OrdList a | ( olen v ) > 0 } @-}","title":"What is a Non-Empty OrdList?"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#capturing-the-invariants-in-a-refined-type","text":"Let's return to the original type, and refine it with the above non-empty variants to specify the invariants as part of the data declaration 110: {-@ data OrdList [ olen ] a 111: = None 112: | One ( x :: a ) 113: | Many ( xs :: ListNE a ) 114: | Cons ( x :: a ) ( xs :: OrdList a ) 115: | Snoc ( xs :: OrdList a ) ( x :: a ) 116: | Two ( x :: OrdListNE a ) ( y :: OrdListNE a ) 117: @-} Notice immediately that LiquidHaskell can use the refined definition to warn us about malformed OrdList values. 124: (OrdList.OrdList {VV : (GHC.Integer.Type.Integer) | (VV > 0)}) ok = x1:{x6 : [{x9 : (GHC.Integer.Type.Integer) | (x9 > 0)}] | ((len x6) > 0)} -> {x2 : (OrdList.OrdList {x9 : (GHC.Integer.Type.Integer) | (x9 > 0)}) | ((olen x2) == (len x1))} Many {x5 : [{x11 : (GHC.Integer.Type.Integer) | (x11 > 0)}]<\\x9 VV -> (x8 > 0) && (x8 > x9)> | (((null x5)) <=> false) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} [ 1 , 2 , 3 ] 125: forall a. {VV : (OrdList.OrdList {VV : a | false}) | ((olen VV) == 0)} bad = x1:{x4 : [{VV : a | false}] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList {VV : a | false}) | ((olen x2) == (len x1))} Many {x8 : [{VV : a | false}]<\\_ VV -> false> | (((null x8)) <=> true) && ((len x8) == 0) && ((olens x8) == 0) && ((sumLens x8) == 0) && ((len x8) >= 0) && ((olens x8) >= 0) && ((sumLens x8) >= 0)} [] 126: {VV : (OrdList.OrdList {VV : (GHC.Integer.Type.Integer) | (VV > 0)}) | ((olen VV) == (olen OrdList.ok))} badder = x1:{x10 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x10) > 0)} -> x2:{x6 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x6) > 0)} -> {x2 : (OrdList.OrdList {x12 : (GHC.Integer.Type.Integer) | (x12 > 0)}) | ((olen x2) == ((olen x1) + (olen x2)))} Two {x3 : (OrdList.OrdList {x4 : (GHC.Integer.Type.Integer) | false}) | ((olen x3) == 0) && ((olen x3) >= 0)} None {x3 : (OrdList.OrdList {x5 : (GHC.Integer.Type.Integer) | (x5 > 0)}) | (x3 == OrdList.ok) && ((olen x3) >= 0)} ok All of the above are accepted by GHC, but only the first one is actually a valid OrdList . Happily, LiquidHaskell will reject the latter two, as they violate the invariants.","title":"Capturing the Invariants In a Refined Type"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#basic-functions","text":"Now let's look at some of the functions! First, we'll define a handy alias for OrdList s of a given size: 142: {-@ type OrdListN a N = { v : OrdList a | ( olen v ) = N } @-} Now, the nilOL constructor returns an empty OrdList : 148: {-@ nilOL :: OrdListN a {0} @-} 149: forall a. {v : (OrdList.OrdList a) | ((olen v) == 0)} nilOL = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None the unitOL constructor returns an OrdList with one element: 155: {-@ unitOL :: a -> OrdListN a {1} @-} 156: forall a. a -> {v : (OrdList.OrdList a) | ((olen v) == 1)} unitOL a as = {VV : a | (VV == as)} -> {x2 : (OrdList.OrdList {VV : a | (VV == as)}) | ((olen x2) == 1)} One {VV : a | (VV == as)} as and snocOL and consOL return outputs with precisely one more element: 162: {-@ snocOL :: xs : OrdList a -> a -> OrdListN a {1 + (olen xs)} @-} 163: forall a. xs:(OrdList.OrdList a) -> a -> {v : (OrdList.OrdList a) | ((olen v) == (1 + (olen xs)))} snocOL (OrdList.OrdList a) as a b = x1:(OrdList.OrdList a) -> a -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x1)))} Snoc {x3 : (OrdList.OrdList a) | (x3 == as) && ((olen x3) >= 0)} as {VV : a | (VV == b)} b 164: 165: {-@ consOL :: a -> xs : OrdList a -> OrdListN a {1 + (olen xs)} @-} 166: forall a. a -> xs:(OrdList.OrdList a) -> {v : (OrdList.OrdList a) | ((olen v) == (1 + (olen xs)))} consOL a a (OrdList.OrdList a) bs = a -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x2)))} Cons {VV : a | (VV == a)} a {x3 : (OrdList.OrdList a) | (x3 == bs) && ((olen x3) >= 0)} bs Note: The OrdListN a {e} syntax just lets us use LiquidHaskell expressions e as a parameter to the type alias OrdListN . 175: {-@ isNilOL :: xs : OrdList a -> {v: Bool | ((Prop v) <=> ((olen xs) = 0))} @-} 176: forall a. xs:(OrdList.OrdList a) -> {v : (GHC.Types.Bool) | (((Prop v)) <=> ((olen xs) == 0))} isNilOL None = {x3 : (GHC.Types.Bool) | ((Prop x3)) && (x3 == GHC.Types.True)} True 177: isNilOL _ = {x3 : (GHC.Types.Bool) | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False","title":"Basic Functions"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#appending-ordlists","text":"The above functions really aren't terribly interesting, however, since their types fall right out of the definition of olen . So how about something that takes a little thinking? 190: {-@ appOL :: xs : OrdList a -> ys : OrdList a 191: -> OrdListN a {(olen xs) + (olen ys)} 192: @-} 193: None forall a. xs:(OrdList.OrdList a) -> ys:(OrdList.OrdList a) -> {v : (OrdList.OrdList a) | ((olen v) == ((olen xs) + (olen ys)))} `appOL` (OrdList.OrdList a) b = {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b 194: a `appOL` None = {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a 195: One a `appOL` b = {VV : a | (VV == a) && (VV > a) && (VV < a)} -> x2:(OrdList.OrdList {VV : a | (VV == a) && (VV > a) && (VV < a)}) -> {x2 : (OrdList.OrdList {VV : a | (VV == a) && (VV > a) && (VV < a)}) | ((olen x2) == (1 + (olen x2)))} Cons {VV : a | (VV == a)} a {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b 196: a `appOL` One b = x1:(OrdList.OrdList {VV : a | (VV == b) && (VV > b) && (VV < b)}) -> {VV : a | (VV == b) && (VV > b) && (VV < b)} -> {x2 : (OrdList.OrdList {VV : a | (VV == b) && (VV > b) && (VV < b)}) | ((olen x2) == (1 + (olen x1)))} Snoc {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a {VV : a | (VV == b)} b 197: a `appOL` b = x1:{x6 : (OrdList.OrdList a) | ((olen x6) > 0)} -> x2:{x4 : (OrdList.OrdList a) | ((olen x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} Two {x2 : (OrdList.OrdList a) | ((olen x2) >= 0)} a {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b appOL takes two OrdList s and returns a list whose length is the sum of the two input lists. The most important thing to notice here is that we haven't had to insert any extra checks in appOL , unlike the GADT solution. LiquidHaskell uses the definition of olen to infer that in the last case of appOL , a and b must be non-empty , so they are valid arguments to Two . We can prove other things about OrdList s as well, like the fact that converting an OrdList to a Haskell list preserves length 211: {-@ toOL :: xs : [ a ] -> OrdListN a {(len xs)} @-} 212: forall a. xs:[a] -> {v : (OrdList.OrdList a) | ((olen v) == (len xs))} toOL [] = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 213: toOL xs = x1:{x4 : [a] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == (len x1))} Many {x4 : [a] | ((len x4) >= 0) && ((olens x4) >= 0) && ((sumLens x4) >= 0)} xs as does mapping over an OrdList 219: {-@ mapOL :: ( a -> b ) -> xs : OrdList a -> OrdListN b {(olen xs)} @-} 220: forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL _ None = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 221: mapOL f ( One x ) = a -> {x2 : (OrdList.OrdList a) | ((olen x2) == 1)} One ( a -> b f {VV : a | (VV == x)} x ) 222: mapOL f ( Cons x xs ) = a -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x2)))} Cons ( a -> b f {VV : a | (VV == x)} x ) ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) 223: mapOL f ( Snoc xs x ) = x1:(OrdList.OrdList a) -> a -> {x2 : (OrdList.OrdList a) | ((olen x2) == (1 + (olen x1)))} Snoc ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) ( a -> b f {VV : a | (VV == x)} x ) 224: mapOL f ( Two x y ) = x1:{x6 : (OrdList.OrdList a) | ((olen x6) > 0)} -> x2:{x4 : (OrdList.OrdList a) | ((olen x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} Two ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x4 : (OrdList.OrdList a) | (x4 == x) && ((olen x4) > 0) && ((olen x4) >= 0)} x ) ( forall a b. (b -> a) -> x3:(OrdList.OrdList b) -> {VV : (OrdList.OrdList a) | ((olen VV) == (olen x3))} mapOL a -> b f {x4 : (OrdList.OrdList a) | (x4 == y) && ((olen x4) > 0) && ((olen x4) >= 0)} y ) 225: mapOL f ( Many xs ) = x1:{x4 : [a] | ((len x4) > 0)} -> {x2 : (OrdList.OrdList a) | ((olen x2) == (len x1))} Many ( (a -> b) -> x3:[a] -> {x2 : [b] | ((len x2) == (len x3))} map a -> b f {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs ) as does converting a Haskell list to an OrdList . 231: {-@ type ListN a N = { v : [ a ] | ( len v ) = N } @-} 232: 233: {-@ fromOL :: xs : OrdList a -> ListN a {(olen xs)} @-} 234: forall a. xs:(OrdList.OrdList a) -> {v : [a] | ((len v) == (olen xs))} fromOL (OrdList.OrdList a) a = x1:(OrdList.OrdList a) -> x2:{x4 : [a] | ((len x4) == 0)} -> {x2 : [a] | ((len x2) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == a) && ((olen x3) >= 0)} a {x8 : [{VV : a | false}]<\\_ VV -> false> | (((null x8)) <=> true) && ((len x8) == 0) && ((olens x8) == 0) && ((sumLens x8) == 0) && ((len x8) >= 0) && ((olens x8) >= 0) && ((sumLens x8) >= 0)} [] 235: where 236: {-@ go :: xs : _ -> ys : _ 237: -> {v: _ | (len v) = (olen xs) + (len ys)} 238: @-} 239: x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go None {VV : [a] | ((len VV) >= 0)} acc = {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 240: go ( One a ) acc = {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 241: go ( Cons a b ) acc = {VV : a | (VV == a)} a forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == b) && ((olen x3) >= 0)} b {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc 242: go ( Snoc a b ) acc = x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x3 : (OrdList.OrdList a) | (x3 == a) && ((olen x3) >= 0)} a ( {VV : a | (VV == b)} b forall <p :: a-> a-> Bool>. x1:a -> x2:[{VV : a<p x1> | true}]<p> -> {x5 : [a]<p> | (((null x5)) <=> false) && ((len x5) == (1 + (len x2))) && ((olens x5) == ((olen x1) + (olens x2))) && ((sumLens x5) == ((len x1) + (sumLens x2)))} : {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc ) 243: go ( Two a b ) acc = x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x4 : (OrdList.OrdList a) | (x4 == a) && ((olen x4) > 0) && ((olen x4) >= 0)} a ( x1:(OrdList.OrdList a) -> x2:{VV : [a] | ((len VV) >= 0)} -> {v : [a] | ((len v) == ((olen x1) + (len x2)))} go {x4 : (OrdList.OrdList a) | (x4 == b) && ((olen x4) > 0) && ((olen x4) >= 0)} b {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc ) 244: go ( Many xs ) acc = {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs x1:[a] -> x2:[a] -> {x2 : [a] | ((len x2) == ((len x1) + (len x2)))} ++ {x5 : [a] | (x5 == acc) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} acc though for this last one we actually need to provide an explicit qualifier, which we haven't really seen so far. Can anyone guess why? 252: {-@ qualif Go ( v : List a , xs : OrdList a , ys : List a ) : 253: ( len v ) = ( olen xs ) + ( len ys ) 254: @-} The answer is that the return type of `go` must refer to the length of the `OrdList` that it's folding over *as well as* the length of the accumulator `acc`! We haven't written a refinement like that in any of our type signatures in this module, so LiquidHaskell doesn't know to guess that type. There's nothing super interesting to say about the foldOL s but I'll include them here for completeness' sake. 268: foldrOL :: ( a -> b -> b ) -> b -> OrdList a -> b 269: forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL _ a z None = {VV : a | (VV == z)} z 270: foldrOL k z ( One x ) = a -> b -> b k {VV : a | (VV == x)} x {VV : a | (VV == z)} z 271: foldrOL k z ( Cons x xs ) = a -> b -> b k {VV : a | (VV == x)} x ( forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k {VV : a | (VV == z)} z {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) 272: foldrOL k z ( Snoc xs x ) = forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k ( a -> b -> b k {VV : a | (VV == x)} x {VV : a | (VV == z)} z ) {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs 273: foldrOL k z ( Two b1 b2 ) = forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k ( forall a b. (a -> b -> b) -> b -> (OrdList.OrdList a) -> b foldrOL a -> b -> b k {VV : a | (VV == z)} z {x4 : (OrdList.OrdList a) | (x4 == b2) && ((olen x4) > 0) && ((olen x4) >= 0)} b2 ) {x4 : (OrdList.OrdList a) | (x4 == b1) && ((olen x4) > 0) && ((olen x4) >= 0)} b1 274: foldrOL k z ( Many xs ) = (a -> b -> b) -> b -> [a] -> b foldr a -> b -> b k {VV : a | (VV == z)} z {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs 275: 276: foldlOL :: ( b -> a -> b ) -> b -> OrdList a -> b 277: forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL _ a z None = {VV : a | (VV == z)} z 278: foldlOL k z ( One x ) = a -> b -> a k {VV : a | (VV == z)} z {VV : a | (VV == x)} x 279: foldlOL k z ( Cons x xs ) = forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k ( a -> b -> a k {VV : a | (VV == z)} z {VV : a | (VV == x)} x ) {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs 280: foldlOL k z ( Snoc xs x ) = a -> b -> a k ( forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k {VV : a | (VV == z)} z {x3 : (OrdList.OrdList a) | (x3 == xs) && ((olen x3) >= 0)} xs ) {VV : a | (VV == x)} x 281: foldlOL k z ( Two b1 b2 ) = forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k ( forall a b. (a -> b -> a) -> a -> (OrdList.OrdList b) -> a foldlOL a -> b -> a k {VV : a | (VV == z)} z {x4 : (OrdList.OrdList a) | (x4 == b1) && ((olen x4) > 0) && ((olen x4) >= 0)} b1 ) {x4 : (OrdList.OrdList a) | (x4 == b2) && ((olen x4) > 0) && ((olen x4) >= 0)} b2 282: foldlOL k z ( Many xs ) = (a -> b -> a) -> a -> [b] -> a foldl a -> b -> a k {VV : a | (VV == z)} z {x6 : [a] | (x6 == xs) && ((len x6) > 0) && ((len x6) >= 0) && ((olens x6) >= 0) && ((sumLens x6) >= 0)} xs","title":"Appending OrdLists"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#concatenatation-nested-measures","text":"Now, the astute readers will have probably noticed that I'm missing one function, concatOL , which glues a list of OrdList s into a single long OrdList . With LiquidHaskell we can give concatOL a super precise type, which states that the size of the output list equals the sum-of-the-sizes of the input OrdLists . 298: {-@ concatOL :: xs : [ OrdList a ] -> OrdListN a {(olens xs)} @-} 299: forall a. x1:[(OrdList.OrdList a)] -> {VV : (OrdList.OrdList a) | ((olen VV) == (olens x1))} concatOL [] = forall a. {x2 : (OrdList.OrdList a) | ((olen x2) == 0)} None 300: concatOL ( ol : ols ) = {x3 : (OrdList.OrdList a) | (x3 == ol) && ((olen x3) >= 0)} ol x1:(OrdList.OrdList a) -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} `appOL` forall a. x1:[(OrdList.OrdList a)] -> {VV : (OrdList.OrdList a) | ((olen VV) == (olens x1))} concatOL {x5 : [(OrdList.OrdList a)] | (x5 == ols) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} ols The notion of sum-of-the-sizes of the input lists is specifed by the measure 306: {-@ measure olens :: [ OrdList a ] -> Int 307: olens ( [] ) = 0 308: olens ( ol : ols ) = ( olen ol ) + ( olens ols ) 309: @-} 310: 311: {-@ invariant {v: [ OrdList a ] | (olens v) >= 0} @-} LiquidHaskell is happy to verify the above signature, again without requiring any explict proofs.","title":"Concatenatation: Nested Measures"},{"location":"blogposts/2014-02-11-the-advantage-of-measures.lhs/#conclusion","text":"The above illustrates the flexibility provided by LiquidHaskell measures . Instead of having to bake particular invariants into a datatype using indices or phantom types (as in the GADT approach), we are able to split our properties out into independent views of the datatype, yielding an approach that is more modular as we didn't have to go back and change the definition of [] to talk about OrdList s, we didn't have to provide explict non-emptiness witnesses, we obtained extra information about the behavior of API functions like concatOL . We can actually even verify the original definition of `concatOL` with a clever use of *abstract refinements*, but we have to slightly change the signature of `foldr`. 338: {- UGH CAN'T PARSE `GHC.Types.:`... foldr' :: forall <p :: [a] -> b -> Prop>. (xs:[a] -> x:a -> b<p xs> -> b<p (GHC.Types.: x xs)>) -> b<p GHC.Types.[]> -> ys:[a] -> b<p ys> @-} 345: forall a b. ({VV : [a] | ((len VV) >= 0)} -> a -> b -> b) -> b -> [a] -> b foldr' {VV : [a] | ((len VV) >= 0)} -> a -> b -> b f a z [] = {VV : a | (VV == z)} z 346: foldr' f z ( x : xs ) = {x2 : [a] | ((len x2) >= 0)} -> a -> b -> b f {x5 : [a] | (x5 == xs) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} xs {VV : a | (VV == x)} x ( forall a b. ({VV : [a] | ((len VV) >= 0)} -> a -> b -> b) -> b -> [a] -> b foldr' {x2 : [a] | ((len x2) >= 0)} -> a -> b -> b f {VV : a | (VV == z)} z {x5 : [a] | (x5 == xs) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} xs ) We've added a *ghost parameter* to the folding function, letting us refer to the tail of the list at each folding step. This lets us encode inductive reasoning in the type of `foldr`, specifically that 1. given a base case `z` that satisfies `p []` 2. and a function that, given a value that satisfies `p xs`, returns a value satisfying `p (x:xs)` 3. the value returned by `foldr f z ys` must satisfy `p ys`! LiquidHaskell can use this signature, instantiating `p` with `\\xs -> {v:OrdList a | (olen v) = (olens xs)}` to prove the original definition of `concatOL`! 363: {- concatOL' :: xs:[OrdList a] -> OrdListN a {(olens xs)} @-} 364: forall a. [(OrdList.OrdList a)] -> (OrdList.OrdList a) concatOL' [(OrdList.OrdList a)] aas = ([(OrdList.OrdList a)] -> (OrdList.OrdList a) -> (OrdList.OrdList a) -> (OrdList.OrdList a)) -> (OrdList.OrdList a) -> [(OrdList.OrdList a)] -> (OrdList.OrdList a) foldr' ( (x5:(OrdList.OrdList a) -> x6:(OrdList.OrdList a) -> {x15 : (OrdList.OrdList a) | ((olen x15) == ((olen x5) + (olen x6))) && ((olen x15) == ((olen x6) + (olen x5)))}) -> [(OrdList.OrdList a)] -> x5:(OrdList.OrdList a) -> x6:(OrdList.OrdList a) -> {x15 : (OrdList.OrdList a) | ((olen x15) == ((olen x5) + (olen x6))) && ((olen x15) == ((olen x6) + (olen x5)))} const x1:(OrdList.OrdList a) -> x2:(OrdList.OrdList a) -> {x2 : (OrdList.OrdList a) | ((olen x2) == ((olen x1) + (olen x2)))} appOL ) {x3 : (OrdList.OrdList {VV : a | false}) | ((olen x3) == 0) && ((olen x3) >= 0)} None {x5 : [(OrdList.OrdList a)] | (x5 == aas) && ((len x5) >= 0) && ((olens x5) >= 0) && ((sumLens x5) >= 0)} aas We haven't added the modified version of `foldr` to the LiquidHaskell Prelude yet because it adds the ghost variable to the Haskell type-signature.","title":"Conclusion"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/","text":"A large part of the allure of Haskell is its elegant, high-level ADTs that ensure 1 that programs won't be plagued by problems like the infamous SSL heartbleed bug . However, another part of Haskell's charm is that when you really really need to, you can drop down to low-level pointer twiddling to squeeze the most performance out of your machine. But of course, that opens the door to the #heartbleeds. Can we have have our cake and eat it too? Can we twiddle pointers and still get the nice safety assurances of high-level types? To understand the potential for potential bleeding, let's study the popular text library for efficient text processing. The library provides the high-level API Haskellers have come to expect while using stream fusion and byte arrays under the hood to guarantee high performance. Suppose we wanted to get the i th Char of a Text , we could write a function 2 39: charAt ( Text a o l ) i = word2char $ unsafeIndex a ( o + i ) 40: where 41: word2char = chr . fromIntegral which extracts the underlying array a , indexes into it starting at the offset o and casts the Word16 to a Char , using functions exported by text . Let's try this out in GHCi. 50: ghci > let t = pack [ 'd' , 'o' , 'g' ] 51: ghci > charAt t 0 52: 'd' 53: ghci > charAt t 2 54: 'g' Looks good so far, what happens if we keep going? 58: ghci > charAt t 3 59: '\\NUL' 60: ghci > charAt t 100 61: '\\8745' Oh dear, not only did we not get any sort of exception from Haskell, we weren't even stopped by the OS with a segfault. This is quite dangerous since we have no idea what sort of data we just read! To be fair to the library's authors, we did use a function that was clearly branded unsafe , but these functions, while not intended for clients , pervade the implementation of the library . Wouldn't it be nice to have these last two calls rejected at compile time ? In this post we'll see exactly how prevent invalid memory accesses like this with LiquidHaskell. 80: {-# LANGUAGE BangPatterns, MagicHash, Rank2Types, RecordWildCards, UnboxedTuples, ExistentialQuantification #-} 82: {-@ LIQUID \"--no-termination\" @-} 83: module TextInternal ( test , goodMain , badMain , charAt , charAt' ) where 84: 85: import qualified Control . Exception as Ex 86: import Control . Applicative ( ( <$> ) ) 87: import Control . Monad ( when ) 88: import Control . Monad . ST . Unsafe ( unsafeIOToST ) 89: import Data . Bits ( shiftR , xor , ( .&. ) ) 90: import Data . Char 91: import Foreign . C . Types ( CSize ) 92: import GHC . Base ( Int ( .. ) , ByteArray # , MutableByteArray # , newByteArray # , 93: writeWord16Array # , indexWord16Array # , unsafeCoerce # , ord , 94: iShiftL # ) 95: import GHC . ST ( ST ( .. ) , runST ) 96: import GHC . Word ( Word16 ( .. ) ) 97: 98: import qualified Data . Text . Lazy . IO as TIO 99: import qualified Data . Text as T 100: import qualified Data . Text . Internal as T 101: 102: import Language . Haskell . Liquid . Prelude 103: 104: {-@ aLen :: a : Array -> {v: Nat | v = (aLen a)} @-} 105: 106: {-@ maLen :: a : MArray s -> {v: Nat | v = (maLen a)} @-} 107: 108: new :: forall s . Int -> ST s ( MArray s ) 109: unsafeWrite :: MArray s -> Int -> Word16 -> ST s () 110: unsafeFreeze :: MArray s -> ST s Array 111: unsafeIndex :: Array -> Int -> Word16 112: copyM :: MArray s -- ^ Destination 113: -> Int -- ^ Destination offset 114: -> MArray s -- ^ Source 115: -> Int -- ^ Source offset 116: -> Int -- ^ Count 117: -> ST s () 118: 119: {-@ memcpyM :: MutableByteArray # s -> CSize -> MutableByteArray # s -> CSize -> CSize -> IO () @-} 120: memcpyM :: MutableByteArray # s -> CSize -> MutableByteArray # s -> CSize -> CSize -> IO () 121: forall a. (MutableByteArray# a) -> CSize -> (MutableByteArray# a) -> CSize -> CSize -> (IO ()) memcpyM = forall a. a undefined 122: 123: -------------------------------------------------------------------------------- 124: --- Helper Code 125: -------------------------------------------------------------------------------- 126: {-@ shiftL :: i : Nat -> n : Nat -> {v: Nat | ((n = 1) => (v = (i * 2)))} @-} 127: shiftL :: Int -> Int -> Int 128: x1:{v : Int | (v >= 0)} -> x2:{v : Int | (v >= 0)} -> {v : Int | ((x2 == 1) => (v == (x1 * 2))) && (v >= 0)} shiftL = forall a. a undefined -- (I# x#) (I# i#) = I# (x# `iShiftL#` i#) 129: 130: pack :: String -> Text 131: x1:[Char] -> {v : Text | ((tLen v) == (len x1))} pack = forall a. a undefined -- not \"actually\" using 132: 133: forall a. {v : Bool | ((Prop v))} -> a -> a assert {v : Bool | ((Prop v))} b a a = Bool -> a -> a Ex . assert {x3 : Bool | ((Prop x3)) && (x3 == b)} b {VV : a | (VV == a)} a 134: 135: 136: data Text = Text Array Int Int 137: 138: {-@ tLength :: t : Text -> {v: _ | v = (tLen t)} @-} 139: x1:Text -> {v : Int | (v == (tLen x1))} tLength ( Text _ _ n ) = {x3 : Int | (x3 == n) && (x3 >= 0)} n The Text Lifecycle \u00b6 text splits the reading and writing array operations between two types of arrays, immutable Array s and mutable MArray s. This leads to the following general lifecycle: The main four array operations we care about are: creating an MArray , writing into an MArray , freezing an MArray into an Array , and reading from an Array . Creating an MArray \u00b6 The (mutable) MArray is a thin wrapper around GHC's primitive MutableByteArray# , additionally carrying the number of Word16 s it can store. 167: data MArray s = MArray { forall a. (MArray a) -> (MutableByteArray# a) maBA :: MutableByteArray # s 168: , forall a. x1:(MArray a) -> {v : Int | (v == (maLen x1)) && (v >= 0)} maLen :: ! Int 169: } It doesn't make any sense to have a negative length, so we refine the data definition to require that maLen be non-negative. 176: {-@ data MArray s = MArray { maBA :: MutableByteArray # s 177: , maLen :: Nat 178: } 179: @-} As an added bonus, the above specification generates field-accessor measures that we will use inside the refined types: 184: {-@ measure maLen :: MArray s -> Int 185: maLen ( MArray a l ) = l 186: @-} We can use these accessor measures to define MArray s of size N : 192: {-@ type MArrayN a N = { v : MArray a | ( maLen v ) = N } @-} and we can use the above alias, to write a type that tracks the size of an MArray at the point where it is created: 199: {-@ new :: forall s . n : Nat -> ST s ( MArrayN s n ) @-} 200: forall a. x1:{v : Int | (v >= 0)} -> (ST a {v : (MArray a) | ((maLen v) == x1)}) new {v : Int | (v >= 0)} n 201: | {x3 : Int | (x3 == n) && (x3 >= 0)} n x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x3 : Int | (x3 == n) && (x3 >= 0)} n Int -> Int -> Int .&. {x2 : Int | (x2 == highBit)} highBit x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 /= x2))} /= {x2 : Int | (x2 == (0 : int))} 0 = [Char] -> {x1 : (ST a {x2 : (MArray a) | false}) | false} error {x2 : [Char] | ((len x2) >= 0)} \"size overflow\" 202: | otherwise = ((State# a) -> ((State# a), {x7 : (MArray a) | ((maLen x7) == n)})) -> (ST a {x3 : (MArray a) | ((maLen x3) == n)}) ST (((State# a) -> ((State# a), {x17 : (MArray a) | ((maLen x17) == n)})) -> (ST a {x12 : (MArray a) | ((maLen x12) == n)})) -> ((State# a) -> ((State# a), {x17 : (MArray a) | ((maLen x17) == n)})) -> (ST a {x12 : (MArray a) | ((maLen x12) == n)}) $ \\ (State# a) s1 # -> 203: case Int# -> (State# a) -> ((State# a), (MutableByteArray# a)) newByteArray # {x2 : Int# | (x2 == len)} len # {x2 : (State# a) | (x2 == s1)} s1 # of 204: ( # s2 # , marr # # ) -> forall a b. a -> b -> (a, b) ( # {x2 : (State# a) | (x2 == s2)} s2 # , x1:(MutableByteArray# a) -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : (MArray a) | ((maBA x3) == x1) && ((maLen x3) == x2)} MArray {x2 : (MutableByteArray# a) | (x2 == marr)} marr # {x3 : Int | (x3 == n) && (x3 >= 0)} n # ) 205: where ! ( I # len # ) = x1:{x11 : Int | (x11 == n) && (x11 >= 0)} -> {x8 : Int | ((x1 == 1) => (x8 == (x1 * 2))) && ((x1 == 1) => (x8 == (n * 2))) && ((n == 1) => (x8 == (x1 * 2))) && ((n == 1) => (x8 == (n * 2))) && (x8 >= 0) && (x8 >= x1) && (x8 >= n)} bytesInArray {x3 : Int | (x3 == n) && (x3 >= 0)} n 206: Int highBit = Int maxBound Int -> Int -> Int `xor` ( Int maxBound Int -> Int -> Int `shiftR` {x2 : Int | (x2 == (1 : int))} 1 ) 207: n:{VV : Int | (VV == n) && (VV >= 0)} -> {VV : Int | ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && (VV >= 0) && (VV >= n) && (VV >= n)} bytesInArray {VV : Int | (VV == n) && (VV >= 0)} n = {x4 : Int | (x4 == n) && (x4 == n) && (x4 >= 0)} n x1:{x7 : Int | (x7 >= 0)} -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : Int | ((x2 == 1) => (x3 == (x1 * 2))) && (x3 >= 0)} `shiftL` {x2 : Int | (x2 == (1 : int))} 1 new n is an ST action that produces an MArray s with n slots each of which is 2 bytes (as internally text manipulates Word16 s). The verification process here is quite simple; LH recognizes that the n used to construct the returned array ( MArray marr# n ) the same n passed to new . Writing into an MArray \u00b6 Once we have created an MArray , we'll want to write our data into it. A Nat is a valid index into an MArray if it is strictly less than the size of the array. 226: {-@ type MAValidI MA = { v : Nat | v < ( maLen MA ) } @-} We use this valid index alias to refine the type of unsafeWrite 232: {-@ unsafeWrite :: ma : MArray s -> MAValidI ma -> Word16 -> ST s () @-} 233: forall a. x1:(MArray a) -> {v : Int | (v >= 0) && (v < (maLen x1))} -> Word16 -> (ST a ()) unsafeWrite MArray { .. } {v : Int | (v >= 0)} i @ ( I # i # ) ( W16 # e # ) 234: | {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 >= x2))} >= {x2 : Int | (x2 >= 0)} maLen = {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert {x3 : Bool | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False ((ST a ()) -> (ST a ())) -> (ST a ()) -> (ST a ()) $ [Char] -> (ST a ()) error {x2 : [Char] | ((len x2) >= 0)} \"out of bounds\" 235: | otherwise = ((State# a) -> ((State# a), ())) -> (ST a ()) ST (((State# a) -> ((State# a), ())) -> (ST a ())) -> ((State# a) -> ((State# a), ())) -> (ST a ()) $ \\ (State# a) s1 # -> 236: case (MutableByteArray# a) -> Int# -> Word# -> (State# a) -> (State# a) writeWord16Array # (MutableByteArray# a) maBA {x2 : Int# | (x2 == i)} i # {x2 : Word# | (x2 == e)} e # {x2 : (State# a) | (x2 == s1)} s1 # of 237: s2 # -> forall a b. a -> b -> (a, b) ( # (State# a) s2 # , {x2 : () | (x2 == GHC.Tuple.())} () # ) Note that, when compiled with appropriate options, the implementation of text checks the bounds at run-time. However, LiquidHaskell can statically prove that the error branch is unreachable, i.e. the assert cannot fail (as long as the inputs adhere to the given specification) by giving assert the type: 247: {-@ assert assert :: {v: Bool | (Prop v)} -> a -> a @-} Bulk Writing into an MArray \u00b6 So now we can write individual Word16 s into an array, but maybe we have a whole bunch of text we want to dump into the array. Remember, text is supposed to be fast! C has memcpy for cases like this but it's notoriously unsafe; with the right type however, we can regain safety. text provides a wrapper around memcpy to copy n elements from one MArray to another. copyM requires two MArray s and valid offsets into each -- note that a valid offset is not necessarily a valid index , it may be one element out-of-bounds 265: {-@ type MAValidO MA = { v : Nat | v <= ( maLen MA ) } @-} -- and a count of elements to copy. The count must represent a valid region in each MArray , in other words offset + count <= length must hold for each array. 273: {-@ copyM :: dest : MArray s 274: -> didx : MAValidO dest 275: -> src : MArray s 276: -> sidx : MAValidO src 277: -> {v: Nat | (((didx + v) <= (maLen dest)) && ((sidx + v) <= (maLen src)))} 279: -> ST s () 280: @-} 281: forall a. x1:(MArray a) -> x2:{v : Int | (v >= 0) && (v <= (maLen x1))} -> x3:(MArray a) -> x4:{v : Int | (v >= 0) && (v <= (maLen x3))} -> {v : Int | (v >= 0) && ((x2 + v) <= (maLen x1)) && ((x4 + v) <= (maLen x3))} -> (ST a ()) copyM (MArray a) dest {v : Int | (v >= 0) && (v <= (maLen dest))} didx (MArray a) src {v : Int | (v >= 0) && (v <= (maLen src))} sidx {v : Int | (v >= 0) && ((didx + v) <= (maLen dest)) && ((sidx + v) <= (maLen src))} count 282: | {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == (0 : int))} 0 = () -> (ST a ()) return {x2 : () | (x2 == GHC.Tuple.())} () 283: | otherwise = 284: {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert ( {x4 : Int | (x4 == sidx) && (x4 >= 0) && (x4 <= (maLen src))} sidx x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= x1:(MArray a) -> {x3 : Int | (x3 == (maLen x1)) && (x3 >= 0)} maLen {x2 : (MArray a) | (x2 == src)} src ) ((ST a ()) -> (ST a ())) -> ((IO ()) -> (ST a ())) -> (IO ()) -> exists [(ST a ())].(ST a ()) . 285: {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert ( {x4 : Int | (x4 == didx) && (x4 >= 0) && (x4 <= (maLen dest))} didx x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= x1:(MArray a) -> {x3 : Int | (x3 == (maLen x1)) && (x3 >= 0)} maLen {x2 : (MArray a) | (x2 == dest)} dest ) ((ST a ()) -> (ST a ())) -> ((IO ()) -> (ST a ())) -> (IO ()) -> exists [(ST a ())].(ST a ()) . 286: (IO ()) -> (ST a ()) unsafeIOToST ((IO ()) -> (ST a ())) -> (IO ()) -> (ST a ()) $ (MutableByteArray# a) -> CSize -> (MutableByteArray# a) -> CSize -> CSize -> (IO ()) memcpyM ( (MArray a) -> (MutableByteArray# a) maBA {x2 : (MArray a) | (x2 == dest)} dest ) ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x4 : Int | (x4 == didx) && (x4 >= 0) && (x4 <= (maLen dest))} didx ) 287: ( (MArray a) -> (MutableByteArray# a) maBA {x2 : (MArray a) | (x2 == src)} src ) ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x4 : Int | (x4 == sidx) && (x4 >= 0) && (x4 <= (maLen src))} sidx ) 288: ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count ) Again, the two assert s in the function were in the original code as (optionally compiled out) run-time checks of the precondition, but with LiquidHaskell we can actually prove that the assert s always succeed . Freezing an MArray into an Array \u00b6 Before we can package up our MArray into a Text , we need to freeze it, preventing any further mutation. The key property here is of course that the frozen Array should have the same length as the MArray . Just as MArray wraps a mutable array, Array wraps an immutable ByteArray# and carries its length in Word16 s. 307: data Array = Array { Array -> ByteArray# aBA :: ByteArray # 308: , x1:Array -> {v : Int | (v == (aLen x1)) && (v >= 0)} aLen :: ! Int 309: } As before, we get free accessor measures aBA and aLen just by refining the data definition 316: {-@ data Array = Array { aBA :: ByteArray # 317: , aLen :: Nat 318: } 319: @-} so we can refer to the components of an Array in our refinements. Using these measures, we can define 326: {-@ type ArrayN N = { v : Array | ( aLen v ) = N } @-} 327: {-@ unsafeFreeze :: ma : MArray s -> ST s ( ArrayN ( maLen ma ) ) @-} 328: forall a. x1:(MArray a) -> (ST a {v : Array | ((aLen v) == (maLen x1))}) unsafeFreeze MArray { .. } = ((State# a) -> ((State# a), {x5 : Array | false})) -> (ST a {x2 : Array | false}) ST (((State# a) -> {x11 : ((State# a), {x13 : Array | false}) | false}) -> (ST a {x9 : Array | false})) -> ((State# a) -> {x11 : ((State# a), {x13 : Array | false}) | false}) -> (ST a {x9 : Array | false}) $ \\ (State# a) s # -> 329: forall a b. a -> b -> (a, b) ( # {x2 : (State# a) | (x2 == s)} s # , x1:ByteArray# -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : Array | ((aBA x3) == x1) && ((aLen x3) == x2)} Array ( (MutableByteArray# a) -> {x1 : ByteArray# | false} unsafeCoerce # (MutableByteArray# a) maBA ) {x2 : Int | (x2 >= 0)} maLen # ) Again, LiquidHaskell is happy to prove our specification as we simply copy the length parameter maLen over into the Array . Reading from an Array \u00b6 Finally, we will eventually want to read a value out of the Array . As with unsafeWrite we require a valid index into the Array , which we denote using the AValidI alias. 342: {-@ type AValidI A = { v : Nat | v < ( aLen A ) } @-} 343: {-@ unsafeIndex :: a : Array -> AValidI a -> Word16 @-} 344: x1:Array -> {v : Int | (v >= 0) && (v < (aLen x1))} -> Word16 unsafeIndex Array { .. } {v : Int | (v >= 0)} i @ ( I # i # ) 345: | {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 >= x2))} >= {x2 : Int | (x2 >= 0)} aLen = {x4 : Bool | ((Prop x4))} -> Word16 -> Word16 assert {x3 : Bool | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False (Word16 -> Word16) -> Word16 -> Word16 $ [Char] -> Word16 error {x2 : [Char] | ((len x2) >= 0)} \"out of bounds\" 346: | otherwise = case ByteArray# -> Int# -> Word# indexWord16Array # ByteArray# aBA {x2 : Int# | (x2 == i)} i # of 347: r # -> ( Word# -> Word16 W16 # Word# r # ) As before, LiquidHaskell can easily prove that the error branch is unreachable, i.e. is never executed at run-time. Wrapping it all up \u00b6 Now we can finally define the core datatype of the text package! A Text value consists of three fields: A. an Array , B. an Int offset into the middle of the array, and C. an Int length denoting the number of valid indices after the offset. We can specify the invariants for fields (b) and (c) with the refined type: 368: {-@ data Text 369: = Text { tArr :: Array 370: , tOff :: { v : Nat | v <= ( aLen tArr ) } 371: , tLen :: { v : Nat | v + tOff <= ( aLen tArr ) } 372: } 373: @-} These invariants ensure that any index we pick between tOff and tOff + tLen will be a valid index into tArr . As shown above with new , unsafeWrite , and unsafeFreeze , we can type the top-level function that creates a Text from a [Char] as: 383: {-@ pack :: s : String -> {v: Text | (tLen v) = (len s)} @-} Preventing Bleeds \u00b6 Now, let us close the circle and return to potentially bleeding function: 392: Text -> Int -> Char charAt' ( Text a o l ) Int i = Word16 -> exists [Int].Char word2char (Word16 -> Char) -> Word16 -> Char $ x1:Array -> {x4 : Int | (x4 >= 0) && (x4 < (aLen x1))} -> Word16 unsafeIndex {x2 : Array | (x2 == a)} a ( {x4 : Int | (x4 == o) && (x4 >= 0) && (x4 <= (aLen a))} o x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x2 : Int | (x2 == i)} i ) 393: where 394: Word16 -> exists [Int].Char word2char = Int -> Char chr (Int -> Char) -> (Word16 -> Int) -> Word16 -> exists [Int].Char . x1:Word16 -> {x2 : Int | (x2 == x1)} fromIntegral Aha! LiquidHaskell flags the call to unsafeIndex because of course, i may fall outside the bounds of the given array a ! We can remedy that by specifying a bound for the index: 402: {-@ charAt :: t : Text -> {v: Nat | v < (tLen t)} -> Char @-} 403: x1:Text -> {v : Int | (v >= 0) && (v < (tLen x1))} -> Char charAt ( Text a o l ) {v : Int | (v >= 0)} i = Word16 -> exists [Int].Char word2char (Word16 -> Char) -> Word16 -> Char $ x1:Array -> {x4 : Int | (x4 >= 0) && (x4 < (aLen x1))} -> Word16 unsafeIndex {x2 : Array | (x2 == a)} a ( {x4 : Int | (x4 == o) && (x4 >= 0) && (x4 <= (aLen a))} o x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x3 : Int | (x3 == i) && (x3 >= 0)} i ) 404: where 405: Word16 -> exists [Int].Char word2char = Int -> Char chr (Int -> Char) -> (Word16 -> Int) -> Word16 -> exists [Int].Char . x1:Word16 -> {x2 : Int | (x2 == x1)} fromIntegral That is, we can access the i th Char as long as i is a Nat less than the the size of the text, namely tLen t . Now LiquidHaskell is convinced that the call to unsafeIndex is safe, but of course, we have passed the burden of proof onto users of charAt . Now, if we try calling charAt as we did at the beginning 416: [Char] test = {x3 : [Char] | (((null x3)) <=> false) && ((len x3) >= 0)} [ {x2 : Char | (x2 == good)} good , {x2 : Char | (x2 == bad)} bad ] 417: where 418: {x2 : [Char] | (((null x2)) <=> false)} dog = {x2 : [Char] | (((null x2)) <=> false)} [ Char 'd' , Char 'o' , Char 'g' ] 419: Char good = x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt ( x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack {x4 : [Char] | (((null x4)) <=> false) && (x4 == dog) && ((len x4) >= 0)} dog ) {x2 : Int | (x2 == (2 : int))} 2 420: Char bad = x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt ( x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack {x4 : [Char] | (((null x4)) <=> false) && (x4 == dog) && ((len x4) >= 0)} dog ) {x2 : Int | (x2 == (3 : int))} 3 we see that LiquidHaskell verifies the good call, but flags bad as unsafe . Enforcing Sanitization \u00b6 EDIT: As several folks have pointed out, the #heartbleed error was due to inputs not being properly sanitized. The above approach ensures, at compile time , that proper sanitization has been performed. To see this in action, lets write a little function that just shows the character at a given position: 438: {-@ showCharAt :: t : _ -> {v: Nat | v < (tLen t)} -> _ @-} 439: x1:Text -> {v : Int | (v >= 0) && (v < (tLen x1))} -> (IO ()) showCharAt Text t {v : Int | (v >= 0) && (v < (tLen t))} i = [Char] -> (IO ()) putStrLn ([Char] -> (IO ())) -> [Char] -> (IO ()) $ Char -> [Char] show (Char -> [Char]) -> Char -> [Char] $ x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt {x2 : Text | (x2 == t)} t {x4 : Int | (x4 == i) && (x4 >= 0) && (x4 < (tLen t))} i Now, the following function, that correctly sanitizes is accepted 445: goodMain :: IO () 446: (IO ()) goodMain 447: = do Text txt <- x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack ([Char] -> Text) -> (IO [Char]) -> (IO Text) <$> {x2 : (IO [Char]) | (x2 == System.IO.getLine)} getLine 448: Int i <- (IO Int) readLn 449: if {x2 : Int | (x2 == (0 : int))} 0 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == i)} i x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) && ((Prop x2))))} && {x2 : Int | (x2 == i)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < x1:Text -> {x2 : Int | (x2 == (tLen x1))} tLength {x2 : Text | (x2 == txt)} txt 450: then x1:Text -> {x5 : Int | (x5 >= 0) && (x5 < (tLen x1))} -> (IO ()) showCharAt {x2 : Text | (x2 == txt)} txt {x2 : Int | (x2 == i)} i 451: else [Char] -> (IO ()) putStrLn {x2 : [Char] | ((len x2) >= 0)} \"Bad Input!\" but this function, which has insufficient sanitization, is rejected 457: badMain :: IO () 458: (IO ()) badMain 459: = do Text txt <- x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack ([Char] -> Text) -> (IO [Char]) -> (IO Text) <$> {x2 : (IO [Char]) | (x2 == System.IO.getLine)} getLine 460: Int i <- (IO Int) readLn 461: if {x2 : Int | (x2 == (0 : int))} 0 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == i)} i 462: then x1:Text -> {x5 : Int | (x5 >= 0) && (x5 < (tLen x1))} -> (IO ()) showCharAt {x2 : Text | (x2 == txt)} txt {x2 : Int | (x2 == i)} i 463: else [Char] -> (IO ()) putStrLn {x2 : [Char] | ((len x2) >= 0)} \"Bad Input!\" Thus, we can use LiquidHaskell to block, at compile time, any serious bleeding from pointers gone wild. Assuming the absence of errors in the compiler and run-time... \u21a9 This function is bad for numerous reasons, least of which is that Data.Text.index is already provided, but stay with us... \u21a9","title":"Pointers Gone Wild"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#the-text-lifecycle","text":"text splits the reading and writing array operations between two types of arrays, immutable Array s and mutable MArray s. This leads to the following general lifecycle: The main four array operations we care about are: creating an MArray , writing into an MArray , freezing an MArray into an Array , and reading from an Array .","title":"The Text Lifecycle"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#creating-an-marray","text":"The (mutable) MArray is a thin wrapper around GHC's primitive MutableByteArray# , additionally carrying the number of Word16 s it can store. 167: data MArray s = MArray { forall a. (MArray a) -> (MutableByteArray# a) maBA :: MutableByteArray # s 168: , forall a. x1:(MArray a) -> {v : Int | (v == (maLen x1)) && (v >= 0)} maLen :: ! Int 169: } It doesn't make any sense to have a negative length, so we refine the data definition to require that maLen be non-negative. 176: {-@ data MArray s = MArray { maBA :: MutableByteArray # s 177: , maLen :: Nat 178: } 179: @-} As an added bonus, the above specification generates field-accessor measures that we will use inside the refined types: 184: {-@ measure maLen :: MArray s -> Int 185: maLen ( MArray a l ) = l 186: @-} We can use these accessor measures to define MArray s of size N : 192: {-@ type MArrayN a N = { v : MArray a | ( maLen v ) = N } @-} and we can use the above alias, to write a type that tracks the size of an MArray at the point where it is created: 199: {-@ new :: forall s . n : Nat -> ST s ( MArrayN s n ) @-} 200: forall a. x1:{v : Int | (v >= 0)} -> (ST a {v : (MArray a) | ((maLen v) == x1)}) new {v : Int | (v >= 0)} n 201: | {x3 : Int | (x3 == n) && (x3 >= 0)} n x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x3 : Int | (x3 == n) && (x3 >= 0)} n Int -> Int -> Int .&. {x2 : Int | (x2 == highBit)} highBit x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 /= x2))} /= {x2 : Int | (x2 == (0 : int))} 0 = [Char] -> {x1 : (ST a {x2 : (MArray a) | false}) | false} error {x2 : [Char] | ((len x2) >= 0)} \"size overflow\" 202: | otherwise = ((State# a) -> ((State# a), {x7 : (MArray a) | ((maLen x7) == n)})) -> (ST a {x3 : (MArray a) | ((maLen x3) == n)}) ST (((State# a) -> ((State# a), {x17 : (MArray a) | ((maLen x17) == n)})) -> (ST a {x12 : (MArray a) | ((maLen x12) == n)})) -> ((State# a) -> ((State# a), {x17 : (MArray a) | ((maLen x17) == n)})) -> (ST a {x12 : (MArray a) | ((maLen x12) == n)}) $ \\ (State# a) s1 # -> 203: case Int# -> (State# a) -> ((State# a), (MutableByteArray# a)) newByteArray # {x2 : Int# | (x2 == len)} len # {x2 : (State# a) | (x2 == s1)} s1 # of 204: ( # s2 # , marr # # ) -> forall a b. a -> b -> (a, b) ( # {x2 : (State# a) | (x2 == s2)} s2 # , x1:(MutableByteArray# a) -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : (MArray a) | ((maBA x3) == x1) && ((maLen x3) == x2)} MArray {x2 : (MutableByteArray# a) | (x2 == marr)} marr # {x3 : Int | (x3 == n) && (x3 >= 0)} n # ) 205: where ! ( I # len # ) = x1:{x11 : Int | (x11 == n) && (x11 >= 0)} -> {x8 : Int | ((x1 == 1) => (x8 == (x1 * 2))) && ((x1 == 1) => (x8 == (n * 2))) && ((n == 1) => (x8 == (x1 * 2))) && ((n == 1) => (x8 == (n * 2))) && (x8 >= 0) && (x8 >= x1) && (x8 >= n)} bytesInArray {x3 : Int | (x3 == n) && (x3 >= 0)} n 206: Int highBit = Int maxBound Int -> Int -> Int `xor` ( Int maxBound Int -> Int -> Int `shiftR` {x2 : Int | (x2 == (1 : int))} 1 ) 207: n:{VV : Int | (VV == n) && (VV >= 0)} -> {VV : Int | ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && ((n == 1) => (VV == (n * 2))) && (VV >= 0) && (VV >= n) && (VV >= n)} bytesInArray {VV : Int | (VV == n) && (VV >= 0)} n = {x4 : Int | (x4 == n) && (x4 == n) && (x4 >= 0)} n x1:{x7 : Int | (x7 >= 0)} -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : Int | ((x2 == 1) => (x3 == (x1 * 2))) && (x3 >= 0)} `shiftL` {x2 : Int | (x2 == (1 : int))} 1 new n is an ST action that produces an MArray s with n slots each of which is 2 bytes (as internally text manipulates Word16 s). The verification process here is quite simple; LH recognizes that the n used to construct the returned array ( MArray marr# n ) the same n passed to new .","title":"Creating an MArray"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#writing-into-an-marray","text":"Once we have created an MArray , we'll want to write our data into it. A Nat is a valid index into an MArray if it is strictly less than the size of the array. 226: {-@ type MAValidI MA = { v : Nat | v < ( maLen MA ) } @-} We use this valid index alias to refine the type of unsafeWrite 232: {-@ unsafeWrite :: ma : MArray s -> MAValidI ma -> Word16 -> ST s () @-} 233: forall a. x1:(MArray a) -> {v : Int | (v >= 0) && (v < (maLen x1))} -> Word16 -> (ST a ()) unsafeWrite MArray { .. } {v : Int | (v >= 0)} i @ ( I # i # ) ( W16 # e # ) 234: | {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 >= x2))} >= {x2 : Int | (x2 >= 0)} maLen = {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert {x3 : Bool | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False ((ST a ()) -> (ST a ())) -> (ST a ()) -> (ST a ()) $ [Char] -> (ST a ()) error {x2 : [Char] | ((len x2) >= 0)} \"out of bounds\" 235: | otherwise = ((State# a) -> ((State# a), ())) -> (ST a ()) ST (((State# a) -> ((State# a), ())) -> (ST a ())) -> ((State# a) -> ((State# a), ())) -> (ST a ()) $ \\ (State# a) s1 # -> 236: case (MutableByteArray# a) -> Int# -> Word# -> (State# a) -> (State# a) writeWord16Array # (MutableByteArray# a) maBA {x2 : Int# | (x2 == i)} i # {x2 : Word# | (x2 == e)} e # {x2 : (State# a) | (x2 == s1)} s1 # of 237: s2 # -> forall a b. a -> b -> (a, b) ( # (State# a) s2 # , {x2 : () | (x2 == GHC.Tuple.())} () # ) Note that, when compiled with appropriate options, the implementation of text checks the bounds at run-time. However, LiquidHaskell can statically prove that the error branch is unreachable, i.e. the assert cannot fail (as long as the inputs adhere to the given specification) by giving assert the type: 247: {-@ assert assert :: {v: Bool | (Prop v)} -> a -> a @-}","title":"Writing into an MArray"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#bulk-writing-into-an-marray","text":"So now we can write individual Word16 s into an array, but maybe we have a whole bunch of text we want to dump into the array. Remember, text is supposed to be fast! C has memcpy for cases like this but it's notoriously unsafe; with the right type however, we can regain safety. text provides a wrapper around memcpy to copy n elements from one MArray to another. copyM requires two MArray s and valid offsets into each -- note that a valid offset is not necessarily a valid index , it may be one element out-of-bounds 265: {-@ type MAValidO MA = { v : Nat | v <= ( maLen MA ) } @-} -- and a count of elements to copy. The count must represent a valid region in each MArray , in other words offset + count <= length must hold for each array. 273: {-@ copyM :: dest : MArray s 274: -> didx : MAValidO dest 275: -> src : MArray s 276: -> sidx : MAValidO src 277: -> {v: Nat | (((didx + v) <= (maLen dest)) && ((sidx + v) <= (maLen src)))} 279: -> ST s () 280: @-} 281: forall a. x1:(MArray a) -> x2:{v : Int | (v >= 0) && (v <= (maLen x1))} -> x3:(MArray a) -> x4:{v : Int | (v >= 0) && (v <= (maLen x3))} -> {v : Int | (v >= 0) && ((x2 + v) <= (maLen x1)) && ((x4 + v) <= (maLen x3))} -> (ST a ()) copyM (MArray a) dest {v : Int | (v >= 0) && (v <= (maLen dest))} didx (MArray a) src {v : Int | (v >= 0) && (v <= (maLen src))} sidx {v : Int | (v >= 0) && ((didx + v) <= (maLen dest)) && ((sidx + v) <= (maLen src))} count 282: | {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == (0 : int))} 0 = () -> (ST a ()) return {x2 : () | (x2 == GHC.Tuple.())} () 283: | otherwise = 284: {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert ( {x4 : Int | (x4 == sidx) && (x4 >= 0) && (x4 <= (maLen src))} sidx x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= x1:(MArray a) -> {x3 : Int | (x3 == (maLen x1)) && (x3 >= 0)} maLen {x2 : (MArray a) | (x2 == src)} src ) ((ST a ()) -> (ST a ())) -> ((IO ()) -> (ST a ())) -> (IO ()) -> exists [(ST a ())].(ST a ()) . 285: {x6 : Bool | ((Prop x6))} -> (ST a ()) -> (ST a ()) assert ( {x4 : Int | (x4 == didx) && (x4 >= 0) && (x4 <= (maLen dest))} didx x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= x1:(MArray a) -> {x3 : Int | (x3 == (maLen x1)) && (x3 >= 0)} maLen {x2 : (MArray a) | (x2 == dest)} dest ) ((ST a ()) -> (ST a ())) -> ((IO ()) -> (ST a ())) -> (IO ()) -> exists [(ST a ())].(ST a ()) . 286: (IO ()) -> (ST a ()) unsafeIOToST ((IO ()) -> (ST a ())) -> (IO ()) -> (ST a ()) $ (MutableByteArray# a) -> CSize -> (MutableByteArray# a) -> CSize -> CSize -> (IO ()) memcpyM ( (MArray a) -> (MutableByteArray# a) maBA {x2 : (MArray a) | (x2 == dest)} dest ) ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x4 : Int | (x4 == didx) && (x4 >= 0) && (x4 <= (maLen dest))} didx ) 287: ( (MArray a) -> (MutableByteArray# a) maBA {x2 : (MArray a) | (x2 == src)} src ) ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x4 : Int | (x4 == sidx) && (x4 >= 0) && (x4 <= (maLen src))} sidx ) 288: ( x1:Int -> {x2 : CSize | (x2 == x1)} fromIntegral {x5 : Int | (x5 == count) && (x5 >= 0) && ((didx + x5) <= (maLen dest)) && ((sidx + x5) <= (maLen src))} count ) Again, the two assert s in the function were in the original code as (optionally compiled out) run-time checks of the precondition, but with LiquidHaskell we can actually prove that the assert s always succeed .","title":"Bulk Writing into an MArray"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#freezing-an-marray-into-an-array","text":"Before we can package up our MArray into a Text , we need to freeze it, preventing any further mutation. The key property here is of course that the frozen Array should have the same length as the MArray . Just as MArray wraps a mutable array, Array wraps an immutable ByteArray# and carries its length in Word16 s. 307: data Array = Array { Array -> ByteArray# aBA :: ByteArray # 308: , x1:Array -> {v : Int | (v == (aLen x1)) && (v >= 0)} aLen :: ! Int 309: } As before, we get free accessor measures aBA and aLen just by refining the data definition 316: {-@ data Array = Array { aBA :: ByteArray # 317: , aLen :: Nat 318: } 319: @-} so we can refer to the components of an Array in our refinements. Using these measures, we can define 326: {-@ type ArrayN N = { v : Array | ( aLen v ) = N } @-} 327: {-@ unsafeFreeze :: ma : MArray s -> ST s ( ArrayN ( maLen ma ) ) @-} 328: forall a. x1:(MArray a) -> (ST a {v : Array | ((aLen v) == (maLen x1))}) unsafeFreeze MArray { .. } = ((State# a) -> ((State# a), {x5 : Array | false})) -> (ST a {x2 : Array | false}) ST (((State# a) -> {x11 : ((State# a), {x13 : Array | false}) | false}) -> (ST a {x9 : Array | false})) -> ((State# a) -> {x11 : ((State# a), {x13 : Array | false}) | false}) -> (ST a {x9 : Array | false}) $ \\ (State# a) s # -> 329: forall a b. a -> b -> (a, b) ( # {x2 : (State# a) | (x2 == s)} s # , x1:ByteArray# -> x2:{x5 : Int | (x5 >= 0)} -> {x3 : Array | ((aBA x3) == x1) && ((aLen x3) == x2)} Array ( (MutableByteArray# a) -> {x1 : ByteArray# | false} unsafeCoerce # (MutableByteArray# a) maBA ) {x2 : Int | (x2 >= 0)} maLen # ) Again, LiquidHaskell is happy to prove our specification as we simply copy the length parameter maLen over into the Array .","title":"Freezing an MArray into an Array"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#reading-from-an-array","text":"Finally, we will eventually want to read a value out of the Array . As with unsafeWrite we require a valid index into the Array , which we denote using the AValidI alias. 342: {-@ type AValidI A = { v : Nat | v < ( aLen A ) } @-} 343: {-@ unsafeIndex :: a : Array -> AValidI a -> Word16 @-} 344: x1:Array -> {v : Int | (v >= 0) && (v < (aLen x1))} -> Word16 unsafeIndex Array { .. } {v : Int | (v >= 0)} i @ ( I # i # ) 345: | {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < {x2 : Int | (x2 == (0 : int))} 0 x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) || ((Prop x2))))} || {x5 : Int | (x5 == i) && (x5 == i) && (x5 == (i : int)) && (x5 >= 0)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 >= x2))} >= {x2 : Int | (x2 >= 0)} aLen = {x4 : Bool | ((Prop x4))} -> Word16 -> Word16 assert {x3 : Bool | (not (((Prop x3)))) && (x3 == GHC.Types.False)} False (Word16 -> Word16) -> Word16 -> Word16 $ [Char] -> Word16 error {x2 : [Char] | ((len x2) >= 0)} \"out of bounds\" 346: | otherwise = case ByteArray# -> Int# -> Word# indexWord16Array # ByteArray# aBA {x2 : Int# | (x2 == i)} i # of 347: r # -> ( Word# -> Word16 W16 # Word# r # ) As before, LiquidHaskell can easily prove that the error branch is unreachable, i.e. is never executed at run-time.","title":"Reading from an Array"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#wrapping-it-all-up","text":"Now we can finally define the core datatype of the text package! A Text value consists of three fields: A. an Array , B. an Int offset into the middle of the array, and C. an Int length denoting the number of valid indices after the offset. We can specify the invariants for fields (b) and (c) with the refined type: 368: {-@ data Text 369: = Text { tArr :: Array 370: , tOff :: { v : Nat | v <= ( aLen tArr ) } 371: , tLen :: { v : Nat | v + tOff <= ( aLen tArr ) } 372: } 373: @-} These invariants ensure that any index we pick between tOff and tOff + tLen will be a valid index into tArr . As shown above with new , unsafeWrite , and unsafeFreeze , we can type the top-level function that creates a Text from a [Char] as: 383: {-@ pack :: s : String -> {v: Text | (tLen v) = (len s)} @-}","title":"Wrapping it all up"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#preventing-bleeds","text":"Now, let us close the circle and return to potentially bleeding function: 392: Text -> Int -> Char charAt' ( Text a o l ) Int i = Word16 -> exists [Int].Char word2char (Word16 -> Char) -> Word16 -> Char $ x1:Array -> {x4 : Int | (x4 >= 0) && (x4 < (aLen x1))} -> Word16 unsafeIndex {x2 : Array | (x2 == a)} a ( {x4 : Int | (x4 == o) && (x4 >= 0) && (x4 <= (aLen a))} o x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x2 : Int | (x2 == i)} i ) 393: where 394: Word16 -> exists [Int].Char word2char = Int -> Char chr (Int -> Char) -> (Word16 -> Int) -> Word16 -> exists [Int].Char . x1:Word16 -> {x2 : Int | (x2 == x1)} fromIntegral Aha! LiquidHaskell flags the call to unsafeIndex because of course, i may fall outside the bounds of the given array a ! We can remedy that by specifying a bound for the index: 402: {-@ charAt :: t : Text -> {v: Nat | v < (tLen t)} -> Char @-} 403: x1:Text -> {v : Int | (v >= 0) && (v < (tLen x1))} -> Char charAt ( Text a o l ) {v : Int | (v >= 0)} i = Word16 -> exists [Int].Char word2char (Word16 -> Char) -> Word16 -> Char $ x1:Array -> {x4 : Int | (x4 >= 0) && (x4 < (aLen x1))} -> Word16 unsafeIndex {x2 : Array | (x2 == a)} a ( {x4 : Int | (x4 == o) && (x4 >= 0) && (x4 <= (aLen a))} o x1:Int -> x2:Int -> {x4 : Int | (x4 == (x1 + x2))} + {x3 : Int | (x3 == i) && (x3 >= 0)} i ) 404: where 405: Word16 -> exists [Int].Char word2char = Int -> Char chr (Int -> Char) -> (Word16 -> Int) -> Word16 -> exists [Int].Char . x1:Word16 -> {x2 : Int | (x2 == x1)} fromIntegral That is, we can access the i th Char as long as i is a Nat less than the the size of the text, namely tLen t . Now LiquidHaskell is convinced that the call to unsafeIndex is safe, but of course, we have passed the burden of proof onto users of charAt . Now, if we try calling charAt as we did at the beginning 416: [Char] test = {x3 : [Char] | (((null x3)) <=> false) && ((len x3) >= 0)} [ {x2 : Char | (x2 == good)} good , {x2 : Char | (x2 == bad)} bad ] 417: where 418: {x2 : [Char] | (((null x2)) <=> false)} dog = {x2 : [Char] | (((null x2)) <=> false)} [ Char 'd' , Char 'o' , Char 'g' ] 419: Char good = x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt ( x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack {x4 : [Char] | (((null x4)) <=> false) && (x4 == dog) && ((len x4) >= 0)} dog ) {x2 : Int | (x2 == (2 : int))} 2 420: Char bad = x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt ( x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack {x4 : [Char] | (((null x4)) <=> false) && (x4 == dog) && ((len x4) >= 0)} dog ) {x2 : Int | (x2 == (3 : int))} 3 we see that LiquidHaskell verifies the good call, but flags bad as unsafe .","title":"Preventing Bleeds"},{"location":"blogposts/2014-05-28-pointers-gone-wild.lhs/#enforcing-sanitization","text":"EDIT: As several folks have pointed out, the #heartbleed error was due to inputs not being properly sanitized. The above approach ensures, at compile time , that proper sanitization has been performed. To see this in action, lets write a little function that just shows the character at a given position: 438: {-@ showCharAt :: t : _ -> {v: Nat | v < (tLen t)} -> _ @-} 439: x1:Text -> {v : Int | (v >= 0) && (v < (tLen x1))} -> (IO ()) showCharAt Text t {v : Int | (v >= 0) && (v < (tLen t))} i = [Char] -> (IO ()) putStrLn ([Char] -> (IO ())) -> [Char] -> (IO ()) $ Char -> [Char] show (Char -> [Char]) -> Char -> [Char] $ x1:Text -> {x4 : Int | (x4 >= 0) && (x4 < (tLen x1))} -> Char charAt {x2 : Text | (x2 == t)} t {x4 : Int | (x4 == i) && (x4 >= 0) && (x4 < (tLen t))} i Now, the following function, that correctly sanitizes is accepted 445: goodMain :: IO () 446: (IO ()) goodMain 447: = do Text txt <- x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack ([Char] -> Text) -> (IO [Char]) -> (IO Text) <$> {x2 : (IO [Char]) | (x2 == System.IO.getLine)} getLine 448: Int i <- (IO Int) readLn 449: if {x2 : Int | (x2 == (0 : int))} 0 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == i)} i x1:Bool -> x2:Bool -> {x2 : Bool | (((Prop x2)) <=> (((Prop x1)) && ((Prop x2))))} && {x2 : Int | (x2 == i)} i x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 < x2))} < x1:Text -> {x2 : Int | (x2 == (tLen x1))} tLength {x2 : Text | (x2 == txt)} txt 450: then x1:Text -> {x5 : Int | (x5 >= 0) && (x5 < (tLen x1))} -> (IO ()) showCharAt {x2 : Text | (x2 == txt)} txt {x2 : Int | (x2 == i)} i 451: else [Char] -> (IO ()) putStrLn {x2 : [Char] | ((len x2) >= 0)} \"Bad Input!\" but this function, which has insufficient sanitization, is rejected 457: badMain :: IO () 458: (IO ()) badMain 459: = do Text txt <- x1:[Char] -> {x2 : Text | ((tLen x2) == (len x1))} pack ([Char] -> Text) -> (IO [Char]) -> (IO Text) <$> {x2 : (IO [Char]) | (x2 == System.IO.getLine)} getLine 460: Int i <- (IO Int) readLn 461: if {x2 : Int | (x2 == (0 : int))} 0 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 <= x2))} <= {x2 : Int | (x2 == i)} i 462: then x1:Text -> {x5 : Int | (x5 >= 0) && (x5 < (tLen x1))} -> (IO ()) showCharAt {x2 : Text | (x2 == txt)} txt {x2 : Int | (x2 == i)} i 463: else [Char] -> (IO ()) putStrLn {x2 : [Char] | ((len x2) >= 0)} \"Bad Input!\" Thus, we can use LiquidHaskell to block, at compile time, any serious bleeding from pointers gone wild. Assuming the absence of errors in the compiler and run-time... \u21a9 This function is bad for numerous reasons, least of which is that Data.Text.index is already provided, but stay with us... \u21a9","title":"Enforcing Sanitization"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/","text":"This morning, I came across this nice post which describes how one can write a very expressive type for filter using singletons . Lets see how one might achieve this with abstract refinements . 23: 24: {-@ LIQUID \"--short-names\" @-} 25: 26: module Filter ( filter ) where 27: 28: import Prelude hiding ( filter ) 29: import Data . Set ( Set ) 30: 31: import Prelude hiding ( filter ) 32: isPos , isEven , isOdd :: Int -> Maybe Int 33: filter , filter3 :: ( a -> Maybe a ) -> [ a ] -> [ a ] 34: 35: {-@ measure elts :: [ a ] -> ( Set a ) 36: elts ( [] ) = { v | Set_emp v } 37: elts ( x : xs ) = { v | v = Set_cup ( Set_sng x ) ( elts xs ) } 38: @-} 39: Goal \u00b6 What we're after is a way to write a filter function such that: 50: {-@ getPoss :: [ Int ] -> [ Pos ] @-} 51: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getPoss = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 52: 53: {-@ getEvens :: [ Int ] -> [ Even ] @-} 54: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getEvens = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 55: 56: {-@ getOdds :: [ Int ] -> [ Odd ] @-} 57: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getOdds = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd where Pos , Even and Odd are just subsets of Int : 63: {-@ type Pos = { v : Int | 0 < v } @-} 64: 65: {-@ type Even = { v : Int | v mod 2 == 0 } @-} 66: 67: {-@ type Odd = { v : Int | v mod 2 /= 0 } @-} Take 1: Map, maybe? \u00b6 Bowing to the anti-boolean sentiment currently in the air, lets eschew the classical approach where the predicates ( isPos etc.) return True or False and instead implement filter using a map. 78: filter1 :: ( a -> Maybe b ) -> [ a ] -> [ b ] 79: 80: forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 81: filter1 f ( x : xs ) = case a -> (Maybe b) f {VV : a | (VV == x)} x of 82: Just y -> {VV : a | (VV == y)} y x1:a -> x2:[a] -> {x5 : [a] | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 83: Nothing -> forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs To complete the picture, we need just define the predicates as functions returning a Maybe : 90: {- isPos :: Int -> Maybe Pos @-} 91: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && (VV > 0) && (0 < VV)}) isPos Int x 92: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 > x2))} > {x2 : Int | (x2 == (0 : int))} 0 = x1:{x13 : Int | (x13 == x) && (x13 == (x : int)) && (x13 > 0) && (0 < x13)} -> {x3 : (Maybe {x13 : Int | (x13 == x) && (x13 == (x : int)) && (x13 > 0) && (0 < x13)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 93: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing 94: 95: {- isEven :: Int -> Maybe Even @-} 96: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && ((VV mod 2) == 0)}) isEven Int x 97: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x6 : Int | (((0 <= x1) && (0 < x2)) => ((0 <= x6) && (x6 < x2))) && (x6 == (x1 mod x2))} `mod` {x2 : Int | (x2 == (2 : int))} 2 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 == x2))} == {x2 : Int | (x2 == (0 : int))} 0 = x1:{x11 : Int | (x11 == x) && (x11 == (x : int)) && ((x11 mod 2) == 0)} -> {x3 : (Maybe {x11 : Int | (x11 == x) && (x11 == (x : int)) && ((x11 mod 2) == 0)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 98: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing 99: 100: {- isOdd :: Int -> Maybe Odd @-} 101: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && ((VV mod 2) == 1) && (VV /= 0)}) isOdd Int x 102: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x6 : Int | (((0 <= x1) && (0 < x2)) => ((0 <= x6) && (x6 < x2))) && (x6 == (x1 mod x2))} `mod` {x2 : Int | (x2 == (2 : int))} 2 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 /= x2))} /= {x2 : Int | (x2 == (0 : int))} 0 = x1:{x13 : Int | (x13 == x) && (x13 == (x : int)) && ((x13 mod 2) == 1) && (x13 /= 0)} -> {x3 : (Maybe {x13 : Int | (x13 == x) && (x13 == (x : int)) && ((x13 mod 2) == 1) && (x13 /= 0)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 103: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing and now, we can achieve our goal! 109: {-@ getPoss1 :: [ Int ] -> [ Pos ] @-} 110: [Int] -> [{v : Int | (0 < v)}] getPoss1 = (Int -> (Maybe {x14 : Int | (x14 > 0) && (0 < x14)})) -> x3:[Int] -> {x3 : [{x14 : Int | (x14 > 0) && (0 < x14)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 111: 112: {-@ getEvens1 :: [ Int ] -> [ Even ] @-} 113: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens1 = (Int -> (Maybe {x12 : Int | ((x12 mod 2) == 0)})) -> x3:[Int] -> {x3 : [{x12 : Int | ((x12 mod 2) == 0)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 114: 115: {-@ getOdds1 :: [ Int ] -> [ Odd ] @-} 116: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds1 = (Int -> (Maybe {x14 : Int | ((x14 mod 2) == 1) && (x14 /= 0)})) -> x3:[Int] -> {x3 : [{x14 : Int | ((x14 mod 2) == 1) && (x14 /= 0)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd The Subset Guarantee Well that was easy! Or was it? I fear we've cheated a little bit. One of the nice things about the classical filter is that by eyeballing the signature: 129: filter :: ( a -> Bool ) -> [ a ] -> [ a ] we are guaranteed, via parametricity, that the output list's elements are a subset of the input list's elements. The signature for our new-fangled 136: filter1 :: ( a -> Maybe b ) -> [ a ] -> [ b ] yields no such guarantee! In this case, things work out, because in each case, LiquidHaskell instantiates the type variables a and b in the signature of filter1 suitably: In getPoss LH instantiates a := Int and b := Pos In getEvens LH instantiates a := Int and b := Even In getOdds LH instantiates a := Int and b := Odd (Hover over the different instances of filter1 above to confirm this.) But in general, we'd rather not lose the nice \"subset\" guarantee that the classical filter provides. Take 2: One Type Variable \u00b6 Easy enough! Why do we need two type variables anyway? 160: filter2 :: ( a -> Maybe a ) -> [ a ] -> [ a ] 161: 162: forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 163: filter2 f ( x : xs ) = case x1:a -> (Maybe {VV : a | (VV == x1)}) f {VV : a | (VV == x)} x of 164: Just y -> {VV : a | (VV == y) && (VV == x)} y x1:a -> x2:[a] -> {x5 : [a] | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 165: Nothing -> forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs There! Now the f is forced to take or leave its input x , and so we can breathe easy knowing that filter2 returns a subset of its inputs. But... 175: {-@ getPoss2 :: [ Int ] -> [ Pos ] @-} 176: [Int] -> [{v : Int | (0 < v)}] getPoss2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 177: 178: {-@ getEvens2 :: [ Int ] -> [ Even ] @-} 179: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 180: 181: {-@ getOdds2 :: [ Int ] -> [ Odd ] @-} 182: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd Yikes, LH is not impressed -- the red highlight indicates that LH is not convinced that the functions have the specified types. Perhaps you know why already? Since we used the same type variable a for both the input and output, LH must instantiate a with a type that matches both the input and output, i.e. is a super-type of both, which is simply Int in all the cases. Consequently, we get the errors above -- \"expected Pos but got Int \". Take 3: Add Abstract Refinement \u00b6 What we need is a generic way of specifying that the output of the predicate is not just an a but an a that also enjoys whatever property we are filtering for. This sounds like a job for abstract refinements which let us parameterize a signature over its refinements: 208: {-@ filter3 :: forall a < p :: a -> Prop >. 209: ( a -> Maybe a < p > ) -> [ a ] -> [ a < p > ] @-} 210: forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 211: filter3 f ( x : xs ) = case a -> (Maybe {VV : a | ((papp1 p VV))}) f {VV : a | (VV == x)} x of 212: Just x' -> {VV : a | ((papp1 p VV)) && (VV == x')} x' x1:{VV : a | ((papp1 p VV))} -> x2:[{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> -> {x5 : [{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 213: Nothing -> forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs Now, we've decoupled the filter-property from the type variable a . The input still is a mere a , but the output is an a with bells on, specifically, which satisfies the (abstract) refinement p . Voila! 224: {-@ getPoss3 :: [ Int ] -> [ Pos ] @-} 225: [Int] -> [{v : Int | (0 < v)}] getPoss3 = (Int -> (Maybe {x13 : Int | (x13 > 0) && (0 < x13)})) -> [Int] -> [{x13 : Int | (x13 > 0) && (0 < x13)}] filter3 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 226: 227: {-@ getEvens3 :: [ Int ] -> [ Even ] @-} 228: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens3 = (Int -> (Maybe {x11 : Int | ((x11 mod 2) == 0)})) -> [Int] -> [{x11 : Int | ((x11 mod 2) == 0)}] filter3 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 229: 230: {-@ getOdds3 :: [ Int ] -> [ Odd ] @-} 231: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds3 = (Int -> (Maybe {x13 : Int | ((x13 mod 2) == 1) && (x13 /= 0)})) -> [Int] -> [{x13 : Int | ((x13 mod 2) == 1) && (x13 /= 0)}] filter3 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd Now, LH happily accepts each of the above. At each use of filter LH separately instantiates the a and the p . In each case, the a is just Int but the p is instantiated as: In getPoss LH instantiates p := \\v -> 0 <= v In getEvens LH instantiates p := \\v -> v mod 2 == 0 In getOdds LH instantiates p := \\v -> v mod 2 /= 0 That is, in each case, LH instantiates p with the refinement that describes the output type we are looking for. Edit: At this point, I was ready to go to bed, and so happily declared victory and turned in. The next morning, mypetclone graciously pointed out my folly: the signature for filter3 makes no guarantees about the subset property. In fact, 252: [Integer] -> [Integer] doubles = (Integer -> (Maybe Integer)) -> [Integer] -> [Integer] filter3 ( Integer -> (Maybe Integer) \\ Integer x -> x1:Integer -> {x3 : (Maybe Integer) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just ( {x2 : Integer | (x2 == x)} x x1:Integer -> x2:Integer -> {x4 : Integer | (x4 == (x1 + x2))} + {x2 : Integer | (x2 == x)} x ) ) typechecks just fine, while doubles clearly violates the subset property. Take 4: \u00b6 I suppose the moral is that it may be tricky -- for me at least! -- to read more into a type than what it actually says . Fortunately, with refinements, our types can say quite a lot. In particular, lets make the subset property explicit, by Requiring the predicate return its input (or nothing), and, Ensuring the output is indeed a subset of the inputs. 270: {-@ filter :: forall a < p :: a -> Prop >. 271: ( x : a -> Maybe {v: a < p > | v = x} ) 272: -> xs : [ a ] 273: -> {v: [ a < p > ] | Set_sub (elts v) (elts xs)} @-} 274: 275: forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 276: filter f ( x : xs ) = case x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {VV : a | (VV == x)} x of 277: Just x' -> {VV : a | ((papp1 p VV)) && (VV == x) && (VV == x')} x' x1:{VV : a | ((papp1 p VV))} -> x2:[{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> -> {x5 : [{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 278: Nothing -> forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs where elts describes the set of elements in a list . Note: The implementation of each of the above filter functions are the same; they only differ in their type specification . Conclusion \u00b6 And so, using abstract refinements, we've written a filter whose signature guarantees: The outputs must be a subset of the inputs, and The outputs indeed satisfy the property being filtered for. Another thing that I've learnt from this exercise, is that the old school Boolean approach has its merits. Take a look at the clever \"latent predicates\" technique of Tobin-Hochstadt and Felleisen or this lovely new paper by Kaki and Jagannathan which shows how refinements can be further generalized to make Boolean filters fine.","title":"A Finer Filter"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#goal","text":"What we're after is a way to write a filter function such that: 50: {-@ getPoss :: [ Int ] -> [ Pos ] @-} 51: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getPoss = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 52: 53: {-@ getEvens :: [ Int ] -> [ Even ] @-} 54: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getEvens = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 55: 56: {-@ getOdds :: [ Int ] -> [ Odd ] @-} 57: x1:[{x7 : Int | false}] -> {x2 : [{x7 : Int | false}] | ((Set_sub (elts x2) (elts x1)))} getOdds = ({x10 : Int | false} -> (Maybe {x10 : Int | false})) -> x3:[{x10 : Int | false}] -> {x2 : [{x10 : Int | false}] | ((Set_sub (elts x2) (elts x3)))} filter x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd where Pos , Even and Odd are just subsets of Int : 63: {-@ type Pos = { v : Int | 0 < v } @-} 64: 65: {-@ type Even = { v : Int | v mod 2 == 0 } @-} 66: 67: {-@ type Odd = { v : Int | v mod 2 /= 0 } @-}","title":"Goal"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#take-1-map-maybe","text":"Bowing to the anti-boolean sentiment currently in the air, lets eschew the classical approach where the predicates ( isPos etc.) return True or False and instead implement filter using a map. 78: filter1 :: ( a -> Maybe b ) -> [ a ] -> [ b ] 79: 80: forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 81: filter1 f ( x : xs ) = case a -> (Maybe b) f {VV : a | (VV == x)} x of 82: Just y -> {VV : a | (VV == y)} y x1:a -> x2:[a] -> {x5 : [a] | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 83: Nothing -> forall a b. (a -> (Maybe b)) -> x3:[a] -> {VV : [b] | ((len VV) >= 0) && ((len VV) <= (len x3))} filter1 a -> (Maybe b) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs To complete the picture, we need just define the predicates as functions returning a Maybe : 90: {- isPos :: Int -> Maybe Pos @-} 91: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && (VV > 0) && (0 < VV)}) isPos Int x 92: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 > x2))} > {x2 : Int | (x2 == (0 : int))} 0 = x1:{x13 : Int | (x13 == x) && (x13 == (x : int)) && (x13 > 0) && (0 < x13)} -> {x3 : (Maybe {x13 : Int | (x13 == x) && (x13 == (x : int)) && (x13 > 0) && (0 < x13)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 93: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing 94: 95: {- isEven :: Int -> Maybe Even @-} 96: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && ((VV mod 2) == 0)}) isEven Int x 97: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x6 : Int | (((0 <= x1) && (0 < x2)) => ((0 <= x6) && (x6 < x2))) && (x6 == (x1 mod x2))} `mod` {x2 : Int | (x2 == (2 : int))} 2 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 == x2))} == {x2 : Int | (x2 == (0 : int))} 0 = x1:{x11 : Int | (x11 == x) && (x11 == (x : int)) && ((x11 mod 2) == 0)} -> {x3 : (Maybe {x11 : Int | (x11 == x) && (x11 == (x : int)) && ((x11 mod 2) == 0)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 98: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing 99: 100: {- isOdd :: Int -> Maybe Odd @-} 101: x:Int -> (Maybe {VV : Int | (VV == x) && (VV == (x : int)) && ((VV mod 2) == 1) && (VV /= 0)}) isOdd Int x 102: | {x2 : Int | (x2 == x)} x x1:Int -> x2:Int -> {x6 : Int | (((0 <= x1) && (0 < x2)) => ((0 <= x6) && (x6 < x2))) && (x6 == (x1 mod x2))} `mod` {x2 : Int | (x2 == (2 : int))} 2 x1:Int -> x2:Int -> {x2 : Bool | (((Prop x2)) <=> (x1 /= x2))} /= {x2 : Int | (x2 == (0 : int))} 0 = x1:{x13 : Int | (x13 == x) && (x13 == (x : int)) && ((x13 mod 2) == 1) && (x13 /= 0)} -> {x3 : (Maybe {x13 : Int | (x13 == x) && (x13 == (x : int)) && ((x13 mod 2) == 1) && (x13 /= 0)}) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just {x2 : Int | (x2 == x)} x 103: | otherwise = {x2 : (Maybe {x3 : Int | false}) | (((isJust x2)) <=> false)} Nothing and now, we can achieve our goal! 109: {-@ getPoss1 :: [ Int ] -> [ Pos ] @-} 110: [Int] -> [{v : Int | (0 < v)}] getPoss1 = (Int -> (Maybe {x14 : Int | (x14 > 0) && (0 < x14)})) -> x3:[Int] -> {x3 : [{x14 : Int | (x14 > 0) && (0 < x14)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 111: 112: {-@ getEvens1 :: [ Int ] -> [ Even ] @-} 113: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens1 = (Int -> (Maybe {x12 : Int | ((x12 mod 2) == 0)})) -> x3:[Int] -> {x3 : [{x12 : Int | ((x12 mod 2) == 0)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 114: 115: {-@ getOdds1 :: [ Int ] -> [ Odd ] @-} 116: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds1 = (Int -> (Maybe {x14 : Int | ((x14 mod 2) == 1) && (x14 /= 0)})) -> x3:[Int] -> {x3 : [{x14 : Int | ((x14 mod 2) == 1) && (x14 /= 0)}] | ((len x3) >= 0) && ((len x3) <= (len x3))} filter1 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd The Subset Guarantee Well that was easy! Or was it? I fear we've cheated a little bit. One of the nice things about the classical filter is that by eyeballing the signature: 129: filter :: ( a -> Bool ) -> [ a ] -> [ a ] we are guaranteed, via parametricity, that the output list's elements are a subset of the input list's elements. The signature for our new-fangled 136: filter1 :: ( a -> Maybe b ) -> [ a ] -> [ b ] yields no such guarantee! In this case, things work out, because in each case, LiquidHaskell instantiates the type variables a and b in the signature of filter1 suitably: In getPoss LH instantiates a := Int and b := Pos In getEvens LH instantiates a := Int and b := Even In getOdds LH instantiates a := Int and b := Odd (Hover over the different instances of filter1 above to confirm this.) But in general, we'd rather not lose the nice \"subset\" guarantee that the classical filter provides.","title":"Take 1: Map, maybe?"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#take-2-one-type-variable","text":"Easy enough! Why do we need two type variables anyway? 160: filter2 :: ( a -> Maybe a ) -> [ a ] -> [ a ] 161: 162: forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 163: filter2 f ( x : xs ) = case x1:a -> (Maybe {VV : a | (VV == x1)}) f {VV : a | (VV == x)} x of 164: Just y -> {VV : a | (VV == y) && (VV == x)} y x1:a -> x2:[a] -> {x5 : [a] | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 165: Nothing -> forall a. (x2:a -> (Maybe {VV : a | (VV == x2)})) -> x3:[a] -> {VV : [a] | ((Set_sub (elts VV) (elts x3))) && ((len VV) >= 0) && ((len VV) <= (len x3))} filter2 x1:a -> (Maybe {VV : a | (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs There! Now the f is forced to take or leave its input x , and so we can breathe easy knowing that filter2 returns a subset of its inputs. But... 175: {-@ getPoss2 :: [ Int ] -> [ Pos ] @-} 176: [Int] -> [{v : Int | (0 < v)}] getPoss2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 177: 178: {-@ getEvens2 :: [ Int ] -> [ Even ] @-} 179: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 180: 181: {-@ getOdds2 :: [ Int ] -> [ Odd ] @-} 182: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds2 = (x2:Int -> (Maybe {x13 : Int | (x13 == x2)})) -> x3:[Int] -> {x4 : [Int] | ((Set_sub (elts x4) (elts x3))) && ((len x4) >= 0) && ((len x4) <= (len x3))} filter2 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd Yikes, LH is not impressed -- the red highlight indicates that LH is not convinced that the functions have the specified types. Perhaps you know why already? Since we used the same type variable a for both the input and output, LH must instantiate a with a type that matches both the input and output, i.e. is a super-type of both, which is simply Int in all the cases. Consequently, we get the errors above -- \"expected Pos but got Int \".","title":"Take 2: One Type Variable"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#take-3-add-abstract-refinement","text":"What we need is a generic way of specifying that the output of the predicate is not just an a but an a that also enjoys whatever property we are filtering for. This sounds like a job for abstract refinements which let us parameterize a signature over its refinements: 208: {-@ filter3 :: forall a < p :: a -> Prop >. 209: ( a -> Maybe a < p > ) -> [ a ] -> [ a < p > ] @-} 210: forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 211: filter3 f ( x : xs ) = case a -> (Maybe {VV : a | ((papp1 p VV))}) f {VV : a | (VV == x)} x of 212: Just x' -> {VV : a | ((papp1 p VV)) && (VV == x')} x' x1:{VV : a | ((papp1 p VV))} -> x2:[{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> -> {x5 : [{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 213: Nothing -> forall a <p :: a -> Prop>. (a -> (Maybe {VV : a<p> | true})) -> [a] -> [{VV : a<p> | true}] filter3 a -> (Maybe {VV : a | ((papp1 p VV))}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs Now, we've decoupled the filter-property from the type variable a . The input still is a mere a , but the output is an a with bells on, specifically, which satisfies the (abstract) refinement p . Voila! 224: {-@ getPoss3 :: [ Int ] -> [ Pos ] @-} 225: [Int] -> [{v : Int | (0 < v)}] getPoss3 = (Int -> (Maybe {x13 : Int | (x13 > 0) && (0 < x13)})) -> [Int] -> [{x13 : Int | (x13 > 0) && (0 < x13)}] filter3 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && (x6 > 0) && (0 < x6)}) isPos 226: 227: {-@ getEvens3 :: [ Int ] -> [ Even ] @-} 228: [Int] -> [{v : Int | ((v mod 2) == 0)}] getEvens3 = (Int -> (Maybe {x11 : Int | ((x11 mod 2) == 0)})) -> [Int] -> [{x11 : Int | ((x11 mod 2) == 0)}] filter3 x1:Int -> (Maybe {x5 : Int | (x5 == x1) && (x5 == (x1 : int)) && ((x5 mod 2) == 0)}) isEven 229: 230: {-@ getOdds3 :: [ Int ] -> [ Odd ] @-} 231: [Int] -> [{v : Int | ((v mod 2) == 1)}] getOdds3 = (Int -> (Maybe {x13 : Int | ((x13 mod 2) == 1) && (x13 /= 0)})) -> [Int] -> [{x13 : Int | ((x13 mod 2) == 1) && (x13 /= 0)}] filter3 x1:Int -> (Maybe {x6 : Int | (x6 == x1) && (x6 == (x1 : int)) && ((x6 mod 2) == 1) && (x6 /= 0)}) isOdd Now, LH happily accepts each of the above. At each use of filter LH separately instantiates the a and the p . In each case, the a is just Int but the p is instantiated as: In getPoss LH instantiates p := \\v -> 0 <= v In getEvens LH instantiates p := \\v -> v mod 2 == 0 In getOdds LH instantiates p := \\v -> v mod 2 /= 0 That is, in each case, LH instantiates p with the refinement that describes the output type we are looking for. Edit: At this point, I was ready to go to bed, and so happily declared victory and turned in. The next morning, mypetclone graciously pointed out my folly: the signature for filter3 makes no guarantees about the subset property. In fact, 252: [Integer] -> [Integer] doubles = (Integer -> (Maybe Integer)) -> [Integer] -> [Integer] filter3 ( Integer -> (Maybe Integer) \\ Integer x -> x1:Integer -> {x3 : (Maybe Integer) | (((isJust x3)) <=> true) && ((fromJust x3) == x1)} Just ( {x2 : Integer | (x2 == x)} x x1:Integer -> x2:Integer -> {x4 : Integer | (x4 == (x1 + x2))} + {x2 : Integer | (x2 == x)} x ) ) typechecks just fine, while doubles clearly violates the subset property.","title":"Take 3: Add Abstract Refinement"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#take-4","text":"I suppose the moral is that it may be tricky -- for me at least! -- to read more into a type than what it actually says . Fortunately, with refinements, our types can say quite a lot. In particular, lets make the subset property explicit, by Requiring the predicate return its input (or nothing), and, Ensuring the output is indeed a subset of the inputs. 270: {-@ filter :: forall a < p :: a -> Prop >. 271: ( x : a -> Maybe {v: a < p > | v = x} ) 272: -> xs : [ a ] 273: -> {v: [ a < p > ] | Set_sub (elts v) (elts xs)} @-} 274: 275: forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f [] = forall a <p :: a a -> Prop>. {x5 : [a]<\\x6 VV -> p x6> | (((null x5)) <=> true) && ((Set_emp (listElts x5))) && ((Set_emp (elts x5))) && ((len x5) == 0)} [] 276: filter f ( x : xs ) = case x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {VV : a | (VV == x)} x of 277: Just x' -> {VV : a | ((papp1 p VV)) && (VV == x) && (VV == x')} x' x1:{VV : a | ((papp1 p VV))} -> x2:[{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> -> {x5 : [{VV : a | ((papp1 p VV))}]<\\_ VV -> ((papp1 p VV))> | (((null x5)) <=> false) && ((listElts x5) == (Set_cup (Set_sng x1) (listElts x2))) && ((len x5) == (1 + (len x2))) && ((elts x5) == (Set_cup (Set_sng x1) (elts x2)))} : forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs 278: Nothing -> forall a <p :: a -> Prop>. (x2:a -> (Maybe {VV : a<p> | (VV == x2)})) -> x3:[a] -> {v : [{VV : a<p> | true}] | ((Set_sub (elts v) (elts x3)))} filter x1:a -> (Maybe {VV : a | ((papp1 p VV)) && (VV == x1)}) f {x3 : [a] | (x3 == xs) && ((len x3) >= 0)} xs where elts describes the set of elements in a list . Note: The implementation of each of the above filter functions are the same; they only differ in their type specification .","title":"Take 4:"},{"location":"blogposts/2014-08-15-a-finer-filter.lhs/#conclusion","text":"And so, using abstract refinements, we've written a filter whose signature guarantees: The outputs must be a subset of the inputs, and The outputs indeed satisfy the property being filtered for. Another thing that I've learnt from this exercise, is that the old school Boolean approach has its merits. Take a look at the clever \"latent predicates\" technique of Tobin-Hochstadt and Felleisen or this lovely new paper by Kaki and Jagannathan which shows how refinements can be further generalized to make Boolean filters fine.","title":"Conclusion"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/","text":"The \"Hello World!\" example for fancy type systems is probably the sized vector or list append function (\"The output has size equal to the sum of the inputs!\"). One the one hand, it is perfect: simple enough to explain without pages of code, yet complex enough to show off whats cool about dependency. On the other hand, like the sweater I'm sporting right now, it's a bit well-worn and worse, was never wholly convincing (\"Why do I care what the size of the output list is anyway?\") Recently, I came across a nice example that is almost as simple, but is also well motivated: Okasaki's beautiful Lazy Amortized Queues . This structure leans heavily on an invariant to provide fast insertion and deletion . Let's see how to enforce that invariant with LiquidHaskell. 30: {-@ LIQUID \"--no-termination\" @-} 31: {-@ LIQUID \"--total\" @-} 32: {-@ LIQUID \"--maxparams=3\" @-} 33: 34: module LazyQueue ( Queue , insert , remove , emp ) where 35: 36: import Prelude hiding ( length ) 37: 38: -- | Size function actually returns the size: (Duh!) 39: 40: {-@ size :: q : SList a -> {v: Nat | v = size q} @-} 41: data Queue a = Q { forall a. (LazyQueue.Queue a) -> (LazyQueue.SList a) front :: SList a 42: , forall a. (LazyQueue.Queue a) -> (LazyQueue.SList a) back :: SList a 43: } 44: 45: -- Source: Okasaki, JFP 1995 46: -- http://www.westpoint.edu/eecs/SiteAssets/SitePages/Faculty%20Publication%20Documents/Okasaki/jfp95queue.pdf 47: Queues \u00b6 A queue is a structure into which we can insert and remove data such that the order in which the data is removed is the same as the order in which it was inserted. To implement a queue efficiently one needs to have rapid access to both the \"head\" as well as the \"tail\" because we remove elements from former and insert elements into the latter. This is quite straightforward with explicit pointers and mutation -- one uses an old school linked list and maintains pointers to the head and the tail. But can we implement the structure efficiently without having stoop so low? Queues = Pair of Lists \u00b6 Almost two decades ago, Chris Okasaki came up with a very cunning way to implement queues using a pair of lists -- let's call them front and back which represent the corresponding parts of the Queue. To insert elements, we just cons them onto the back list, To remove elements, we just un-cons them from the front list. The catch is that we need to shunt elements from the back to the front every so often, e.g. when a remove call is triggered, and the front list is empty, We can transfer the elements from the back to the front . Okasaki observed that every element is only moved once from the front to the back; hence, the time for insert and lookup could be O(1) when amortized over all the operations. Awesome, right?! Almost. Some set of unlucky remove calls (which occur when the front is empty) are stuck paying the bill. They have a rather high latency up to O(n) where n is the total number of operations. Oops. Queue = Balanced Lazy Lists \u00b6 This is where Okasaki's beautiful insights kick in. Okasaki observed that all we need to do is to enforce a simple invariant: Invariant: Size of front >= Size of back Now, if the lists are lazy i.e. only constructed as the head value is demanded, then a single remove needs only a tiny O(log n) in the worst case, and so no single remove is stuck paying the bill. Let's see how to represent these Queues and ensure the crucial invariant(s) with LiquidHaskell. What we need are the following ingredients: A type for List s, and a way to track their size , A type for Queue s which encodes the balance invariant -- ``front longer than back\", A way to implement the insert , remove and transfer operations. Sized Lists \u00b6 The first part is super easy. Let's define a type: 127: data SList a = SL { forall a. x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size :: Int , forall a. (LazyQueue.SList a) -> [a] elems :: [ a ] } We have a special field that saves the size because otherwise, we have a linear time computation that wrecks Okasaki's careful analysis. (Actually, he presents a variant which does not require saving the size as well, but that's for another day.) But how can we be sure that size is indeed the real size of elems ? Let's write a function to measure the real size: 140: {-@ measure realSize @-} 141: realSize :: [ a ] -> Int 142: forall a. x1:[a] -> {VV : GHC.Types.Int | VV == realSize x1} realSize [] = x1:GHC.Prim.Int# -> {v : GHC.Types.Int | v == (x1 : int)} 0 143: realSize ( _ : xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + forall a. x1:[a] -> {VV : GHC.Types.Int | VV == realSize x1} realSize {v : [a] | v == xs && len v >= 0} xs and now, we can simply specify a refined type for SList that ensures that the real size is saved in the size field: 150: {-@ data SList a = SL { 151: size :: Nat 152: , elems :: { v : [ a ] | realSize v = size } 153: } 154: @-} As a sanity check, consider this: 160: {VV : (LazyQueue.SList {VV : [GHC.Types.Char] | len VV >= 0}) | size VV > 0} okList = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [{v : [GHC.Types.Char] | len v >= 0}] | realSize v == x1} -> {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (1 : int)} 1 {v : [{v : [GHC.Types.Char] | len v >= 0}]<\\_ VV -> false> | null v <=> false && len v >= 0} [ {v : [GHC.Types.Char] | len v >= 0} \"cat\" ] -- accepted 161: 162: forall a. (LazyQueue.SList a) badList = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (1 : int)} 1 {v : [a] | null v <=> true && realSize v == 0 && len v == 0 && len v >= 0} [] -- rejected It is helpful to define a few aliases for SList s of a size N and non-empty SList s: 169: -- | SList of size N 170: 171: {-@ type SListN a N = { v : SList a | size v = N } @-} 172: 173: -- | Non-Empty SLists: 174: 175: {-@ type NEList a = { v : SList a | size v > 0 } @-} 176: Finally, we can define a basic API for SList . To Construct lists, we use nil and cons : 184: {-@ nil :: SListN a 0 @-} 185: forall a. {v : (LazyQueue.SList a) | size v == 0} nil = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (0 : int)} 0 {v : [a] | null v <=> true && realSize v == 0 && len v == 0 && len v >= 0} [] 186: 187: {-@ cons :: a -> xs : SList a -> SListN a {size xs + 1} @-} 188: forall a. a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x2 + 1} cons a x ( SL n xs ) = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL ( {v : GHC.Types.Int | v == n && v >= 0} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v == (1 : int)} 1 ) ( {VV : a | VV == x} x x1:a -> x2:[a] -> {v : [a] | null v <=> false && xListSelector v == x1 && realSize v == 1 + realSize x2 && xsListSelector v == x2 && len v == 1 + len x2} : {v : [a] | v == xs && realSize v == n && len v >= 0} xs ) To Destruct lists, we have hd and tl . 194: {-@ tl :: xs : NEList a -> SListN a {size xs - 1} @-} 195: forall a. x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl ( SL n ( _ : xs ) ) = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL ( {v : GHC.Types.Int | v == n && v >= 0} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v == (1 : int)} 1 ) {v : [a] | v == xs && len v >= 0} xs 196: 197: {-@ hd :: xs : NEList a -> a @-} 198: forall a. {v : (LazyQueue.SList a) | size v > 0} -> a hd ( SL _ ( x : _ ) ) = {VV : a | VV == x} x Don't worry, they are perfectly safe as LiquidHaskell will make sure we only call these operators on non-empty SList s. For example, 205: {v : [GHC.Types.Char] | len v >= 0} okHd = {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : [GHC.Types.Char] | len v >= 0} hd {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList -- accepted 206: 207: {VV : [GHC.Types.Char] | len VV >= 0} badHd = {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : [GHC.Types.Char] | len v >= 0} hd ( x1:{v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v == size x1 - 1} tl {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList ) -- rejected Queue Type \u00b6 Now, it is quite straightforward to define the Queue type, as a pair of lists, front and back , such that the latter is always smaller than the former: 218: {-@ data Queue a = Q { 219: front :: SList a 220: , back :: SListLE a ( size front ) 221: } 222: @-} Where the alias SListLE a L corresponds to lists with less than N elements: 228: {-@ type SListLE a N = { v : SList a | size v <= N } @-} As a quick check, notice that we cannot represent illegal Queues : 234: {VV : (LazyQueue.Queue [GHC.Types.Char]) | 0 < qsize VV} okQ = x1:(LazyQueue.SList [GHC.Types.Char]) -> x2:{v : (LazyQueue.SList [GHC.Types.Char]) | size v <= size x1} -> {v : (LazyQueue.Queue [GHC.Types.Char]) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList {v : (LazyQueue.SList [GHC.Types.Char]) | size v == 0} nil -- accepted, |front| > |back| 235: 236: {VV : (LazyQueue.Queue [GHC.Types.Char]) | 0 < qsize VV} badQ = x1:(LazyQueue.SList [GHC.Types.Char]) -> x2:{v : (LazyQueue.SList [GHC.Types.Char]) | size v <= size x1} -> {v : (LazyQueue.Queue [GHC.Types.Char]) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList [GHC.Types.Char]) | size v == 0} nil {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList -- rejected, |front| < |back| To Measure Queue Size let us define a function 242: {-@ measure qsize @-} 243: qsize :: Queue a -> Int 244: forall a. x1:(LazyQueue.Queue a) -> {VV : GHC.Types.Int | VV == qsize x1} qsize ( Q l r ) = x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == l} l x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == r && size v <= size l} r This will prove helpful to define Queue s of a given size N and non-empty Queue s (from which values can be safely removed.) 251: {-@ type QueueN a N = { v : Queue a | N = qsize v } @-} 252: {-@ type NEQueue a = { v : Queue a | 0 < qsize v } @-} Queue Operations \u00b6 Almost there! Now all that remains is to define the Queue API. The code below is more or less identical to Okasaki's (I prefer front and back to his left and right .) The Empty Queue is simply one where both front and back are nil . 267: {-@ emp :: QueueN a 0 @-} 268: forall a. {v : (LazyQueue.Queue a) | 0 == qsize v} emp = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList a) | size v == 0} nil {v : (LazyQueue.SList a) | size v == 0} nil To Insert an element we just cons it to the back list, and call the smart constructor makeq to ensure that the balance invariant holds: 275: {-@ insert :: a -> q : Queue a -> QueueN a {qsize q + 1} @-} 276: forall a. a -> x2:(LazyQueue.Queue a) -> {v : (LazyQueue.Queue a) | qsize x2 + 1 == qsize v} insert a e ( Q f b ) = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size v == qsize v} makeq {v : (LazyQueue.SList a) | v == f} f ( {VV : a | VV == e} e a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == b && size v <= size f} b ) To Remove an element we pop it off the front by using hd and tl . Notice that the remove is only called on non-empty Queue s, which together with the key balance invariant, ensures that the calls to hd and tl are safe. 284: {-@ remove :: q : NEQueue a -> ( a , QueueN a {qsize q - 1} ) @-} 285: forall a. x1:{v : (LazyQueue.Queue a) | 0 < qsize v} -> (a, {v : (LazyQueue.Queue a) | qsize x1 - 1 == qsize v}) remove ( Q f b ) = forall a b <p2 :: a b -> Prop>. x1:a -> x2:{VV : b<p2 x1> | true} -> {v : (a, b)<\\x6 VV -> p2 x6> | fst v == x1 && x_Tuple22 v == x2 && snd v == x2 && x_Tuple21 v == x1} ( {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == f} f , x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size v == qsize v} makeq ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == f} f ) {v : (LazyQueue.SList a) | v == b && size v <= size f} b ) Aside: Why didn't we (or Okasaki) use a pattern match here? To Ensure the Invariant we use the smart constructor makeq , which is where the heavy lifting, such as it is, happens. The constructor takes two lists, the front f and back b and if they are balanced, directly returns the Queue , and otherwise transfers the elements from b over using rot ate. 297: {-@ makeq :: f : SList a 298: -> b : SListLE a {size f + 1 } 299: -> QueueN a {size f + size b} 300: @-} 301: forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size x2 == qsize v} makeq (LazyQueue.SList a) f {v : (LazyQueue.SList a) | size v <= size f + 1} b 302: | x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 <= v} <= x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == f} f = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList a) | v == f} f {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b 303: | otherwise = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q ( forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot {v : (LazyQueue.SList a) | v == f} f {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b {v : (LazyQueue.SList a) | size v == 0} nil ) {v : (LazyQueue.SList a) | size v == 0} nil The Rotate function is only called when the back is one larger than the front (we never let things drift beyond that). It is arranged so that it the hd is built up fast, before the entire computation finishes; which, combined with laziness provides the efficient worst-case guarantee. 313: {-@ rot :: f : SList a 314: -> b : SListN _ {1 + size f} 315: -> a : SList _ 316: -> SListN _ {size f + size b + size a} 317: @-} 318: forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot (LazyQueue.SList a) f {v : (LazyQueue.SList a) | size v == 1 + size f} b (LazyQueue.SList a) a 319: | x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == f} f x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == v} == {v : GHC.Types.Int | v == (0 : int)} 0 = {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == a} a 320: | otherwise = {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == f} f a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == f} f ) ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b ) ( {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == a} a ) Conclusion \u00b6 Well there you have it; Okasaki's beautiful lazy Queue, with the invariants easily expressed and checked with LiquidHaskell. I find this example particularly interesting because the refinements express invariants that are critical for efficiency, and furthermore the code introspects on the size in order to guarantee the invariants. Plus, it's just marginally more complicated than append and so, (I hope!) was easy to follow.","title":"Okasaki's Lazy Queues"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#queues","text":"A queue is a structure into which we can insert and remove data such that the order in which the data is removed is the same as the order in which it was inserted. To implement a queue efficiently one needs to have rapid access to both the \"head\" as well as the \"tail\" because we remove elements from former and insert elements into the latter. This is quite straightforward with explicit pointers and mutation -- one uses an old school linked list and maintains pointers to the head and the tail. But can we implement the structure efficiently without having stoop so low?","title":"Queues"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#queues-pair-of-lists","text":"Almost two decades ago, Chris Okasaki came up with a very cunning way to implement queues using a pair of lists -- let's call them front and back which represent the corresponding parts of the Queue. To insert elements, we just cons them onto the back list, To remove elements, we just un-cons them from the front list. The catch is that we need to shunt elements from the back to the front every so often, e.g. when a remove call is triggered, and the front list is empty, We can transfer the elements from the back to the front . Okasaki observed that every element is only moved once from the front to the back; hence, the time for insert and lookup could be O(1) when amortized over all the operations. Awesome, right?! Almost. Some set of unlucky remove calls (which occur when the front is empty) are stuck paying the bill. They have a rather high latency up to O(n) where n is the total number of operations. Oops.","title":"Queues = Pair of Lists"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#queue-balanced-lazy-lists","text":"This is where Okasaki's beautiful insights kick in. Okasaki observed that all we need to do is to enforce a simple invariant: Invariant: Size of front >= Size of back Now, if the lists are lazy i.e. only constructed as the head value is demanded, then a single remove needs only a tiny O(log n) in the worst case, and so no single remove is stuck paying the bill. Let's see how to represent these Queues and ensure the crucial invariant(s) with LiquidHaskell. What we need are the following ingredients: A type for List s, and a way to track their size , A type for Queue s which encodes the balance invariant -- ``front longer than back\", A way to implement the insert , remove and transfer operations.","title":"Queue = Balanced Lazy Lists"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#sized-lists","text":"The first part is super easy. Let's define a type: 127: data SList a = SL { forall a. x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size :: Int , forall a. (LazyQueue.SList a) -> [a] elems :: [ a ] } We have a special field that saves the size because otherwise, we have a linear time computation that wrecks Okasaki's careful analysis. (Actually, he presents a variant which does not require saving the size as well, but that's for another day.) But how can we be sure that size is indeed the real size of elems ? Let's write a function to measure the real size: 140: {-@ measure realSize @-} 141: realSize :: [ a ] -> Int 142: forall a. x1:[a] -> {VV : GHC.Types.Int | VV == realSize x1} realSize [] = x1:GHC.Prim.Int# -> {v : GHC.Types.Int | v == (x1 : int)} 0 143: realSize ( _ : xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + forall a. x1:[a] -> {VV : GHC.Types.Int | VV == realSize x1} realSize {v : [a] | v == xs && len v >= 0} xs and now, we can simply specify a refined type for SList that ensures that the real size is saved in the size field: 150: {-@ data SList a = SL { 151: size :: Nat 152: , elems :: { v : [ a ] | realSize v = size } 153: } 154: @-} As a sanity check, consider this: 160: {VV : (LazyQueue.SList {VV : [GHC.Types.Char] | len VV >= 0}) | size VV > 0} okList = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [{v : [GHC.Types.Char] | len v >= 0}] | realSize v == x1} -> {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (1 : int)} 1 {v : [{v : [GHC.Types.Char] | len v >= 0}]<\\_ VV -> false> | null v <=> false && len v >= 0} [ {v : [GHC.Types.Char] | len v >= 0} \"cat\" ] -- accepted 161: 162: forall a. (LazyQueue.SList a) badList = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (1 : int)} 1 {v : [a] | null v <=> true && realSize v == 0 && len v == 0 && len v >= 0} [] -- rejected It is helpful to define a few aliases for SList s of a size N and non-empty SList s: 169: -- | SList of size N 170: 171: {-@ type SListN a N = { v : SList a | size v = N } @-} 172: 173: -- | Non-Empty SLists: 174: 175: {-@ type NEList a = { v : SList a | size v > 0 } @-} 176: Finally, we can define a basic API for SList . To Construct lists, we use nil and cons : 184: {-@ nil :: SListN a 0 @-} 185: forall a. {v : (LazyQueue.SList a) | size v == 0} nil = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL {v : GHC.Types.Int | v == (0 : int)} 0 {v : [a] | null v <=> true && realSize v == 0 && len v == 0 && len v >= 0} [] 186: 187: {-@ cons :: a -> xs : SList a -> SListN a {size xs + 1} @-} 188: forall a. a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x2 + 1} cons a x ( SL n xs ) = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL ( {v : GHC.Types.Int | v == n && v >= 0} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v == (1 : int)} 1 ) ( {VV : a | VV == x} x x1:a -> x2:[a] -> {v : [a] | null v <=> false && xListSelector v == x1 && realSize v == 1 + realSize x2 && xsListSelector v == x2 && len v == 1 + len x2} : {v : [a] | v == xs && realSize v == n && len v >= 0} xs ) To Destruct lists, we have hd and tl . 194: {-@ tl :: xs : NEList a -> SListN a {size xs - 1} @-} 195: forall a. x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl ( SL n ( _ : xs ) ) = x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : [a] | realSize v == x1} -> {v : (LazyQueue.SList a) | elems v == x2 && size v == x1} SL ( {v : GHC.Types.Int | v == n && v >= 0} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v == (1 : int)} 1 ) {v : [a] | v == xs && len v >= 0} xs 196: 197: {-@ hd :: xs : NEList a -> a @-} 198: forall a. {v : (LazyQueue.SList a) | size v > 0} -> a hd ( SL _ ( x : _ ) ) = {VV : a | VV == x} x Don't worry, they are perfectly safe as LiquidHaskell will make sure we only call these operators on non-empty SList s. For example, 205: {v : [GHC.Types.Char] | len v >= 0} okHd = {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : [GHC.Types.Char] | len v >= 0} hd {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList -- accepted 206: 207: {VV : [GHC.Types.Char] | len VV >= 0} badHd = {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : [GHC.Types.Char] | len v >= 0} hd ( x1:{v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v > 0} -> {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | size v == size x1 - 1} tl {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList ) -- rejected","title":"Sized Lists"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#queue-type","text":"Now, it is quite straightforward to define the Queue type, as a pair of lists, front and back , such that the latter is always smaller than the former: 218: {-@ data Queue a = Q { 219: front :: SList a 220: , back :: SListLE a ( size front ) 221: } 222: @-} Where the alias SListLE a L corresponds to lists with less than N elements: 228: {-@ type SListLE a N = { v : SList a | size v <= N } @-} As a quick check, notice that we cannot represent illegal Queues : 234: {VV : (LazyQueue.Queue [GHC.Types.Char]) | 0 < qsize VV} okQ = x1:(LazyQueue.SList [GHC.Types.Char]) -> x2:{v : (LazyQueue.SList [GHC.Types.Char]) | size v <= size x1} -> {v : (LazyQueue.Queue [GHC.Types.Char]) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList {v : (LazyQueue.SList [GHC.Types.Char]) | size v == 0} nil -- accepted, |front| > |back| 235: 236: {VV : (LazyQueue.Queue [GHC.Types.Char]) | 0 < qsize VV} badQ = x1:(LazyQueue.SList [GHC.Types.Char]) -> x2:{v : (LazyQueue.SList [GHC.Types.Char]) | size v <= size x1} -> {v : (LazyQueue.Queue [GHC.Types.Char]) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList [GHC.Types.Char]) | size v == 0} nil {v : (LazyQueue.SList {v : [GHC.Types.Char] | len v >= 0}) | v == LazyQueue.okList && size v > 0} okList -- rejected, |front| < |back| To Measure Queue Size let us define a function 242: {-@ measure qsize @-} 243: qsize :: Queue a -> Int 244: forall a. x1:(LazyQueue.Queue a) -> {VV : GHC.Types.Int | VV == qsize x1} qsize ( Q l r ) = x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == l} l x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == r && size v <= size l} r This will prove helpful to define Queue s of a given size N and non-empty Queue s (from which values can be safely removed.) 251: {-@ type QueueN a N = { v : Queue a | N = qsize v } @-} 252: {-@ type NEQueue a = { v : Queue a | 0 < qsize v } @-}","title":"Queue Type"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#queue-operations","text":"Almost there! Now all that remains is to define the Queue API. The code below is more or less identical to Okasaki's (I prefer front and back to his left and right .) The Empty Queue is simply one where both front and back are nil . 267: {-@ emp :: QueueN a 0 @-} 268: forall a. {v : (LazyQueue.Queue a) | 0 == qsize v} emp = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList a) | size v == 0} nil {v : (LazyQueue.SList a) | size v == 0} nil To Insert an element we just cons it to the back list, and call the smart constructor makeq to ensure that the balance invariant holds: 275: {-@ insert :: a -> q : Queue a -> QueueN a {qsize q + 1} @-} 276: forall a. a -> x2:(LazyQueue.Queue a) -> {v : (LazyQueue.Queue a) | qsize x2 + 1 == qsize v} insert a e ( Q f b ) = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size v == qsize v} makeq {v : (LazyQueue.SList a) | v == f} f ( {VV : a | VV == e} e a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == b && size v <= size f} b ) To Remove an element we pop it off the front by using hd and tl . Notice that the remove is only called on non-empty Queue s, which together with the key balance invariant, ensures that the calls to hd and tl are safe. 284: {-@ remove :: q : NEQueue a -> ( a , QueueN a {qsize q - 1} ) @-} 285: forall a. x1:{v : (LazyQueue.Queue a) | 0 < qsize v} -> (a, {v : (LazyQueue.Queue a) | qsize x1 - 1 == qsize v}) remove ( Q f b ) = forall a b <p2 :: a b -> Prop>. x1:a -> x2:{VV : b<p2 x1> | true} -> {v : (a, b)<\\x6 VV -> p2 x6> | fst v == x1 && x_Tuple22 v == x2 && snd v == x2 && x_Tuple21 v == x1} ( {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == f} f , x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size v == qsize v} makeq ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == f} f ) {v : (LazyQueue.SList a) | v == b && size v <= size f} b ) Aside: Why didn't we (or Okasaki) use a pattern match here? To Ensure the Invariant we use the smart constructor makeq , which is where the heavy lifting, such as it is, happens. The constructor takes two lists, the front f and back b and if they are balanced, directly returns the Queue , and otherwise transfers the elements from b over using rot ate. 297: {-@ makeq :: f : SList a 298: -> b : SListLE a {size f + 1 } 299: -> QueueN a {size f + size b} 300: @-} 301: forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1 + 1} -> {v : (LazyQueue.Queue a) | size x1 + size x2 == qsize v} makeq (LazyQueue.SList a) f {v : (LazyQueue.SList a) | size v <= size f + 1} b 302: | x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 <= v} <= x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == f} f = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q {v : (LazyQueue.SList a) | v == f} f {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b 303: | otherwise = x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v <= size x1} -> {v : (LazyQueue.Queue a) | qsize v == size x1 + size x2 && front v == x1 && back v == x2} Q ( forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot {v : (LazyQueue.SList a) | v == f} f {v : (LazyQueue.SList a) | v == b && size v <= size f + 1} b {v : (LazyQueue.SList a) | size v == 0} nil ) {v : (LazyQueue.SList a) | size v == 0} nil The Rotate function is only called when the back is one larger than the front (we never let things drift beyond that). It is arranged so that it the hd is built up fast, before the entire computation finishes; which, combined with laziness provides the efficient worst-case guarantee. 313: {-@ rot :: f : SList a 314: -> b : SListN _ {1 + size f} 315: -> a : SList _ 316: -> SListN _ {size f + size b + size a} 317: @-} 318: forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot (LazyQueue.SList a) f {v : (LazyQueue.SList a) | size v == 1 + size f} b (LazyQueue.SList a) a 319: | x1:(LazyQueue.SList a) -> {v : GHC.Types.Int | v == size x1 && v >= 0} size {v : (LazyQueue.SList a) | v == f} f x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == v} == {v : GHC.Types.Int | v == (0 : int)} 0 = {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == a} a 320: | otherwise = {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == f} f a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` forall a. x1:(LazyQueue.SList a) -> x2:{v : (LazyQueue.SList a) | size v == 1 + size x1} -> x3:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size x1 + size x2 + size x3} rot ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == f} f ) ( x1:{v : (LazyQueue.SList a) | size v > 0} -> {v : (LazyQueue.SList a) | size v == size x1 - 1} tl {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b ) ( {v : (LazyQueue.SList a) | size v > 0} -> a hd {v : (LazyQueue.SList a) | v == b && size v == 1 + size f} b a -> x2:(LazyQueue.SList a) -> {v : (LazyQueue.SList a) | size v == size v + 1} `cons` {v : (LazyQueue.SList a) | v == a} a )","title":"Queue Operations"},{"location":"blogposts/2015-01-30-okasakis-lazy-queue.lhs/#conclusion","text":"Well there you have it; Okasaki's beautiful lazy Queue, with the invariants easily expressed and checked with LiquidHaskell. I find this example particularly interesting because the refinements express invariants that are critical for efficiency, and furthermore the code introspects on the size in order to guarantee the invariants. Plus, it's just marginally more complicated than append and so, (I hope!) was easy to follow.","title":"Conclusion"},{"location":"blogposts/2016-09-01-normal-forms.lhs/","text":"I have been preparing an undergraduate course on Compilers in which we build a compiler that crunches an ML-like language to X86 assembly. One of my favorite steps in the compilation is the conversion to A-Normal Form (ANF) where, informally speaking, each call or primitive operation's arguments are immediate values, i.e. constants or variable lookups whose values can be loaded with a single machine instruction. For example, the expression 25: ( ( 2 + 3 ) * ( 12 - 4 ) ) * ( 7 + 8 ) has the A-Normal Form: 31: let anf0 = 2 + 3 32: anf1 = 12 - 4 33: anf2 = anf0 * anf1 34: anf3 = 7 + 8 35: in 36: anf2 * anf3 The usual presentation of ANF conversion is very elegant but relies upon a clever use of continuations . Lets look at another perhaps simpler approach, where we can use refinements to light the way. 49: {-@ LIQUID \"--no-termination\" @-} 50: {-@ LIQUID \"--total\" @-} 51: 52: module ANF ( Op ( .. ) , Expr ( .. ) , isImm , isAnf , toAnf ) where 53: 54: import Control . Monad . State . Lazy 55: 56: mkLet :: [ ( Var , AnfExpr ) ] -> AnfExpr -> AnfExpr 57: imm , immExpr :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) 58: anf :: Expr -> AnfM AnfExpr 59: 60: -- data IExpr 61: -- = IInt Int 62: -- | IVar Var 63: -- 64: -- data AExpr 65: -- = AImm IExpr 66: -- | ABin Op IExpr IExpr 67: -- | ALet Var AExpr AExpr 68: -- | ALam Var AExpr 69: -- | AApp IExpr IExpr 70: 71: type AnfExpr = Expr 72: type ImmExpr = Expr Source Language \u00b6 Lets commence by defining the source language that we wish to work with: 82: data Expr 83: = EInt Int -- ^ Integers 84: | EVar Var -- ^ Variables 85: | EBin Op Expr Expr -- ^ Binary Operators 86: | ELet Var Expr Expr -- ^ Let-binders 87: | ELam Var Expr -- ^ Function definitions 88: | EApp Expr Expr -- ^ Function applications 89: deriving ( (GHC.Show.Show ANF.Expr) Show ) The language, defined by Expr has integers, variables, binary operators, let-binders and function definitions (lambdas) and calls (applications). In the above, Var and Op are simply: 97: type Var = String 98: 99: data Op = Plus | Minus | Times 100: deriving ( (GHC.Show.Show ANF.Op) Show ) For example, the source expression above corresponds to the value: 106: -- ((2 + 3) * (12 - 4)) * (7 + 8) 107: srcExpr :: Expr 108: {VV : ANF.Expr | VV /= ANF.e1 && VV /= ANF.e2 && VV /= ANF.e2' && VV /= ANF.e3 && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false)} srcExpr = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Times 109: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Times 110: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 2 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 3 ) ) 111: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Minus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 12 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 4 ) ) ) 112: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 7 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 8 ) ) A-Normal Form \u00b6 Before we can describe a conversion to A-Normal Form (ANF), we must pin down what ANF is . Our informal description was: ``each call or primitive operation's arguments are immediate values, i.e. constants or variable lookups''. We could define a brand new datatypes, say IExpr and AExpr whose values correspond to immediate and ANF terms. (Try it, as an exercise.) Unfortunately, doing so leads to a bunch of code duplication, e.g. duplicate printers for Expr and AExpr . Instead, lets see how we can use refinements to carve out suitable subsets. Immediate Expressions An Expr is immediate if it is a Number or a Var ; we can formalize this as a Haskell predicate: 136: {-@ measure isImm @-} 137: isImm :: Expr -> Bool 138: x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isImm x1)} isImm ( EInt _ ) = True 139: isImm ( EVar _ ) = True 140: isImm _ = False and then we can use the predicate to define a refinement type for immediate expressions: 147: {-@ type ImmExpr = { v : Expr | isImm v } @-} For example, e1 is immediate but e2 is not: 153: {-@ e1 :: ImmExpr @-} 154: {v : ANF.Expr | Prop (isImm v)} e1 = {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 7 155: 156: {-@ e2 :: ImmExpr @-} 157: {v : ANF.Expr | Prop (isImm v)} e2 = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e1 e1 ANF Expressions Similiarly, an Expr is in ANF if all arguments for operators and applications are immediate . Once again, we can formalize this intuition as a Haskell predicate: 167: {-@ measure isAnf @-} 168: isAnf :: Expr -> Bool 169: x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf ( EInt { } ) = True 170: isAnf ( EVar { } ) = True 171: isAnf ( EBin _ e1 e2 ) = {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e2 -- args for operators 172: isAnf ( EApp e1 e2 ) = {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e2 -- must be immediate, 173: isAnf ( ELet _ e1 e2 ) = x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e2 -- and sub-expressions 174: isAnf ( ELam _ e ) = x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e -- must be in ANF and then use the predicate to define the subset of legal ANF expressions: 180: {-@ type AnfExpr = { v : Expr | isAnf v } @-} For example, e2 above is in ANF but e3 is not: 186: {-@ e2' :: AnfExpr @-} 187: {v : ANF.Expr | Prop (isAnf v)} e2' = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e1 e1 188: 189: {-@ e3 :: AnfExpr @-} 190: {v : ANF.Expr | Prop (isAnf v)} e3 = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e2' e2' ANF Conversion: Intuition \u00b6 Now that we have clearly demarcated the territories belonging to plain Expr , immediate ImmExpr and A-Normal AnfExpr , lets see how we can convert the former to the latter. Recall that our goal is to convert expressions like 203: ( ( 2 + 3 ) * ( 12 - 4 ) ) * ( 7 + 8 ) into 209: let anf0 = 2 + 3 210: anf1 = 12 - 4 211: anf2 = anf0 * anf1 212: anf3 = 7 + 8 213: in 214: anf2 * anf3 Generalising a bit, we want to convert 220: e1 + e2 into 226: let x1 = a1 ... xn = an 227: x1' = a1' ... xm' = am' 228: in 229: v1 + v2 where, v1 and v2 are immediate, and ai are ANF. Making Arguments Immediate In other words, the key requirement is a way to crunch arbitrary argument expressions like e1 into a pair 240: ( [ ( x1 , a1 ) ... ( xn , an ) ] , v1 ) where a1...an are AnfExpr , and v1 is an immediate ImmExpr such that e1 is equivalent to let x1 = a1 ... xn = an in v1 . Thus, we need a function 252: imm :: Expr -> ( [ ( Var , AnfExpr ) ] , ImmExpr ) which we will use to make arguments immediate thereby yielding a top level conversion function 259: anf :: Expr -> AnfExpr As we need to generate \"temporary\" intermediate binders, it will be convenient to work within a monad that generates fresh variables: 267: type AnfM a = State Int a 268: 269: fresh :: AnfM Var 270: (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {VV : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0}) fresh = do 271: GHC.Types.Int n <- (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity GHC.Types.Int) get 272: GHC.Types.Int -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ()) put ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 273: [GHC.Types.Char] -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity [GHC.Types.Char]) return ( [GHC.Types.Char] \"anf\" ++ GHC.Types.Int -> [GHC.Types.Char] show n ) Thus, the conversion functions will have the types: 279: anf :: Expr -> AnfM AnfExpr 280: imm :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) ANF Conversion: Code \u00b6 We can now define the top-level conversion thus: 289: -------------------------------------------------------------------------------- 290: {-@ anf :: Expr -> AnfM AnfExpr @-} 291: -------------------------------------------------------------------------------- 292: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf ( EInt n ) = 293: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt n ) 294: 295: anf ( EVar x ) = 296: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar x ) 297: 298: anf ( ELet x e1 e2 ) = do 299: {v : ANF.Expr | Prop (isAnf v)} a1 <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e1 300: {v : ANF.Expr | Prop (isAnf v)} a2 <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e2 301: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2) && Prop (isAnf x3))} | v == ANF.ELet} ELet x a1 a2 ) 302: 303: anf ( EBin o e1 e2 ) = do 304: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 305: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 306: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet ( {v : [([GHC.Types.Char], ANF.Expr)] | len v == len b1s + len b2s} b1s ++ b2s ) ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin o v1 v2 ) ) 307: 308: anf ( ELam x e ) = do 309: {v : ANF.Expr | Prop (isAnf v)} a <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e 310: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2))} | v == ANF.ELam} ELam x a ) 311: 312: anf ( EApp e1 e2 ) = do 313: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 314: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 315: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet ( {v : [([GHC.Types.Char], ANF.Expr)] | len v == len b1s + len b2s} b1s ++ b2s ) ( {v : x1:ANF.Expr -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x1) && Prop (isImm x2))} | v == ANF.EApp} EApp v1 v2 ) ) In anf the real work happens inside imm which takes an arbitary argument expression and makes it immediate by generating temporary (ANF) bindings. The resulting bindings (and immediate values) are composed by the helper mkLet that takes a list of binders and a body AnfExpr and stitches them into a single AnfExpr : 325: {-@ mkLet :: [ ( Var , AnfExpr ) ] -> AnfExpr -> AnfExpr @-} 326: [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet [] {v : ANF.Expr | Prop (isAnf v)} e' = e' 327: mkLet ( ( x , e ) : bs ) e' = {v : [GHC.Types.Char] -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2) && Prop (isAnf x3))} | v == ANF.ELet} ELet x e ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet bs e' ) The arguments are made immediate by imm defined as: 333: -------------------------------------------------------------------------------- 334: {-@ imm :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) @-} 335: -------------------------------------------------------------------------------- 336: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm ( EInt n ) = ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [] , {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt n ) 337: imm ( EVar x ) = ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [] , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar x ) 338: imm e @ ( ELet { } ) = ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr e 339: imm e @ ( ELam { } ) = ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr e 340: imm ( EBin o e1 e2 ) = ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 e1 e2 ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin o ) 341: imm ( EApp e1 e2 ) = ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 e1 e2 {v : x1:ANF.Expr -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x1) && Prop (isImm x2))} | v == ANF.EApp} EApp Numbers and variables are already immediate, and are returned directly. Let-binders and lambdas are simply converted to ANF, and assigned to a fresh binder: 350: {-@ immExpr :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) @-} 351: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr ANF.Expr e = do 352: {v : ANF.Expr | Prop (isAnf v)} a <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e 353: {v : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) >= 0} t <- fresh 354: ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [ ( t , a ) ] , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar t ) Finally, binary operators and applications are converted by imm2 that takes two arbitrary expressions and an expression constructor, yielding the anf-binders and immediate expression. 362: imm2 :: Expr -> Expr -> ( ImmExpr -> ImmExpr -> AnfExpr ) 363: -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) 364: ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 ANF.Expr e1 ANF.Expr e2 x1:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x2:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x2 && VV /= ANF.e2 && VV /= x1 && VV /= ANF.e1} f = do 365: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 366: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 367: {v : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) >= 0} t <- fresh 368: let [([GHC.Types.Char], ANF.Expr)] bs' = [([GHC.Types.Char], ANF.Expr)] b1s ++ [([GHC.Types.Char], ANF.Expr)] b2s ++ [ ( t , {v : x1:{v : ANF.Expr | v /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool)} -> x2:{v : ANF.Expr | v /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool)} -> {v : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && v /= x2 && v /= ANF.e2 && v /= x1 && v /= ANF.e1} | v == f} f v1 v2 ) ] 369: ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( bs' , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar t ) You can run it thus: 376: toAnf :: Expr -> AnfExpr 377: ANF.Expr -> ANF.Expr toAnf ANF.Expr e = GHC.Types.Int -> ANF.Expr evalState ( ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e ) 0 381: ghci > toAnf srcExpr 382: ELet \"anf0\" ( EBin Plus ( EInt 2 ) ( EInt 3 ) ) 383: ( ELet \"anf1\" ( EBin Minus ( EInt 12 ) ( EInt 4 ) ) 384: ( ELet \"anf2\" ( EBin Times ( EVar \"anf0\" ) ( EVar \"anf1\" ) ) 385: ( ELet \"anf3\" ( EBin Plus ( EInt 7 ) ( EInt 8 ) ) 386: ( EBin Times ( EVar \"anf2\" ) ( EVar \"anf3\" ) ) ) ) ) which, can be pretty-printed to yield exactly the outcome desired at the top: 392: let anf0 = 2 + 3 393: anf1 = 12 - 4 394: anf2 = anf0 * anf1 395: anf3 = 7 + 8 396: in 397: anf2 * anf3 There! The refinements make this tricky conversion quite straightforward and natural, without requiring us to duplicate types and code. As an exercise, can you use refinements to: Port the classic continuation-based conversion ? Check that the conversion yields well-scoped terms ?","title":"Normal Forms"},{"location":"blogposts/2016-09-01-normal-forms.lhs/#source-language","text":"Lets commence by defining the source language that we wish to work with: 82: data Expr 83: = EInt Int -- ^ Integers 84: | EVar Var -- ^ Variables 85: | EBin Op Expr Expr -- ^ Binary Operators 86: | ELet Var Expr Expr -- ^ Let-binders 87: | ELam Var Expr -- ^ Function definitions 88: | EApp Expr Expr -- ^ Function applications 89: deriving ( (GHC.Show.Show ANF.Expr) Show ) The language, defined by Expr has integers, variables, binary operators, let-binders and function definitions (lambdas) and calls (applications). In the above, Var and Op are simply: 97: type Var = String 98: 99: data Op = Plus | Minus | Times 100: deriving ( (GHC.Show.Show ANF.Op) Show ) For example, the source expression above corresponds to the value: 106: -- ((2 + 3) * (12 - 4)) * (7 + 8) 107: srcExpr :: Expr 108: {VV : ANF.Expr | VV /= ANF.e1 && VV /= ANF.e2 && VV /= ANF.e2' && VV /= ANF.e3 && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false)} srcExpr = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Times 109: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Times 110: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 2 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 3 ) ) 111: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Minus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 12 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 4 ) ) ) 112: ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 7 ) ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 8 ) )","title":"Source Language"},{"location":"blogposts/2016-09-01-normal-forms.lhs/#a-normal-form","text":"Before we can describe a conversion to A-Normal Form (ANF), we must pin down what ANF is . Our informal description was: ``each call or primitive operation's arguments are immediate values, i.e. constants or variable lookups''. We could define a brand new datatypes, say IExpr and AExpr whose values correspond to immediate and ANF terms. (Try it, as an exercise.) Unfortunately, doing so leads to a bunch of code duplication, e.g. duplicate printers for Expr and AExpr . Instead, lets see how we can use refinements to carve out suitable subsets. Immediate Expressions An Expr is immediate if it is a Number or a Var ; we can formalize this as a Haskell predicate: 136: {-@ measure isImm @-} 137: isImm :: Expr -> Bool 138: x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isImm x1)} isImm ( EInt _ ) = True 139: isImm ( EVar _ ) = True 140: isImm _ = False and then we can use the predicate to define a refinement type for immediate expressions: 147: {-@ type ImmExpr = { v : Expr | isImm v } @-} For example, e1 is immediate but e2 is not: 153: {-@ e1 :: ImmExpr @-} 154: {v : ANF.Expr | Prop (isImm v)} e1 = {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt 7 155: 156: {-@ e2 :: ImmExpr @-} 157: {v : ANF.Expr | Prop (isImm v)} e2 = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e1 e1 ANF Expressions Similiarly, an Expr is in ANF if all arguments for operators and applications are immediate . Once again, we can formalize this intuition as a Haskell predicate: 167: {-@ measure isAnf @-} 168: isAnf :: Expr -> Bool 169: x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf ( EInt { } ) = True 170: isAnf ( EVar { } ) = True 171: isAnf ( EBin _ e1 e2 ) = {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e2 -- args for operators 172: isAnf ( EApp e1 e2 ) = {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && {v : x1:ANF.Expr -> {v : GHC.Types.Bool | Prop v <=> Prop (isImm x1)} | v == isImm} isImm e2 -- must be immediate, 173: isAnf ( ELet _ e1 e2 ) = x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e1 {v : x1:GHC.Types.Bool -> x2:GHC.Types.Bool -> {v : GHC.Types.Bool | Prop v <=> Prop x1 && Prop x2} | v == GHC.Classes.&&} && x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e2 -- and sub-expressions 174: isAnf ( ELam _ e ) = x1:ANF.Expr -> {VV : GHC.Types.Bool | Prop VV <=> Prop (isAnf x1)} isAnf e -- must be in ANF and then use the predicate to define the subset of legal ANF expressions: 180: {-@ type AnfExpr = { v : Expr | isAnf v } @-} For example, e2 above is in ANF but e3 is not: 186: {-@ e2' :: AnfExpr @-} 187: {v : ANF.Expr | Prop (isAnf v)} e2' = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e1 e1 188: 189: {-@ e3 :: AnfExpr @-} 190: {v : ANF.Expr | Prop (isAnf v)} e3 = {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin Plus e2' e2'","title":"A-Normal Form"},{"location":"blogposts/2016-09-01-normal-forms.lhs/#anf-conversion-intuition","text":"Now that we have clearly demarcated the territories belonging to plain Expr , immediate ImmExpr and A-Normal AnfExpr , lets see how we can convert the former to the latter. Recall that our goal is to convert expressions like 203: ( ( 2 + 3 ) * ( 12 - 4 ) ) * ( 7 + 8 ) into 209: let anf0 = 2 + 3 210: anf1 = 12 - 4 211: anf2 = anf0 * anf1 212: anf3 = 7 + 8 213: in 214: anf2 * anf3 Generalising a bit, we want to convert 220: e1 + e2 into 226: let x1 = a1 ... xn = an 227: x1' = a1' ... xm' = am' 228: in 229: v1 + v2 where, v1 and v2 are immediate, and ai are ANF. Making Arguments Immediate In other words, the key requirement is a way to crunch arbitrary argument expressions like e1 into a pair 240: ( [ ( x1 , a1 ) ... ( xn , an ) ] , v1 ) where a1...an are AnfExpr , and v1 is an immediate ImmExpr such that e1 is equivalent to let x1 = a1 ... xn = an in v1 . Thus, we need a function 252: imm :: Expr -> ( [ ( Var , AnfExpr ) ] , ImmExpr ) which we will use to make arguments immediate thereby yielding a top level conversion function 259: anf :: Expr -> AnfExpr As we need to generate \"temporary\" intermediate binders, it will be convenient to work within a monad that generates fresh variables: 267: type AnfM a = State Int a 268: 269: fresh :: AnfM Var 270: (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {VV : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0}) fresh = do 271: GHC.Types.Int n <- (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity GHC.Types.Int) get 272: GHC.Types.Int -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ()) put ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 273: [GHC.Types.Char] -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity [GHC.Types.Char]) return ( [GHC.Types.Char] \"anf\" ++ GHC.Types.Int -> [GHC.Types.Char] show n ) Thus, the conversion functions will have the types: 279: anf :: Expr -> AnfM AnfExpr 280: imm :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr )","title":"ANF Conversion: Intuition"},{"location":"blogposts/2016-09-01-normal-forms.lhs/#anf-conversion-code","text":"We can now define the top-level conversion thus: 289: -------------------------------------------------------------------------------- 290: {-@ anf :: Expr -> AnfM AnfExpr @-} 291: -------------------------------------------------------------------------------- 292: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf ( EInt n ) = 293: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt n ) 294: 295: anf ( EVar x ) = 296: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar x ) 297: 298: anf ( ELet x e1 e2 ) = do 299: {v : ANF.Expr | Prop (isAnf v)} a1 <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e1 300: {v : ANF.Expr | Prop (isAnf v)} a2 <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e2 301: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2) && Prop (isAnf x3))} | v == ANF.ELet} ELet x a1 a2 ) 302: 303: anf ( EBin o e1 e2 ) = do 304: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 305: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 306: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet ( {v : [([GHC.Types.Char], ANF.Expr)] | len v == len b1s + len b2s} b1s ++ b2s ) ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin o v1 v2 ) ) 307: 308: anf ( ELam x e ) = do 309: {v : ANF.Expr | Prop (isAnf v)} a <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e 310: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( {v : [GHC.Types.Char] -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2))} | v == ANF.ELam} ELam x a ) 311: 312: anf ( EApp e1 e2 ) = do 313: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 314: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 315: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ANF.Expr) return ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet ( {v : [([GHC.Types.Char], ANF.Expr)] | len v == len b1s + len b2s} b1s ++ b2s ) ( {v : x1:ANF.Expr -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x1) && Prop (isImm x2))} | v == ANF.EApp} EApp v1 v2 ) ) In anf the real work happens inside imm which takes an arbitary argument expression and makes it immediate by generating temporary (ANF) bindings. The resulting bindings (and immediate values) are composed by the helper mkLet that takes a list of binders and a body AnfExpr and stitches them into a single AnfExpr : 325: {-@ mkLet :: [ ( Var , AnfExpr ) ] -> AnfExpr -> AnfExpr @-} 326: [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet [] {v : ANF.Expr | Prop (isAnf v)} e' = e' 327: mkLet ( ( x , e ) : bs ) e' = {v : [GHC.Types.Char] -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isAnf x2) && Prop (isAnf x3))} | v == ANF.ELet} ELet x e ( [([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})] -> {v : ANF.Expr | Prop (isAnf v)} -> {v : ANF.Expr | Prop (isAnf v)} mkLet bs e' ) The arguments are made immediate by imm defined as: 333: -------------------------------------------------------------------------------- 334: {-@ imm :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) @-} 335: -------------------------------------------------------------------------------- 336: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm ( EInt n ) = ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [] , {v : GHC.Types.Int -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EInt} EInt n ) 337: imm ( EVar x ) = ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [] , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar x ) 338: imm e @ ( ELet { } ) = ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr e 339: imm e @ ( ELam { } ) = ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr e 340: imm ( EBin o e1 e2 ) = ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 e1 e2 ( {v : ANF.Op -> x2:ANF.Expr -> x3:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x2) && Prop (isImm x3))} | v == ANF.EBin} EBin o ) 341: imm ( EApp e1 e2 ) = ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 e1 e2 {v : x1:ANF.Expr -> x2:ANF.Expr -> {v : ANF.Expr | (Prop (isImm v) <=> false) && (Prop (isAnf v) <=> Prop (isImm x1) && Prop (isImm x2))} | v == ANF.EApp} EApp Numbers and variables are already immediate, and are returned directly. Let-binders and lambdas are simply converted to ANF, and assigned to a fresh binder: 350: {-@ immExpr :: Expr -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) @-} 351: ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) immExpr ANF.Expr e = do 352: {v : ANF.Expr | Prop (isAnf v)} a <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e 353: {v : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) >= 0} t <- fresh 354: ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( [ ( t , a ) ] , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar t ) Finally, binary operators and applications are converted by imm2 that takes two arbitrary expressions and an expression constructor, yielding the anf-binders and immediate expression. 362: imm2 :: Expr -> Expr -> ( ImmExpr -> ImmExpr -> AnfExpr ) 363: -> AnfM ( [ ( Var , AnfExpr ) ] , ImmExpr ) 364: ANF.Expr -> ANF.Expr -> (x4:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x5:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x5 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x4 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x5 && VV /= ANF.e2 && VV /= x4 && VV /= ANF.e1}) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ({VV : [([GHC.Types.Char], {VV : ANF.Expr | ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)})] | (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (VV : [@(0)]) >= 0 && (VV : @(43)) == ((fst : func(0, [(Tuple @(43) @(44)); @(43)])) (VV : (Tuple @(45) @(44))) : @(43))}, {VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && (VV : @(42)) == ((snd : func(0, [(Tuple @(45) @(42)); @(42)])) (VV : (Tuple @(45) @(44))) : @(42))})) imm2 ANF.Expr e1 ANF.Expr e2 x1:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> x2:{VV : ANF.Expr | VV /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool)} -> {VV : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (VV : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && VV /= x2 && VV /= ANF.e2 && VV /= x1 && VV /= ANF.e1} f = do 365: ( b1s , v1 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e1 366: ( b2s , v2 ) <- ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], {v : ANF.Expr | Prop (isAnf v)})], {v : ANF.Expr | Prop (isImm v)})) imm e2 367: {v : [GHC.Types.Char] | (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) > 0 && (len : func(2, [(@(0) @(1)); int])) (v : [@(0)]) >= 0} t <- fresh 368: let [([GHC.Types.Char], ANF.Expr)] bs' = [([GHC.Types.Char], ANF.Expr)] b1s ++ [([GHC.Types.Char], ANF.Expr)] b2s ++ [ ( t , {v : x1:{v : ANF.Expr | v /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool)} -> x2:{v : ANF.Expr | v /= ANF.srcExpr && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool)} -> {v : ANF.Expr | (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> false) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (x1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool) && (Prop : func(0, [GHC.Types.Bool; bool])) ((isImm : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e1 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> true) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e3 : ANF.Expr) : GHC.Types.Bool)) && ((Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (v : ANF.Expr) : GHC.Types.Bool) <=> (Prop : func(0, [GHC.Types.Bool; bool])) ((isAnf : func(0, [ANF.Expr; GHC.Types.Bool])) (ANF.e2' : ANF.Expr) : GHC.Types.Bool)) && v /= x2 && v /= ANF.e2 && v /= x1 && v /= ANF.e1} | v == f} f v1 v2 ) ] 369: ([([GHC.Types.Char], ANF.Expr)], ANF.Expr) -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity ([([GHC.Types.Char], ANF.Expr)], ANF.Expr)) return ( bs' , {v : [GHC.Types.Char] -> {v : ANF.Expr | (Prop (isImm v) <=> true) && (Prop (isAnf v) <=> true)} | v == ANF.EVar} EVar t ) You can run it thus: 376: toAnf :: Expr -> AnfExpr 377: ANF.Expr -> ANF.Expr toAnf ANF.Expr e = GHC.Types.Int -> ANF.Expr evalState ( ANF.Expr -> (Control.Monad.Trans.State.Lazy.StateT GHC.Types.Int Data.Functor.Identity.Identity {v : ANF.Expr | Prop (isAnf v)}) anf e ) 0 381: ghci > toAnf srcExpr 382: ELet \"anf0\" ( EBin Plus ( EInt 2 ) ( EInt 3 ) ) 383: ( ELet \"anf1\" ( EBin Minus ( EInt 12 ) ( EInt 4 ) ) 384: ( ELet \"anf2\" ( EBin Times ( EVar \"anf0\" ) ( EVar \"anf1\" ) ) 385: ( ELet \"anf3\" ( EBin Plus ( EInt 7 ) ( EInt 8 ) ) 386: ( EBin Times ( EVar \"anf2\" ) ( EVar \"anf3\" ) ) ) ) ) which, can be pretty-printed to yield exactly the outcome desired at the top: 392: let anf0 = 2 + 3 393: anf1 = 12 - 4 394: anf2 = anf0 * anf1 395: anf3 = 7 + 8 396: in 397: anf2 * anf3 There! The refinements make this tricky conversion quite straightforward and natural, without requiring us to duplicate types and code. As an exercise, can you use refinements to: Port the classic continuation-based conversion ? Check that the conversion yields well-scoped terms ?","title":"ANF Conversion: Code"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/","text":"We've taught LiquidHaskell a new trick that we call ``Refinement Reflection'' which lets us turn Haskell into a theorem prover capable of proving arbitrary properties of code. The key idea is to reflect the code of the function into its output type , which lets us then reason about the function at the (refinement) type level. Lets see how to use refinement types to express a theorem, for example that fibonacci is a monotonically increasing function, then write plain Haskell code to reify a paper-and-pencil-style proof for that theorem, that can be machine checked by LiquidHaskell. 38: {-@ LIQUID \"--higherorder\" @-} 39: {-@ LIQUID \"--totality\" @-} 40: module RefinementReflection where 41: import Language . Haskell . Liquid . ProofCombinators 42: 43: fib :: Int -> Int 44: propPlusComm :: Int -> Int -> Proof 45: propOnePlueOne :: () -> Proof 46: fibTwo :: () -> Proof 47: fibCongruence :: Int -> Int -> Proof 48: fibUp :: Int -> Proof 49: fibTwoPretty :: Proof 50: fibThree :: () -> Proof 51: fMono :: ( Int -> Int ) 52: -> ( Int -> Proof ) 53: -> Int 54: -> Int 55: -> Proof 56: fibMono :: Int -> Int -> Proof 57: Shallow vs. Deep Specifications \u00b6 Up to now, we have been using Liquid Haskell to specify and verify \"shallow\" specifications that abstractly describe the behavior of functions. For example, below, we specify and verify that fib restricted to natural numbers, always terminates returning a natural number. 70: {-@ fib :: i : Nat -> Nat / [ i ] @-} 71: {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib {v : GHC.Types.Int | v >= 0} i | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 0 = 0 72: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 1 = 1 73: | otherwise = {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) In this post we present how refinement reflection is used to verify \"deep\" specifications that use the exact definition of Haskell functions. For example, we will prove that the Haskell fib function is increasing. Propositions \u00b6 To begin with, we import ProofCombinators , a (Liquid) Haskell library that defines and manipulates logical proofs. 89: import Language . Haskell . Liquid . ProofCombinators A Proof is a data type that carries no run time information 95: type Proof = () but can be refined with desired logical propositions. For example, the following type states that 1 + 1 == 2 102: {-@ type OnePlusOne = { v : Proof | 1 + 1 == 2 } @-} Since the v and Proof are irrelevant, we may as well abbreviate the above to 109: {-@ type OnePlusOne' = { 1 + 1 == 2 } @-} As another example, the following function type declares that for each x and y the plus operator commutes. 117: {-@ type PlusComm = x : Int -> y : Int -> { x + y == y + x } @-} Trivial Proofs \u00b6 We prove the above theorems using Haskell programs. The ProofCombinators module defines the trivial proof 129: trivial :: Proof 130: trivial = () and the \"casting\" operator (***) that makes proof terms look nice: 137: data QED = QED 138: 139: ( *** ) :: a -> QED -> Proof 140: _ *** _ = () Using the underlying SMT's knowledge on linear arithmetic, we can trivially prove the above propositions. 147: {-@ propOnePlueOne :: _ -> OnePlusOne @-} 148: () -> {VV : () | 1 + 1 == 2} propOnePlueOne _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED 149: 150: {-@ propPlusComm :: PlusComm @-} 151: x1:GHC.Types.Int -> x2:GHC.Types.Int -> {VV : () | x1 + x2 == x2 + x1} propPlusComm _ _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED We saw how we use SMT's knowledge on linear arithmetic to trivially prove arithmetic properties. But how can we prove ``deep'' properties on Haskell's functions? Refinement Reflection \u00b6 Refinement Reflection allows deep specification and verification by reflecting the code implementing a Haskell function into the function\u2019s output refinement type. Refinement Reflection proceeds in 3 steps: definition, reflection, and application. Consider reflecting the definition of fib into the logic 171: {-@ reflect fib @-} then the following three reflection steps will occur. Step 1: Definition \u00b6 Reflection of the Haskell function fib defines in logic an uninterpreted function fib that satisfies the congruence axiom. In the logic the function fib is defined. 185: fib :: Int -> Int SMT only knows that fib satisfies the congruence axiom. 191: {-@ fibCongruence :: i : Nat -> j : Nat -> {i == j => fib i == fib j} @-} 192: x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 == x2 => fib x1 == fib x2} fibCongruence _ _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED Other than congruence, SMT knowns nothing for the function fib , until reflection happens! Step 2: Reflection \u00b6 As a second step, Liquid Haskell connects the Haskell function fib with the homonymous logical function, by reflecting the implementation of fib in its result type. The result type of fib is automatically strengthened to the following. 210: fib :: i : Nat -> { v : Nat | v == fib i && v = fibP i } That is, the result satisfies the fibP predicate exactly reflecting the implementation of fib . 217: fibP i = if i == 0 then 0 else 218: if i == 1 then 1 else 219: fin ( i - 1 ) + fib ( i - 2 ) Step 3: Application \u00b6 With the reflected refinement type, each application of fib automatically unfolds the definition of fib once. As an example, applying fib to 0 , 1 , and 2 allows us to prove that fib 2 == 1 : 231: {-@ fibTwo :: _ -> { fib 2 == 1 } @-} 232: () -> {VV : () | fib 2 == 1} fibTwo _ = {v : [GHC.Types.Int] | null v <=> false} [ {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 , {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 , {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 ] *** QED Though valid, the above fibTwo proof is not pretty! Structuring Proofs \u00b6 To make our proofs look nice, we use combinators from the ProofCombinators library, which exports a family of operators (*.) where * comes from the theory of linear arithmetic and the refinement type of x *. y requires that x *. y holds and ensures that the returned value is equal to x . For example, (==.) and (<=.) are predefined in ProofCombinators as 252: ( ==. ) :: x : a -> y : { a | x == y } -> { v : a | v == x } 253: x ==. _ = x 254: 255: ( <=. ) :: x : a -> y : { a | x <= y } -> { v : a | v == x } 256: x <=. _ = x Using these predefined operators, we construct paper and pencil-like proofs for the fib function. 263: {-@ fibTwoPretty :: { fib 2 == 1 } @-} 264: {VV : () | fib 2 == 1} fibTwoPretty 265: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 266: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 267: *** QED Because operator \u00b6 To allow the reuse of existing proofs, ProofCombinators defines the because operator (\u2235) 279: ( \u2235 ) :: ( Proof -> a ) -> Proof -> a 280: f \u2235 y = f y For example, fib 3 == 2 holds because fib 2 == 1 : 286: {-@ fibThree :: _ -> { fib 3 == 2 } @-} 287: () -> {VV : () | fib 3 == 2} fibThree _ 288: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 3 289: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 290: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int ==. GHC.Types.Int 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 \u2235 fibTwoPretty 291: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. 2 292: *** QED Proofs by Induction (i.e. Recursion) \u00b6 Next, combining the above operators we specify and prove that fib is increasing, that is for each natural number i , fib i <= fib (i+1) . We specify the theorem as a refinement type for fubUp and use Haskell code to persuade Liquid Haskell that the theorem holds. 309: {-@ fibUp :: i : Nat -> {fib i <= fib (i+1)} @-} 310: x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp {v : GHC.Types.Int | v >= 0} i 311: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 0 312: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 313: *** QED 314: 315: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 1 316: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 317: *** QED 318: 319: | otherwise 320: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i 321: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) 322: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) \u2235 x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 323: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) \u2235 x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) 324: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 325: *** QED The proof proceeds by induction on i . The base cases i == 0 and i == 1 are represented as Haskell's case splitting. The inductive hypothesis is represented by recursive calls on smaller inputs. Finally, the SMT solves arithmetic reasoning to conclude the proof. Higher Order Theorems \u00b6 Refinement Reflection can be used to express and verify higher order theorems! For example, fMono specifies that each locally increasing function is monotonic! 345: {-@ fMono :: f : ( Nat -> Int ) 346: -> fUp : ( z : Nat -> {f z <= f (z+1)} ) 347: -> x : Nat 348: -> y : {Nat|x < y} 349: -> {f x <= f y} / [ y ] 350: @-} 351: x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {VV : () | x1 x5 <= x1 x6} fMono {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int f x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | f x1 <= f (x1 + 1)} thm {v : GHC.Types.Int | v >= 0} x {v : GHC.Types.Int | v >= 0 && x < v} y 352: | GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == y 353: = {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f y GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f ( GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 354: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int >. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f x \u2235 {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm x 355: *** QED 356: 357: | GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 < x2} < y 358: = {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f x 359: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) \u2235 x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {VV : () | x1 x5 <= x1 x6} fMono {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm x ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 360: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f y \u2235 {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 361: *** QED Again, the recursive implementation of fMono depicts the paper and pencil proof of fMono by induction on the decreasing argument / [y] . Since fib is proven to be locally increasing by fUp , we use fMono to prove that fib is monotonic. 371: {-@ fibMono :: n : Nat -> m : {Nat | n < m } -> {fib n <= fib m} @-} 372: x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : GHC.Types.Int | v >= 0 && x1 < v} -> {VV : () | fib x1 <= fib x2} fibMono = {v : x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {v : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {v : () | x1 x5 <= x1 x6} | v == RefinementReflection.fMono} fMono {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | fib x1 <= fib (x1 + 1)} | v == RefinementReflection.fibUp} fibUp Conclusion \u00b6 We saw how refinement reflection turns Haskell into a theorem prover by reflecting the code implementing a Haskell function into the function\u2019s output refinement type. Refinement Types are used to express theorems, Haskell code is used to prove such theorems expressing paper pencil proofs, and Liquid Haskell verifies the validity of the proofs! Proving fib monotonic is great, but this is Haskell! Wouldn\u2019t it be nice to prove theorems about inductive data types and higher order functions? Like fusions and folds? Or program equivalence on run-time optimizations like map-reduce? Stay tuned! Even better, if you happen you be in Nara for ICFP'16, come to my CUFP tutorial for more!","title":"Haskell as a Theorem Prover"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#shallow-vs-deep-specifications","text":"Up to now, we have been using Liquid Haskell to specify and verify \"shallow\" specifications that abstractly describe the behavior of functions. For example, below, we specify and verify that fib restricted to natural numbers, always terminates returning a natural number. 70: {-@ fib :: i : Nat -> Nat / [ i ] @-} 71: {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib {v : GHC.Types.Int | v >= 0} i | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 0 = 0 72: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 1 = 1 73: | otherwise = {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) In this post we present how refinement reflection is used to verify \"deep\" specifications that use the exact definition of Haskell functions. For example, we will prove that the Haskell fib function is increasing.","title":"Shallow vs. Deep Specifications"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#propositions","text":"To begin with, we import ProofCombinators , a (Liquid) Haskell library that defines and manipulates logical proofs. 89: import Language . Haskell . Liquid . ProofCombinators A Proof is a data type that carries no run time information 95: type Proof = () but can be refined with desired logical propositions. For example, the following type states that 1 + 1 == 2 102: {-@ type OnePlusOne = { v : Proof | 1 + 1 == 2 } @-} Since the v and Proof are irrelevant, we may as well abbreviate the above to 109: {-@ type OnePlusOne' = { 1 + 1 == 2 } @-} As another example, the following function type declares that for each x and y the plus operator commutes. 117: {-@ type PlusComm = x : Int -> y : Int -> { x + y == y + x } @-}","title":"Propositions"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#trivial-proofs","text":"We prove the above theorems using Haskell programs. The ProofCombinators module defines the trivial proof 129: trivial :: Proof 130: trivial = () and the \"casting\" operator (***) that makes proof terms look nice: 137: data QED = QED 138: 139: ( *** ) :: a -> QED -> Proof 140: _ *** _ = () Using the underlying SMT's knowledge on linear arithmetic, we can trivially prove the above propositions. 147: {-@ propOnePlueOne :: _ -> OnePlusOne @-} 148: () -> {VV : () | 1 + 1 == 2} propOnePlueOne _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED 149: 150: {-@ propPlusComm :: PlusComm @-} 151: x1:GHC.Types.Int -> x2:GHC.Types.Int -> {VV : () | x1 + x2 == x2 + x1} propPlusComm _ _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED We saw how we use SMT's knowledge on linear arithmetic to trivially prove arithmetic properties. But how can we prove ``deep'' properties on Haskell's functions?","title":"Trivial Proofs"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#refinement-reflection","text":"Refinement Reflection allows deep specification and verification by reflecting the code implementing a Haskell function into the function\u2019s output refinement type. Refinement Reflection proceeds in 3 steps: definition, reflection, and application. Consider reflecting the definition of fib into the logic 171: {-@ reflect fib @-} then the following three reflection steps will occur.","title":"Refinement Reflection"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#step-1-definition","text":"Reflection of the Haskell function fib defines in logic an uninterpreted function fib that satisfies the congruence axiom. In the logic the function fib is defined. 185: fib :: Int -> Int SMT only knows that fib satisfies the congruence axiom. 191: {-@ fibCongruence :: i : Nat -> j : Nat -> {i == j => fib i == fib j} @-} 192: x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 == x2 => fib x1 == fib x2} fibCongruence _ _ = {v : Language.Haskell.Liquid.ProofCombinators.QED | v == Language.Haskell.Liquid.ProofCombinators.QED} trivial *** QED Other than congruence, SMT knowns nothing for the function fib , until reflection happens!","title":"Step 1: Definition"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#step-2-reflection","text":"As a second step, Liquid Haskell connects the Haskell function fib with the homonymous logical function, by reflecting the implementation of fib in its result type. The result type of fib is automatically strengthened to the following. 210: fib :: i : Nat -> { v : Nat | v == fib i && v = fibP i } That is, the result satisfies the fibP predicate exactly reflecting the implementation of fib . 217: fibP i = if i == 0 then 0 else 218: if i == 1 then 1 else 219: fin ( i - 1 ) + fib ( i - 2 )","title":"Step 2: Reflection"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#step-3-application","text":"With the reflected refinement type, each application of fib automatically unfolds the definition of fib once. As an example, applying fib to 0 , 1 , and 2 allows us to prove that fib 2 == 1 : 231: {-@ fibTwo :: _ -> { fib 2 == 1 } @-} 232: () -> {VV : () | fib 2 == 1} fibTwo _ = {v : [GHC.Types.Int] | null v <=> false} [ {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 , {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 , {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 ] *** QED Though valid, the above fibTwo proof is not pretty!","title":"Step 3: Application"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#structuring-proofs","text":"To make our proofs look nice, we use combinators from the ProofCombinators library, which exports a family of operators (*.) where * comes from the theory of linear arithmetic and the refinement type of x *. y requires that x *. y holds and ensures that the returned value is equal to x . For example, (==.) and (<=.) are predefined in ProofCombinators as 252: ( ==. ) :: x : a -> y : { a | x == y } -> { v : a | v == x } 253: x ==. _ = x 254: 255: ( <=. ) :: x : a -> y : { a | x <= y } -> { v : a | v == x } 256: x <=. _ = x Using these predefined operators, we construct paper and pencil-like proofs for the fib function. 263: {-@ fibTwoPretty :: { fib 2 == 1 } @-} 264: {VV : () | fib 2 == 1} fibTwoPretty 265: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 266: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 267: *** QED","title":"Structuring Proofs"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#because-operator","text":"To allow the reuse of existing proofs, ProofCombinators defines the because operator (\u2235) 279: ( \u2235 ) :: ( Proof -> a ) -> Proof -> a 280: f \u2235 y = f y For example, fib 3 == 2 holds because fib 2 == 1 : 286: {-@ fibThree :: _ -> { fib 3 == 2 } @-} 287: () -> {VV : () | fib 3 == 2} fibThree _ 288: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 3 289: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 290: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int ==. GHC.Types.Int 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 \u2235 fibTwoPretty 291: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. 2 292: *** QED","title":"Because operator"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#proofs-by-induction-ie-recursion","text":"Next, combining the above operators we specify and prove that fib is increasing, that is for each natural number i , fib i <= fib (i+1) . We specify the theorem as a refinement type for fubUp and use Haskell code to persuade Liquid Haskell that the theorem holds. 309: {-@ fibUp :: i : Nat -> {fib i <= fib (i+1)} @-} 310: x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp {v : GHC.Types.Int | v >= 0} i 311: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 0 312: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 313: *** QED 314: 315: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == 1 316: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 0 GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib 2 317: *** QED 318: 319: | otherwise 320: = {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i 321: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) 322: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) \u2235 x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 323: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) \u2235 x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | fib x1 <= fib (x1 + 1)} fibUp ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 2 ) 324: GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int <=. {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 325: *** QED The proof proceeds by induction on i . The base cases i == 0 and i == 1 are represented as Haskell's case splitting. The inductive hypothesis is represented by recursive calls on smaller inputs. Finally, the SMT solves arithmetic reasoning to conclude the proof.","title":"Proofs by Induction (i.e. Recursion)"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#higher-order-theorems","text":"Refinement Reflection can be used to express and verify higher order theorems! For example, fMono specifies that each locally increasing function is monotonic! 345: {-@ fMono :: f : ( Nat -> Int ) 346: -> fUp : ( z : Nat -> {f z <= f (z+1)} ) 347: -> x : Nat 348: -> y : {Nat|x < y} 349: -> {f x <= f y} / [ y ] 350: @-} 351: x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {VV : () | x1 x5 <= x1 x6} fMono {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int f x1:{v : GHC.Types.Int | v >= 0} -> {VV : () | f x1 <= f (x1 + 1)} thm {v : GHC.Types.Int | v >= 0} x {v : GHC.Types.Int | v >= 0 && x < v} y 352: | GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 == x2} == y 353: = {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f y GHC.Types.Int -> GHC.Types.Int -> GHC.Types.Int ==. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f ( GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 ) 354: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int >. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f x \u2235 {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm x 355: *** QED 356: 357: | GHC.Types.Int x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | Prop v <=> x1 < x2} < y 358: = {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f x 359: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) \u2235 x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {VV : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {VV : () | x1 x5 <= x1 x6} fMono {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm x ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 360: GHC.Types.Int -> GHC.Types.Int -> () -> GHC.Types.Int <. {v : {v : GHC.Types.Int | v >= 0} -> GHC.Types.Int | v == f} f y \u2235 {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | f x1 <= f (x1 + 1)} | v == thm} thm ( GHC.Types.Int y x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 361: *** QED Again, the recursive implementation of fMono depicts the paper and pencil proof of fMono by induction on the decreasing argument / [y] . Since fib is proven to be locally increasing by fUp , we use fMono to prove that fib is monotonic. 371: {-@ fibMono :: n : Nat -> m : {Nat | n < m } -> {fib n <= fib m} @-} 372: x1:{v : GHC.Types.Int | v >= 0} -> x2:{v : GHC.Types.Int | v >= 0 && x1 < v} -> {VV : () | fib x1 <= fib x2} fibMono = {v : x1:({v : GHC.Types.Int | v >= 0} -> GHC.Types.Int) -> (x4:{v : GHC.Types.Int | v >= 0} -> {v : () | x1 x4 <= x1 (x4 + 1)}) -> x5:{v : GHC.Types.Int | v >= 0} -> x6:{v : GHC.Types.Int | v >= 0 && x5 < v} -> {v : () | x1 x5 <= x1 x6} | v == RefinementReflection.fMono} fMono {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : GHC.Types.Int | v >= 0 && v == fib x1 && v == (if x1 == 0 then 0 else (if x1 == 1 then 1 else fib (x1 - 1) + fib (x1 - 2)))} | v == fib} fib {v : x1:{v : GHC.Types.Int | v >= 0} -> {v : () | fib x1 <= fib (x1 + 1)} | v == RefinementReflection.fibUp} fibUp","title":"Higher Order Theorems"},{"location":"blogposts/2016-09-18-refinement-reflection.lhs/#conclusion","text":"We saw how refinement reflection turns Haskell into a theorem prover by reflecting the code implementing a Haskell function into the function\u2019s output refinement type. Refinement Types are used to express theorems, Haskell code is used to prove such theorems expressing paper pencil proofs, and Liquid Haskell verifies the validity of the proofs! Proving fib monotonic is great, but this is Haskell! Wouldn\u2019t it be nice to prove theorems about inductive data types and higher order functions? Like fusions and folds? Or program equivalence on run-time optimizations like map-reduce? Stay tuned! Even better, if you happen you be in Nara for ICFP'16, come to my CUFP tutorial for more!","title":"Conclusion"},{"location":"blogposts/2016-10-06-structural-induction.lhs/","text":"Lists are Monoids \u00b6 Previously we saw how Refinement Reflection can be used to write Haskell functions that prove theorems about other Haskell functions. Today, we will see how Refinement Reflection works on recursive data types . As an example, we will prove that lists are monoids (under nil and append). Lets see how to express the monoid laws as liquid types, and then prove the laws by writing plain Haskell functions that are checked by LiquidHaskell. Recursive Paper and Pencil Proofs. \"Drawing Hands\" by Escher. 46: {-@ LIQUID \"--higherorder\" @-} 47: {-@ LIQUID \"--totality\" @-} 48: module StructuralInduction where 49: import Language . Haskell . Liquid . ProofCombinators 50: 51: import Prelude hiding ( length ) 52: 53: length :: List a -> Int 54: leftId :: List a -> Proof 55: rightId :: List a -> Proof 56: associativity :: List a -> List a -> List a -> Proof Lists \u00b6 First, lets define the List a data type 66: data List a = N | C a ( List a ) Induction on Lists \u00b6 As we will see, proofs by structural induction will correspond to programs that perform recursion on lists. To keep things legit, we must verify that those programs are total and terminating. To that end, lets define a length function that computes the natural number that is the size of a list. 81: {-@ measure length @-} 82: {-@ length :: List a -> Nat @-} 83: x1:(StructuralInduction.List a) -> {v : GHC.Types.Int | v >= 0 && v == length x1} length N = 0 84: length ( C x xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0 && v == length xs && v == length xs} length xs We lift length in the logic, as a measure . We can now tell Liquid Haskell that when proving termination on recursive functions with a list argument xs , it should check whether the length xs is decreasing. 94: {-@ data List [ length ] a = N | C { hd :: a , tl :: List a } @-} Reflecting Lists into the Logic \u00b6 To talk about lists in the logic, we use the annotation 104: {-@ LIQUID \"--exact-data-cons\" @-} which automatically derives measures for testing if a value has a given data constructor, and extracting the corresponding field's value. For our example, LH will automatically derive the following functions in the refinement logic. 116: isN :: L a -> Bool -- Haskell's null 117: isC :: L a -> Bool -- Haskell's not . null 118: 119: select_C_1 :: L a -> a -- Haskell's head 120: select_C_2 :: L a -> L a -- Haskell's tail A programmer never sees the above operators; they are internally used by LH to reflect Haskell functions into the refinement logic, as we shall see shortly. Defining the Monoid Operators \u00b6 A structure is a monoid, when it has two operators: the identity element empty and an associative operator <> . Lets define these two operators for our List . the identity element is the empty list, and the associative operator <> is list append. 141: {-@ reflect empty @-} 142: empty :: List a 143: {VV : (StructuralInduction.List a) | VV == empty && VV == StructuralInduction.N} empty = N 144: 145: {-@ infix <> @-} 146: {-@ reflect <> @-} 147: ( <> ) :: List a -> List a -> List a 148: N x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> {VV : (StructuralInduction.List a) | VV == <> x1 x2 && VV == (if is_N x1 then x2 else StructuralInduction.C (select_C_1 x1) (<> (select_C_2 x1) x2))} <> (StructuralInduction.List a) ys = ys 149: ( C x xs ) <> ys = x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( {VV : (StructuralInduction.List a) | VV == <> xs ys && VV == (if is_N xs then ys else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) ys)) && VV == <> xs ys} xs <> ys ) LiquidHaskell automatically checked that the recursive (<>) is terminating, by checking that the length of its first argument is decreasing. Since both the above operators are provably terminating, LH lets us reflect them into logic. As with our previous fibonacci example, reflection of a function into logic, means strengthening the result type of the function with its implementation. Thus, the automatically derived, strengthened types for empty and (<>) will be 166: empty :: { v : List a | v == empty && v == N } 167: 168: ( <> ) :: xs : List a -> ys : List a 169: -> { v : List a | v == xs <> ys && 170: v == if isN xs then ys else 171: C ( select_C_1 xs ) ( select_C_2 xs <> ys ) 172: } In effect, the derived checker and selector functions are used to translate Haskell to logic. The above is just to explain how LH reasons about the operators; the programmer never (directly) reads or writes the operators isN or select_C_1 etc. Proving the Monoid Laws \u00b6 Finally, we have set everything up, (actually LiquidHaskell did most of the work for us) and we are ready to prove the monoid laws for the List . First we prove left identity of empty . 190: {-@ leftId :: x : List a -> { empty <> x == x } @-} 191: x1:(StructuralInduction.List a) -> {VV : () | <> empty x1 == x1} leftId (StructuralInduction.List a) x 192: = (StructuralInduction.List a) empty <> x 193: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) N <> x 194: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x 195: *** QED This proof was trivial, because left identity is satisfied by the way we defined (<>) . Next, we prove right identity of empty . 204: {-@ rightId :: x : List a -> { x <> empty == x } @-} 205: x1:(StructuralInduction.List a) -> {VV : () | <> x1 empty == x1} rightId N 206: = (StructuralInduction.List (GHC.Prim.Any *)) N <> empty 207: (StructuralInduction.List (GHC.Prim.Any *)) -> (StructuralInduction.List (GHC.Prim.Any *)) -> (StructuralInduction.List (GHC.Prim.Any *)) ==. N 208: *** QED 209: 210: rightId ( C x xs ) 211: = (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> empty 212: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) xs <> empty ) 213: (StructuralInduction.List a) -> (StructuralInduction.List a) -> () -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs \u2235 {VV : () | <> xs empty == xs} rightId xs 214: *** QED This proof is more tricky, as it requires structural induction which is encoded in LH proofs simply as recursion . LH ensures that the inductive hypothesis is appropriately applied by checking that the recursive proof is total and terminating. In the rightId case, for termination, Liquid Haskell checked that length xs < length (C x xs) . It turns out that we can prove lots of properties about lists using structural induction, encoded in Haskell as case splitting, recursive calls, and rewriting, To see a last example, lets prove the associativity of (<>) . 233: {-@ associativity :: x : List a -> y : List a -> z : List a 234: -> { x <> (y <> z) == (x <> y) <> z } @-} 235: x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> x3:(StructuralInduction.List a) -> {VV : () | <> x1 (<> x2 x3) == <> (<> x1 x2) x3} associativity N (StructuralInduction.List a) y (StructuralInduction.List a) z 236: = (StructuralInduction.List a) N <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) 237: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z 238: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( (StructuralInduction.List a) N <> y ) <> z 239: *** QED 240: 241: associativity ( C x xs ) y z 242: = (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) 243: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) xs <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) ) 244: (StructuralInduction.List a) -> (StructuralInduction.List a) -> () -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) ( {v : (StructuralInduction.List a) | v == <> xs y && v == (if is_N xs then y else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) y)) && v == <> xs y} xs <> y ) <> z ) \u2235 x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> x3:(StructuralInduction.List a) -> {VV : () | <> x1 (<> x2 x3) == <> (<> x1 x2) x3} associativity xs y z 245: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( {v : (StructuralInduction.List a) | v == <> xs y && v == (if is_N xs then y else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) y)) && v == <> xs y} xs <> y ) ) <> z 246: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> y ) <> z 247: *** QED The above proof of associativity reifies the paper and pencil proof by structural induction. With that, we can safely conclude that our user defined list is a monoid! Conclusion \u00b6 We saw how Refinement Reflection can be used to specify properties of ADTs , naturally encode structural inductive proofs of these properties, and have these proofs machine checked by Liquid Haskell. Why is this useful? Because the theorems we prove refer to your Haskell functions! Thus you (or in the future, the compiler) can use properties like monoid or monad laws to optimize your Haskell code. In the future, we will present examples of code optimizations using monoid laws. Stay tuned!","title":"Refinement Reflection on ADTs"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#lists-are-monoids","text":"Previously we saw how Refinement Reflection can be used to write Haskell functions that prove theorems about other Haskell functions. Today, we will see how Refinement Reflection works on recursive data types . As an example, we will prove that lists are monoids (under nil and append). Lets see how to express the monoid laws as liquid types, and then prove the laws by writing plain Haskell functions that are checked by LiquidHaskell. Recursive Paper and Pencil Proofs. \"Drawing Hands\" by Escher. 46: {-@ LIQUID \"--higherorder\" @-} 47: {-@ LIQUID \"--totality\" @-} 48: module StructuralInduction where 49: import Language . Haskell . Liquid . ProofCombinators 50: 51: import Prelude hiding ( length ) 52: 53: length :: List a -> Int 54: leftId :: List a -> Proof 55: rightId :: List a -> Proof 56: associativity :: List a -> List a -> List a -> Proof","title":"Lists are Monoids"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#lists","text":"First, lets define the List a data type 66: data List a = N | C a ( List a )","title":"Lists"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#induction-on-lists","text":"As we will see, proofs by structural induction will correspond to programs that perform recursion on lists. To keep things legit, we must verify that those programs are total and terminating. To that end, lets define a length function that computes the natural number that is the size of a list. 81: {-@ measure length @-} 82: {-@ length :: List a -> Nat @-} 83: x1:(StructuralInduction.List a) -> {v : GHC.Types.Int | v >= 0 && v == length x1} length N = 0 84: length ( C x xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0 && v == length xs && v == length xs} length xs We lift length in the logic, as a measure . We can now tell Liquid Haskell that when proving termination on recursive functions with a list argument xs , it should check whether the length xs is decreasing. 94: {-@ data List [ length ] a = N | C { hd :: a , tl :: List a } @-}","title":"Induction on Lists"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#reflecting-lists-into-the-logic","text":"To talk about lists in the logic, we use the annotation 104: {-@ LIQUID \"--exact-data-cons\" @-} which automatically derives measures for testing if a value has a given data constructor, and extracting the corresponding field's value. For our example, LH will automatically derive the following functions in the refinement logic. 116: isN :: L a -> Bool -- Haskell's null 117: isC :: L a -> Bool -- Haskell's not . null 118: 119: select_C_1 :: L a -> a -- Haskell's head 120: select_C_2 :: L a -> L a -- Haskell's tail A programmer never sees the above operators; they are internally used by LH to reflect Haskell functions into the refinement logic, as we shall see shortly.","title":"Reflecting Lists into the Logic"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#defining-the-monoid-operators","text":"A structure is a monoid, when it has two operators: the identity element empty and an associative operator <> . Lets define these two operators for our List . the identity element is the empty list, and the associative operator <> is list append. 141: {-@ reflect empty @-} 142: empty :: List a 143: {VV : (StructuralInduction.List a) | VV == empty && VV == StructuralInduction.N} empty = N 144: 145: {-@ infix <> @-} 146: {-@ reflect <> @-} 147: ( <> ) :: List a -> List a -> List a 148: N x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> {VV : (StructuralInduction.List a) | VV == <> x1 x2 && VV == (if is_N x1 then x2 else StructuralInduction.C (select_C_1 x1) (<> (select_C_2 x1) x2))} <> (StructuralInduction.List a) ys = ys 149: ( C x xs ) <> ys = x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( {VV : (StructuralInduction.List a) | VV == <> xs ys && VV == (if is_N xs then ys else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) ys)) && VV == <> xs ys} xs <> ys ) LiquidHaskell automatically checked that the recursive (<>) is terminating, by checking that the length of its first argument is decreasing. Since both the above operators are provably terminating, LH lets us reflect them into logic. As with our previous fibonacci example, reflection of a function into logic, means strengthening the result type of the function with its implementation. Thus, the automatically derived, strengthened types for empty and (<>) will be 166: empty :: { v : List a | v == empty && v == N } 167: 168: ( <> ) :: xs : List a -> ys : List a 169: -> { v : List a | v == xs <> ys && 170: v == if isN xs then ys else 171: C ( select_C_1 xs ) ( select_C_2 xs <> ys ) 172: } In effect, the derived checker and selector functions are used to translate Haskell to logic. The above is just to explain how LH reasons about the operators; the programmer never (directly) reads or writes the operators isN or select_C_1 etc.","title":"Defining the Monoid Operators"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#proving-the-monoid-laws","text":"Finally, we have set everything up, (actually LiquidHaskell did most of the work for us) and we are ready to prove the monoid laws for the List . First we prove left identity of empty . 190: {-@ leftId :: x : List a -> { empty <> x == x } @-} 191: x1:(StructuralInduction.List a) -> {VV : () | <> empty x1 == x1} leftId (StructuralInduction.List a) x 192: = (StructuralInduction.List a) empty <> x 193: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) N <> x 194: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x 195: *** QED This proof was trivial, because left identity is satisfied by the way we defined (<>) . Next, we prove right identity of empty . 204: {-@ rightId :: x : List a -> { x <> empty == x } @-} 205: x1:(StructuralInduction.List a) -> {VV : () | <> x1 empty == x1} rightId N 206: = (StructuralInduction.List (GHC.Prim.Any *)) N <> empty 207: (StructuralInduction.List (GHC.Prim.Any *)) -> (StructuralInduction.List (GHC.Prim.Any *)) -> (StructuralInduction.List (GHC.Prim.Any *)) ==. N 208: *** QED 209: 210: rightId ( C x xs ) 211: = (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> empty 212: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) xs <> empty ) 213: (StructuralInduction.List a) -> (StructuralInduction.List a) -> () -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs \u2235 {VV : () | <> xs empty == xs} rightId xs 214: *** QED This proof is more tricky, as it requires structural induction which is encoded in LH proofs simply as recursion . LH ensures that the inductive hypothesis is appropriately applied by checking that the recursive proof is total and terminating. In the rightId case, for termination, Liquid Haskell checked that length xs < length (C x xs) . It turns out that we can prove lots of properties about lists using structural induction, encoded in Haskell as case splitting, recursive calls, and rewriting, To see a last example, lets prove the associativity of (<>) . 233: {-@ associativity :: x : List a -> y : List a -> z : List a 234: -> { x <> (y <> z) == (x <> y) <> z } @-} 235: x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> x3:(StructuralInduction.List a) -> {VV : () | <> x1 (<> x2 x3) == <> (<> x1 x2) x3} associativity N (StructuralInduction.List a) y (StructuralInduction.List a) z 236: = (StructuralInduction.List a) N <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) 237: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z 238: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( (StructuralInduction.List a) N <> y ) <> z 239: *** QED 240: 241: associativity ( C x xs ) y z 242: = (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) 243: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) xs <> ( {v : (StructuralInduction.List a) | v == <> y z && v == (if is_N y then z else StructuralInduction.C (select_C_1 y) (<> (select_C_2 y) z)) && v == <> y z} y <> z ) ) 244: (StructuralInduction.List a) -> (StructuralInduction.List a) -> () -> (StructuralInduction.List a) ==. x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( (StructuralInduction.List a) ( {v : (StructuralInduction.List a) | v == <> xs y && v == (if is_N xs then y else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) y)) && v == <> xs y} xs <> y ) <> z ) \u2235 x1:(StructuralInduction.List a) -> x2:(StructuralInduction.List a) -> x3:(StructuralInduction.List a) -> {VV : () | <> x1 (<> x2 x3) == <> (<> x1 x2) x3} associativity xs y z 245: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x ( {v : (StructuralInduction.List a) | v == <> xs y && v == (if is_N xs then y else StructuralInduction.C (select_C_1 xs) (<> (select_C_2 xs) y)) && v == <> xs y} xs <> y ) ) <> z 246: (StructuralInduction.List a) -> (StructuralInduction.List a) -> (StructuralInduction.List a) ==. (StructuralInduction.List a) ( (StructuralInduction.List a) ( x1:(StructuralInduction.List a) -> {v : (StructuralInduction.List a) | tl v == x1 && hd v == x && select_C_2 v == x1 && select_C_1 v == x && (is_C v <=> true) && (is_N v <=> false) && length v == 1 + length x1 && v == StructuralInduction.C x x1} C x xs ) <> y ) <> z 247: *** QED The above proof of associativity reifies the paper and pencil proof by structural induction. With that, we can safely conclude that our user defined list is a monoid!","title":"Proving the Monoid Laws"},{"location":"blogposts/2016-10-06-structural-induction.lhs/#conclusion","text":"We saw how Refinement Reflection can be used to specify properties of ADTs , naturally encode structural inductive proofs of these properties, and have these proofs machine checked by Liquid Haskell. Why is this useful? Because the theorems we prove refer to your Haskell functions! Thus you (or in the future, the compiler) can use properties like monoid or monad laws to optimize your Haskell code. In the future, we will present examples of code optimizations using monoid laws. Stay tuned!","title":"Conclusion"},{"location":"blogposts/2017-03-20-arithmetic-overflows.lhs/","text":"Computers are great at crunching numbers. However, if programmers aren't careful, their machines can end up biting off more than they can chew: simple arithmetic operations over very large (or very tiny) inputs can overflow leading to bizarre crashes or vulnerabilities. For example, Joshua Bloch's classic post argues that nearly all binary searches are broken due to integer overflows. Lets see how we can teach LiquidHaskell to spot such overflows. 30: module Bounded where 31: 32: import Control . Exception ( assert ) 33: import Prelude hiding ( Num ( .. ) ) 34: import qualified Prelude 35: 36: plusStrict :: Int -> Int -> Int 37: plusLazy :: Int -> Int -> Int 38: mono :: Int -> Bool 1. The Problem \u00b6 LiquidHaskell, like some programmers, likes to make believe that Int represents the set of integers. For example, you might define a function plus as: 51: {-@ plus :: x : Int -> y : Int -> {v: Int | v == x + y} @-} 52: plus :: Int -> Int -> Int 53: x1:Int -> x2:Int -> {v : Int | v == x1 + x2} plus Int x Int y = {v : Int | v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The output type of the function states that the returned value is equal to the \\emph{logical} result of adding the two inputs. The above signature lets us \"prove\" facts like addition by one yields a bigger number: 63: {-@ monoPlus :: Int -> {v: Bool | v <=> true } @-} 64: monoPlus :: Int -> Bool 65: Int -> {v : Bool | v <=> true} monoPlus Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:Int -> {v : Int | v == x1 + x2} | v == Bounded.plus} plus x 1 Unfortunately, the signature for plus and hence, the above \"fact\" are both lies. LH checks plus as the same signature is assumed for the primitive Int addition operator Prelude.+ . LH has to assume some signature for this \"foreign\" machine operation, and by default, LH assumes that machine addition behaves like logical addition. However, this assumption, and its consequences are only true upto a point: \u03bb> monoPlus 0 True \u03bb> monoPlus 100 True \u03bb> monoPlus 10000 True \u03bb> monoPlus 1000000 True Once we get to maxBound at the very edge of Int , a tiny bump is enough to send us tumbling backwards into a twilight zone. \u03bb> monoPlus maxBound False \u03bb> plus maxBound 1 -9223372036854775808 2. Keeping Int In Their Place \u00b6 The news isn't all bad: the glass half full view is that for \"reasonable\" values like 10, 100, 10000 and 1000000, the machine's arithmetic is the same as logical arithmetic. Lets see how to impart this wisdom to LH. We do this in two steps: define the biggest Int value, and then, use this value to type the arithmetic operations. A. The Biggest Int First, we need a way to talk about \"the edge\" -- i.e. the largest Int value at which overflows occur. We could use the concrete number \u03bb> maxBound :: Int 9223372036854775807 However, instead of hardwiring a particular number, a more general strategy is to define a symbolic constant maxInt to represent any arbitrary overflow value and thus, make the type checking robust to different machine integer widths. 135: -- defines an Int constant called `maxInt` 136: {-@ measure maxInt :: Int @-} To tell LH that maxInt is the \"biggest\" Int , we write a predicate that describes values bounded by maxInt : 144: {-@ predicate Bounded N = 0 < N + maxInt && N < maxInt @-} Thus, Bounded n means that the number n is in the range [-maxInt, maxInt] . B. Bounded Machine Arithmetic Next, we can assign the machine arithmetic operations types that properly capture the possibility of arithmetic overflows. Here are two possible specifications. Strict: Thou Shalt Not Overflow A strict specification simply prohibits any overflow: 160: {-@ plusStrict :: x : Int -> y : {Int|Bounded(x+y)} -> {v: Int |v = x+y} @-} 161: x1:Int -> x2:{y : Int | 0 < (x1 + y) + maxInt && x1 + y < maxInt} -> {v : Int | v == x1 + x2} plusStrict Int x {y : Int | 0 < (x + y) + maxInt && x + y < maxInt} y = {v : Int | 0 < (x + v) + maxInt && x + v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The inputs x and y must be such that the result is Bounded , and in that case, the output value is indeed their logical sum. Lazy: Overflow at Thine Own Risk Instead, a lazy specification could permit overflows but gives no guarantees about the output when they occur. 172: {-@ plusLazy :: x : Int -> y : Int -> {v: Int |Bounded(x+y) => v = x+y} @-} 173: x1:Int -> x2:Int -> {v : Int | 0 < (x1 + x2) + maxInt && x1 + x2 < maxInt => v == x1 + x2} plusLazy Int x Int y = {v : Int | v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The lazy specification says that while plusLazy can be called with any values you like, the result is the logical sum only if there is no overflow . To understand the difference between the two specifications, lets revisit the monoPlus property using the new machine-arithmetic sensitive signatures: 188: {-@ monoPlusStrict :: Int -> {v: Bool | v <=> true } @-} 189: Int -> {v : Bool | v <=> true} monoPlusStrict Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:{v : Int | 0 < (x1 + v) + maxInt && x1 + v < maxInt} -> {v : Int | v == x1 + x2} | v == Bounded.plusStrict} plusStrict x 1 190: 191: {-@ monoPlusLazy :: Int -> {v: Bool | v <=> true } @-} 192: Int -> {v : Bool | v <=> true} monoPlusLazy Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:Int -> {v : Int | 0 < (x1 + x2) + maxInt && x1 + x2 < maxInt => v == x1 + x2} | v == Bounded.plusLazy} plusLazy x 1 Both are rejected by LH, since, as we saw earlier, the functions do not always evaluate to True . However, in the strict version the error is at the possibly overflowing call to plusStrict . In the lazy version, the call to plusLazy is accepted, but as the returned value is some arbitrary Int (not the logical x+1 ), the comparison may return False hence the output is not always True . Exercise: Can you fix the specification for monoPlusStrict and monoPlusLazy to get LH to verify the implementation? 3. A Typeclass for Machine Arithmetic \u00b6 Its a bit inconvenient to write plusStrict and plusLazy , and really, we'd just like to write + and - and so on. We can do so, by tucking the above specifications into a bounded numeric typeclass whose signatures capture machine arithmetic. First, we define a BoundedNum variant of Num 220: class BoundedNum a where 221: ( + ) :: a -> a -> a 222: ( - ) :: a -> a -> a 223: -- other operations ... and now, we can define its Int instance just as wrappers around the Prelude operations: 230: instance BoundedNum Int where 231: Int x x1:Int -> x2:{y : Int | 0 < (x1 + y) + maxInt && x1 + y < maxInt} -> {v : Int | v == x1 + x2} + {y : Int | 0 < (x + y) + maxInt && x + y < maxInt} y = {v : Int | 0 < (x + v) + maxInt && x + v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y 232: Int x x1:Int -> x2:{y : Int | 0 < (x1 - y) + maxInt && x1 - y < maxInt} -> {v : Int | v == x1 - x2} - {y : Int | 0 < (x - y) + maxInt && x - y < maxInt} y = {v : Int | 0 < (x - v) + maxInt && x - v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 - x2} Prelude .- y Finally, we can tell LH that the above above instance obeys the (strict) specifications for machine arithmetic: 239: {-@ instance BoundedNum Int where 240: + :: x : Int -> y : {Int | Bounded (x+y)} -> {v: Int | v == x+y } ; 241: - :: x : Int -> y : {Int | Bounded (x-y)} -> {v: Int | v == x-y } 242: @-} With the above instance in scope, we can just use the plain + operator and have LH flag potential overflows: 249: {-@ mono :: Int -> {v: Bool | v <=> true} @-} 250: Int -> {v : Bool | v <=> true} mono Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < Int x + 1 4. An Application: Binary Search \u00b6 The above seems a bit paranoid. Do overflows really matter? And if they do, is it really practical to check for them using the above? Joshua Bloch's famous article describes a tricky overflow bug in an implementation of binary-search that lay hidden in plain sight in classic textbooks and his own implementation in the JDK for nearly a decade. Gabriel Gonzalez wrote a lovely introduction to LH using binary-search as an example, and a careful reader pointed out that it had the same overflow bug! Lets see how we might spot and fix such bugs using BoundedNum . ( Hover over the images to animate .) **A. Off by One** Lets begin by just using the default `Num Int` which ignores overflow. As Gabriel explains, LH flags a bunch of errors if we start the search with `loop x v 0 n` as the resulting search can access `v` at any index between `0` and `n` inclusive, which may lead to an out of bounds at `n`. We can fix the off-by-one by correcting the upper bound to `n-1`, at which point LH reports the code free of errors. **B. Lots of Overflows** To spot arithmetic overflows, we need only hide the default `Prelude` and instead import the `BoundedNum` instance described above. Upon doing so, LH flags a whole bunch of potential errors -- essentially *all* the arithmetic operations which seems rather dire! **C. Vector Sizes are Bounded** Of course, things aren't _so_ bad. LH is missing the information that the size of any `Vector` must be `Bounded`. Once we inform LH about this invariant with the [`using` directive][lh-invariants], it infers that as the `lo` and `hi` indices are upper-bounded by the `Vector`'s size, all the arithmetic on them is also `Bounded` and hence, free of overflows. **D. Staying In The Middle** Well, *almost* all. The one pesky pink highlight that remains is exactly the bug that Bloch made famous. Namely: the addition used to compute the new midpoint between `lo` and `hi` could overflow e.g. if the array was large and both those indices were near the end. To ensure the machine doesn't choke, we follow Bloch's suggestion and re-jigger the computation to instead compute the midpoint by splitting the difference between `hi` and `lo`! the code is now free of arithmetic overflows and truly memory safe.","title":"Arithmetic Overflows"},{"location":"blogposts/2017-03-20-arithmetic-overflows.lhs/#1-the-problem","text":"LiquidHaskell, like some programmers, likes to make believe that Int represents the set of integers. For example, you might define a function plus as: 51: {-@ plus :: x : Int -> y : Int -> {v: Int | v == x + y} @-} 52: plus :: Int -> Int -> Int 53: x1:Int -> x2:Int -> {v : Int | v == x1 + x2} plus Int x Int y = {v : Int | v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The output type of the function states that the returned value is equal to the \\emph{logical} result of adding the two inputs. The above signature lets us \"prove\" facts like addition by one yields a bigger number: 63: {-@ monoPlus :: Int -> {v: Bool | v <=> true } @-} 64: monoPlus :: Int -> Bool 65: Int -> {v : Bool | v <=> true} monoPlus Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:Int -> {v : Int | v == x1 + x2} | v == Bounded.plus} plus x 1 Unfortunately, the signature for plus and hence, the above \"fact\" are both lies. LH checks plus as the same signature is assumed for the primitive Int addition operator Prelude.+ . LH has to assume some signature for this \"foreign\" machine operation, and by default, LH assumes that machine addition behaves like logical addition. However, this assumption, and its consequences are only true upto a point: \u03bb> monoPlus 0 True \u03bb> monoPlus 100 True \u03bb> monoPlus 10000 True \u03bb> monoPlus 1000000 True Once we get to maxBound at the very edge of Int , a tiny bump is enough to send us tumbling backwards into a twilight zone. \u03bb> monoPlus maxBound False \u03bb> plus maxBound 1 -9223372036854775808","title":"1. The Problem"},{"location":"blogposts/2017-03-20-arithmetic-overflows.lhs/#2-keeping-int-in-their-place","text":"The news isn't all bad: the glass half full view is that for \"reasonable\" values like 10, 100, 10000 and 1000000, the machine's arithmetic is the same as logical arithmetic. Lets see how to impart this wisdom to LH. We do this in two steps: define the biggest Int value, and then, use this value to type the arithmetic operations. A. The Biggest Int First, we need a way to talk about \"the edge\" -- i.e. the largest Int value at which overflows occur. We could use the concrete number \u03bb> maxBound :: Int 9223372036854775807 However, instead of hardwiring a particular number, a more general strategy is to define a symbolic constant maxInt to represent any arbitrary overflow value and thus, make the type checking robust to different machine integer widths. 135: -- defines an Int constant called `maxInt` 136: {-@ measure maxInt :: Int @-} To tell LH that maxInt is the \"biggest\" Int , we write a predicate that describes values bounded by maxInt : 144: {-@ predicate Bounded N = 0 < N + maxInt && N < maxInt @-} Thus, Bounded n means that the number n is in the range [-maxInt, maxInt] . B. Bounded Machine Arithmetic Next, we can assign the machine arithmetic operations types that properly capture the possibility of arithmetic overflows. Here are two possible specifications. Strict: Thou Shalt Not Overflow A strict specification simply prohibits any overflow: 160: {-@ plusStrict :: x : Int -> y : {Int|Bounded(x+y)} -> {v: Int |v = x+y} @-} 161: x1:Int -> x2:{y : Int | 0 < (x1 + y) + maxInt && x1 + y < maxInt} -> {v : Int | v == x1 + x2} plusStrict Int x {y : Int | 0 < (x + y) + maxInt && x + y < maxInt} y = {v : Int | 0 < (x + v) + maxInt && x + v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The inputs x and y must be such that the result is Bounded , and in that case, the output value is indeed their logical sum. Lazy: Overflow at Thine Own Risk Instead, a lazy specification could permit overflows but gives no guarantees about the output when they occur. 172: {-@ plusLazy :: x : Int -> y : Int -> {v: Int |Bounded(x+y) => v = x+y} @-} 173: x1:Int -> x2:Int -> {v : Int | 0 < (x1 + x2) + maxInt && x1 + x2 < maxInt => v == x1 + x2} plusLazy Int x Int y = {v : Int | v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y The lazy specification says that while plusLazy can be called with any values you like, the result is the logical sum only if there is no overflow . To understand the difference between the two specifications, lets revisit the monoPlus property using the new machine-arithmetic sensitive signatures: 188: {-@ monoPlusStrict :: Int -> {v: Bool | v <=> true } @-} 189: Int -> {v : Bool | v <=> true} monoPlusStrict Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:{v : Int | 0 < (x1 + v) + maxInt && x1 + v < maxInt} -> {v : Int | v == x1 + x2} | v == Bounded.plusStrict} plusStrict x 1 190: 191: {-@ monoPlusLazy :: Int -> {v: Bool | v <=> true } @-} 192: Int -> {v : Bool | v <=> true} monoPlusLazy Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < {v : x1:Int -> x2:Int -> {v : Int | 0 < (x1 + x2) + maxInt && x1 + x2 < maxInt => v == x1 + x2} | v == Bounded.plusLazy} plusLazy x 1 Both are rejected by LH, since, as we saw earlier, the functions do not always evaluate to True . However, in the strict version the error is at the possibly overflowing call to plusStrict . In the lazy version, the call to plusLazy is accepted, but as the returned value is some arbitrary Int (not the logical x+1 ), the comparison may return False hence the output is not always True . Exercise: Can you fix the specification for monoPlusStrict and monoPlusLazy to get LH to verify the implementation?","title":"2. Keeping Int In Their Place"},{"location":"blogposts/2017-03-20-arithmetic-overflows.lhs/#3-a-typeclass-for-machine-arithmetic","text":"Its a bit inconvenient to write plusStrict and plusLazy , and really, we'd just like to write + and - and so on. We can do so, by tucking the above specifications into a bounded numeric typeclass whose signatures capture machine arithmetic. First, we define a BoundedNum variant of Num 220: class BoundedNum a where 221: ( + ) :: a -> a -> a 222: ( - ) :: a -> a -> a 223: -- other operations ... and now, we can define its Int instance just as wrappers around the Prelude operations: 230: instance BoundedNum Int where 231: Int x x1:Int -> x2:{y : Int | 0 < (x1 + y) + maxInt && x1 + y < maxInt} -> {v : Int | v == x1 + x2} + {y : Int | 0 < (x + y) + maxInt && x + y < maxInt} y = {v : Int | 0 < (x + v) + maxInt && x + v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 + x2} Prelude .+ y 232: Int x x1:Int -> x2:{y : Int | 0 < (x1 - y) + maxInt && x1 - y < maxInt} -> {v : Int | v == x1 - x2} - {y : Int | 0 < (x - y) + maxInt && x - y < maxInt} y = {v : Int | 0 < (x - v) + maxInt && x - v < maxInt && v == y} x x1:Int -> x2:Int -> {v : Int | v == x1 - x2} Prelude .- y Finally, we can tell LH that the above above instance obeys the (strict) specifications for machine arithmetic: 239: {-@ instance BoundedNum Int where 240: + :: x : Int -> y : {Int | Bounded (x+y)} -> {v: Int | v == x+y } ; 241: - :: x : Int -> y : {Int | Bounded (x-y)} -> {v: Int | v == x-y } 242: @-} With the above instance in scope, we can just use the plain + operator and have LH flag potential overflows: 249: {-@ mono :: Int -> {v: Bool | v <=> true} @-} 250: Int -> {v : Bool | v <=> true} mono Int x = {v : Int | v == x} x x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < Int x + 1","title":"3. A Typeclass for Machine Arithmetic"},{"location":"blogposts/2017-03-20-arithmetic-overflows.lhs/#4-an-application-binary-search","text":"The above seems a bit paranoid. Do overflows really matter? And if they do, is it really practical to check for them using the above? Joshua Bloch's famous article describes a tricky overflow bug in an implementation of binary-search that lay hidden in plain sight in classic textbooks and his own implementation in the JDK for nearly a decade. Gabriel Gonzalez wrote a lovely introduction to LH using binary-search as an example, and a careful reader pointed out that it had the same overflow bug! Lets see how we might spot and fix such bugs using BoundedNum . ( Hover over the images to animate .) **A. Off by One** Lets begin by just using the default `Num Int` which ignores overflow. As Gabriel explains, LH flags a bunch of errors if we start the search with `loop x v 0 n` as the resulting search can access `v` at any index between `0` and `n` inclusive, which may lead to an out of bounds at `n`. We can fix the off-by-one by correcting the upper bound to `n-1`, at which point LH reports the code free of errors. **B. Lots of Overflows** To spot arithmetic overflows, we need only hide the default `Prelude` and instead import the `BoundedNum` instance described above. Upon doing so, LH flags a whole bunch of potential errors -- essentially *all* the arithmetic operations which seems rather dire! **C. Vector Sizes are Bounded** Of course, things aren't _so_ bad. LH is missing the information that the size of any `Vector` must be `Bounded`. Once we inform LH about this invariant with the [`using` directive][lh-invariants], it infers that as the `lo` and `hi` indices are upper-bounded by the `Vector`'s size, all the arithmetic on them is also `Bounded` and hence, free of overflows. **D. Staying In The Middle** Well, *almost* all. The one pesky pink highlight that remains is exactly the bug that Bloch made famous. Namely: the addition used to compute the new midpoint between `lo` and `hi` could overflow e.g. if the array was large and both those indices were near the end. To ensure the machine doesn't choke, we follow Bloch's suggestion and re-jigger the computation to instead compute the midpoint by splitting the difference between `hi` and `lo`! the code is now free of arithmetic overflows and truly memory safe.","title":"4. An Application: Binary Search"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/","text":"Joachim Breitner wrote a cool post describing a library for representing sets of integers as sorted lists of intervals , and how they were able to formally verify the code by translating it to Coq using their nifty new tool . First, lets just see how plain refinement types let us specify the key \"goodness\" invariant, and check it automatically. Next, we'll see how LH's new \"type-level computation\" abilities let us specify and check \"correctness\", and even better, understand why the code works. (Click here to demo ) 41: {-@ LIQUID \"--short-names\" @-} 42: {-@ LIQUID \"--exact-data-con\" @-} 43: {-@ LIQUID \"--no-adt\" @-} 44: {-@ LIQUID \"--prune-unsorted\" @-} 45: {-@ LIQUID \"--higherorder\" @-} 46: {-@ LIQUID \"--no-termination\" @-} 47: 48: module Intervals where 49: 50: data Interval = I 51: { from :: Int 52: , to :: Int 53: } deriving ( (Show Interval) Show ) 54: Encoding Sets as Intervals \u00b6 The key idea underlying the intervals data structure, is that we can represent sets of integers like: { 7, 1, 10, 3, 11, 2, 9, 12, 4} by first ordering them into a list [ 1, 2, 3, 4, 7, 9, 10, 11, 12 ] and then partitioning the list into compact intervals [ (1, 5), (7, 8), (9, 13) ] That is, Each interval (from, to) corresponds to the set {from,from+1,...,to-1} . Ordering ensures there is a canonical representation that simplifies interval operations. Making Illegal Intervals Unrepresentable \u00b6 We require that the list of intervals be \"sorted, non-empty, disjoint and non-adjacent\". Lets follow the slogan of make-illegal-values-unrepresentable to see how we can encode the legality constraints with refinements. A Single Interval We can ensure that each interval is non-empty by refining the data type for a single interval to specify that the to field must be strictly bigger than the from field: 104: {-@ data Interval = I 105: { from :: Int 106: , to :: { v : Int | from < v } 107: } 108: @-} Now, LH will ensure that we can only construct legal , non-empty Interval s 115: Interval goodItv = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 10 20 116: Interval badItv = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 20 10 -- ILLEGAL: empty interval! Many Intervals We can represent arbitrary sets as a list of Interval s: 124: data Intervals = Intervals { itvs :: [ Interval ] } The plain Haskell type doesn't have enough teeth to enforce legality, specifically, to ensure ordering and the absence of overlaps . Refinements to the rescue! First, we specify a lower-bounded Interval as: 134: {-@ type LbItv N = { v : Interval | N <= from v } @-} Intuitively, an LbItv n is one that starts (at or) after n . Next, we use the above to define an ordered list of lower-bounded intervals: 143: {-@ type OrdItvs N = [ LbItv N ] < { \\ vHd vTl -> to vHd <= from vTl } > @-} The signature above uses an abstract-refinement to capture the legality requirements. An OrdInterval N is a list of Interval that are lower-bounded by N , and In each sub-list, the head Interval vHd precedes each in the tail vTl . Legal Intervals \u00b6 We can now describe legal Intervals simply as: 161: {-@ data Intervals = Intervals { itvs :: OrdItvs 0 } @-} LH will now ensure that illegal Intervals are not representable. 167: Intervals goodItvs = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 5 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 7 8 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 9 13 ] -- LEGAL 168: 169: Intervals badItvs1 = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 7 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 5 8 ] -- ILLEGAL: overlap! 170: Intervals badItvs2 = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 5 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 9 13 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 7 8 ] -- ILLEGAL: disorder! Do the types really capture the legality requirements? In the original code, Breitner described goodness as a recursively defined predicate that takes an additional lower bound lb and returns True iff the representation was legal: 180: goodLIs :: Int -> [ Interval ] -> Bool 181: x1:{v : Int | v >= 0} -> [{v : Interval | x1 <= Intervals.from v}] -> {v : Bool | v} goodLIs _ [] = True 182: goodLIs lb ( ( I f t ) : is ) = Bool lb x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && {v : Bool | v <=> f < t} f x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && x1:{v : Int | v >= 0} -> [{v : Interval | x1 <= Intervals.from v}] -> {v : Bool | v} goodLIs t is We can check that our type-based representation is indeed legit by checking that goodLIs returns True whenever it is called with a valid of OrdItvs : 190: {-@ goodLIs :: lb : Nat -> is : OrdItvs lb -> {v : Bool | v } @-} Algorithms on Intervals \u00b6 We represent legality as a type, but is that good for ? After all, we could, as seen above, just as well have written a predicate goodLIs ? The payoff comes when it comes to using the Intervals e.g. to implement various set operations. For example, here's the code for intersecting two sets, each represented as intervals. We've made exactly one change to the function implemented by Breitner: we added the extra lower-bound parameter lb to the recursive go to make clear that the function takes two OrdItvs lb and returns an OrdItvs lb . 210: intersect :: Intervals -> Intervals -> Intervals 211: Intervals -> Intervals -> Intervals intersect ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 212: where 213: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 214: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ _ [] = [] 215: go _ [] _ = [] 216: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 217: -- reorder for symmetry 218: | {v : Bool | v <=> t1 < t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i2 : is2 ) ( i1 : is1 ) 219: -- disjoint 220: | {v : Bool | v <=> f1 >= t2} f1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i1 : is1 ) is2 221: -- subset 222: | {v : Bool | v <=> t1 == t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 == x2} == t2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 is1 is2 223: -- overlapping 224: | {v : Bool | v <=> f2 < f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < f1 = ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 ) 225: | otherwise = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f2 t1 : is1 ) ( i2 : is2 ) 226: where {v : Int | v == (if f1 > f2 then f1 else f2)} f' = x1:Int -> x2:Int -> {v : Int | v == (if x1 > x2 then x1 else x2)} max f1 f2 Internal vs External Verification \u00b6 By representing legality internally as a refinement type, as opposed to externally as predicate ( goodLIs ) we have exposed enough information about the structure of the values that LH can automatically chomp through the above code to guarantee that we haven't messed up the invariants. To appreciate the payoff, compare to the effort needed to verify legality using the external representation used in the hs-to-coq proof . The same principle and simplification benefits apply to both the union 245: union :: Intervals -> Intervals -> Intervals 246: Intervals -> Intervals -> Intervals union ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 247: where 248: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 249: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ [Interval] is [] = is 250: go _ [] is = is 251: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 252: -- reorder for symmetry 253: | {v : Bool | v <=> t1 < t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i2 : is2 ) ( i1 : is1 ) 254: -- disjoint 255: | {v : Bool | v <=> f1 > t2} f1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 > x2} > t2 = i2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( i1 : is1 ) is2 256: -- overlapping 257: | otherwise = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t1 ) : is1 ) is2 258: where 259: {v : Int | v == (if f1 < f2 then f1 else f2)} f' = x1:Int -> x2:Int -> {v : Int | v == (if x1 < x2 then x1 else x2)} min f1 f2 and the subtract functions too: 265: subtract :: Intervals -> Intervals -> Intervals 266: Intervals -> Intervals -> Intervals subtract ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 267: where 268: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 269: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ [Interval] is [] = is 270: go _ [] _ = [] 271: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 272: -- i2 past i1 273: | {v : Bool | v <=> t1 <= f2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f2 = ( i1 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t1 is1 ( i2 : is2 ) ) 274: -- i1 past i2 275: | {v : Bool | v <=> t2 <= f1} t2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 = ( x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i1 : is1 ) is2 ) 276: -- i1 contained in i2 277: | {v : Bool | v <=> f2 <= f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 , {v : Bool | v <=> t1 <= t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb is1 ( i2 : is2 ) 278: -- i2 covers beginning of i1 279: | {v : Bool | v <=> f2 <= f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 280: -- -- i2 covers end of i1 281: | {v : Bool | v <=> t1 <= t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= t2 = ( ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f1 f2 ) : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go f2 is1 ( i2 : is2 ) ) 282: -- i2 in the middle of i1 283: | otherwise = ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f1 f2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go f2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 ) both of which require non-trivial proofs in the external style . (Of course, its possible those proofs can be simplified.) Summing Up (and Looking Ahead) \u00b6 I hope the above example illustrates why \"making illegal states\" unrepresentable is a great principle for engineering code and proofs. That said, notice that with hs-to-coq , Breitner was able to go far beyond the above legality requirement: he was able to specify and verify the far more important (and difficult) property that the above is a correct implementation of a Set library. Is it even possible , let alone easier to do that with LH?","title":"Splitting and Splicing Intervals (Part 1)"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#encoding-sets-as-intervals","text":"The key idea underlying the intervals data structure, is that we can represent sets of integers like: { 7, 1, 10, 3, 11, 2, 9, 12, 4} by first ordering them into a list [ 1, 2, 3, 4, 7, 9, 10, 11, 12 ] and then partitioning the list into compact intervals [ (1, 5), (7, 8), (9, 13) ] That is, Each interval (from, to) corresponds to the set {from,from+1,...,to-1} . Ordering ensures there is a canonical representation that simplifies interval operations.","title":"Encoding Sets as Intervals"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#making-illegal-intervals-unrepresentable","text":"We require that the list of intervals be \"sorted, non-empty, disjoint and non-adjacent\". Lets follow the slogan of make-illegal-values-unrepresentable to see how we can encode the legality constraints with refinements. A Single Interval We can ensure that each interval is non-empty by refining the data type for a single interval to specify that the to field must be strictly bigger than the from field: 104: {-@ data Interval = I 105: { from :: Int 106: , to :: { v : Int | from < v } 107: } 108: @-} Now, LH will ensure that we can only construct legal , non-empty Interval s 115: Interval goodItv = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 10 20 116: Interval badItv = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 20 10 -- ILLEGAL: empty interval! Many Intervals We can represent arbitrary sets as a list of Interval s: 124: data Intervals = Intervals { itvs :: [ Interval ] } The plain Haskell type doesn't have enough teeth to enforce legality, specifically, to ensure ordering and the absence of overlaps . Refinements to the rescue! First, we specify a lower-bounded Interval as: 134: {-@ type LbItv N = { v : Interval | N <= from v } @-} Intuitively, an LbItv n is one that starts (at or) after n . Next, we use the above to define an ordered list of lower-bounded intervals: 143: {-@ type OrdItvs N = [ LbItv N ] < { \\ vHd vTl -> to vHd <= from vTl } > @-} The signature above uses an abstract-refinement to capture the legality requirements. An OrdInterval N is a list of Interval that are lower-bounded by N , and In each sub-list, the head Interval vHd precedes each in the tail vTl .","title":"Making Illegal Intervals Unrepresentable"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#legal-intervals","text":"We can now describe legal Intervals simply as: 161: {-@ data Intervals = Intervals { itvs :: OrdItvs 0 } @-} LH will now ensure that illegal Intervals are not representable. 167: Intervals goodItvs = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 5 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 7 8 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 9 13 ] -- LEGAL 168: 169: Intervals badItvs1 = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 7 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 5 8 ] -- ILLEGAL: overlap! 170: Intervals badItvs2 = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals [ {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 1 5 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 9 13 , {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I 7 8 ] -- ILLEGAL: disorder! Do the types really capture the legality requirements? In the original code, Breitner described goodness as a recursively defined predicate that takes an additional lower bound lb and returns True iff the representation was legal: 180: goodLIs :: Int -> [ Interval ] -> Bool 181: x1:{v : Int | v >= 0} -> [{v : Interval | x1 <= Intervals.from v}] -> {v : Bool | v} goodLIs _ [] = True 182: goodLIs lb ( ( I f t ) : is ) = Bool lb x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && {v : Bool | v <=> f < t} f x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && x1:{v : Int | v >= 0} -> [{v : Interval | x1 <= Intervals.from v}] -> {v : Bool | v} goodLIs t is We can check that our type-based representation is indeed legit by checking that goodLIs returns True whenever it is called with a valid of OrdItvs : 190: {-@ goodLIs :: lb : Nat -> is : OrdItvs lb -> {v : Bool | v } @-}","title":"Legal Intervals"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#algorithms-on-intervals","text":"We represent legality as a type, but is that good for ? After all, we could, as seen above, just as well have written a predicate goodLIs ? The payoff comes when it comes to using the Intervals e.g. to implement various set operations. For example, here's the code for intersecting two sets, each represented as intervals. We've made exactly one change to the function implemented by Breitner: we added the extra lower-bound parameter lb to the recursive go to make clear that the function takes two OrdItvs lb and returns an OrdItvs lb . 210: intersect :: Intervals -> Intervals -> Intervals 211: Intervals -> Intervals -> Intervals intersect ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 212: where 213: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 214: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ _ [] = [] 215: go _ [] _ = [] 216: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 217: -- reorder for symmetry 218: | {v : Bool | v <=> t1 < t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i2 : is2 ) ( i1 : is1 ) 219: -- disjoint 220: | {v : Bool | v <=> f1 >= t2} f1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i1 : is1 ) is2 221: -- subset 222: | {v : Bool | v <=> t1 == t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 == x2} == t2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 is1 is2 223: -- overlapping 224: | {v : Bool | v <=> f2 < f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < f1 = ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 ) 225: | otherwise = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f2 t1 : is1 ) ( i2 : is2 ) 226: where {v : Int | v == (if f1 > f2 then f1 else f2)} f' = x1:Int -> x2:Int -> {v : Int | v == (if x1 > x2 then x1 else x2)} max f1 f2","title":"Algorithms on Intervals"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#internal-vs-external-verification","text":"By representing legality internally as a refinement type, as opposed to externally as predicate ( goodLIs ) we have exposed enough information about the structure of the values that LH can automatically chomp through the above code to guarantee that we haven't messed up the invariants. To appreciate the payoff, compare to the effort needed to verify legality using the external representation used in the hs-to-coq proof . The same principle and simplification benefits apply to both the union 245: union :: Intervals -> Intervals -> Intervals 246: Intervals -> Intervals -> Intervals union ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 247: where 248: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 249: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ [Interval] is [] = is 250: go _ [] is = is 251: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 252: -- reorder for symmetry 253: | {v : Bool | v <=> t1 < t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i2 : is2 ) ( i1 : is1 ) 254: -- disjoint 255: | {v : Bool | v <=> f1 > t2} f1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 > x2} > t2 = i2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( i1 : is1 ) is2 256: -- overlapping 257: | otherwise = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f' t1 ) : is1 ) is2 258: where 259: {v : Int | v == (if f1 < f2 then f1 else f2)} f' = x1:Int -> x2:Int -> {v : Int | v == (if x1 < x2 then x1 else x2)} min f1 f2 and the subtract functions too: 265: subtract :: Intervals -> Intervals -> Intervals 266: Intervals -> Intervals -> Intervals subtract ( Intervals is1 ) ( Intervals is2 ) = {v : x1:[{v : Interval | 0 <= Intervals.from v}] -> {v : Intervals | Intervals.itvs v == x1 && lqdc##$select v == x1 && v == Intervals.Intervals x1} | v == Intervals.Intervals} Intervals ( {v : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] | v == go} go 0 is1 is2 ) 267: where 268: {-@ go :: lb : Int -> OrdItvs lb -> OrdItvs lb -> OrdItvs lb @-} 269: x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go _ [Interval] is [] = is 270: go _ [] _ = [] 271: go lb ( i1 @ ( I f1 t1 ) : is1 ) ( i2 @ ( I f2 t2 ) : is2 ) 272: -- i2 past i1 273: | {v : Bool | v <=> t1 <= f2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f2 = ( i1 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t1 is1 ( i2 : is2 ) ) 274: -- i1 past i2 275: | {v : Bool | v <=> t2 <= f1} t2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 = ( x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb ( i1 : is1 ) is2 ) 276: -- i1 contained in i2 277: | {v : Bool | v <=> f2 <= f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 , {v : Bool | v <=> t1 <= t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= t2 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go lb is1 ( i2 : is2 ) 278: -- i2 covers beginning of i1 279: | {v : Bool | v <=> f2 <= f1} f2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= f1 = x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go t2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 280: -- -- i2 covers end of i1 281: | {v : Bool | v <=> t1 <= t2} t1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 <= x2} <= t2 = ( ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f1 f2 ) : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go f2 is1 ( i2 : is2 ) ) 282: -- i2 in the middle of i1 283: | otherwise = ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I f1 f2 : x1:Int -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] -> [{v : Interval | x1 <= Intervals.from v}] go f2 ( {v : x1:Int -> x2:{v : Int | x1 < v} -> {v : Interval | Intervals.to v == x2 && Intervals.from v == x1 && lqdc##$select v == x2 && lqdc##$select v == x1 && v == Intervals.I x1 x2} | v == Intervals.I} I t2 t1 : is1 ) is2 ) both of which require non-trivial proofs in the external style . (Of course, its possible those proofs can be simplified.)","title":"Internal vs External Verification"},{"location":"blogposts/2017-12-15-splitting-and-splicing-intervals-I.lhs/#summing-up-and-looking-ahead","text":"I hope the above example illustrates why \"making illegal states\" unrepresentable is a great principle for engineering code and proofs. That said, notice that with hs-to-coq , Breitner was able to go far beyond the above legality requirement: he was able to specify and verify the far more important (and difficult) property that the above is a correct implementation of a Set library. Is it even possible , let alone easier to do that with LH?","title":"Summing Up (and Looking Ahead)"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/","text":"Previously , we saw how the principle of \"making illegal states unrepresentable\" allowed LH to easily enforce a key invariant in Joachim Breitner's library for representing sets of integers as sorted lists of intervals . However, Hs-to-coq let Breitner specify and verify that his code properly implemented a set library. Today, lets see how LH's new \"type-level computation\" abilities let us reason about the sets of values corresponding to intervals, while using the SMT solver to greatly simplify the overhead of proof. (Click here to demo ) 42: {-@ LIQUID \"--short-names\" @-} 43: {-@ LIQUID \"--exact-data-con\" @-} 44: {-@ LIQUID \"--no-adt\" @-} 45: {-@ LIQUID \"--higherorder\" @-} 46: {-@ LIQUID \"--diff\" @-} 47: {-@ LIQUID \"--ple\" @-} 48: 49: module RangeSet where 50: 51: import Prelude hiding ( min , max ) 52: import Language . Haskell . Liquid . NewProofCombinators Intervals \u00b6 Recall that the key idea is to represent sets of integers like { 7, 1, 10, 3, 11, 2, 9, 12, 4} as ordered lists of intervals [ (1, 5), (7, 8), (9, 13) ] where each pair (i, j) represents the set {i, i+1,..., j-1} . To verify that the implementation correctly implements a set data type, we need a way to Specify the set of values being described, Establish some key properties of these sets. Range-Sets: Semantics of Intervals \u00b6 We can describe the set of values corresponding to (i.e. \"the semantics of\") an interval i, j by importing the Data.Set library 88: import qualified Data . Set as S to write a function rng i j that defines the range-set i..j 94: {-@ reflect rng @-} 95: {-@ rng :: i : Int -> j : Int -> S . Set Int / [ j - i ] @-} 96: Int -> Int -> (Set Int) rng Int i Int j 97: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j = x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i} S . singleton i ) ( Int -> Int -> (Set Int) rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) 98: | otherwise = S . empty The reflect rng tells LH that we are going to want to work with the Haskell function rng at the refinement-type level. Equational Reasoning \u00b6 To build up a little intuition about the above definition and how LH reasons about Sets, lets write some simple unit proofs . For example, lets check that 2 is indeed in the range-set rng 1 3 , by writing a type signature 116: {-@ test1 :: () -> { S.member 2 (rng 1 3) } @-} Any implementation of the above type is a proof that 2 is indeed in rng 1 3 . Notice that we can reuse the operators from Data.Set (here, S.member ) to talk about set operations in the refinement logic. Lets write this proof in an equational style : 126: () -> {VV : () | Set_mem 2 (RangeSet.rng 1 3)} test1 () 127: = x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 1 3 ) 128: -- by unfolding `rng 1 3` 129: === x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 2 3 ) ) 130: -- by unfolding `rng 2 3` 131: === x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 1 ) 132: ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 2 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 3 3 ) ) ) 133: -- by set-theory 134: === True 135: *** QED the \"proof\" uses two library operators: e1 === e2 is an implicit equality that checks e1 is indeed equal to e2 after unfolding functions at most once , and returns a term that equals e1 and e2 , and e *** QED converts any term e into a proof. The first two steps of test1 , simply unfold rng and the final step uses the SMT solver's decision procedure for sets to check equalities over set operations like S.union , S.singleton and S.member . Reusing Proofs \u00b6 Next, lets check that: 160: {-@ test2 :: () -> { S.member 2 (rng 0 3) } @-} 161: () -> {VV : () | Set_mem 2 (RangeSet.rng 0 3)} test2 () 162: = x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 0 3 ) 163: -- by unfolding and set-theory 164: === ( Bool 2 x1:Integer -> x2:Integer -> {v : Bool | v <=> x1 == x2} == 0 {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 || x2} | v == GHC.Classes.||} || x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 1 3 ) ) 165: -- by re-using test1 as a lemma 166: ==? True ? {v : () -> {v : () | Set_mem 2 (RangeSet.rng 1 3)} | v == RangeSet.test1} test1 () 167: *** QED We could do the proof by unfolding in the equational style. However, test1 already establishes that S.member 2 (rng 1 3) and we can reuse this fact using: e1 ==? e2 ? pf an explicit equality which checks that e1 equals e2 because of the extra facts asserted by the Proof named pf (in addition to unfolding functions at most once) and returns a term that equals both e1 and e2 . Proof by Logical Evaluation \u00b6 Equational proofs like test1 and test2 often have long chains of calculations that can be tedious to spell out. Fortunately, we taught LH a new trick called Proof by Logical Evaluation (PLE) that optionally shifts the burden of performing those calculations onto the machine. For example, PLE completely automates the above proofs: 194: {-@ test1_ple :: () -> { S.member 2 (rng 1 3) } @-} 195: () -> {VV : () | Set_mem 2 (RangeSet.rng 1 3)} test1_ple () = () 196: 197: {-@ test2_ple :: () -> { S.member 2 (rng 0 3) } @-} 198: () -> {VV : () | Set_mem 2 (RangeSet.rng 0 3)} test2_ple () = () Be Warned! While automation is cool, it can be very helpful to first write out all the steps of an equational proof, at least while building up intuition. Proof by Induction \u00b6 At this point, we have enough tools to start proving some interesting facts about range-sets. For example, if x is outside the range i..j then it does not belong in rng i j : 216: {-@ lem_mem :: i : _ -> j : _ -> x : {x < i || j <= x} -> 217: { not (S.member x (rng i j)) } / [ j - i ] 218: @-} We will prove the above \"by induction\" . A confession: I always had trouble understanding what exactly proof by induction really meant. Why was it it ok to \"do\" induction on one thing but not another? Induction is Recursion Fortunately, with LH, induction is just recursion. That is, We can recursively use the same theorem we are trying to prove, but We must make sure that the recursive function/proof terminates . The proof makes this clear: 239: x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem Int i Int j {v : Int | v < i || j <= v} x 240: | {v : Bool | v <=> i >= j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j 241: -- BASE CASE 242: = {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i j ) ) 243: -- by unfolding 244: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x S . empty ) 245: -- by set-theory 246: === True *** QED 247: 248: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j 249: -- INDUCTIVE CASE 250: = {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i j ) ) 251: -- by unfolding 252: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i} S . singleton i ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) ) ) 253: -- by set-theory 254: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) ) 255: -- by \"induction hypothesis\" 256: ==? True ? x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j x *** QED There are two cases. Base Case: As i >= j , we know rng i j is empty, so x cannot be in it. Inductive Case As i < j we can unfold rng i j and then recursively call lem_mem (i+1) j to obtain the fact that x cannot be in i+1..j to complete the proof. LH automatically checks that the proof: Accounts for all cases , as otherwise the function is not total i.e. like the head function which is only defined on non-empty lists. (Try deleting a case at the demo to see what happens.) Terminates , as otherwise the induction is bogus, or in math-speak, not well-founded . We use the explicit termination metric / [j-i] as a hint to tell LH that in each recursive call, the size of the interval j-i shrinks and is always non-negative. LH checks that is indeed the case, ensuring that we have a legit proof by induction. Proof by Evaluation Once you get the hang of the above style, you get tired of spelling out all the details. Logical evaluation lets us eliminate all the boring calculational steps, leaving the essential bits: the recursive (inductive) skeleton 291: {-@ lem_mem_ple :: i : _ -> j : _ -> x : {x < i || j <= x} -> 292: {not (S.member x (rng i j))} / [ j - i ] 293: @-} 294: x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem_ple Int i Int j {v : Int | v < i || j <= v} x 295: | {v : Bool | v <=> i >= j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j = () 296: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j = x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem_ple ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j x The above is just lem_mem sans the (PLE-synthesized) intermediate equalities. Disjointness \u00b6 We say that two sets are disjoint if their intersection is empty : 309: {-@ inline disjoint @-} 310: disjoint :: S . Set Int -> S . Set Int -> Bool 311: x1:(Set Int) -> x2:(Set Int) -> {VV : Bool | VV <=> Set_cap x1 x2 == Set_empty 0} disjoint (Set Int) a (Set Int) b = x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cap x1 x2} S . intersection a b x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> x1 == x2} == S . empty Lets prove that two intervals are disjoint if the first ends before the second begins : 318: {-@ lem_disj :: i1 : _ -> j1 : _ -> i2 : {j1 <= i2} -> j2 : _ -> 319: {disjoint (rng i1 j1) (rng i2 j2)} / [ j2 - i2 ] 320: @-} This proof goes \"by induction\" on the size of the second interval, i.e. j2-i2 : 327: x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj Int i1 Int j1 {i2 : Int | j1 <= i2} i2 Int j2 328: | {v : Bool | v <=> i2 >= j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j2 329: -- Base CASE 330: = {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i2 j2 ) 331: -- by unfolding 332: === {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) S . empty 333: -- by set-theory 334: === True 335: *** QED 336: 337: | {v : Bool | v <=> i2 < j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j2 338: -- Inductive CASE 339: = {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i2 j2 ) 340: -- by unfolding 341: === {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i2} S . singleton i2 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2 ) ) 342: -- by induction and lem_mem 343: ==? True ? ( {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem i1 j1 i2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj i1 j1 ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2 ) 344: *** QED Here, the operator pf1 &&& pf2 conjoins the two facts asserted by pf1 and pf2 . Again, we can get PLE to do the boring calculations: 353: {-@ lem_disj_ple :: i1 : _ -> j1 : _ -> i2 : {j1 <= i2} -> j2 : _ -> 354: {disjoint (rng i1 j1) (rng i2 j2)} / [ j2 - i2 ] 355: @-} 356: x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj_ple Int i1 Int j1 {i2 : Int | j1 <= i2} i2 Int j2 357: | {v : Bool | v <=> i2 >= j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j2 = () 358: | {v : Bool | v <=> i2 < j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j2 = {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem i1 j1 i2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj_ple i1 j1 ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2 Splitting Intervals \u00b6 Finally, we can establish the splitting property of an interval i..j , that is, given some x that lies between i and j we can split i..j into i..x and x..j . We define a predicate that a set s can be split into a and b as: 372: {-@ inline split @-} 373: split :: S . Set Int -> S . Set Int -> S . Set Int -> Bool 374: x1:(Set Int) -> x2:(Set Int) -> x3:(Set Int) -> {VV : Bool | VV <=> x1 == Set_cup x2 x3 && Set_cap x2 x3 == Set_empty 0} split (Set Int) s (Set Int) a (Set Int) b = Bool s x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> x1 == x2} == x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union a b {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint a b We can now state and prove the splitting property as: 380: {-@ lem_split :: i : _ -> x : {i <= x} -> j : {x <= j} -> 381: {split (rng i j) (rng i x) (rng x j)} / [ x - i ] 382: @-} 383: x1:Int -> x2:{v : Int | x1 <= v} -> x3:{j : Int | x2 <= j} -> {VV : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} lem_split Int i {v : Int | i <= v} x {j : Int | x <= j} t 384: | {v : Bool | v <=> i == x} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 == x2} == x = () 385: | {v : Bool | v <=> i < x} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < x = x1:Int -> x2:{v : Int | x1 <= v} -> x3:{j : Int | x2 <= j} -> {VV : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} lem_split ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) x t {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem x t i (We're using PLE here quite aggressively, can you work out the equational proof?) Set Operations \u00b6 The splitting abstraction is a wonderful hammer that lets us break higher-level proofs into the bite sized pieces suitable for the SMT solver's decision procedures. Subset An interval i1..j1 is enclosed by i2..j2 if i2 <= i1 < j1 <= j2 . Lets verify that the range-set of an interval is contained in that of an enclosing one. 406: {-@ lem_sub :: i1 : _ -> j1 : {i1 < j1} -> 407: i2 : _ -> j2 : {i2 < j2 && i2 <= i1 && j1 <= j2 } -> 408: { S.isSubsetOf (rng i1 j1) (rng i2 j2) } 409: @-} Here's a \"proof-by-picture\". We can split the larger interval i2..j2 into smaller pieces, i2..i1 , i1..j1 and j1..j2 one of which is the i1..j1 , thereby completing the proof: ![`lem_sub` a proof by picture](../static/img/lem_sub.png \"lem_sub proof by picture\") The intuition represented by the picture can distilled into the following proof, that invokes lem_split to carve i2..j2 into the relevant sub-intervals: 432: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x3 <= x1 && x2 <= j2} -> {VV : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_sub Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i2 <= i1 && j1 <= j2} j2 = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j1 j2 Union An interval i1..j1 overlaps i2..j2 if i1 <= j2 <= i2 , that is, if the latter ends somewhere inside the former. The same splitting hammer lets us compute the union of two overlapping intervals simply by picking the interval defined by the endpoints . 446: {-@ lem_union :: 447: i1 : _ -> j1 : {i1 < j1} -> 448: i2 : _ -> j2 : {i2 < j2 && i1 <= j2 && j2 <= j1 } -> 449: { rng (min i1 i2) j1 = S.union (rng i1 j1) (rng i2 j2) } 450: @-} ![`lem_union` a proof by picture](../static/img/lem_union.png \"lem_union proof by picture\") The pictorial proof illustrates the two cases: i1..j1 encloses i2..j2 ; here the union is just i1..j1 , i1..j1 only overlaps i1..j1 ; here the union is i2..j1 which can be split into i2..i1 , i1..j2 and j2..j1 which are exactly the union of the intervals i1..j1 and i2..j2 . Again, we render the picture into a formal proof as: 474: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x1 <= j2 && j2 <= x2} -> {VV : () | RangeSet.rng (RangeSet.min x1 x3) x2 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_union Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i1 <= j2 && j2 <= j1} j2 475: -- i1..j1 encloses i2..j2 476: | {v : Bool | v <=> i1 < i2} i1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < i2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> x3:Int -> x4:{v : Int | x3 < v && x3 <= x1 && x2 <= v} -> {v : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} | v == RangeSet.lem_sub} lem_sub i2 j2 i1 j1 477: -- i1..j1 overlaps i2..j2 478: | otherwise = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j1 479: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j2 j1 480: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 Intersection Finally, we check that the intersection of two overlapping intervals is given by their inner-points . 489: {-@ lem_intersect :: 490: i1 : _ -> j1 : {i1 < j1} -> 491: i2 : _ -> j2 : {i2 < j2 && i1 <= j2 && j2 <= j1 } -> 492: {rng (max i1 i2) j2 = S.intersection (rng i1 j1) (rng i2 j2)} 493: @-} ![`lem_intersect` a proof by picture](../static/img/lem_intersect.png \"lem_intersect proof by picture\") We have the same two cases as for lem_union i1..j1 encloses i2..j2 ; here the intersection is just i2..j2 , i1..j1 only overlaps i1..j1 ; here the intersection is the middle segment i1..j2 , which we obtain by (a) splitting i1..j1 at j2 , (b) splitting i2..j2 at i1 , (c) discarding the end segments which do not belong in the intersection. 517: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x1 <= j2 && j2 <= x2} -> {VV : () | RangeSet.rng (RangeSet.max x1 x3) x4 == Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_intersect Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i1 <= j2 && j2 <= j1} j2 518: -- i1..j1 encloses i2..j2 519: | {v : Bool | v <=> i1 < i2} i1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < i2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> x3:Int -> x4:{v : Int | x3 < v && x3 <= x1 && x2 <= v} -> {v : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} | v == RangeSet.lem_sub} lem_sub i2 j2 i1 j1 520: -- i1..j1 overlaps i2..j2 521: | otherwise = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j2 j1 522: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 523: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | x2 <= v} -> x4:Int -> {v : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} | v == RangeSet.lem_disj} lem_disj i2 i1 i1 j1 -- discard i2..i1 524: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | x2 <= v} -> x4:Int -> {v : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} | v == RangeSet.lem_disj} lem_disj i2 j2 j2 j1 -- discard j2..j1 Conclusions \u00b6 Whew. That turned out a lot longer than I'd expected! On the bright side, we saw how to: Specify the semantics of range-sets, Write equational proofs using plain Haskell code, Avoid boring proof steps using PLE, Verify key properties of operations on range-sets. Next time we'll finish the series by showing how to use the above lemmas to specify and verify the correctness of Breitner's implementation . 547: -------------------------------------------------------------------------------- 548: -- | Some helper definitions 549: -------------------------------------------------------------------------------- 550: {-@ reflect min @-} 551: min :: ( Ord a ) => a -> a -> a 552: (Ord a) => x2:a -> x3:a -> {VV : a | VV == RangeSet.min x2 x3 && VV == (if x2 < x3 then x2 else x3)} min a x a y = {v : Bool | v <=> x < y} if {v : Bool | v <=> x < y} x x1:a -> x2:a -> {v : Bool | v <=> x1 < x2} < y then x else y 553: 554: {-@ reflect max @-} 555: max :: ( Ord a ) => a -> a -> a 556: (Ord a) => x2:a -> x3:a -> {VV : a | VV == RangeSet.max x2 x3 && VV == (if x2 < x3 then x3 else x2)} max a x a y = {v : Bool | v <=> x < y} if {v : Bool | v <=> x < y} x x1:a -> x2:a -> {v : Bool | v <=> x1 < x2} < y then y else x 557: 558: rng :: Int -> Int -> S . Set Int 559: test1 :: () -> () 560: test2 :: () -> () 561: test1_ple :: () -> () 562: test2_ple :: () -> () 563: lem_mem :: Int -> Int -> Int -> () 564: lem_mem_ple :: Int -> Int -> Int -> () 565: lem_sub :: Int -> Int -> Int -> Int -> () 566: lem_disj :: Int -> Int -> Int -> Int -> () 567: lem_disj_ple :: Int -> Int -> Int -> Int -> () 568: lem_split :: Int -> Int -> Int -> () 569: 570: lem_intersect :: Int -> Int -> Int -> Int -> () 571: lem_union :: Int -> Int -> Int -> Int -> () 572: -- tags/induction.html 573:","title":"Splitting and Splicing Intervals (Part 2)"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#intervals","text":"Recall that the key idea is to represent sets of integers like { 7, 1, 10, 3, 11, 2, 9, 12, 4} as ordered lists of intervals [ (1, 5), (7, 8), (9, 13) ] where each pair (i, j) represents the set {i, i+1,..., j-1} . To verify that the implementation correctly implements a set data type, we need a way to Specify the set of values being described, Establish some key properties of these sets.","title":"Intervals"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#range-sets-semantics-of-intervals","text":"We can describe the set of values corresponding to (i.e. \"the semantics of\") an interval i, j by importing the Data.Set library 88: import qualified Data . Set as S to write a function rng i j that defines the range-set i..j 94: {-@ reflect rng @-} 95: {-@ rng :: i : Int -> j : Int -> S . Set Int / [ j - i ] @-} 96: Int -> Int -> (Set Int) rng Int i Int j 97: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j = x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i} S . singleton i ) ( Int -> Int -> (Set Int) rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) 98: | otherwise = S . empty The reflect rng tells LH that we are going to want to work with the Haskell function rng at the refinement-type level.","title":"Range-Sets: Semantics of Intervals"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#equational-reasoning","text":"To build up a little intuition about the above definition and how LH reasons about Sets, lets write some simple unit proofs . For example, lets check that 2 is indeed in the range-set rng 1 3 , by writing a type signature 116: {-@ test1 :: () -> { S.member 2 (rng 1 3) } @-} Any implementation of the above type is a proof that 2 is indeed in rng 1 3 . Notice that we can reuse the operators from Data.Set (here, S.member ) to talk about set operations in the refinement logic. Lets write this proof in an equational style : 126: () -> {VV : () | Set_mem 2 (RangeSet.rng 1 3)} test1 () 127: = x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 1 3 ) 128: -- by unfolding `rng 1 3` 129: === x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 2 3 ) ) 130: -- by unfolding `rng 2 3` 131: === x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 1 ) 132: ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( (Set Int) S . singleton 2 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 3 3 ) ) ) 133: -- by set-theory 134: === True 135: *** QED the \"proof\" uses two library operators: e1 === e2 is an implicit equality that checks e1 is indeed equal to e2 after unfolding functions at most once , and returns a term that equals e1 and e2 , and e *** QED converts any term e into a proof. The first two steps of test1 , simply unfold rng and the final step uses the SMT solver's decision procedure for sets to check equalities over set operations like S.union , S.singleton and S.member .","title":"Equational Reasoning"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#reusing-proofs","text":"Next, lets check that: 160: {-@ test2 :: () -> { S.member 2 (rng 0 3) } @-} 161: () -> {VV : () | Set_mem 2 (RangeSet.rng 0 3)} test2 () 162: = x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 0 3 ) 163: -- by unfolding and set-theory 164: === ( Bool 2 x1:Integer -> x2:Integer -> {v : Bool | v <=> x1 == x2} == 0 {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 || x2} | v == GHC.Classes.||} || x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member 2 ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng 1 3 ) ) 165: -- by re-using test1 as a lemma 166: ==? True ? {v : () -> {v : () | Set_mem 2 (RangeSet.rng 1 3)} | v == RangeSet.test1} test1 () 167: *** QED We could do the proof by unfolding in the equational style. However, test1 already establishes that S.member 2 (rng 1 3) and we can reuse this fact using: e1 ==? e2 ? pf an explicit equality which checks that e1 equals e2 because of the extra facts asserted by the Proof named pf (in addition to unfolding functions at most once) and returns a term that equals both e1 and e2 .","title":"Reusing Proofs"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#proof-by-logical-evaluation","text":"Equational proofs like test1 and test2 often have long chains of calculations that can be tedious to spell out. Fortunately, we taught LH a new trick called Proof by Logical Evaluation (PLE) that optionally shifts the burden of performing those calculations onto the machine. For example, PLE completely automates the above proofs: 194: {-@ test1_ple :: () -> { S.member 2 (rng 1 3) } @-} 195: () -> {VV : () | Set_mem 2 (RangeSet.rng 1 3)} test1_ple () = () 196: 197: {-@ test2_ple :: () -> { S.member 2 (rng 0 3) } @-} 198: () -> {VV : () | Set_mem 2 (RangeSet.rng 0 3)} test2_ple () = () Be Warned! While automation is cool, it can be very helpful to first write out all the steps of an equational proof, at least while building up intuition.","title":"Proof by Logical Evaluation"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#proof-by-induction","text":"At this point, we have enough tools to start proving some interesting facts about range-sets. For example, if x is outside the range i..j then it does not belong in rng i j : 216: {-@ lem_mem :: i : _ -> j : _ -> x : {x < i || j <= x} -> 217: { not (S.member x (rng i j)) } / [ j - i ] 218: @-} We will prove the above \"by induction\" . A confession: I always had trouble understanding what exactly proof by induction really meant. Why was it it ok to \"do\" induction on one thing but not another? Induction is Recursion Fortunately, with LH, induction is just recursion. That is, We can recursively use the same theorem we are trying to prove, but We must make sure that the recursive function/proof terminates . The proof makes this clear: 239: x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem Int i Int j {v : Int | v < i || j <= v} x 240: | {v : Bool | v <=> i >= j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j 241: -- BASE CASE 242: = {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i j ) ) 243: -- by unfolding 244: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x S . empty ) 245: -- by set-theory 246: === True *** QED 247: 248: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j 249: -- INDUCTIVE CASE 250: = {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i j ) ) 251: -- by unfolding 252: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i} S . singleton i ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) ) ) 253: -- by set-theory 254: === {v : x1:Bool -> {v : Bool | v <=> not x1} | v == GHC.Classes.not} not ( x1:Int -> x2:(Set Int) -> {v : Bool | v <=> Set_mem x1 x2} S . member x ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j ) ) 255: -- by \"induction hypothesis\" 256: ==? True ? x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j x *** QED There are two cases. Base Case: As i >= j , we know rng i j is empty, so x cannot be in it. Inductive Case As i < j we can unfold rng i j and then recursively call lem_mem (i+1) j to obtain the fact that x cannot be in i+1..j to complete the proof. LH automatically checks that the proof: Accounts for all cases , as otherwise the function is not total i.e. like the head function which is only defined on non-empty lists. (Try deleting a case at the demo to see what happens.) Terminates , as otherwise the induction is bogus, or in math-speak, not well-founded . We use the explicit termination metric / [j-i] as a hint to tell LH that in each recursive call, the size of the interval j-i shrinks and is always non-negative. LH checks that is indeed the case, ensuring that we have a legit proof by induction. Proof by Evaluation Once you get the hang of the above style, you get tired of spelling out all the details. Logical evaluation lets us eliminate all the boring calculational steps, leaving the essential bits: the recursive (inductive) skeleton 291: {-@ lem_mem_ple :: i : _ -> j : _ -> x : {x < i || j <= x} -> 292: {not (S.member x (rng i j))} / [ j - i ] 293: @-} 294: x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem_ple Int i Int j {v : Int | v < i || j <= v} x 295: | {v : Bool | v <=> i >= j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j = () 296: | {v : Bool | v <=> i < j} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j = x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {VV : () | not (Set_mem x3 (RangeSet.rng x1 x2))} lem_mem_ple ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j x The above is just lem_mem sans the (PLE-synthesized) intermediate equalities.","title":"Proof by Induction"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#disjointness","text":"We say that two sets are disjoint if their intersection is empty : 309: {-@ inline disjoint @-} 310: disjoint :: S . Set Int -> S . Set Int -> Bool 311: x1:(Set Int) -> x2:(Set Int) -> {VV : Bool | VV <=> Set_cap x1 x2 == Set_empty 0} disjoint (Set Int) a (Set Int) b = x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cap x1 x2} S . intersection a b x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> x1 == x2} == S . empty Lets prove that two intervals are disjoint if the first ends before the second begins : 318: {-@ lem_disj :: i1 : _ -> j1 : _ -> i2 : {j1 <= i2} -> j2 : _ -> 319: {disjoint (rng i1 j1) (rng i2 j2)} / [ j2 - i2 ] 320: @-} This proof goes \"by induction\" on the size of the second interval, i.e. j2-i2 : 327: x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj Int i1 Int j1 {i2 : Int | j1 <= i2} i2 Int j2 328: | {v : Bool | v <=> i2 >= j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j2 329: -- Base CASE 330: = {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i2 j2 ) 331: -- by unfolding 332: === {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) S . empty 333: -- by set-theory 334: === True 335: *** QED 336: 337: | {v : Bool | v <=> i2 < j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j2 338: -- Inductive CASE 339: = {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i2 j2 ) 340: -- by unfolding 341: === {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng i1 j1 ) ( x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union ( {v : (Set Int) | v == Set_sng i2} S . singleton i2 ) ( {v : x1:Int -> x2:Int -> {v : (Set Int) | v == RangeSet.rng x1 x2 && v == (if x1 < x2 then Set_cup (Set_sng x1) (RangeSet.rng (x1 + 1) x2) else Set_empty 0)} | v == RangeSet.rng} rng ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2 ) ) 342: -- by induction and lem_mem 343: ==? True ? ( {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem i1 j1 i2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj i1 j1 ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2 ) 344: *** QED Here, the operator pf1 &&& pf2 conjoins the two facts asserted by pf1 and pf2 . Again, we can get PLE to do the boring calculations: 353: {-@ lem_disj_ple :: i1 : _ -> j1 : _ -> i2 : {j1 <= i2} -> j2 : _ -> 354: {disjoint (rng i1 j1) (rng i2 j2)} / [ j2 - i2 ] 355: @-} 356: x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj_ple Int i1 Int j1 {i2 : Int | j1 <= i2} i2 Int j2 357: | {v : Bool | v <=> i2 >= j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 >= x2} >= j2 = () 358: | {v : Bool | v <=> i2 < j2} i2 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < j2 = {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem i1 j1 i2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& x1:Int -> x2:Int -> x3:{i2 : Int | x2 <= i2} -> x4:Int -> {VV : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} lem_disj_ple i1 j1 ( Int i2 x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) j2","title":"Disjointness"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#splitting-intervals","text":"Finally, we can establish the splitting property of an interval i..j , that is, given some x that lies between i and j we can split i..j into i..x and x..j . We define a predicate that a set s can be split into a and b as: 372: {-@ inline split @-} 373: split :: S . Set Int -> S . Set Int -> S . Set Int -> Bool 374: x1:(Set Int) -> x2:(Set Int) -> x3:(Set Int) -> {VV : Bool | VV <=> x1 == Set_cup x2 x3 && Set_cap x2 x3 == Set_empty 0} split (Set Int) s (Set Int) a (Set Int) b = Bool s x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> x1 == x2} == x1:(Set Int) -> x2:(Set Int) -> {v : (Set Int) | v == Set_cup x1 x2} S . union a b {v : x1:Bool -> x2:Bool -> {v : Bool | v <=> x1 && x2} | v == GHC.Classes.&&} && {v : x1:(Set Int) -> x2:(Set Int) -> {v : Bool | v <=> Set_cap x1 x2 == Set_empty 0} | v == RangeSet.disjoint} disjoint a b We can now state and prove the splitting property as: 380: {-@ lem_split :: i : _ -> x : {i <= x} -> j : {x <= j} -> 381: {split (rng i j) (rng i x) (rng x j)} / [ x - i ] 382: @-} 383: x1:Int -> x2:{v : Int | x1 <= v} -> x3:{j : Int | x2 <= j} -> {VV : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} lem_split Int i {v : Int | i <= v} x {j : Int | x <= j} t 384: | {v : Bool | v <=> i == x} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 == x2} == x = () 385: | {v : Bool | v <=> i < x} i x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < x = x1:Int -> x2:{v : Int | x1 <= v} -> x3:{j : Int | x2 <= j} -> {VV : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} lem_split ( Int i x1:Int -> x2:Int -> {v : Int | v == x1 + x2} + 1 ) x t {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | v < x1 || x2 <= v} -> {v : () | not (Set_mem x3 (RangeSet.rng x1 x2))} | v == RangeSet.lem_mem} lem_mem x t i (We're using PLE here quite aggressively, can you work out the equational proof?)","title":"Splitting Intervals"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#set-operations","text":"The splitting abstraction is a wonderful hammer that lets us break higher-level proofs into the bite sized pieces suitable for the SMT solver's decision procedures. Subset An interval i1..j1 is enclosed by i2..j2 if i2 <= i1 < j1 <= j2 . Lets verify that the range-set of an interval is contained in that of an enclosing one. 406: {-@ lem_sub :: i1 : _ -> j1 : {i1 < j1} -> 407: i2 : _ -> j2 : {i2 < j2 && i2 <= i1 && j1 <= j2 } -> 408: { S.isSubsetOf (rng i1 j1) (rng i2 j2) } 409: @-} Here's a \"proof-by-picture\". We can split the larger interval i2..j2 into smaller pieces, i2..i1 , i1..j1 and j1..j2 one of which is the i1..j1 , thereby completing the proof: ![`lem_sub` a proof by picture](../static/img/lem_sub.png \"lem_sub proof by picture\") The intuition represented by the picture can distilled into the following proof, that invokes lem_split to carve i2..j2 into the relevant sub-intervals: 432: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x3 <= x1 && x2 <= j2} -> {VV : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_sub Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i2 <= i1 && j1 <= j2} j2 = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j1 j2 Union An interval i1..j1 overlaps i2..j2 if i1 <= j2 <= i2 , that is, if the latter ends somewhere inside the former. The same splitting hammer lets us compute the union of two overlapping intervals simply by picking the interval defined by the endpoints . 446: {-@ lem_union :: 447: i1 : _ -> j1 : {i1 < j1} -> 448: i2 : _ -> j2 : {i2 < j2 && i1 <= j2 && j2 <= j1 } -> 449: { rng (min i1 i2) j1 = S.union (rng i1 j1) (rng i2 j2) } 450: @-} ![`lem_union` a proof by picture](../static/img/lem_union.png \"lem_union proof by picture\") The pictorial proof illustrates the two cases: i1..j1 encloses i2..j2 ; here the union is just i1..j1 , i1..j1 only overlaps i1..j1 ; here the union is i2..j1 which can be split into i2..i1 , i1..j2 and j2..j1 which are exactly the union of the intervals i1..j1 and i2..j2 . Again, we render the picture into a formal proof as: 474: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x1 <= j2 && j2 <= x2} -> {VV : () | RangeSet.rng (RangeSet.min x1 x3) x2 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_union Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i1 <= j2 && j2 <= j1} j2 475: -- i1..j1 encloses i2..j2 476: | {v : Bool | v <=> i1 < i2} i1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < i2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> x3:Int -> x4:{v : Int | x3 < v && x3 <= x1 && x2 <= v} -> {v : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} | v == RangeSet.lem_sub} lem_sub i2 j2 i1 j1 477: -- i1..j1 overlaps i2..j2 478: | otherwise = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j1 479: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j2 j1 480: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 Intersection Finally, we check that the intersection of two overlapping intervals is given by their inner-points . 489: {-@ lem_intersect :: 490: i1 : _ -> j1 : {i1 < j1} -> 491: i2 : _ -> j2 : {i2 < j2 && i1 <= j2 && j2 <= j1 } -> 492: {rng (max i1 i2) j2 = S.intersection (rng i1 j1) (rng i2 j2)} 493: @-} ![`lem_intersect` a proof by picture](../static/img/lem_intersect.png \"lem_intersect proof by picture\") We have the same two cases as for lem_union i1..j1 encloses i2..j2 ; here the intersection is just i2..j2 , i1..j1 only overlaps i1..j1 ; here the intersection is the middle segment i1..j2 , which we obtain by (a) splitting i1..j1 at j2 , (b) splitting i2..j2 at i1 , (c) discarding the end segments which do not belong in the intersection. 517: x1:Int -> x2:{j1 : Int | x1 < j1} -> x3:Int -> x4:{j2 : Int | x3 < j2 && x1 <= j2 && j2 <= x2} -> {VV : () | RangeSet.rng (RangeSet.max x1 x3) x4 == Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} lem_intersect Int i1 {j1 : Int | i1 < j1} j1 Int i2 {j2 : Int | i2 < j2 && i1 <= j2 && j2 <= j1} j2 518: -- i1..j1 encloses i2..j2 519: | {v : Bool | v <=> i1 < i2} i1 x1:Int -> x2:Int -> {v : Bool | v <=> x1 < x2} < i2 = {v : x1:Int -> x2:{v : Int | x1 < v} -> x3:Int -> x4:{v : Int | x3 < v && x3 <= x1 && x2 <= v} -> {v : () | Set_sub (RangeSet.rng x1 x2) (RangeSet.rng x3 x4)} | v == RangeSet.lem_sub} lem_sub i2 j2 i1 j1 520: -- i1..j1 overlaps i2..j2 521: | otherwise = {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i1 j2 j1 522: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:{v : Int | x1 <= v} -> x3:{v : Int | x2 <= v} -> {v : () | RangeSet.rng x1 x3 == Set_cup (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) && Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x2 x3) == Set_empty 0} | v == RangeSet.lem_split} lem_split i2 i1 j2 523: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | x2 <= v} -> x4:Int -> {v : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} | v == RangeSet.lem_disj} lem_disj i2 i1 i1 j1 -- discard i2..i1 524: {v : () -> () -> () | v == Language.Haskell.Liquid.NewProofCombinators.&&&} &&& {v : x1:Int -> x2:Int -> x3:{v : Int | x2 <= v} -> x4:Int -> {v : () | Set_cap (RangeSet.rng x1 x2) (RangeSet.rng x3 x4) == Set_empty 0} | v == RangeSet.lem_disj} lem_disj i2 j2 j2 j1 -- discard j2..j1","title":"Set Operations"},{"location":"blogposts/2017-12-24-splitting-and-splicing-intervals-II.lhs/#conclusions","text":"Whew. That turned out a lot longer than I'd expected! On the bright side, we saw how to: Specify the semantics of range-sets, Write equational proofs using plain Haskell code, Avoid boring proof steps using PLE, Verify key properties of operations on range-sets. Next time we'll finish the series by showing how to use the above lemmas to specify and verify the correctness of Breitner's implementation . 547: -------------------------------------------------------------------------------- 548: -- | Some helper definitions 549: -------------------------------------------------------------------------------- 550: {-@ reflect min @-} 551: min :: ( Ord a ) => a -> a -> a 552: (Ord a) => x2:a -> x3:a -> {VV : a | VV == RangeSet.min x2 x3 && VV == (if x2 < x3 then x2 else x3)} min a x a y = {v : Bool | v <=> x < y} if {v : Bool | v <=> x < y} x x1:a -> x2:a -> {v : Bool | v <=> x1 < x2} < y then x else y 553: 554: {-@ reflect max @-} 555: max :: ( Ord a ) => a -> a -> a 556: (Ord a) => x2:a -> x3:a -> {VV : a | VV == RangeSet.max x2 x3 && VV == (if x2 < x3 then x3 else x2)} max a x a y = {v : Bool | v <=> x < y} if {v : Bool | v <=> x < y} x x1:a -> x2:a -> {v : Bool | v <=> x1 < x2} < y then y else x 557: 558: rng :: Int -> Int -> S . Set Int 559: test1 :: () -> () 560: test2 :: () -> () 561: test1_ple :: () -> () 562: test2_ple :: () -> () 563: lem_mem :: Int -> Int -> Int -> () 564: lem_mem_ple :: Int -> Int -> Int -> () 565: lem_sub :: Int -> Int -> Int -> Int -> () 566: lem_disj :: Int -> Int -> Int -> Int -> () 567: lem_disj_ple :: Int -> Int -> Int -> Int -> () 568: lem_split :: Int -> Int -> Int -> () 569: 570: lem_intersect :: Int -> Int -> Int -> Int -> () 571: lem_union :: Int -> Int -> Int -> Int -> () 572: -- tags/induction.html 573:","title":"Conclusions"},{"location":"blogposts/2018-02-23-measures-and-case-splitting.lhs/","text":"Liquid Haskell has a flag called --no-case-expand which can make verification of your code much faster, especially when your code is using ADTs with many alternatives. This flag says relax precision to get fast verification, thus may lead to rejecting safe code. In this post, I explain how --no-case-expand works using a trivial example! (Click here to demo ) 28: 29: module MeasuresAndCaseSplitting where Measures \u00b6 Let's define a simple data type with three alternatives 40: data ABC = A | B | C and a measure that turns ABD into an integer 46: {-@ measure toInt @-} 47: toInt :: ABC -> Int 48: x1:MeasuresAndCaseSplitting.ABC -> {VV : GHC.Types.Int | VV == MeasuresAndCaseSplitting.toInt x1} toInt A = 1 49: toInt B = 2 50: toInt C = 3 Though obvious to us, Liquid Haskell will fail to check that toInt of any ABC argument gives back a natural number. Or, the following call leads to a refinement type error. 59: {-@ unsafe :: x : ABC -> {o: () | 0 <= toInt x } @-} 60: unsafe :: ABC -> () 61: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} unsafe MeasuresAndCaseSplitting.ABC x = () Why? By turning toInt into a measure, Liquid Haskell gives precise information to each data constructor of ABC . Thus it knows that toInt or A , B , and C is respectively 1 , 2 , and 3 , by automatically generating the following types: 72: A :: { v : ABC | toInt v == 1 } 73: B :: { v : ABC | toInt v == 2 } 74: C :: { v : ABC | toInt v == 3 } Thus, to get the toInt information one need to explicitly perform case analysis on an ABC argument. The following code is safe 82: {-@ safe :: x : ABC -> {o: () | 0 <= toInt x} @-} 83: safe :: ABC -> () 84: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safe A = () 85: safe B = () 86: safe C = () Liquid Haskell type check the above code because in the first case the body is checked under the assumption that the argument, call it x , is an A . Under this assumption, toInt x is indeed non negative. Yet, this is the case for the rest two alternatives, where x is either B or C . So, 0 <= toInt x holds for all the alternatives, because case analysis on x automatically reasons about the value of the measure toInt . Now, what if I match the argument x only with A and provide a default body for the rest? 104: {-@ safeBut :: x : ABC -> {o: () | 0 <= toInt x} @-} 105: safeBut :: ABC -> () 106: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safeBut A = () 107: safeBut _ = () Liquid Haskell knows that if the argument x is actually an A , then toInt x is not negative, but does not know the value of toInt for the default case. But, by default Liquid Haskell will do the the case expansion of the default case for you and rewrite your code to match _ with all the possible cases. Thus, Liquid Haskell will internally rewrite safeBut as 119: {-@ safeButLH :: x : ABC -> {o: () | 0 <= toInt x} @-} 120: safeButLH :: ABC -> () 121: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safeButLH A = () 122: safeButLH B = () 123: safeButLH C = () With this rewrite Liquid Haskell gets precision! Thus, it has all the information it needs to prove safeBut as safe. Yet, it repeats the code of the default case, thus verification slows down. In this example, we only have three case alternatives, so we only repeat the code two times with a minor slow down. In cases with many more alternatives repeating the code of the default case can kill the verification time. For that reason, Liquid Haskell comes with the no-case-expand flag that deactivates this expansion of the default cases. With the no-case-expand flag on, the safeBut code will not type check and to fix it the user needs to perform the case expansion manually. In short, the no-case-expand increases verification speed but reduces precision. Then it is up to the user to manually expand the default cases, as required, to restore all the precision required for the code to type check.","title":"Measures and Case Splitting"},{"location":"blogposts/2018-02-23-measures-and-case-splitting.lhs/#measures","text":"Let's define a simple data type with three alternatives 40: data ABC = A | B | C and a measure that turns ABD into an integer 46: {-@ measure toInt @-} 47: toInt :: ABC -> Int 48: x1:MeasuresAndCaseSplitting.ABC -> {VV : GHC.Types.Int | VV == MeasuresAndCaseSplitting.toInt x1} toInt A = 1 49: toInt B = 2 50: toInt C = 3 Though obvious to us, Liquid Haskell will fail to check that toInt of any ABC argument gives back a natural number. Or, the following call leads to a refinement type error. 59: {-@ unsafe :: x : ABC -> {o: () | 0 <= toInt x } @-} 60: unsafe :: ABC -> () 61: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} unsafe MeasuresAndCaseSplitting.ABC x = () Why? By turning toInt into a measure, Liquid Haskell gives precise information to each data constructor of ABC . Thus it knows that toInt or A , B , and C is respectively 1 , 2 , and 3 , by automatically generating the following types: 72: A :: { v : ABC | toInt v == 1 } 73: B :: { v : ABC | toInt v == 2 } 74: C :: { v : ABC | toInt v == 3 } Thus, to get the toInt information one need to explicitly perform case analysis on an ABC argument. The following code is safe 82: {-@ safe :: x : ABC -> {o: () | 0 <= toInt x} @-} 83: safe :: ABC -> () 84: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safe A = () 85: safe B = () 86: safe C = () Liquid Haskell type check the above code because in the first case the body is checked under the assumption that the argument, call it x , is an A . Under this assumption, toInt x is indeed non negative. Yet, this is the case for the rest two alternatives, where x is either B or C . So, 0 <= toInt x holds for all the alternatives, because case analysis on x automatically reasons about the value of the measure toInt . Now, what if I match the argument x only with A and provide a default body for the rest? 104: {-@ safeBut :: x : ABC -> {o: () | 0 <= toInt x} @-} 105: safeBut :: ABC -> () 106: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safeBut A = () 107: safeBut _ = () Liquid Haskell knows that if the argument x is actually an A , then toInt x is not negative, but does not know the value of toInt for the default case. But, by default Liquid Haskell will do the the case expansion of the default case for you and rewrite your code to match _ with all the possible cases. Thus, Liquid Haskell will internally rewrite safeBut as 119: {-@ safeButLH :: x : ABC -> {o: () | 0 <= toInt x} @-} 120: safeButLH :: ABC -> () 121: x1:MeasuresAndCaseSplitting.ABC -> {o : () | 0 <= MeasuresAndCaseSplitting.toInt x1} safeButLH A = () 122: safeButLH B = () 123: safeButLH C = () With this rewrite Liquid Haskell gets precision! Thus, it has all the information it needs to prove safeBut as safe. Yet, it repeats the code of the default case, thus verification slows down. In this example, we only have three case alternatives, so we only repeat the code two times with a minor slow down. In cases with many more alternatives repeating the code of the default case can kill the verification time. For that reason, Liquid Haskell comes with the no-case-expand flag that deactivates this expansion of the default cases. With the no-case-expand flag on, the safeBut code will not type check and to fix it the user needs to perform the case expansion manually. In short, the no-case-expand increases verification speed but reduces precision. Then it is up to the user to manually expand the default cases, as required, to restore all the precision required for the code to type check.","title":"Measures"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/","text":"A month ago, Hillel Wayne posted a verification challenge comprising three problems that might sound frivolous, but which, in fact, hit the sweet spot of being easy to describe and yet interesting to implement and verify. I had a lot of fun hacking them up in LH, and learned some things doing so. Today, lets see how to implement the first of these challenges -- leftPad -- in Haskell, and to check Hillel's specification with LH. (Click here to demo ) 35: {-@ LIQUID \"--reflection\" @-} 36: {-@ LIQUID \"--ple\" @-} 37: {-@ infixr ++ @-} 38: {-@ infixr !! @-} 39: 40: module PadLeft where 41: 42: import Prelude hiding ( max , replicate , ( ++ ) , ( !! ) ) 43: ( !! ) :: [ a ] -> Int -> a 44: size :: [ a ] -> Int 45: ( ++ ) :: [ a ] -> [ a ] -> [ a ] 46: obviously :: Int -> a -> [ a ] -> () 47: replicate :: Int -> a -> [ a ] 48: thmReplicate :: Int -> a -> Int -> () 49: thmAppLeft :: [ a ] -> [ a ] -> Int -> () 50: thmAppRight :: [ a ] -> [ a ] -> Int -> () 51: thmLeftPad :: Int -> a -> [ a ] -> Int -> () 52: 53: {-@ reflect max @-} 54: max :: Int -> Int -> Int 55: x1:GHC.Types.Int -> x2:GHC.Types.Int -> {VV : GHC.Types.Int | VV == max x1 x2 && VV == (if x1 > x2 then x1 else x2)} max GHC.Types.Int x GHC.Types.Int y = {v : GHC.Types.Bool | v <=> x > y} if {v : GHC.Types.Bool | v <=> x > y} x x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 > x2} > y then x else y 56: 57: -- A ghost function only used in the specification 58: {-@ leftPadVal :: n : {Int | False} -> _ -> _ -> _ -> _ @-} The LeftPad Challenge \u00b6 The first of these problems was leftPad 1. Leftpad. Takes a padding character, a string, and a total length, returns the string padded with that length with that character. If length is less than string, does nothing. https://t.co/X8qR8gTZdO \u2014 Hillel (@Hillelogram) April 20, 2018 Implementation \u00b6 First, lets write an idiomatic implementation of leftPad where we will take the liberty of generalizing the padding character to be the input c that is of some (polymorphic) type a the string to be the input xs that is a list of a If the target length n is indeed greater than the input string xs , i.e. if k = n - size xs is positive, we replicate the character c k times and append the result to the left of the input xs . Otherwise, if k is negative, we do nothing, i.e. return the input. 87: {-@ reflect leftPad @-} 88: leftPad :: Int -> a -> [ a ] -> [ a ] 89: x1:GHC.Types.Int -> a -> x3:[a] -> {res : [a] | size res == max x1 (size x3)} leftPad GHC.Types.Int n a c [a] xs 90: | GHC.Types.Bool 0 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = {v : x1:a -> {v : [a] | size v == k && v == replicate k x1 && v == (if 0 == k then [] else : x1 (replicate (k - 1) x1))} | v == replicate k} replicate k c ++ xs 91: | otherwise = xs 92: where 93: GHC.Types.Int k = GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v >= 0 && v == size xs} size xs The code for leftPad is short because we've delegated much of the work to size , replicate and ++ . Here's how we can compute the size of a list: 101: {-@ measure size @-} 102: {-@ size :: [ a ] -> Nat @-} 103: x1:[a] -> {v : GHC.Types.Int | v >= 0 && v == size x1} size [] = 0 104: size ( x : xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0 && v == size xs} size xs and here is the list append function ++ : 110: {-@ reflect ++ @-} 111: {-@ ( ++ ) :: xs : [ a ] -> ys : [ a ] -> 112: {v: [ a ] | size v = size xs + size ys} 113: @-} 114: [] x1:[a] -> x2:[a] -> {v : [a] | size v == size x1 + size x2} ++ [a] ys = ys 115: ( x : xs ) ++ ys = x : ( {v : [a] | size v == size xs + size ys && v == ++ xs ys} xs ++ ys ) and finally the implementation of replicate : 121: {-@ reflect replicate @-} 122: {-@ replicate :: n : Nat -> a -> 123: {v: [ a ] | size v = n} 124: @-} 125: x1:{v : GHC.Types.Int | v >= 0} -> a -> {v : [a] | size v == x1} replicate 0 _ = [] 126: replicate n c = c : x1:{v : GHC.Types.Int | v >= 0} -> a -> {v : [a] | size v == x1} replicate ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) c What shall we Prove? \u00b6 My eyes roll whenever I read the phrase \"proved X (a function, a program) correct \". There is no such thing as \"correct\". There are only \"specifications\" or \"properties\", and proofs that ensures that your code matches those specifications or properties. What specifications shall we verify about our implementation of leftPad ? One might argue that the above code is \"obviously correct\", i.e. the implementation more or less directly matches the informal requirements. One way to formalize this notion of \"obviously correct\" is to verify a specification that directly captures the informal requirements: 151: {-@ obviously :: n : Int -> c : a -> xs : [ a ] -> 152: { leftPad n c xs = if (size xs < n) then (replicate (n - size xs) c ++ xs) else xs } 155: @-} 156: x1:GHC.Types.Int -> x2:a -> x3:[a] -> {VV : () | leftPad x1 x2 x3 == (if size x3 < x1 then ++ (replicate (x1 - size x3) x2) x3 else x3)} obviously _ _ _ = () In the above, the type signature is a specification that says that for all n , c and xs , the value returned by leftPad n c xs is xs when n is too small, and the suitably padded definition otherwise. The code, namely () , is the proof. LH is able to trivially check that leftPad meets the \"obviously correct\" specification, because, well, in this case, the implementation is the specification. (Incidentally, this is also why the Idris solution is terse.) So, if you are happy with the above specification, you can stop reading right here: we're done. Hillel's Specifications \u00b6 However, the verification rodeo is made more interesting by Hillel's Dafny specifications : Size The size of the returned sequence is the larger of n and the size of xs ; Pad-Value Let K = n - size xs . We require that the i -th element of the padded-sequence is c if 0 <= i < K , and is the i - K -th element of xs otherwise. Digression: The Importance of being Decidable \u00b6 LH, like many of the other rodeo entries, uses SMT solvers to automate verification. For example, the leftPad solutions in Dafny and SPARK and F* make heavy use quantified axioms to encode properties of sequences. However, unlike its many SMT-based brethren, LH takes a somewhat fanatical stance: it never uses quantifiers or axioms. We take this rigid position because SMT solvers are only predictable on queries from (certain) decidable logics . Axioms, or more generally, quantified formulas rapidly take SMT solvers out of this \"comfort zone\", causing them to reject valid formulas, run slowly, or even, to run forever . Thus, we have chosen to deliberately avoid the siren song of quantifiers by lashing LH firmly to the steady mast of decidable logics. Reasoning about Sequences \u00b6 Unfortunately, this design choice leaves us with some work: we must develop i.e. state and prove relevant properties about sequences from scratch. Indexing into a Sequence To start, lets define the notion of the i -th element of a sequence (this is pretty much Haskell's list-index operator) 247: {-@ reflect !! @-} 248: {-@ ( !! ) :: xs : [ a ] -> {n: Nat | n < size xs} -> a @-} 249: ( x : _ ) x1:[a] -> {v : GHC.Types.Int | v >= 0 && v < size x1} -> a !! 0 = x 250: ( _ : xs ) !! n = x1:[a] -> {v : GHC.Types.Int | v >= 0 && v < size x1} -> a xs !! ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) Replicated Sequences Next, we verify that every element in a replicate -d sequence is the element being cloned: 259: {-@ thmReplicate :: n : Nat -> c : a -> i : {Nat | i < n} -> 260: { replicate n c !! i == c } 261: @-} 262: x1:{v : GHC.Types.Int | v >= 0} -> x2:a -> x3:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (replicate x1 x2) x3 == x2} thmReplicate {v : GHC.Types.Int | v >= 0} n a c {v : GHC.Types.Int | v >= 0 && v < n} i 263: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 == x2} == 0 = () 264: | otherwise = x1:{v : GHC.Types.Int | v >= 0} -> x2:a -> x3:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (replicate x1 x2) x3 == x2} thmReplicate ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) c ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) LH verifies the above \"proof by induction\": In the base case i == 0 and the value returned is c by the definition of replicate and !! . In the inductive case, replicate n c !! i is equal to replicate (n-1) c !! (i-1) which, by the \"induction hypothesis\" (i.e. by recursively calling the theorem) is c . Concatenating Sequences Finally, we need two properties that relate concatenation and appending, namely, the i -th element of xs ++ ys is: Left the i -th element of xs if 0 <= i < size xs , and Right the i - size xs element of ys otherwise. 286: {-@ thmAppLeft :: xs : [ a ] -> ys : [ a ] -> {i: Nat | i < size xs} -> 287: { (xs ++ ys) !! i == xs !! i } 288: @-} 289: x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && v < size x1} -> {VV : () | !! (++ x1 x2) x3 == !! x1 x3} thmAppLeft ( x : xs ) [a] ys 0 = () 290: thmAppLeft ( x : xs ) ys i = x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && v < size x1} -> {VV : () | !! (++ x1 x2) x3 == !! x1 x3} thmAppLeft xs ys ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 291: 292: {-@ thmAppRight :: xs : [ a ] -> ys : [ a ] -> {i: Nat | size xs <= i} -> 293: { (xs ++ ys) !! i == ys !! (i - size xs) } 294: @-} 295: x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && size x1 <= v} -> {VV : () | !! (++ x1 x2) x3 == !! x2 (x3 - size x1)} thmAppRight [] [a] ys {v : GHC.Types.Int | v >= 0} i = () 296: thmAppRight ( x : xs ) ys i = x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && size x1 <= v} -> {VV : () | !! (++ x1 x2) x3 == !! x2 (x3 - size x1)} thmAppRight xs ys ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) Both of the above properties are proved by induction on i . Proving Hillel's Specifications \u00b6 Finally, we're ready to state and prove Hillel's specifications. Size Specification The size specification is straightforward, in that LH proves it automatically, when type-checking leftPad against the signature: 313: {-@ leftPad :: n : Int -> c : a -> xs : [ a ] -> 314: {res: [ a ] | size res = max n (size xs)} 315: @-} Pad-Value Specification We specify the pad-value property -- i.e. the i -th element equals c or the corresponding element of xs -- by a type signature: 325: {-@ thmLeftPad 326: :: n : _ -> c : _ -> xs : {size xs < n} -> i : {Nat | i < n} -> 327: { leftPad n c xs !! i == leftPadVal n c xs i } 328: @-} 329: 330: {-@ reflect leftPadVal @-} 331: {n : GHC.Types.Int | False} -> a -> [a] -> GHC.Types.Int -> a leftPadVal {n : GHC.Types.Int | False} n a c [a] xs GHC.Types.Int i 332: | {v : GHC.Types.Bool | v <=> i < k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = c 333: | otherwise = {v : [a] | size v >= 0 && len v >= 0 && v == xs} xs !! ( {v : GHC.Types.Int | v == i - k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - k ) 334: where GHC.Types.Int k = {v : GHC.Types.Int | v >= 0 && v == size xs} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - size xs Pad-Value Verification We verify the above property by filling in the implementation of thmLeftPad as: 343: x1:GHC.Types.Int -> x2:a -> x3:{v : [a] | size v < x1} -> x4:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (leftPad x1 x2 x3) x4 == leftPadVal x1 x2 x3 x4} thmLeftPad GHC.Types.Int n a c {v : [a] | size v < n} xs {v : GHC.Types.Int | v >= 0 && v < n} i 344: | {v : GHC.Types.Bool | v <=> i < k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = x1:[a] -> x2:{v : GHC.Types.Int | v >= 0 && v < size cs} -> {v : () | !! (++ cs x1) x2 == !! cs x2} thmAppLeft cs xs i `seq` x1:a -> x2:{v : GHC.Types.Int | v >= 0 && v < k} -> {v : () | !! (replicate k x1) x2 == x1} thmReplicate k c i 345: | otherwise = x1:[a] -> x2:{v : GHC.Types.Int | v >= 0 && size cs <= v} -> {v : () | !! (++ cs x1) x2 == !! x1 (x2 - size cs)} thmAppRight cs xs i 346: where 347: GHC.Types.Int k = GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v >= 0 && v == size xs} size xs 348: {v : [a] | size v == k && v == replicate k c && v == (if 0 == k then [] else : c (replicate (k - 1) c))} cs = {v : x1:a -> {v : [a] | size v == k && v == replicate k x1 && v == (if 0 == k then [] else : x1 (replicate (k - 1) x1))} | v == replicate k} replicate k c The \"proof\" -- in quotes because its just a Haskell function -- simply combines the replicate- and concatenate-left theorems if i is in the \"pad\", and the concatenate-right theorem, otherwise. Conclusions \u00b6 That concludes part I of the rodeo. What did I learn from this exercise? Even apparently simple functions like leftPad can have many different specifications; there is no necessarily \"best\" specification as different specs make different assumptions about what is \"trusted\", and more importantly, though we didn't see it here, ultimately a spec is a particular view into how a piece of code behaves and we may want different views depending on the context where we want to use the given piece of code. The leftPad exercise illustrates a fundamental problem with Floyd-Hoare style \"modular\" verification, where pre- and post-conditions (or contracts or refinement types or ...) are used to modularly \"abstract\" functions i.e. are used to describe the behavior of a function at a call-site. As the above exercise shows, we often need properties connecting the behavior of different functions, e.g. append ( ++ ), indexing ( !! ). In these cases, the only meaningful specification for the underlying function is its implementation . Finally, the above proofs are all over user-defined recursive functions which this was not even possible before refinement reflection , i.e till about a year ago. I'm also quite pleased by how logical evaluation makes these proofs quite short, letting LH verify expressive specifications while steering clear of the siren song of quantifiers.","title":"The Hillelogram Verifier Rodeo I (LeftPad)"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#the-leftpad-challenge","text":"The first of these problems was leftPad 1. Leftpad. Takes a padding character, a string, and a total length, returns the string padded with that length with that character. If length is less than string, does nothing. https://t.co/X8qR8gTZdO \u2014 Hillel (@Hillelogram) April 20, 2018","title":"The LeftPad Challenge"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#implementation","text":"First, lets write an idiomatic implementation of leftPad where we will take the liberty of generalizing the padding character to be the input c that is of some (polymorphic) type a the string to be the input xs that is a list of a If the target length n is indeed greater than the input string xs , i.e. if k = n - size xs is positive, we replicate the character c k times and append the result to the left of the input xs . Otherwise, if k is negative, we do nothing, i.e. return the input. 87: {-@ reflect leftPad @-} 88: leftPad :: Int -> a -> [ a ] -> [ a ] 89: x1:GHC.Types.Int -> a -> x3:[a] -> {res : [a] | size res == max x1 (size x3)} leftPad GHC.Types.Int n a c [a] xs 90: | GHC.Types.Bool 0 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = {v : x1:a -> {v : [a] | size v == k && v == replicate k x1 && v == (if 0 == k then [] else : x1 (replicate (k - 1) x1))} | v == replicate k} replicate k c ++ xs 91: | otherwise = xs 92: where 93: GHC.Types.Int k = GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v >= 0 && v == size xs} size xs The code for leftPad is short because we've delegated much of the work to size , replicate and ++ . Here's how we can compute the size of a list: 101: {-@ measure size @-} 102: {-@ size :: [ a ] -> Nat @-} 103: x1:[a] -> {v : GHC.Types.Int | v >= 0 && v == size x1} size [] = 0 104: size ( x : xs ) = {v : GHC.Types.Int | v == (1 : int)} 1 x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 + x2} + {v : GHC.Types.Int | v >= 0 && v == size xs} size xs and here is the list append function ++ : 110: {-@ reflect ++ @-} 111: {-@ ( ++ ) :: xs : [ a ] -> ys : [ a ] -> 112: {v: [ a ] | size v = size xs + size ys} 113: @-} 114: [] x1:[a] -> x2:[a] -> {v : [a] | size v == size x1 + size x2} ++ [a] ys = ys 115: ( x : xs ) ++ ys = x : ( {v : [a] | size v == size xs + size ys && v == ++ xs ys} xs ++ ys ) and finally the implementation of replicate : 121: {-@ reflect replicate @-} 122: {-@ replicate :: n : Nat -> a -> 123: {v: [ a ] | size v = n} 124: @-} 125: x1:{v : GHC.Types.Int | v >= 0} -> a -> {v : [a] | size v == x1} replicate 0 _ = [] 126: replicate n c = c : x1:{v : GHC.Types.Int | v >= 0} -> a -> {v : [a] | size v == x1} replicate ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) c","title":"Implementation"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#what-shall-we-prove","text":"My eyes roll whenever I read the phrase \"proved X (a function, a program) correct \". There is no such thing as \"correct\". There are only \"specifications\" or \"properties\", and proofs that ensures that your code matches those specifications or properties. What specifications shall we verify about our implementation of leftPad ? One might argue that the above code is \"obviously correct\", i.e. the implementation more or less directly matches the informal requirements. One way to formalize this notion of \"obviously correct\" is to verify a specification that directly captures the informal requirements: 151: {-@ obviously :: n : Int -> c : a -> xs : [ a ] -> 152: { leftPad n c xs = if (size xs < n) then (replicate (n - size xs) c ++ xs) else xs } 155: @-} 156: x1:GHC.Types.Int -> x2:a -> x3:[a] -> {VV : () | leftPad x1 x2 x3 == (if size x3 < x1 then ++ (replicate (x1 - size x3) x2) x3 else x3)} obviously _ _ _ = () In the above, the type signature is a specification that says that for all n , c and xs , the value returned by leftPad n c xs is xs when n is too small, and the suitably padded definition otherwise. The code, namely () , is the proof. LH is able to trivially check that leftPad meets the \"obviously correct\" specification, because, well, in this case, the implementation is the specification. (Incidentally, this is also why the Idris solution is terse.) So, if you are happy with the above specification, you can stop reading right here: we're done.","title":"What shall we Prove?"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#hillels-specifications","text":"However, the verification rodeo is made more interesting by Hillel's Dafny specifications : Size The size of the returned sequence is the larger of n and the size of xs ; Pad-Value Let K = n - size xs . We require that the i -th element of the padded-sequence is c if 0 <= i < K , and is the i - K -th element of xs otherwise.","title":"Hillel's Specifications"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#digression-the-importance-of-being-decidable","text":"LH, like many of the other rodeo entries, uses SMT solvers to automate verification. For example, the leftPad solutions in Dafny and SPARK and F* make heavy use quantified axioms to encode properties of sequences. However, unlike its many SMT-based brethren, LH takes a somewhat fanatical stance: it never uses quantifiers or axioms. We take this rigid position because SMT solvers are only predictable on queries from (certain) decidable logics . Axioms, or more generally, quantified formulas rapidly take SMT solvers out of this \"comfort zone\", causing them to reject valid formulas, run slowly, or even, to run forever . Thus, we have chosen to deliberately avoid the siren song of quantifiers by lashing LH firmly to the steady mast of decidable logics.","title":"Digression: The Importance of being Decidable"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#reasoning-about-sequences","text":"Unfortunately, this design choice leaves us with some work: we must develop i.e. state and prove relevant properties about sequences from scratch. Indexing into a Sequence To start, lets define the notion of the i -th element of a sequence (this is pretty much Haskell's list-index operator) 247: {-@ reflect !! @-} 248: {-@ ( !! ) :: xs : [ a ] -> {n: Nat | n < size xs} -> a @-} 249: ( x : _ ) x1:[a] -> {v : GHC.Types.Int | v >= 0 && v < size x1} -> a !! 0 = x 250: ( _ : xs ) !! n = x1:[a] -> {v : GHC.Types.Int | v >= 0 && v < size x1} -> a xs !! ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) Replicated Sequences Next, we verify that every element in a replicate -d sequence is the element being cloned: 259: {-@ thmReplicate :: n : Nat -> c : a -> i : {Nat | i < n} -> 260: { replicate n c !! i == c } 261: @-} 262: x1:{v : GHC.Types.Int | v >= 0} -> x2:a -> x3:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (replicate x1 x2) x3 == x2} thmReplicate {v : GHC.Types.Int | v >= 0} n a c {v : GHC.Types.Int | v >= 0 && v < n} i 263: | GHC.Types.Bool i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 == x2} == 0 = () 264: | otherwise = x1:{v : GHC.Types.Int | v >= 0} -> x2:a -> x3:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (replicate x1 x2) x3 == x2} thmReplicate ( GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) c ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) LH verifies the above \"proof by induction\": In the base case i == 0 and the value returned is c by the definition of replicate and !! . In the inductive case, replicate n c !! i is equal to replicate (n-1) c !! (i-1) which, by the \"induction hypothesis\" (i.e. by recursively calling the theorem) is c . Concatenating Sequences Finally, we need two properties that relate concatenation and appending, namely, the i -th element of xs ++ ys is: Left the i -th element of xs if 0 <= i < size xs , and Right the i - size xs element of ys otherwise. 286: {-@ thmAppLeft :: xs : [ a ] -> ys : [ a ] -> {i: Nat | i < size xs} -> 287: { (xs ++ ys) !! i == xs !! i } 288: @-} 289: x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && v < size x1} -> {VV : () | !! (++ x1 x2) x3 == !! x1 x3} thmAppLeft ( x : xs ) [a] ys 0 = () 290: thmAppLeft ( x : xs ) ys i = x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && v < size x1} -> {VV : () | !! (++ x1 x2) x3 == !! x1 x3} thmAppLeft xs ys ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) 291: 292: {-@ thmAppRight :: xs : [ a ] -> ys : [ a ] -> {i: Nat | size xs <= i} -> 293: { (xs ++ ys) !! i == ys !! (i - size xs) } 294: @-} 295: x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && size x1 <= v} -> {VV : () | !! (++ x1 x2) x3 == !! x2 (x3 - size x1)} thmAppRight [] [a] ys {v : GHC.Types.Int | v >= 0} i = () 296: thmAppRight ( x : xs ) ys i = x1:[a] -> x2:[a] -> x3:{v : GHC.Types.Int | v >= 0 && size x1 <= v} -> {VV : () | !! (++ x1 x2) x3 == !! x2 (x3 - size x1)} thmAppRight xs ys ( GHC.Types.Int i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - 1 ) Both of the above properties are proved by induction on i .","title":"Reasoning about Sequences"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#proving-hillels-specifications","text":"Finally, we're ready to state and prove Hillel's specifications. Size Specification The size specification is straightforward, in that LH proves it automatically, when type-checking leftPad against the signature: 313: {-@ leftPad :: n : Int -> c : a -> xs : [ a ] -> 314: {res: [ a ] | size res = max n (size xs)} 315: @-} Pad-Value Specification We specify the pad-value property -- i.e. the i -th element equals c or the corresponding element of xs -- by a type signature: 325: {-@ thmLeftPad 326: :: n : _ -> c : _ -> xs : {size xs < n} -> i : {Nat | i < n} -> 327: { leftPad n c xs !! i == leftPadVal n c xs i } 328: @-} 329: 330: {-@ reflect leftPadVal @-} 331: {n : GHC.Types.Int | False} -> a -> [a] -> GHC.Types.Int -> a leftPadVal {n : GHC.Types.Int | False} n a c [a] xs GHC.Types.Int i 332: | {v : GHC.Types.Bool | v <=> i < k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = c 333: | otherwise = {v : [a] | size v >= 0 && len v >= 0 && v == xs} xs !! ( {v : GHC.Types.Int | v == i - k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - k ) 334: where GHC.Types.Int k = {v : GHC.Types.Int | v >= 0 && v == size xs} n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - size xs Pad-Value Verification We verify the above property by filling in the implementation of thmLeftPad as: 343: x1:GHC.Types.Int -> x2:a -> x3:{v : [a] | size v < x1} -> x4:{v : GHC.Types.Int | v >= 0 && v < x1} -> {VV : () | !! (leftPad x1 x2 x3) x4 == leftPadVal x1 x2 x3 x4} thmLeftPad GHC.Types.Int n a c {v : [a] | size v < n} xs {v : GHC.Types.Int | v >= 0 && v < n} i 344: | {v : GHC.Types.Bool | v <=> i < k} i x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Bool | v <=> x1 < x2} < k = x1:[a] -> x2:{v : GHC.Types.Int | v >= 0 && v < size cs} -> {v : () | !! (++ cs x1) x2 == !! cs x2} thmAppLeft cs xs i `seq` x1:a -> x2:{v : GHC.Types.Int | v >= 0 && v < k} -> {v : () | !! (replicate k x1) x2 == x1} thmReplicate k c i 345: | otherwise = x1:[a] -> x2:{v : GHC.Types.Int | v >= 0 && size cs <= v} -> {v : () | !! (++ cs x1) x2 == !! x1 (x2 - size cs)} thmAppRight cs xs i 346: where 347: GHC.Types.Int k = GHC.Types.Int n x1:GHC.Types.Int -> x2:GHC.Types.Int -> {v : GHC.Types.Int | v == x1 - x2} - {v : GHC.Types.Int | v >= 0 && v == size xs} size xs 348: {v : [a] | size v == k && v == replicate k c && v == (if 0 == k then [] else : c (replicate (k - 1) c))} cs = {v : x1:a -> {v : [a] | size v == k && v == replicate k x1 && v == (if 0 == k then [] else : x1 (replicate (k - 1) x1))} | v == replicate k} replicate k c The \"proof\" -- in quotes because its just a Haskell function -- simply combines the replicate- and concatenate-left theorems if i is in the \"pad\", and the concatenate-right theorem, otherwise.","title":"Proving Hillel's Specifications"},{"location":"blogposts/2018-05-17-hillel-verifier-rodeo-I-leftpad.lhs/#conclusions","text":"That concludes part I of the rodeo. What did I learn from this exercise? Even apparently simple functions like leftPad can have many different specifications; there is no necessarily \"best\" specification as different specs make different assumptions about what is \"trusted\", and more importantly, though we didn't see it here, ultimately a spec is a particular view into how a piece of code behaves and we may want different views depending on the context where we want to use the given piece of code. The leftPad exercise illustrates a fundamental problem with Floyd-Hoare style \"modular\" verification, where pre- and post-conditions (or contracts or refinement types or ...) are used to modularly \"abstract\" functions i.e. are used to describe the behavior of a function at a call-site. As the above exercise shows, we often need properties connecting the behavior of different functions, e.g. append ( ++ ), indexing ( !! ). In these cases, the only meaningful specification for the underlying function is its implementation . Finally, the above proofs are all over user-defined recursive functions which this was not even possible before refinement reflection , i.e till about a year ago. I'm also quite pleased by how logical evaluation makes these proofs quite short, letting LH verify expressive specifications while steering clear of the siren song of quantifiers.","title":"Conclusions"},{"location":"blogposts/2019-10-20-why-types.lhs/","text":"Several folks who are experts in the program verification literature have asked me some variant of the following question: How are Liquid/Refinement types different from Floyd-Hoare logics ? This question always reminds me of Yannis Smaragdakis' clever limerick: No idea is too obvious or dreary, If appropriately expressed in type theory, It's a research advance, That no one understands, But they are all too impressed to be leery. That is, the above question can be rephrased as: why bother with the hassle of encoding properties in types when good old-fashioned assertions , pre - and post -conditions would do? Is it just a marketing gimmick to make readers too impressed to be leery? The Problem: Quantifiers \u00b6 The main algorithmic problem with classical Floyd-Hoare logic is that to do useful things, you need to use universally quantified logical formulas inside invariants, pre- and post-conditions. Verification then proceeds by asking SMT solvers to check verification conditions (VCs) over these quantified formulas. While SMT solvers are marvelous technological artifacts, and I bow to no one in my admiration of them, in reality, they work best on formulas from a narrowly defined set of decidable theories . In particular, they are notoriously (and justifiably!) fickle when quizzed on VCs with quantifiers. Briefly, this is because even if the solver \"knows\" the universally quantified fact: forall x. P(x) the solver doesn't know which particular terms e1 , e2 or e3 to instantiate the fact at. That is, the solver doesn't know which P(e1) or P(e2) or P(e3) it should work with to prove some given goal. At best, it can make some educated guesses, or use hints from the user, but these heuristics can turn out to be quite brittle as the underlying logics are undecidable in general. To make verification predictable, we really want to ensure that the VCs remain decidable, and to do so, we must steer clear of the precipice of quantification. The Solution: Types \u00b6 The great thing about types, as any devotee will tell you, is that the compose . Regrettably, that statement is only comprehensible to believers. I prefer to think of it differently: types decompose . To be precise: Types decompose quantified assertions into quantifier-free refinements. Let me make my point with some examples that show what verification looks like when using Refinement Types (as implemented in LiquidHaskell ) vs Floyd-Hoare style contracts (as implemented in Dafny ). The goal of this exercise is to illustrate how types help with verification, not to compare the tools LH and Dafny. In particular, Dafny could profit from refinement types, and LH could benefit from the many clever ideas embodied within Dafny. Example 1: Properties of Data \u00b6 Consider the following standard definition of a List datatype in Dafny (left) and LH (right). A list data type in Dafny (L) and LiquidHaskell (R) (You can see the full definitions for Dafny and LiquidHaskell .) Accessing a list \u00b6 The two descriptions are more or less the same except for some minor issues of concrete syntax. However, next consider the respective implementations of a function to access the ith element of a List . We also pass in a def ault value returned when the index i is invalid . Accessing the i-th element of a list in Dafny(L) and LiquidHaskell(R) It is (usually) silly to access lists in this fashion. I use this example merely to illustrate the common case of defining a container structure (here, List ) and then accessing its contents (here, ith ). As such, we'd like to specify that the value returned by the ith element is indeed in the container or is the def ault. Floyd-Hoare Logic With classical Floyd-Hoare logic, as shown in the Dafny listing on the left, we must spell out the specification quite explicitly. The programmer must write an elements function that describes the set of values in the container, and then the post-condition of ith states that the res is either in that set or the default. While this specification seems simple enough, we are already on dicey terrain: how are we to encode the semantics of the user-defined function elements to the SMT solver? In the classical Floyd-Hoare approach, we must use a quantified invariant of the form: elements(Nil) = empty && forall h t :: elements(Cons(h, t)) = {h} + elements(t) Thanks to the ingenuity of Greg Nelson who invented the notion of triggers and of Rustan Leino and many others, who devised ingenious heuristics for using them, Dafny handles the quantifier calmly to verify the above specification for ith . However, we are not always so fortunate: it frightfully easy to run into quantifier-related problems with user-defined functions, as we will see in due course. Liquid/Refinement Types In contrast, the liquid/refinement version is quite spare: there is no extra specification beyond the code. Surely there must be some mistake? Look again: the type signature says everything we need: If you call ith with a list of a values and a default a value then you get an a value\". That is parametricity removes the overhead of using an explicit elements function. Building a list \u00b6 Next, lets extend our example to illustrate the common situation where we want some invariant to be true for all the values in a container. To this end, let us write a function mkList that builds a container with values k+1 ,..., k+n and then test that when k is non-negative, any arbitrarily chosen value from the container is indeed strictly positive. Building and accessing a list in Dafny (L) and LiquidHaskell(R) The code in Dafny and LH is more or less the same, except for one crucial difference. Floyd-Hoare Logic Recall that the specification for ith(pos, i, 1) states that the returned value is some element of the container (or 1 ). Thus, to verify the assert in testPosN using classical Floyd-Hoare logic, we need a way to specify that every element in pos is indeed strictly positive. With classical program logics, the only way to do so is to use a universally quantified post-condition, highlighted in blue: \" for all v if v is in the elements of the res ult, then v is greater than k \" Liquid/Refinement Types Regardless of my personal feelings about quantifiers, we can agree that the version on the right is simpler as types make it unnecessary to mention elements or forall . Instead, LH infers mkList :: Int -> k:Int -> List {v:Int | k < v} That is, that the output type of mkList is a list of values v that are all greater than k . The scary forall has been replaced by the friendly type constructor List . In other words, types allow us to decompose the monolithic universally quantified invariant into: a quantifier-free refinement k < v , and a type constructor that implicitly \"quantifies\" over the container's elements. Lesson: Decomposition Enables Inference \u00b6 Am I cheating? After all, what prevents Dafny from inferring the same post-condition as LH? Once again, quantifiers are the villain. There have been many decades worth of papers on the topic of inferring quantified invariants, but save some nicely circumscribed use-cases these methods turn out to be rather difficult to get working efficiently and predictably enough to be practical. In contrast, once the quantifiers are decomposed away, even an extremely basic approach called Monomial Predicate Abstraction , or more snappily, Houdini , suffices to infer the above liquid type. Example 2: Properties of Structures \u00b6 Recall that when discussing the user-defined elements function above, I had issued some dark warnings about quantifier-related problems that arise from user-defined functions. Allow me to explain with another simple example, that continues with the List datatype defined above. (You can see the full definitions for Dafny and LiquidHaskell .) Specifying a size Function \u00b6 Lets write the usual recursive function that computes the size of a list. The definitions are mostly identical, except for the green measure highlight that we will discuss below. A function defining the size of a list in Dafny (L) and LiquidHaskell (R) Floyd-Hoare Logic SMT solvers are restricted to a set of ground theories and hence, do not \"natively\" understand user-defined functions. Instead, the verifer must teach the SMT solver how to reason about formulas (VCs) containing uses of user-defined functions like size . In the classical Floyd-Hoare approach, this is done by converting the definition of size into a universally quantified axiom like: size Nil == 0 && forall h, t :: size (Cons h t) = 1 + size t A quantifier! By the pricking of my thumbs, something wicked this way comes... Liquid/Refinement Types With a more type-centric view, we can think of the recursive function size as a way to decorate or refine the types of the data constructors . So, when you write the definition in the green box above, specifically when you add the measure annotation, the function is converted to strengthened versions for the types of the constructors Nil and Cons , so its as if we had defined the list type as two constructor functions data List a where Cons :: h:a -> t:List a -> {v:List a | size v == 1 + size t} Nil :: {v:List a | size v == 0} That is, the bodies of the measures get translated to refinements on the output types of the corresponding constructors. After this, the SMT solver \"knows nothing\" about the semantics of size , except that it is a function. In logic-speak, size is uninterpreted in the refinement, and there are no quantified axioms. That is, we choose to keep SMT solver blissfully ignorant about the semantics of size . How could this possibly be a good thing? Verifying the size of a List \u00b6 Next, lets see what happens when we write a simple test that builds a small list with two elements and assert s that the lists size is indeed 2 : Verifying the size of a list in Dafny (L) and LiquidHaskell (R) Floyd-Hoare Logic To get Dafny to verifier to sign off on the assert (size(pos) == 2) we have to add a mysterious extra assertion that checks the size of the intermediate value Cons (1, Nil) . (Without it, verification fails.) Huh? Pesky quantifiers. The SMT solver doesn't know where to instantiate the size axom. In this carefully chosen, but nevertheless simple situation, Dafny's instantiation heuristics come up short. I had to help them along by guessing this intermediate assertion, which effectively \"adds\" the fact that the size of the intermediate list is 1, thereby letting the SMT solver prove the second assertion. Liquid/Refinement Types In contrast, with types, the solver is able to verify the code without batting an eyelid. But how could it possibly do so even though we kept it ignorant of the semantics of size ? Because types decompose reasoning. In particular, here, the measure and constructor trick lets us factor reasoning about size into the type system . In particular, LH internally views the code for test in A-Normal Form which is a fancy way of saying, by introducing temporary variables for all sub-expressions: test x1 = let tmp0 = Nil tmp1 = Cons x1 tmp0 pos = Cons 0 tmp1 in assert (size pos == 2) And now, just by the rules of type checking, and applying the types of the constructors, it deduces that: tmp0 :: {size tmp0 == 0} tmp1 :: {size tmp1 == 1 + size tmp0} pos :: {size pos == 1 + size tmp1} which lets the SMT solver prove that size pos == 2 without requiring any axiomatic description of size . This simple measure method goes a very long way in specifying and verifying lots of properties . Lesson: Decomposition Enables Type-Directed Instantiation \u00b6 I'd like to emphasize again that this trick was enabled by the type-centric view: encode the function semantics in data constructors , and let the type checking (or VC generation) do the instantiation . It could easily by incorporated inside and work together with axioms in Floyd-Hoare based systems like Dafny. Of course, this approach is limited to a restricted class of functions -- roughly, case-splits over a single data type's constructors -- but we can generalize the method quite a bit using the idea of logical evaluation . Summary \u00b6 To sum up, we saw two examples where taking a type-centric view made verification more ergonomic , essentially by factoring reasoning about quantifiers into the type system. In the first case, when reasoning about data in containers, the polymorphic type constructor List provided an natural way to reason about the fact that all elements in a container satisfied some property. In the second case, when reasoning about the structure of the container via a recursive function, the types of the data constructors allowed us to factor the instantiation of properties of size at places where the list was constructed (and dually, not shown, destructed) without burdening the SMT solver with any axioms and the pressure of figuring out where to instantiate them. To conclude I'd like to reiterate that the point is not that types and program logics are at odds with each other. Instead, the lesson is that while classical Floyd-Hoare logic associates invariants with program positions, Liquid/Refinement types are a generalization that additionally let you associate invariants with type positions, which lets us exploit types as a program logic, and syntax-directed typing rules as a decision procedure, that, in many common situations, simplify verification by decomposing proof obligations (VCs) into simple, quantifier-free, SMT-friendly formulas. As you might imagine, the benefits are magnified when working with higher-order functions, e.g. map -ing or fold -ing over containers... Acknowledgments \u00b6 Huge thanks to Rustan Leino , Nadia Polikarpova , Daniel Ricketts , Hillel Wayne , and Zizz Vonnegut for patiently answering my many questions about Dafny!","title":"Liquid Types vs. Floyd-Hoare Logic"},{"location":"blogposts/2019-10-20-why-types.lhs/#the-problem-quantifiers","text":"The main algorithmic problem with classical Floyd-Hoare logic is that to do useful things, you need to use universally quantified logical formulas inside invariants, pre- and post-conditions. Verification then proceeds by asking SMT solvers to check verification conditions (VCs) over these quantified formulas. While SMT solvers are marvelous technological artifacts, and I bow to no one in my admiration of them, in reality, they work best on formulas from a narrowly defined set of decidable theories . In particular, they are notoriously (and justifiably!) fickle when quizzed on VCs with quantifiers. Briefly, this is because even if the solver \"knows\" the universally quantified fact: forall x. P(x) the solver doesn't know which particular terms e1 , e2 or e3 to instantiate the fact at. That is, the solver doesn't know which P(e1) or P(e2) or P(e3) it should work with to prove some given goal. At best, it can make some educated guesses, or use hints from the user, but these heuristics can turn out to be quite brittle as the underlying logics are undecidable in general. To make verification predictable, we really want to ensure that the VCs remain decidable, and to do so, we must steer clear of the precipice of quantification.","title":"The Problem: Quantifiers"},{"location":"blogposts/2019-10-20-why-types.lhs/#the-solution-types","text":"The great thing about types, as any devotee will tell you, is that the compose . Regrettably, that statement is only comprehensible to believers. I prefer to think of it differently: types decompose . To be precise: Types decompose quantified assertions into quantifier-free refinements. Let me make my point with some examples that show what verification looks like when using Refinement Types (as implemented in LiquidHaskell ) vs Floyd-Hoare style contracts (as implemented in Dafny ). The goal of this exercise is to illustrate how types help with verification, not to compare the tools LH and Dafny. In particular, Dafny could profit from refinement types, and LH could benefit from the many clever ideas embodied within Dafny.","title":"The Solution: Types"},{"location":"blogposts/2019-10-20-why-types.lhs/#example-1-properties-of-data","text":"Consider the following standard definition of a List datatype in Dafny (left) and LH (right). A list data type in Dafny (L) and LiquidHaskell (R) (You can see the full definitions for Dafny and LiquidHaskell .)","title":"Example 1: Properties of Data"},{"location":"blogposts/2019-10-20-why-types.lhs/#accessing-a-list","text":"The two descriptions are more or less the same except for some minor issues of concrete syntax. However, next consider the respective implementations of a function to access the ith element of a List . We also pass in a def ault value returned when the index i is invalid . Accessing the i-th element of a list in Dafny(L) and LiquidHaskell(R) It is (usually) silly to access lists in this fashion. I use this example merely to illustrate the common case of defining a container structure (here, List ) and then accessing its contents (here, ith ). As such, we'd like to specify that the value returned by the ith element is indeed in the container or is the def ault. Floyd-Hoare Logic With classical Floyd-Hoare logic, as shown in the Dafny listing on the left, we must spell out the specification quite explicitly. The programmer must write an elements function that describes the set of values in the container, and then the post-condition of ith states that the res is either in that set or the default. While this specification seems simple enough, we are already on dicey terrain: how are we to encode the semantics of the user-defined function elements to the SMT solver? In the classical Floyd-Hoare approach, we must use a quantified invariant of the form: elements(Nil) = empty && forall h t :: elements(Cons(h, t)) = {h} + elements(t) Thanks to the ingenuity of Greg Nelson who invented the notion of triggers and of Rustan Leino and many others, who devised ingenious heuristics for using them, Dafny handles the quantifier calmly to verify the above specification for ith . However, we are not always so fortunate: it frightfully easy to run into quantifier-related problems with user-defined functions, as we will see in due course. Liquid/Refinement Types In contrast, the liquid/refinement version is quite spare: there is no extra specification beyond the code. Surely there must be some mistake? Look again: the type signature says everything we need: If you call ith with a list of a values and a default a value then you get an a value\". That is parametricity removes the overhead of using an explicit elements function.","title":"Accessing a list"},{"location":"blogposts/2019-10-20-why-types.lhs/#building-a-list","text":"Next, lets extend our example to illustrate the common situation where we want some invariant to be true for all the values in a container. To this end, let us write a function mkList that builds a container with values k+1 ,..., k+n and then test that when k is non-negative, any arbitrarily chosen value from the container is indeed strictly positive. Building and accessing a list in Dafny (L) and LiquidHaskell(R) The code in Dafny and LH is more or less the same, except for one crucial difference. Floyd-Hoare Logic Recall that the specification for ith(pos, i, 1) states that the returned value is some element of the container (or 1 ). Thus, to verify the assert in testPosN using classical Floyd-Hoare logic, we need a way to specify that every element in pos is indeed strictly positive. With classical program logics, the only way to do so is to use a universally quantified post-condition, highlighted in blue: \" for all v if v is in the elements of the res ult, then v is greater than k \" Liquid/Refinement Types Regardless of my personal feelings about quantifiers, we can agree that the version on the right is simpler as types make it unnecessary to mention elements or forall . Instead, LH infers mkList :: Int -> k:Int -> List {v:Int | k < v} That is, that the output type of mkList is a list of values v that are all greater than k . The scary forall has been replaced by the friendly type constructor List . In other words, types allow us to decompose the monolithic universally quantified invariant into: a quantifier-free refinement k < v , and a type constructor that implicitly \"quantifies\" over the container's elements.","title":"Building a list"},{"location":"blogposts/2019-10-20-why-types.lhs/#lesson-decomposition-enables-inference","text":"Am I cheating? After all, what prevents Dafny from inferring the same post-condition as LH? Once again, quantifiers are the villain. There have been many decades worth of papers on the topic of inferring quantified invariants, but save some nicely circumscribed use-cases these methods turn out to be rather difficult to get working efficiently and predictably enough to be practical. In contrast, once the quantifiers are decomposed away, even an extremely basic approach called Monomial Predicate Abstraction , or more snappily, Houdini , suffices to infer the above liquid type.","title":"Lesson: Decomposition Enables Inference"},{"location":"blogposts/2019-10-20-why-types.lhs/#example-2-properties-of-structures","text":"Recall that when discussing the user-defined elements function above, I had issued some dark warnings about quantifier-related problems that arise from user-defined functions. Allow me to explain with another simple example, that continues with the List datatype defined above. (You can see the full definitions for Dafny and LiquidHaskell .)","title":"Example 2: Properties of Structures"},{"location":"blogposts/2019-10-20-why-types.lhs/#specifying-a-size-function","text":"Lets write the usual recursive function that computes the size of a list. The definitions are mostly identical, except for the green measure highlight that we will discuss below. A function defining the size of a list in Dafny (L) and LiquidHaskell (R) Floyd-Hoare Logic SMT solvers are restricted to a set of ground theories and hence, do not \"natively\" understand user-defined functions. Instead, the verifer must teach the SMT solver how to reason about formulas (VCs) containing uses of user-defined functions like size . In the classical Floyd-Hoare approach, this is done by converting the definition of size into a universally quantified axiom like: size Nil == 0 && forall h, t :: size (Cons h t) = 1 + size t A quantifier! By the pricking of my thumbs, something wicked this way comes... Liquid/Refinement Types With a more type-centric view, we can think of the recursive function size as a way to decorate or refine the types of the data constructors . So, when you write the definition in the green box above, specifically when you add the measure annotation, the function is converted to strengthened versions for the types of the constructors Nil and Cons , so its as if we had defined the list type as two constructor functions data List a where Cons :: h:a -> t:List a -> {v:List a | size v == 1 + size t} Nil :: {v:List a | size v == 0} That is, the bodies of the measures get translated to refinements on the output types of the corresponding constructors. After this, the SMT solver \"knows nothing\" about the semantics of size , except that it is a function. In logic-speak, size is uninterpreted in the refinement, and there are no quantified axioms. That is, we choose to keep SMT solver blissfully ignorant about the semantics of size . How could this possibly be a good thing?","title":"Specifying a size Function"},{"location":"blogposts/2019-10-20-why-types.lhs/#verifying-the-size-of-a-list","text":"Next, lets see what happens when we write a simple test that builds a small list with two elements and assert s that the lists size is indeed 2 : Verifying the size of a list in Dafny (L) and LiquidHaskell (R) Floyd-Hoare Logic To get Dafny to verifier to sign off on the assert (size(pos) == 2) we have to add a mysterious extra assertion that checks the size of the intermediate value Cons (1, Nil) . (Without it, verification fails.) Huh? Pesky quantifiers. The SMT solver doesn't know where to instantiate the size axom. In this carefully chosen, but nevertheless simple situation, Dafny's instantiation heuristics come up short. I had to help them along by guessing this intermediate assertion, which effectively \"adds\" the fact that the size of the intermediate list is 1, thereby letting the SMT solver prove the second assertion. Liquid/Refinement Types In contrast, with types, the solver is able to verify the code without batting an eyelid. But how could it possibly do so even though we kept it ignorant of the semantics of size ? Because types decompose reasoning. In particular, here, the measure and constructor trick lets us factor reasoning about size into the type system . In particular, LH internally views the code for test in A-Normal Form which is a fancy way of saying, by introducing temporary variables for all sub-expressions: test x1 = let tmp0 = Nil tmp1 = Cons x1 tmp0 pos = Cons 0 tmp1 in assert (size pos == 2) And now, just by the rules of type checking, and applying the types of the constructors, it deduces that: tmp0 :: {size tmp0 == 0} tmp1 :: {size tmp1 == 1 + size tmp0} pos :: {size pos == 1 + size tmp1} which lets the SMT solver prove that size pos == 2 without requiring any axiomatic description of size . This simple measure method goes a very long way in specifying and verifying lots of properties .","title":"Verifying the size of a List"},{"location":"blogposts/2019-10-20-why-types.lhs/#lesson-decomposition-enables-type-directed-instantiation","text":"I'd like to emphasize again that this trick was enabled by the type-centric view: encode the function semantics in data constructors , and let the type checking (or VC generation) do the instantiation . It could easily by incorporated inside and work together with axioms in Floyd-Hoare based systems like Dafny. Of course, this approach is limited to a restricted class of functions -- roughly, case-splits over a single data type's constructors -- but we can generalize the method quite a bit using the idea of logical evaluation .","title":"Lesson: Decomposition Enables Type-Directed Instantiation"},{"location":"blogposts/2019-10-20-why-types.lhs/#summary","text":"To sum up, we saw two examples where taking a type-centric view made verification more ergonomic , essentially by factoring reasoning about quantifiers into the type system. In the first case, when reasoning about data in containers, the polymorphic type constructor List provided an natural way to reason about the fact that all elements in a container satisfied some property. In the second case, when reasoning about the structure of the container via a recursive function, the types of the data constructors allowed us to factor the instantiation of properties of size at places where the list was constructed (and dually, not shown, destructed) without burdening the SMT solver with any axioms and the pressure of figuring out where to instantiate them. To conclude I'd like to reiterate that the point is not that types and program logics are at odds with each other. Instead, the lesson is that while classical Floyd-Hoare logic associates invariants with program positions, Liquid/Refinement types are a generalization that additionally let you associate invariants with type positions, which lets us exploit types as a program logic, and syntax-directed typing rules as a decision procedure, that, in many common situations, simplify verification by decomposing proof obligations (VCs) into simple, quantifier-free, SMT-friendly formulas. As you might imagine, the benefits are magnified when working with higher-order functions, e.g. map -ing or fold -ing over containers...","title":"Summary"},{"location":"blogposts/2019-10-20-why-types.lhs/#acknowledgments","text":"Huge thanks to Rustan Leino , Nadia Polikarpova , Daniel Ricketts , Hillel Wayne , and Zizz Vonnegut for patiently answering my many questions about Dafny!","title":"Acknowledgments"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/","text":"Polymorphism plays a vital role in automating verification in LH. However, thanks to its ubiquity, we often take it for granted, and it can be quite baffling to figure out why verification fails with monomorphic signatures. Let me explain why, using a simple example that has puzzled me and other users several times. 22: 23: module PolymorphicPerplexion where A Type for Ordered Lists \u00b6 Previously we have seen how you can use LH to define a type of lists whose values are in increasing (ok, non-decreasing!) order. First, we define an IncList a type, with Emp (\"empty\") and :< (\"cons\") constructors. 38: data IncList a = Emp 39: | ( :< ) { hd :: a , tl :: IncList a } 40: 41: infixr 9 :< Next, we refine the type to specify that each \"cons\" :< constructor takes as input a hd and a tl which must be an IncList a of values v each of which is greater than hd . 50: {-@ data IncList a = Emp 51: | ( :< ) { hd :: a , tl :: IncList { v : a | hd <= v } } 52: @-} We can confirm that the above definition ensures that the only legal values are increasingly ordered lists, as LH accepts the first list below, but rejects the second where the elements are out of order. 61: legalList :: IncList Int 62: (PolymorphicPerplexion.IncList GHC.Types.Int) legalList = GHC.Types.Int 0 :< GHC.Types.Int 1 :< GHC.Types.Int 2 :< GHC.Types.Int 3 :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 63: 64: illegalList :: IncList Int 65: (PolymorphicPerplexion.IncList GHC.Types.Int) illegalList = GHC.Types.Int 0 :< GHC.Types.Int 1 :< GHC.Types.Int 3 :< GHC.Types.Int 2 :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp A Polymorphic Insertion Sort \u00b6 Next, lets write a simple insertion-sort function that takes a plain unordered list of [a] and returns the elements in increasing order: 76: insertSortP :: ( Ord a ) => [ a ] -> IncList a 77: forall a . (GHC.Classes.Ord<[]> a) => [a] -> (PolymorphicPerplexion.IncList a) insertSortP [a] xs = foldr a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) insertP {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp {v : [a] | len v >= 0 && v == xs} xs 78: 79: insertP :: ( Ord a ) => a -> IncList a -> IncList a 80: forall a . (GHC.Classes.Ord<[]> a) => a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) insertP a y Emp = {VV : a | VV == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 81: insertP y ( x :< xs ) 82: | {VV : a | VV == y} y <= {VV : a | VV == x} x = {VV : a | VV == y} y :< {VV : a | VV == x} x :< {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs 83: | otherwise = {VV : a | VV == x} x :< (PolymorphicPerplexion.IncList a) insertP {VV : a | VV == y} y {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs Happily, LH is able to verify the above code without any trouble! (If that seemed too easy, don't worry: if you mess up the comparison, e.g. change the guard to x <= y LH will complain about it.) A Monomorphic Insertion Sort \u00b6 However, lets take the exact same code as above but change the type signatures to make the functions monomorphic , here, specialized to Int lists. 99: insertSortM :: [ Int ] -> IncList Int 100: [GHC.Types.Int] -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertSortM [GHC.Types.Int] xs = foldr GHC.Types.Int -> (PolymorphicPerplexion.IncList GHC.Types.Int) -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertM {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp {v : [GHC.Types.Int] | len v >= 0 && v == xs} xs 101: 102: insertM :: Int -> IncList Int -> IncList Int 103: GHC.Types.Int -> (PolymorphicPerplexion.IncList GHC.Types.Int) -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertM GHC.Types.Int y Emp = {v : GHC.Types.Int | v == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 104: insertM y ( x :< xs ) 105: | {v : GHC.Types.Int | v == y} y <= {v : GHC.Types.Int | v == x} x = {v : GHC.Types.Int | v == y} y :< {v : GHC.Types.Int | v == x} x :< {v : (PolymorphicPerplexion.IncList {v : GHC.Types.Int | x <= v}) | v == xs} xs 106: | otherwise = {v : GHC.Types.Int | v == x} x :< (PolymorphicPerplexion.IncList GHC.Types.Int) insertM {v : GHC.Types.Int | v == y} y {v : (PolymorphicPerplexion.IncList {v : GHC.Types.Int | x <= v}) | v == xs} xs Huh? Now LH appears to be unhappy with the code! How is this possible? Lets look at the type error: 114: / Users / rjhala / PerplexingPolymorphicProperties.lhs : 80 : 27 - 38 : Error : Liquid Type Mismatch 115: 116: 80 | | otherwise = x :< insertM y xs 117: ^^^^^^^^^^^^ 118: Inferred type 119: VV : Int 120: 121: not a subtype of Required type 122: VV : { VV : Int | x <= VV } 123: 124: In Context 125: x : Int LH expects that since we're using the \"cons\" operator :< the \"tail\" value insertM y xs must contain values VV that are greater than the \"head\" x . The error says that, LH cannot prove this requirement of actual list insertM y xs . Hmm, well thats a puzzler. Two questions that should come to mind. Why does the above fact hold in the first place? How is LH able to deduce this fact with the polymorphic signature but not the monomorphic one? Lets ponder the first question: why is every element of insert y xs in fact larger than x ? For three reasons: (a) every element in xs is larger than x , as the list x :< xs was ordered, (b) y is larger than x as established by the otherwise and crucially (c) the elements returned by insert y xs are either y or from xs ! Now onto the second question: how does LH verify the polymorphic code, but not the monomorphic one? The reason is the fact (c)! LH is a modular verifier, meaning that the only information that it has about the behavior of insert at a call-site is the information captured in the (refinement) type specification for insert . The polymorphic signature: 156: insertP :: ( Ord a ) => a -> IncList a -> IncList a via parametricity , implicitly states fact (c). That is, if at a call-site insertP y xs we pass in a value that is greater an x and a list of values greater than x then via polymorphic instantiation at the call-site, LH infers that the returned value must also be a list of elements greater than x ! However, the monomorphic signature 167: insertM :: Int -> IncList Int -> IncList Int offers no such insight. It simply says the function takes in an Int and another ordered list of Int and returns another ordered list, whose actual elements could be arbitrary Int . Specifically, at the call-site insertP y xs LH has no way to conclude the the returned elements are indeed greater than x and hence rejects the monomorphic code. Perplexity \u00b6 While parametricity is all very nice, and LH's polymorphic instanatiation is very clever and useful, it can also be quite mysterious. For example, q curious user Ois\u00edn pointed out that while the code below is rejected that if you uncomment the type signature for go then it is accepted by LH! 187: insertSortP' :: ( Ord a ) => [ a ] -> IncList a 188: forall a . (GHC.Classes.Ord<[]> a) => [a] -> (PolymorphicPerplexion.IncList a) insertSortP' = (PolymorphicPerplexion.IncList a) foldr a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) go {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 189: where 190: -- go :: (Ord a) => a -> IncList a -> IncList a 191: a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) go a y Emp = {VV : a | VV == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 192: go y ( x :< xs ) 193: | {VV : a | VV == y} y <= {VV : a | VV == x} x = {VV : a | VV == y} y :< {VV : a | VV == x} x :< {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs 194: | otherwise = {VV : a | VV == x} x :< (PolymorphicPerplexion.IncList a) go {VV : a | VV == y} y {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs This is thoroughly perplexing, but again, is explained by the absence of parametricity. When we remove the type signature, GHC defaults to giving go a monomorphic signature where the a is not universally quantified, and which roughly captures the same specification as the monomorphic insertM above causing verification to fail! Restoring the signature provides LH with the polymorphic specification, which can be instantiated at the call-site to recover the fact (c) that is crucial for verification. Moral \u00b6 I hope that example illustrates two points. First, parametric polymorphism lets type specifications say a lot more than they immediately let on: so do write polymorphic signatures whenever possible. Second, on a less happy note, explaining why fancy type checkers fail remains a vexing problem, whose difficulty is compounded by increasing the cleverness of the type system. We'd love to hear any ideas you might have to solve the explanation problem!","title":"Polymorphic Perplexion"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/#a-type-for-ordered-lists","text":"Previously we have seen how you can use LH to define a type of lists whose values are in increasing (ok, non-decreasing!) order. First, we define an IncList a type, with Emp (\"empty\") and :< (\"cons\") constructors. 38: data IncList a = Emp 39: | ( :< ) { hd :: a , tl :: IncList a } 40: 41: infixr 9 :< Next, we refine the type to specify that each \"cons\" :< constructor takes as input a hd and a tl which must be an IncList a of values v each of which is greater than hd . 50: {-@ data IncList a = Emp 51: | ( :< ) { hd :: a , tl :: IncList { v : a | hd <= v } } 52: @-} We can confirm that the above definition ensures that the only legal values are increasingly ordered lists, as LH accepts the first list below, but rejects the second where the elements are out of order. 61: legalList :: IncList Int 62: (PolymorphicPerplexion.IncList GHC.Types.Int) legalList = GHC.Types.Int 0 :< GHC.Types.Int 1 :< GHC.Types.Int 2 :< GHC.Types.Int 3 :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 63: 64: illegalList :: IncList Int 65: (PolymorphicPerplexion.IncList GHC.Types.Int) illegalList = GHC.Types.Int 0 :< GHC.Types.Int 1 :< GHC.Types.Int 3 :< GHC.Types.Int 2 :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp","title":"A Type for Ordered Lists"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/#a-polymorphic-insertion-sort","text":"Next, lets write a simple insertion-sort function that takes a plain unordered list of [a] and returns the elements in increasing order: 76: insertSortP :: ( Ord a ) => [ a ] -> IncList a 77: forall a . (GHC.Classes.Ord<[]> a) => [a] -> (PolymorphicPerplexion.IncList a) insertSortP [a] xs = foldr a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) insertP {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp {v : [a] | len v >= 0 && v == xs} xs 78: 79: insertP :: ( Ord a ) => a -> IncList a -> IncList a 80: forall a . (GHC.Classes.Ord<[]> a) => a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) insertP a y Emp = {VV : a | VV == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 81: insertP y ( x :< xs ) 82: | {VV : a | VV == y} y <= {VV : a | VV == x} x = {VV : a | VV == y} y :< {VV : a | VV == x} x :< {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs 83: | otherwise = {VV : a | VV == x} x :< (PolymorphicPerplexion.IncList a) insertP {VV : a | VV == y} y {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs Happily, LH is able to verify the above code without any trouble! (If that seemed too easy, don't worry: if you mess up the comparison, e.g. change the guard to x <= y LH will complain about it.)","title":"A Polymorphic Insertion Sort"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/#a-monomorphic-insertion-sort","text":"However, lets take the exact same code as above but change the type signatures to make the functions monomorphic , here, specialized to Int lists. 99: insertSortM :: [ Int ] -> IncList Int 100: [GHC.Types.Int] -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertSortM [GHC.Types.Int] xs = foldr GHC.Types.Int -> (PolymorphicPerplexion.IncList GHC.Types.Int) -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertM {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp {v : [GHC.Types.Int] | len v >= 0 && v == xs} xs 101: 102: insertM :: Int -> IncList Int -> IncList Int 103: GHC.Types.Int -> (PolymorphicPerplexion.IncList GHC.Types.Int) -> (PolymorphicPerplexion.IncList GHC.Types.Int) insertM GHC.Types.Int y Emp = {v : GHC.Types.Int | v == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 104: insertM y ( x :< xs ) 105: | {v : GHC.Types.Int | v == y} y <= {v : GHC.Types.Int | v == x} x = {v : GHC.Types.Int | v == y} y :< {v : GHC.Types.Int | v == x} x :< {v : (PolymorphicPerplexion.IncList {v : GHC.Types.Int | x <= v}) | v == xs} xs 106: | otherwise = {v : GHC.Types.Int | v == x} x :< (PolymorphicPerplexion.IncList GHC.Types.Int) insertM {v : GHC.Types.Int | v == y} y {v : (PolymorphicPerplexion.IncList {v : GHC.Types.Int | x <= v}) | v == xs} xs Huh? Now LH appears to be unhappy with the code! How is this possible? Lets look at the type error: 114: / Users / rjhala / PerplexingPolymorphicProperties.lhs : 80 : 27 - 38 : Error : Liquid Type Mismatch 115: 116: 80 | | otherwise = x :< insertM y xs 117: ^^^^^^^^^^^^ 118: Inferred type 119: VV : Int 120: 121: not a subtype of Required type 122: VV : { VV : Int | x <= VV } 123: 124: In Context 125: x : Int LH expects that since we're using the \"cons\" operator :< the \"tail\" value insertM y xs must contain values VV that are greater than the \"head\" x . The error says that, LH cannot prove this requirement of actual list insertM y xs . Hmm, well thats a puzzler. Two questions that should come to mind. Why does the above fact hold in the first place? How is LH able to deduce this fact with the polymorphic signature but not the monomorphic one? Lets ponder the first question: why is every element of insert y xs in fact larger than x ? For three reasons: (a) every element in xs is larger than x , as the list x :< xs was ordered, (b) y is larger than x as established by the otherwise and crucially (c) the elements returned by insert y xs are either y or from xs ! Now onto the second question: how does LH verify the polymorphic code, but not the monomorphic one? The reason is the fact (c)! LH is a modular verifier, meaning that the only information that it has about the behavior of insert at a call-site is the information captured in the (refinement) type specification for insert . The polymorphic signature: 156: insertP :: ( Ord a ) => a -> IncList a -> IncList a via parametricity , implicitly states fact (c). That is, if at a call-site insertP y xs we pass in a value that is greater an x and a list of values greater than x then via polymorphic instantiation at the call-site, LH infers that the returned value must also be a list of elements greater than x ! However, the monomorphic signature 167: insertM :: Int -> IncList Int -> IncList Int offers no such insight. It simply says the function takes in an Int and another ordered list of Int and returns another ordered list, whose actual elements could be arbitrary Int . Specifically, at the call-site insertP y xs LH has no way to conclude the the returned elements are indeed greater than x and hence rejects the monomorphic code.","title":"A Monomorphic Insertion Sort"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/#perplexity","text":"While parametricity is all very nice, and LH's polymorphic instanatiation is very clever and useful, it can also be quite mysterious. For example, q curious user Ois\u00edn pointed out that while the code below is rejected that if you uncomment the type signature for go then it is accepted by LH! 187: insertSortP' :: ( Ord a ) => [ a ] -> IncList a 188: forall a . (GHC.Classes.Ord<[]> a) => [a] -> (PolymorphicPerplexion.IncList a) insertSortP' = (PolymorphicPerplexion.IncList a) foldr a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) go {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 189: where 190: -- go :: (Ord a) => a -> IncList a -> IncList a 191: a -> (PolymorphicPerplexion.IncList a) -> (PolymorphicPerplexion.IncList a) go a y Emp = {VV : a | VV == y} y :< {VV : forall a . (PolymorphicPerplexion.IncList a) | VV == Emp} Emp 192: go y ( x :< xs ) 193: | {VV : a | VV == y} y <= {VV : a | VV == x} x = {VV : a | VV == y} y :< {VV : a | VV == x} x :< {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs 194: | otherwise = {VV : a | VV == x} x :< (PolymorphicPerplexion.IncList a) go {VV : a | VV == y} y {v : (PolymorphicPerplexion.IncList {VV : a | x <= VV}) | v == xs} xs This is thoroughly perplexing, but again, is explained by the absence of parametricity. When we remove the type signature, GHC defaults to giving go a monomorphic signature where the a is not universally quantified, and which roughly captures the same specification as the monomorphic insertM above causing verification to fail! Restoring the signature provides LH with the polymorphic specification, which can be instantiated at the call-site to recover the fact (c) that is crucial for verification.","title":"Perplexity"},{"location":"blogposts/2020-04-12-polymorphic-perplexion.lhs/#moral","text":"I hope that example illustrates two points. First, parametric polymorphism lets type specifications say a lot more than they immediately let on: so do write polymorphic signatures whenever possible. Second, on a less happy note, explaining why fancy type checkers fail remains a vexing problem, whose difficulty is compounded by increasing the cleverness of the type system. We'd love to hear any ideas you might have to solve the explanation problem!","title":"Moral"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/","text":"\\begin{code} module Plugin where incr :: Int -> Int incr x = x + 1 \\end{code} I enjoy working with LH. However, I'd be the very first to confess that it has been incredibly tedious to get to work on existing code bases, for various reasons. LH ran one file at a time ; it was a hassle to systematically analyze all the modules in a single package. LH had no notion of packages ; it was impossible to import specifications across packages. LH had no integration with the standard compilation cycle; it was difficult to get robust, development-time feedback using ghci based tools. I'm delighted to announce the release of LH version 0.8.10.2 . Thanks to the ingenuity and tireless efforts of our friends Alfredo Di Napoli and Andres Loh at Well-Typed this new version solves all three of the above problems in a single stroke, making it vastly simpler (dare I say, quite straightforward!) to run LH on your Haskell code. Alfredo and Andres' key insight was that all the above problems could be solved if LH could be re-engineered as a GHC Compiler Plugin using hooks that GHC exposes to integrate external checkers during compilation. I strongly encourage you to check out Alfredo's talk at the Haskell Implementor's Workshop if you want to learn more about the rather non-trivial mechanics of how this plugin was engineered. However, in this post, lets look at how and why to use the plugin, in particular, how the plugin lets us Use GHC's dependency resolution to analyze entire packages with minimal recompilation; Ship refined type specifications for old or new packages, and have them be verified at client code; Use tools like ghci based IDE tooling (e.g. ghcid or ghcide to get interactive feedback), all of which ultimately, I hope, make Liquid Haskell easier to use. 1. Analyzing Packages \u00b6 First, lets see a small \"demo\" of how to use the plugin to compile a small lh-plugin-demo package with two modules module Demo.Lib where {-@ type Pos = {v:Int | 0 < v} @-} {-@ incr :: Pos -> Pos @-} incr :: Int -> Int incr x = x - 1 which defines a function incr that consumes and returns positive integers, and module Demo.Client where import Demo.Lib bump :: Int -> Int bump n = incr n which imports Demo.Lib and uses incr . Updating .cabal to compile with the LH plugin \u00b6 To \"check\" this code with LH we need only tell GHC to use it as a plugin, in two steps. First, adding a dependency to LH in the .cabal file (or package.yaml ) build-depends: liquid-base, liquidhaskell >= 0.8.10 Second, tell GHC to use the plugin ghc-options: -fplugin=LiquidHaskell That's it. Now, everytime you (re-)build the code, GHC will automatically run LH on the changed modules! If you use stack you may have to specify a few more dependencies, as the various packages are not (yet) on stackage, as shown in the demo stack.yaml . No extra dependencies are needede if you use cabal-v2 . In both cases, you can use the respective files stack.yaml and cabal.project point to specific git snapshots if you want to use the most recent versions. If you clone the repo and run, e.g. cabal v2-build or stack build you'll get the following result, after the relevant dependencies are downloaded and built of course... rjhala@khao-soi ~/r/lh-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [1 of 2] Compiling Demo.Lib **** LIQUID: UNSAFE ************************************************************ /Users/rjhala/research/lh-demo/src/Demo/Lib.hs:7:1: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == x - 1} . is not a subtype of the required type VV : {VV : GHC.Types.Int | 0 < VV} . in the context x : {v : GHC.Types.Int | 0 < v} | 7 | incr x = x - 1 | ^^^^^^^^^^^^^^ oops, of course that (-) should be a (+) if we want the output to also be positive so lets edit the code to incr x = x + 1 and now we get rjhala@khao-soi ~/r/lh-plugin-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [1 of 2] Compiling Demo.Lib **** LIQUID: SAFE (2 constraints checked) ***************************** [2 of 2] Compiling Demo.Client **** LIQUID: UNSAFE *************************************************** /Users/rjhala/lh-plugin-demo/src/Demo/Client.hs:6:15: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == n} . is not a subtype of the required type VV : {VV : GHC.Types.Int | 0 < VV} . in the context n : GHC.Types.Int | 6 | bump n = incr n | ^ That is, during the build, LH complains that incr is being called with a value n that is not strictly positive as required by incr . To fix the code, we can edit it in various ways, e.g. to only call incr if n > 0 bump n | n > 0 = incr n | otherwise = 0 and now the code builds successfully rjhala@khao-soi ~/r/lh-plugin-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [2 of 2] Compiling Demo.Client **** LIQUID: SAFE (2 constraints checked) **************************** lh-plugin-demo> copy/register Installing library in ... Registering library for lh-plugin-demo-0.1.0.0.. Benefits \u00b6 There are a couple of benefits to note immediately A plain stack build or cabal v2-build takes care of all the installing and checking! No need to separately install LH; its part of the regular build. GHC's recompilation machinery ensures that only the relevant modules are checked, e.g. the second time round, LH did not need to analyze Lib.hs only Client.hs 2. Shipping Specifications with Packages \u00b6 While the above is nice, in principle it could have been done with some clever makefile trickery (perhaps?). What I'm much more excited about is that now, for the first time, you can ship refinement type specifications within plain Haskell packages . For example, consider a different lh-plugin-demo-client package that uses incr from lh-plugin-demo : bump :: Int -> Int bump n | n > 0 = incr n | otherwise = incr (0 - n) Again, the lh-plugin-demo-client.cabal file need only specify the various dependencies: build-depends: liquid-base, liquidhaskell, lh-plugin-demo ```` and that GHC should use the plugin ghc-options: -fplugin=LiquidHaskell and lo! a plain `stack build` or `cabal v2-build` takes care of all the rest. rjhala@khao-soi ~/r/lh-plugin-demo-client (main)> stack build lh-plugin-demo-client> configure (lib) Configuring lh-plugin-demo-client-0.1.0.0... lh-plugin-demo-client> build (lib) Preprocessing library for lh-plugin-demo-client-0.1.0.0.. Building library for lh-plugin-demo-client-0.1.0.0.. [1 of 1] Compiling Demo.ExternalClient * LIQUID: UNSAFE * * * * * * * /Users/rjhala/lh-plugin-demo-client/src/Demo/ExternalClient.hs:8:22: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == 0 - n} . is not a subtype of the required type VV : {VV : GHC.Types.Int | VV > 0} . in the context n : GHC.Types.Int | 8 | | otherwise = incr (0 - n) | ^^^^^^^ (Whoops another off by one error, lets fix it!) ```haskell bump :: Int -> Int bump n | n > 0 = incr n | otherwise = incr (1 - n) and now all is well rjhala@khao-soi ~/r/lh-plugin-demo-client (main)> stack build --fast lh-plugin-demo-client> configure (lib) Configuring lh-plugin-demo-client-0.1.0.0... lh-plugin-demo-client> build (lib) Preprocessing library for lh-plugin-demo-client-0.1.0.0.. Building library for lh-plugin-demo-client-0.1.0.0.. [1 of 1] Compiling Demo.ExternalClient **** LIQUID: SAFE (3 constraints checked) ***************************** lh-plugin-demo-client> copy/register Installing library in ... Registering library for lh-plugin-demo-client-0.1.0.0.. Prelude Specifications \u00b6 Did you notice the strange liquid-base dependency in the cabal files? Previously, LH came installed with a \"built-in\" set of specifications for various prelude modules. This was hacked inside LH in a rather unfortunate manner, which made these specifications very difficult to extend. Moving forward, all the refinement specifications e.g. for GHC.List or Data.Vector or Data.Set or Data.Bytestring simply live in packages that mirror the original versions, e.g. liquid-base , liquid-vector , liquid-containers , liquid-bytestring . Each liquid-X package directly re-exports all the contents of the corresponding X package, but with any additional refinement type specifications. Thus, all the refined types for various prelude operations like (+) or (-) or head and so on, now ship with liquid-base and we add that dependency instead of base. Similarly, if you want to verify that your code has no vector -index overflow errors, you simply build with liquid-vector instead of vector ! Of course, in an ideal, and hopefully not too distant future, we'd directly include the refinement types inside vector , containers or bytestring respectively. Benefits \u00b6 So to recap, the plugin offers several nice benefits with respect to shipping specifications Refined signatures are bundled together with packages, Importing packages with refined signatures automatically ensures those signatures are checked on client code, You can (optionally) use refined versions of prelude signatures, and hence, even write refined versions of your favorite custom preludes . 3. Editor Tooling \u00b6 I saved my favorite part for the end. What I have enjoyed the most about the plugin is that now (almost) all the GHC-based tools that I use in my regular Haskell development workflow, automatically incorporate LH too! For example, reloading a module in ghci automatically re-runs LH on that file. ghcid \u00b6 This means, that the mega robust, editor-independent ghcid now automatically produces LH type errors when you save a file. Here's ghcid running in a terminal. vscode \u00b6 Editor plugins now produce little red squiggles for LH errors too. Here's code with the Simple GHC (Haskell) Integration plugin emacs \u00b6 Here's doom-emacs with the dante plugin vim \u00b6 And here is neovim with ALE and the stack-build linter Benefits \u00b6 Some of this was possible before: we had to write special LH modes for different editors -- special thanks to Alan Zimmerman's fantastic haskell-ide-engine!. However, now we can simply work with the increasingly more robust GHCi and Language-Server based tools already available for major editors and IDEs. 4. Caveats \u00b6 Of course, all the above is quite new, and so there are a few things to watch out for. First, for certain kinds of code, LH can take much longer than GHC to check a file. This means, it may actually be too slow to run on every save, and you may want to tweak your .cabal file to only run the plugin during particular builds, not on every file update. Second, the liquid-X machinery is designed to allow drop in replacements for various base packages; it appears to work well in our testing, but if you try it, do let us know if you hit some odd problems that we may not have anticipated. Summary \u00b6 Hopefully the above provides an overview of the new plugin mode: how it can be used, and what things it enables. In particular, by virtue of being a GHC plugin, LH can now Run on entire Haskell packages; Export and import specifications across packages; Provide errors via existing GHC/i based editor tooling. All of which, I hope, makes it a lot easier to run LH on your code. Our most profound thanks to the National Science Foundation : this work was made possible by the support provided by grant 1917854: \"FMitF: Track II: Refinement Types in the Haskell Ecosystem\".","title":"LiquidHaskell is a GHC Plugin"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#1-analyzing-packages","text":"First, lets see a small \"demo\" of how to use the plugin to compile a small lh-plugin-demo package with two modules module Demo.Lib where {-@ type Pos = {v:Int | 0 < v} @-} {-@ incr :: Pos -> Pos @-} incr :: Int -> Int incr x = x - 1 which defines a function incr that consumes and returns positive integers, and module Demo.Client where import Demo.Lib bump :: Int -> Int bump n = incr n which imports Demo.Lib and uses incr .","title":"1. Analyzing Packages"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#updating-cabal-to-compile-with-the-lh-plugin","text":"To \"check\" this code with LH we need only tell GHC to use it as a plugin, in two steps. First, adding a dependency to LH in the .cabal file (or package.yaml ) build-depends: liquid-base, liquidhaskell >= 0.8.10 Second, tell GHC to use the plugin ghc-options: -fplugin=LiquidHaskell That's it. Now, everytime you (re-)build the code, GHC will automatically run LH on the changed modules! If you use stack you may have to specify a few more dependencies, as the various packages are not (yet) on stackage, as shown in the demo stack.yaml . No extra dependencies are needede if you use cabal-v2 . In both cases, you can use the respective files stack.yaml and cabal.project point to specific git snapshots if you want to use the most recent versions. If you clone the repo and run, e.g. cabal v2-build or stack build you'll get the following result, after the relevant dependencies are downloaded and built of course... rjhala@khao-soi ~/r/lh-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [1 of 2] Compiling Demo.Lib **** LIQUID: UNSAFE ************************************************************ /Users/rjhala/research/lh-demo/src/Demo/Lib.hs:7:1: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == x - 1} . is not a subtype of the required type VV : {VV : GHC.Types.Int | 0 < VV} . in the context x : {v : GHC.Types.Int | 0 < v} | 7 | incr x = x - 1 | ^^^^^^^^^^^^^^ oops, of course that (-) should be a (+) if we want the output to also be positive so lets edit the code to incr x = x + 1 and now we get rjhala@khao-soi ~/r/lh-plugin-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [1 of 2] Compiling Demo.Lib **** LIQUID: SAFE (2 constraints checked) ***************************** [2 of 2] Compiling Demo.Client **** LIQUID: UNSAFE *************************************************** /Users/rjhala/lh-plugin-demo/src/Demo/Client.hs:6:15: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == n} . is not a subtype of the required type VV : {VV : GHC.Types.Int | 0 < VV} . in the context n : GHC.Types.Int | 6 | bump n = incr n | ^ That is, during the build, LH complains that incr is being called with a value n that is not strictly positive as required by incr . To fix the code, we can edit it in various ways, e.g. to only call incr if n > 0 bump n | n > 0 = incr n | otherwise = 0 and now the code builds successfully rjhala@khao-soi ~/r/lh-plugin-demo (main)> stack build lh-plugin-demo> configure (lib) Configuring lh-plugin-demo-0.1.0.0... lh-plugin-demo> build (lib) Preprocessing library for lh-plugin-demo-0.1.0.0.. Building library for lh-plugin-demo-0.1.0.0.. [2 of 2] Compiling Demo.Client **** LIQUID: SAFE (2 constraints checked) **************************** lh-plugin-demo> copy/register Installing library in ... Registering library for lh-plugin-demo-0.1.0.0..","title":"Updating .cabal to compile with the LH plugin"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#benefits","text":"There are a couple of benefits to note immediately A plain stack build or cabal v2-build takes care of all the installing and checking! No need to separately install LH; its part of the regular build. GHC's recompilation machinery ensures that only the relevant modules are checked, e.g. the second time round, LH did not need to analyze Lib.hs only Client.hs","title":"Benefits"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#2-shipping-specifications-with-packages","text":"While the above is nice, in principle it could have been done with some clever makefile trickery (perhaps?). What I'm much more excited about is that now, for the first time, you can ship refinement type specifications within plain Haskell packages . For example, consider a different lh-plugin-demo-client package that uses incr from lh-plugin-demo : bump :: Int -> Int bump n | n > 0 = incr n | otherwise = incr (0 - n) Again, the lh-plugin-demo-client.cabal file need only specify the various dependencies: build-depends: liquid-base, liquidhaskell, lh-plugin-demo ```` and that GHC should use the plugin ghc-options: -fplugin=LiquidHaskell and lo! a plain `stack build` or `cabal v2-build` takes care of all the rest. rjhala@khao-soi ~/r/lh-plugin-demo-client (main)> stack build lh-plugin-demo-client> configure (lib) Configuring lh-plugin-demo-client-0.1.0.0... lh-plugin-demo-client> build (lib) Preprocessing library for lh-plugin-demo-client-0.1.0.0.. Building library for lh-plugin-demo-client-0.1.0.0.. [1 of 1] Compiling Demo.ExternalClient * LIQUID: UNSAFE * * * * * * * /Users/rjhala/lh-plugin-demo-client/src/Demo/ExternalClient.hs:8:22: error: Liquid Type Mismatch . The inferred type VV : {v : GHC.Types.Int | v == 0 - n} . is not a subtype of the required type VV : {VV : GHC.Types.Int | VV > 0} . in the context n : GHC.Types.Int | 8 | | otherwise = incr (0 - n) | ^^^^^^^ (Whoops another off by one error, lets fix it!) ```haskell bump :: Int -> Int bump n | n > 0 = incr n | otherwise = incr (1 - n) and now all is well rjhala@khao-soi ~/r/lh-plugin-demo-client (main)> stack build --fast lh-plugin-demo-client> configure (lib) Configuring lh-plugin-demo-client-0.1.0.0... lh-plugin-demo-client> build (lib) Preprocessing library for lh-plugin-demo-client-0.1.0.0.. Building library for lh-plugin-demo-client-0.1.0.0.. [1 of 1] Compiling Demo.ExternalClient **** LIQUID: SAFE (3 constraints checked) ***************************** lh-plugin-demo-client> copy/register Installing library in ... Registering library for lh-plugin-demo-client-0.1.0.0..","title":"2. Shipping Specifications with Packages"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#prelude-specifications","text":"Did you notice the strange liquid-base dependency in the cabal files? Previously, LH came installed with a \"built-in\" set of specifications for various prelude modules. This was hacked inside LH in a rather unfortunate manner, which made these specifications very difficult to extend. Moving forward, all the refinement specifications e.g. for GHC.List or Data.Vector or Data.Set or Data.Bytestring simply live in packages that mirror the original versions, e.g. liquid-base , liquid-vector , liquid-containers , liquid-bytestring . Each liquid-X package directly re-exports all the contents of the corresponding X package, but with any additional refinement type specifications. Thus, all the refined types for various prelude operations like (+) or (-) or head and so on, now ship with liquid-base and we add that dependency instead of base. Similarly, if you want to verify that your code has no vector -index overflow errors, you simply build with liquid-vector instead of vector ! Of course, in an ideal, and hopefully not too distant future, we'd directly include the refinement types inside vector , containers or bytestring respectively.","title":"Prelude Specifications"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#benefits_1","text":"So to recap, the plugin offers several nice benefits with respect to shipping specifications Refined signatures are bundled together with packages, Importing packages with refined signatures automatically ensures those signatures are checked on client code, You can (optionally) use refined versions of prelude signatures, and hence, even write refined versions of your favorite custom preludes .","title":"Benefits"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#3-editor-tooling","text":"I saved my favorite part for the end. What I have enjoyed the most about the plugin is that now (almost) all the GHC-based tools that I use in my regular Haskell development workflow, automatically incorporate LH too! For example, reloading a module in ghci automatically re-runs LH on that file.","title":"3. Editor Tooling"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#ghcid","text":"This means, that the mega robust, editor-independent ghcid now automatically produces LH type errors when you save a file. Here's ghcid running in a terminal.","title":"ghcid"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#vscode","text":"Editor plugins now produce little red squiggles for LH errors too. Here's code with the Simple GHC (Haskell) Integration plugin","title":"vscode"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#emacs","text":"Here's doom-emacs with the dante plugin","title":"emacs"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#vim","text":"And here is neovim with ALE and the stack-build linter","title":"vim"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#benefits_2","text":"Some of this was possible before: we had to write special LH modes for different editors -- special thanks to Alan Zimmerman's fantastic haskell-ide-engine!. However, now we can simply work with the increasingly more robust GHCi and Language-Server based tools already available for major editors and IDEs.","title":"Benefits"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#4-caveats","text":"Of course, all the above is quite new, and so there are a few things to watch out for. First, for certain kinds of code, LH can take much longer than GHC to check a file. This means, it may actually be too slow to run on every save, and you may want to tweak your .cabal file to only run the plugin during particular builds, not on every file update. Second, the liquid-X machinery is designed to allow drop in replacements for various base packages; it appears to work well in our testing, but if you try it, do let us know if you hit some odd problems that we may not have anticipated.","title":"4. Caveats"},{"location":"blogposts/2020-08-20-lh-as-a-ghc-plugin.lhs/#summary","text":"Hopefully the above provides an overview of the new plugin mode: how it can be used, and what things it enables. In particular, by virtue of being a GHC plugin, LH can now Run on entire Haskell packages; Export and import specifications across packages; Provide errors via existing GHC/i based editor tooling. All of which, I hope, makes it a lot easier to run LH on your code. Our most profound thanks to the National Science Foundation : this work was made possible by the support provided by grant 1917854: \"FMitF: Track II: Refinement Types in the Haskell Ecosystem\".","title":"Summary"},{"location":"tags.html","text":"Contents grouped by tag \u00b6 abstract-refinements \u00b6 Abstracting Over Refinements Putting Things In Order A Finer Filter Splitting and Splicing Intervals (Part 1) Splitting and Splicing Intervals (Part 2) advanced \u00b6 Measures and Case Splitting basic \u00b6 Refinement Types 101 Refinements 101 (contd.) Bounding Vectors KMeans Clustering I KMeans Clustering II Bounding Vectors Talking About Sets Unique Zippers The Advantage of Measures Arithmetic Overflows Liquid Types vs. Floyd-Hoare Logic Polymorphic Perplexion LiquidHaskell is a GHC Plugin benchmarks \u00b6 Pointers Gone Wild induction \u00b6 Refinement Reflection on ADTs measures \u00b6 Safely Catching A List By Its Tail KMeans Clustering I KMeans Clustering II Talking About Sets Unique Zippers CSV Tables The Advantage of Measures Okasaki's Lazy Queues Normal Forms Refinement Reflection on ADTs Measures and Case Splitting reflection \u00b6 Haskell as a Theorem Prover Refinement Reflection on ADTs Splitting and Splicing Intervals (Part 1) Splitting and Splicing Intervals (Part 2) The Hillelogram Verifier Rodeo I (LeftPad) sets \u00b6 Talking About Sets Unique Zippers termination \u00b6 LiquidHaskell Caught Telling Lies! Getting To the Bottom Checking Termination Termination Requires Refinements text \u00b6 Pointers Gone Wild uniqueness \u00b6 Unique Zippers","title":"Tags"},{"location":"tags.html#contents-grouped-by-tag","text":"","title":"Contents grouped by tag"},{"location":"tags.html#abstract-refinements","text":"Abstracting Over Refinements Putting Things In Order A Finer Filter Splitting and Splicing Intervals (Part 1) Splitting and Splicing Intervals (Part 2)","title":"abstract-refinements"},{"location":"tags.html#advanced","text":"Measures and Case Splitting","title":"advanced"},{"location":"tags.html#basic","text":"Refinement Types 101 Refinements 101 (contd.) Bounding Vectors KMeans Clustering I KMeans Clustering II Bounding Vectors Talking About Sets Unique Zippers The Advantage of Measures Arithmetic Overflows Liquid Types vs. Floyd-Hoare Logic Polymorphic Perplexion LiquidHaskell is a GHC Plugin","title":"basic"},{"location":"tags.html#benchmarks","text":"Pointers Gone Wild","title":"benchmarks"},{"location":"tags.html#induction","text":"Refinement Reflection on ADTs","title":"induction"},{"location":"tags.html#measures","text":"Safely Catching A List By Its Tail KMeans Clustering I KMeans Clustering II Talking About Sets Unique Zippers CSV Tables The Advantage of Measures Okasaki's Lazy Queues Normal Forms Refinement Reflection on ADTs Measures and Case Splitting","title":"measures"},{"location":"tags.html#reflection","text":"Haskell as a Theorem Prover Refinement Reflection on ADTs Splitting and Splicing Intervals (Part 1) Splitting and Splicing Intervals (Part 2) The Hillelogram Verifier Rodeo I (LeftPad)","title":"reflection"},{"location":"tags.html#sets","text":"Talking About Sets Unique Zippers","title":"sets"},{"location":"tags.html#termination","text":"LiquidHaskell Caught Telling Lies! Getting To the Bottom Checking Termination Termination Requires Refinements","title":"termination"},{"location":"tags.html#text","text":"Pointers Gone Wild","title":"text"},{"location":"tags.html#uniqueness","text":"Unique Zippers","title":"uniqueness"}]}